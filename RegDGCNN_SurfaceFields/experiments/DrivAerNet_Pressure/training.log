2025-06-21 03:46:32,397 - INFO - Arguments: Namespace(exp_name='DrivAerNet_Pressure', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data', num_points=10000, batch_size=12, epochs=150, lr=0.001, num_workers=4, test_only=False, gpus='0,1,2,3', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-21 03:46:32,414 - INFO - Starting training with 4 GPUs
2025-06-21 17:37:17,698 - INFO - Arguments: Namespace(exp_name='DrivAerNet_Pressure', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data', num_points=10000, batch_size=12, epochs=150, lr=0.001, num_workers=4, test_only=False, gpus='0,1,2,3', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-21 17:37:17,719 - INFO - Starting training with 4 GPUs
2025-06-22 10:24:22,222 - INFO - Arguments: Namespace(exp_name='DrivAerNet_Pressure', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data', num_points=10000, batch_size=12, epochs=150, lr=0.001, num_workers=4, test_only=False, gpus='0,1,2,3', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-22 10:24:22,253 - INFO - Starting training with 4 GPUs
2025-06-22 18:52:06,603 - INFO - Arguments: Namespace(exp_name='DrivAerNet_Pressure', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data', num_points=10000, batch_size=12, epochs=150, lr=0.001, num_workers=4, test_only=False, gpus='0,1,2,3', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-22 18:52:06,625 - INFO - Starting training with 4 GPUs
2025-06-27 15:18:29,664 - INFO - Arguments: Namespace(exp_name='DrivAerNet_Pressure', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data', num_points=10000, batch_size=12, epochs=150, lr=0.001, num_workers=4, test_only=False, gpus='0,1,2,3', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-27 15:18:29,686 - INFO - Starting training with 4 GPUs
2025-06-27 15:40:08,456 - INFO - Arguments: Namespace(exp_name='DrivAerNet_Pressure', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data', num_points=10000, batch_size=12, epochs=150, lr=0.001, num_workers=4, test_only=False, gpus='0,1,2,3', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-27 15:40:08,456 - INFO - Starting training with 4 GPUs
2025-06-30 17:07:19,787 - INFO - Arguments: Namespace(exp_name='DrivAerNet_Pressure', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data', num_points=10000, batch_size=12, epochs=150, lr=0.001, num_workers=1, test_only=False, gpus='0,1,2,3', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-30 17:07:19,806 - INFO - Starting training with 4 GPUs
2025-06-30 17:13:37,766 - INFO - args.exp_name : DrivAerNet_Pressure
2025-06-30 17:13:37,770 - INFO - Arguments: Namespace(exp_name='DrivAerNet_Pressure', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data', num_points=10000, batch_size=12, epochs=150, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-30 17:13:37,771 - INFO - Starting training with 1 GPUs
2025-06-30 17:13:41,362 - INFO - Total trainable parameters: 1437705
2025-06-30 17:13:41,549 - INFO - Data loaded: 19 training batches, 4 validation batches, 4 test batches
2025-06-30 17:13:41,555 - INFO - Staring training for 150 epochs
2025-06-30 17:14:40,968 - INFO - args.exp_name : DrivAerNet_Pressure
2025-06-30 17:14:40,972 - INFO - Arguments: Namespace(exp_name='DrivAerNet_Pressure', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data', num_points=10000, batch_size=8, epochs=150, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-30 17:14:40,972 - INFO - Starting training with 1 GPUs
2025-06-30 17:14:44,326 - INFO - Total trainable parameters: 1437705
2025-06-30 17:14:44,546 - INFO - Data loaded: 29 training batches, 6 validation batches, 6 test batches
2025-06-30 17:14:44,549 - INFO - Staring training for 150 epochs
2025-06-30 17:19:42,619 - INFO - Arguments: Namespace(exp_name='DrivAerNet_Pressure', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data', num_points=10000, batch_size=8, epochs=150, lr=0.001, num_workers=1, test_only=False, gpus='0,1,2,3', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-30 17:19:42,620 - INFO - Starting training with 4 GPUs
2025-06-30 17:28:11,615 - INFO - Arguments: Namespace(exp_name='DrivAerNet_Pressure', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data', num_points=10000, batch_size=8, epochs=150, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-30 17:28:11,620 - INFO - Starting training with 1 GPUs
2025-06-30 17:28:15,330 - INFO - Total trainable parameters: 1437705
2025-06-30 17:28:15,518 - INFO - Data loaded: 29 training batches, 6 validation batches, 6 test batches
2025-06-30 17:28:15,523 - INFO - Starting training for 150 epochs
2025-06-30 17:29:24,019 - INFO - Arguments: Namespace(exp_name='DrivAerNet_Pressure', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data', num_points=10000, batch_size=6, epochs=150, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-30 17:29:24,021 - INFO - Starting training with 1 GPUs
2025-06-30 17:29:28,186 - INFO - Total trainable parameters: 1437705
2025-06-30 17:29:28,356 - INFO - Data loaded: 39 training batches, 8 validation batches, 9 test batches
2025-06-30 17:29:28,357 - INFO - Starting training for 150 epochs
2025-06-30 17:30:25,234 - INFO - Arguments: Namespace(exp_name='DrivAerNet_Pressure', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data', num_points=10000, batch_size=12, epochs=150, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-30 17:30:25,238 - INFO - Starting training with 1 GPUs
2025-06-30 17:30:29,273 - INFO - Total trainable parameters: 1437705
2025-06-30 17:30:29,482 - INFO - Data loaded: 19 training batches, 4 validation batches, 4 test batches
2025-06-30 17:30:29,484 - INFO - Starting training for 150 epochs
2025-06-30 17:31:49,599 - INFO - Arguments: Namespace(exp_name='DrivAerNet_Pressure', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data', num_points=10000, batch_size=4, epochs=150, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-30 17:31:49,604 - INFO - Starting training with 1 GPUs
2025-06-30 17:31:53,666 - INFO - Total trainable parameters: 1437705
2025-06-30 17:31:53,846 - INFO - Data loaded: 59 training batches, 12 validation batches, 13 test batches
2025-06-30 17:31:53,848 - INFO - Starting training for 150 epochs
2025-06-30 17:34:15,126 - INFO - Arguments: Namespace(exp_name='DrivAerNet_Pressure', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data', num_points=10000, batch_size=2, epochs=150, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-30 17:34:15,130 - INFO - Starting training with 1 GPUs
2025-06-30 17:34:18,520 - INFO - Total trainable parameters: 1437705
2025-06-30 17:34:18,695 - INFO - Data loaded: 119 training batches, 24 validation batches, 27 test batches
2025-06-30 17:34:18,696 - INFO - Starting training for 150 epochs
2025-06-30 17:35:40,214 - INFO - Epoch 1/150 - Train Loss: 0.543953, Val Loss: 3.795130
2025-06-30 17:35:40,256 - INFO - New best model saved with Val Loss: 3.795130
2025-06-30 17:36:58,426 - INFO - Epoch 2/150 - Train Loss: 0.345594, Val Loss: 0.471570
2025-06-30 17:36:58,448 - INFO - New best model saved with Val Loss: 0.471570
2025-06-30 17:38:17,067 - INFO - Epoch 3/150 - Train Loss: 0.283871, Val Loss: 0.363579
2025-06-30 17:38:17,089 - INFO - New best model saved with Val Loss: 0.363579
2025-06-30 17:39:35,077 - INFO - Epoch 4/150 - Train Loss: 0.249932, Val Loss: 0.575976
2025-06-30 17:40:53,593 - INFO - Epoch 5/150 - Train Loss: 0.228832, Val Loss: 0.499856
2025-06-30 17:42:12,157 - INFO - Epoch 6/150 - Train Loss: 0.210904, Val Loss: 0.336948
2025-06-30 17:42:12,181 - INFO - New best model saved with Val Loss: 0.336948
2025-06-30 17:43:30,586 - INFO - Epoch 7/150 - Train Loss: 0.202382, Val Loss: 0.829431
2025-06-30 17:44:48,705 - INFO - Epoch 8/150 - Train Loss: 0.190956, Val Loss: 0.525066
2025-06-30 17:46:07,133 - INFO - Epoch 9/150 - Train Loss: 0.187145, Val Loss: 0.586910
2025-06-30 17:47:25,599 - INFO - Epoch 10/150 - Train Loss: 0.176726, Val Loss: 0.259141
2025-06-30 17:47:25,623 - INFO - New best model saved with Val Loss: 0.259141
2025-06-30 17:48:44,713 - INFO - Epoch 11/150 - Train Loss: 0.172931, Val Loss: 0.323481
2025-06-30 17:50:02,720 - INFO - Epoch 12/150 - Train Loss: 0.167064, Val Loss: 0.393280
2025-06-30 17:51:20,899 - INFO - Epoch 13/150 - Train Loss: 0.164235, Val Loss: 0.393084
2025-06-30 17:52:39,390 - INFO - Epoch 14/150 - Train Loss: 0.160399, Val Loss: 0.340721
2025-06-30 17:53:57,415 - INFO - Epoch 15/150 - Train Loss: 0.156110, Val Loss: 0.707064
2025-06-30 17:55:16,404 - INFO - Epoch 16/150 - Train Loss: 0.154956, Val Loss: 0.316564
2025-06-30 17:56:34,461 - INFO - Epoch 17/150 - Train Loss: 0.150797, Val Loss: 0.363528
2025-06-30 17:57:52,661 - INFO - Epoch 18/150 - Train Loss: 0.150398, Val Loss: 0.306866
2025-06-30 17:59:10,752 - INFO - Epoch 19/150 - Train Loss: 0.146320, Val Loss: 0.307843
2025-06-30 18:00:29,293 - INFO - Epoch 20/150 - Train Loss: 0.145809, Val Loss: 0.330650
2025-06-30 18:01:48,087 - INFO - Epoch 21/150 - Train Loss: 0.142851, Val Loss: 0.391678
2025-06-30 18:03:06,598 - INFO - Epoch 22/150 - Train Loss: 0.126787, Val Loss: 0.337572
2025-06-30 18:04:24,680 - INFO - Epoch 23/150 - Train Loss: 0.123620, Val Loss: 0.355335
2025-06-30 18:05:43,271 - INFO - Epoch 24/150 - Train Loss: 0.122585, Val Loss: 0.340422
2025-06-30 18:07:01,807 - INFO - Epoch 25/150 - Train Loss: 0.122330, Val Loss: 0.406491
2025-06-30 18:08:20,612 - INFO - Epoch 26/150 - Train Loss: 0.121033, Val Loss: 0.286314
2025-06-30 18:09:39,540 - INFO - Epoch 27/150 - Train Loss: 0.120651, Val Loss: 0.318359
2025-06-30 18:10:57,940 - INFO - Epoch 28/150 - Train Loss: 0.120304, Val Loss: 0.382439
2025-06-30 18:12:16,828 - INFO - Epoch 29/150 - Train Loss: 0.119962, Val Loss: 0.345679
2025-06-30 18:13:34,937 - INFO - Epoch 30/150 - Train Loss: 0.119027, Val Loss: 0.341966
2025-06-30 18:14:54,179 - INFO - Epoch 31/150 - Train Loss: 0.118959, Val Loss: 0.391687
2025-06-30 18:16:12,220 - INFO - Epoch 32/150 - Train Loss: 0.118611, Val Loss: 0.313077
2025-06-30 18:17:30,399 - INFO - Epoch 33/150 - Train Loss: 0.116480, Val Loss: 0.330458
2025-06-30 18:18:48,731 - INFO - Epoch 34/150 - Train Loss: 0.115712, Val Loss: 0.326009
2025-06-30 18:20:07,247 - INFO - Epoch 35/150 - Train Loss: 0.115393, Val Loss: 0.306546
2025-06-30 18:21:25,353 - INFO - Epoch 36/150 - Train Loss: 0.115552, Val Loss: 0.340466
2025-06-30 18:22:43,445 - INFO - Epoch 37/150 - Train Loss: 0.115543, Val Loss: 0.373273
2025-06-30 18:24:02,142 - INFO - Epoch 38/150 - Train Loss: 0.115922, Val Loss: 0.309788
2025-06-30 18:25:20,565 - INFO - Epoch 39/150 - Train Loss: 0.115653, Val Loss: 0.271992
2025-06-30 18:26:38,822 - INFO - Epoch 40/150 - Train Loss: 0.115121, Val Loss: 0.348497
2025-06-30 18:27:57,409 - INFO - Epoch 41/150 - Train Loss: 0.115150, Val Loss: 0.297418
2025-06-30 18:29:16,009 - INFO - Epoch 42/150 - Train Loss: 0.115160, Val Loss: 0.383143
2025-06-30 18:30:34,695 - INFO - Epoch 43/150 - Train Loss: 0.115192, Val Loss: 0.440613
2025-06-30 18:31:52,736 - INFO - Epoch 44/150 - Train Loss: 0.115003, Val Loss: 0.345850
2025-06-30 18:33:10,812 - INFO - Epoch 45/150 - Train Loss: 0.114872, Val Loss: 0.311430
2025-06-30 18:34:29,297 - INFO - Epoch 46/150 - Train Loss: 0.115326, Val Loss: 0.343319
2025-06-30 18:35:47,349 - INFO - Epoch 47/150 - Train Loss: 0.114860, Val Loss: 0.344899
2025-06-30 18:37:05,784 - INFO - Epoch 48/150 - Train Loss: 0.114866, Val Loss: 0.284896
2025-06-30 18:38:24,378 - INFO - Epoch 49/150 - Train Loss: 0.114544, Val Loss: 0.408499
2025-06-30 18:39:42,857 - INFO - Epoch 50/150 - Train Loss: 0.114724, Val Loss: 0.305857
2025-06-30 18:41:01,036 - INFO - Epoch 51/150 - Train Loss: 0.114458, Val Loss: 0.299605
2025-06-30 18:42:19,095 - INFO - Epoch 52/150 - Train Loss: 0.114251, Val Loss: 0.326662
2025-06-30 18:43:37,329 - INFO - Epoch 53/150 - Train Loss: 0.114300, Val Loss: 0.370366
2025-06-30 18:44:55,705 - INFO - Epoch 54/150 - Train Loss: 0.114824, Val Loss: 0.342930
2025-06-30 18:46:13,775 - INFO - Epoch 55/150 - Train Loss: 0.114706, Val Loss: 0.275388
2025-06-30 18:47:32,359 - INFO - Epoch 56/150 - Train Loss: 0.114282, Val Loss: 0.363105
2025-06-30 18:48:50,444 - INFO - Epoch 57/150 - Train Loss: 0.114380, Val Loss: 0.325565
2025-06-30 18:50:08,946 - INFO - Epoch 58/150 - Train Loss: 0.114792, Val Loss: 0.318675
2025-06-30 18:51:27,051 - INFO - Epoch 59/150 - Train Loss: 0.114929, Val Loss: 0.321709
2025-06-30 18:52:45,485 - INFO - Epoch 60/150 - Train Loss: 0.114439, Val Loss: 0.348318
2025-06-30 18:54:03,750 - INFO - Epoch 61/150 - Train Loss: 0.114826, Val Loss: 0.310537
2025-06-30 18:55:21,838 - INFO - Epoch 62/150 - Train Loss: 0.114831, Val Loss: 0.356949
2025-06-30 18:56:40,599 - INFO - Epoch 63/150 - Train Loss: 0.114710, Val Loss: 0.333346
2025-06-30 18:57:59,056 - INFO - Epoch 64/150 - Train Loss: 0.114549, Val Loss: 0.330581
2025-06-30 18:59:17,922 - INFO - Epoch 65/150 - Train Loss: 0.114451, Val Loss: 0.324694
2025-06-30 19:00:36,019 - INFO - Epoch 66/150 - Train Loss: 0.115174, Val Loss: 0.367802
2025-06-30 19:01:54,565 - INFO - Epoch 67/150 - Train Loss: 0.114704, Val Loss: 0.354602
2025-06-30 19:03:13,049 - INFO - Epoch 68/150 - Train Loss: 0.114460, Val Loss: 0.328084
2025-06-30 19:04:31,403 - INFO - Epoch 69/150 - Train Loss: 0.114756, Val Loss: 0.350261
2025-06-30 19:05:49,814 - INFO - Epoch 70/150 - Train Loss: 0.114805, Val Loss: 0.289372
2025-06-30 19:07:08,121 - INFO - Epoch 71/150 - Train Loss: 0.114418, Val Loss: 0.335876
2025-06-30 19:08:26,105 - INFO - Epoch 72/150 - Train Loss: 0.114405, Val Loss: 0.366036
2025-06-30 19:09:44,686 - INFO - Epoch 73/150 - Train Loss: 0.114774, Val Loss: 0.408839
2025-06-30 19:11:02,928 - INFO - Epoch 74/150 - Train Loss: 0.114673, Val Loss: 0.384515
2025-06-30 19:12:21,068 - INFO - Epoch 75/150 - Train Loss: 0.114742, Val Loss: 0.352974
2025-06-30 19:13:39,248 - INFO - Epoch 76/150 - Train Loss: 0.114750, Val Loss: 0.387338
2025-06-30 19:14:57,218 - INFO - Epoch 77/150 - Train Loss: 0.114278, Val Loss: 0.332115
2025-06-30 19:16:15,711 - INFO - Epoch 78/150 - Train Loss: 0.114510, Val Loss: 0.340954
2025-06-30 19:17:34,246 - INFO - Epoch 79/150 - Train Loss: 0.114450, Val Loss: 0.316302
2025-06-30 19:18:52,731 - INFO - Epoch 80/150 - Train Loss: 0.114543, Val Loss: 0.373504
2025-06-30 19:20:11,238 - INFO - Epoch 81/150 - Train Loss: 0.114642, Val Loss: 0.370884
2025-06-30 19:21:29,417 - INFO - Epoch 82/150 - Train Loss: 0.114434, Val Loss: 0.380505
2025-06-30 19:22:47,661 - INFO - Epoch 83/150 - Train Loss: 0.114927, Val Loss: 0.336587
2025-06-30 19:24:06,259 - INFO - Epoch 84/150 - Train Loss: 0.114839, Val Loss: 0.328367
2025-06-30 19:25:24,784 - INFO - Epoch 85/150 - Train Loss: 0.115007, Val Loss: 0.309279
2025-06-30 19:26:43,212 - INFO - Epoch 86/150 - Train Loss: 0.114242, Val Loss: 0.370538
2025-06-30 19:28:01,307 - INFO - Epoch 87/150 - Train Loss: 0.114734, Val Loss: 0.337762
2025-06-30 19:29:20,241 - INFO - Epoch 88/150 - Train Loss: 0.114626, Val Loss: 0.289764
2025-06-30 19:30:38,791 - INFO - Epoch 89/150 - Train Loss: 0.115115, Val Loss: 0.318990
2025-06-30 19:31:56,976 - INFO - Epoch 90/150 - Train Loss: 0.115102, Val Loss: 0.354954
2025-06-30 19:33:15,189 - INFO - Epoch 91/150 - Train Loss: 0.114749, Val Loss: 0.294247
2025-06-30 19:34:33,552 - INFO - Epoch 92/150 - Train Loss: 0.114562, Val Loss: 0.314539
2025-06-30 19:35:51,758 - INFO - Epoch 93/150 - Train Loss: 0.114822, Val Loss: 0.366573
2025-06-30 19:37:09,698 - INFO - Epoch 94/150 - Train Loss: 0.114437, Val Loss: 0.375101
2025-06-30 19:38:27,696 - INFO - Epoch 95/150 - Train Loss: 0.114689, Val Loss: 0.323761
2025-06-30 19:39:46,038 - INFO - Epoch 96/150 - Train Loss: 0.114327, Val Loss: 0.318239
2025-06-30 19:41:04,438 - INFO - Epoch 97/150 - Train Loss: 0.114366, Val Loss: 0.392243
2025-06-30 19:42:23,381 - INFO - Epoch 98/150 - Train Loss: 0.114906, Val Loss: 0.358733
2025-06-30 19:43:41,772 - INFO - Epoch 99/150 - Train Loss: 0.114610, Val Loss: 0.331567
2025-06-30 19:44:59,795 - INFO - Epoch 100/150 - Train Loss: 0.114578, Val Loss: 0.310740
2025-06-30 19:46:17,999 - INFO - Epoch 101/150 - Train Loss: 0.115235, Val Loss: 0.391990
2025-06-30 19:47:35,978 - INFO - Epoch 102/150 - Train Loss: 0.114637, Val Loss: 0.320438
2025-06-30 19:48:54,073 - INFO - Epoch 103/150 - Train Loss: 0.114467, Val Loss: 0.292974
2025-06-30 19:50:12,181 - INFO - Epoch 104/150 - Train Loss: 0.115199, Val Loss: 0.282757
2025-06-30 19:51:30,395 - INFO - Epoch 105/150 - Train Loss: 0.114504, Val Loss: 0.333733
2025-06-30 19:52:48,847 - INFO - Epoch 106/150 - Train Loss: 0.115164, Val Loss: 0.383072
2025-06-30 19:54:06,980 - INFO - Epoch 107/150 - Train Loss: 0.114505, Val Loss: 0.330269
2025-06-30 19:55:25,025 - INFO - Epoch 108/150 - Train Loss: 0.115155, Val Loss: 0.292248
2025-06-30 19:56:43,088 - INFO - Epoch 109/150 - Train Loss: 0.114404, Val Loss: 0.274166
2025-06-30 19:58:01,516 - INFO - Epoch 110/150 - Train Loss: 0.114874, Val Loss: 0.283184
2025-06-30 19:59:20,361 - INFO - Epoch 111/150 - Train Loss: 0.114387, Val Loss: 0.299333
2025-06-30 20:00:39,351 - INFO - Epoch 112/150 - Train Loss: 0.114221, Val Loss: 0.358470
2025-06-30 20:01:58,578 - INFO - Epoch 113/150 - Train Loss: 0.114844, Val Loss: 0.335793
2025-06-30 20:03:16,704 - INFO - Epoch 114/150 - Train Loss: 0.114727, Val Loss: 0.262746
2025-06-30 20:04:35,207 - INFO - Epoch 115/150 - Train Loss: 0.115125, Val Loss: 0.305435
2025-06-30 20:05:53,290 - INFO - Epoch 116/150 - Train Loss: 0.114973, Val Loss: 0.352330
2025-06-30 20:07:11,322 - INFO - Epoch 117/150 - Train Loss: 0.114906, Val Loss: 0.380068
2025-06-30 20:08:30,049 - INFO - Epoch 118/150 - Train Loss: 0.114159, Val Loss: 0.330968
2025-06-30 20:09:48,388 - INFO - Epoch 119/150 - Train Loss: 0.114737, Val Loss: 0.392899
2025-06-30 20:11:06,903 - INFO - Epoch 120/150 - Train Loss: 0.114212, Val Loss: 0.457523
2025-06-30 20:12:25,227 - INFO - Epoch 121/150 - Train Loss: 0.114624, Val Loss: 0.392320
2025-06-30 20:13:43,293 - INFO - Epoch 122/150 - Train Loss: 0.114525, Val Loss: 0.329263
2025-06-30 20:15:01,513 - INFO - Epoch 123/150 - Train Loss: 0.114335, Val Loss: 0.335892
2025-06-30 20:16:19,796 - INFO - Epoch 124/150 - Train Loss: 0.114401, Val Loss: 0.394910
2025-06-30 20:17:38,242 - INFO - Epoch 125/150 - Train Loss: 0.114514, Val Loss: 0.323798
2025-06-30 20:18:56,292 - INFO - Epoch 126/150 - Train Loss: 0.114280, Val Loss: 0.310643
2025-06-30 20:20:14,806 - INFO - Epoch 127/150 - Train Loss: 0.114908, Val Loss: 0.279792
2025-06-30 20:21:33,034 - INFO - Epoch 128/150 - Train Loss: 0.114858, Val Loss: 0.364100
2025-06-30 20:22:51,234 - INFO - Epoch 129/150 - Train Loss: 0.114668, Val Loss: 0.327406
2025-06-30 20:24:09,280 - INFO - Epoch 130/150 - Train Loss: 0.114463, Val Loss: 0.400030
2025-06-30 20:25:28,061 - INFO - Epoch 131/150 - Train Loss: 0.114479, Val Loss: 0.373334
2025-06-30 20:26:46,115 - INFO - Epoch 132/150 - Train Loss: 0.114721, Val Loss: 0.291381
2025-06-30 20:28:04,904 - INFO - Epoch 133/150 - Train Loss: 0.114374, Val Loss: 0.330809
2025-06-30 20:29:23,092 - INFO - Epoch 134/150 - Train Loss: 0.114752, Val Loss: 0.338186
2025-06-30 20:30:41,510 - INFO - Epoch 135/150 - Train Loss: 0.114726, Val Loss: 0.333333
2025-06-30 20:31:59,968 - INFO - Epoch 136/150 - Train Loss: 0.114543, Val Loss: 0.393638
2025-06-30 20:33:17,948 - INFO - Epoch 137/150 - Train Loss: 0.114347, Val Loss: 0.356567
2025-06-30 20:34:35,994 - INFO - Epoch 138/150 - Train Loss: 0.114437, Val Loss: 0.335911
2025-06-30 20:35:54,546 - INFO - Epoch 139/150 - Train Loss: 0.114309, Val Loss: 0.354282
2025-06-30 20:37:12,706 - INFO - Epoch 140/150 - Train Loss: 0.114580, Val Loss: 0.296185
2025-06-30 20:38:30,883 - INFO - Epoch 141/150 - Train Loss: 0.114503, Val Loss: 0.350196
2025-06-30 20:39:48,952 - INFO - Epoch 142/150 - Train Loss: 0.114974, Val Loss: 0.352089
2025-06-30 20:41:07,761 - INFO - Epoch 143/150 - Train Loss: 0.114531, Val Loss: 0.429320
2025-06-30 20:42:25,952 - INFO - Epoch 144/150 - Train Loss: 0.115206, Val Loss: 0.314086
2025-06-30 20:43:44,055 - INFO - Epoch 145/150 - Train Loss: 0.114626, Val Loss: 0.337540
2025-06-30 20:45:02,416 - INFO - Epoch 146/150 - Train Loss: 0.114451, Val Loss: 0.277558
2025-06-30 20:46:21,035 - INFO - Epoch 147/150 - Train Loss: 0.114477, Val Loss: 0.318521
2025-06-30 20:47:38,973 - INFO - Epoch 148/150 - Train Loss: 0.114764, Val Loss: 0.341076
2025-06-30 20:48:57,569 - INFO - Epoch 149/150 - Train Loss: 0.114548, Val Loss: 0.377755
2025-06-30 20:50:16,431 - INFO - Epoch 150/150 - Train Loss: 0.114698, Val Loss: 0.341052
2025-06-30 20:50:16,623 - INFO - Final model saved to experiments/DrivAerNet_Pressure/final_model.pth
2025-06-30 20:50:16,626 - INFO - Testing the final model
2025-06-30 20:50:22,616 - INFO - Testing the best model
2025-07-01 14:29:38,407 - INFO - Arguments: Namespace(exp_name='DrivAerNet_Pressure', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data', num_points=10000, batch_size=12, epochs=150, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-07-01 14:29:38,419 - INFO - Starting training with 1 GPUs
2025-07-01 14:29:43,950 - INFO - Total trainable parameters: 1437705
2025-07-01 14:29:44,192 - INFO - Data loaded: 19 training batches, 4 validation batches, 4 test batches
2025-07-01 14:29:44,194 - INFO - Starting training for 150 epochs
2025-07-01 14:30:05,006 - INFO - Epoch 1/150 - Train Loss: 0.944336, Val Loss: 1.219285
2025-07-01 14:30:05,044 - INFO - New best model saved with Val Loss: 1.219285
2025-07-01 14:30:22,290 - INFO - Epoch 2/150 - Train Loss: 0.522877, Val Loss: 1.064568
2025-07-01 14:30:22,306 - INFO - New best model saved with Val Loss: 1.064568
2025-07-01 14:30:39,580 - INFO - Epoch 3/150 - Train Loss: 0.446333, Val Loss: 0.605286
2025-07-01 14:30:39,595 - INFO - New best model saved with Val Loss: 0.605286
2025-07-01 14:30:56,867 - INFO - Epoch 4/150 - Train Loss: 0.400011, Val Loss: 0.645773
2025-07-01 14:31:14,135 - INFO - Epoch 5/150 - Train Loss: 0.367054, Val Loss: 0.493229
2025-07-01 14:31:14,151 - INFO - New best model saved with Val Loss: 0.493229
2025-07-01 14:31:31,393 - INFO - Epoch 6/150 - Train Loss: 0.339636, Val Loss: 0.403541
2025-07-01 14:31:31,408 - INFO - New best model saved with Val Loss: 0.403541
2025-07-01 14:31:48,668 - INFO - Epoch 7/150 - Train Loss: 0.322386, Val Loss: 0.342029
2025-07-01 14:31:48,682 - INFO - New best model saved with Val Loss: 0.342029
2025-07-01 14:32:05,987 - INFO - Epoch 8/150 - Train Loss: 0.298683, Val Loss: 0.348875
2025-07-01 14:32:23,237 - INFO - Epoch 9/150 - Train Loss: 0.288324, Val Loss: 0.370314
2025-07-01 14:32:40,543 - INFO - Epoch 10/150 - Train Loss: 0.268490, Val Loss: 0.350439
2025-07-01 14:32:57,973 - INFO - Epoch 11/150 - Train Loss: 0.253745, Val Loss: 0.298968
2025-07-01 14:32:57,989 - INFO - New best model saved with Val Loss: 0.298968
2025-07-01 14:33:15,214 - INFO - Epoch 12/150 - Train Loss: 0.239486, Val Loss: 0.444282
2025-07-01 14:33:32,454 - INFO - Epoch 13/150 - Train Loss: 0.234676, Val Loss: 0.315308
2025-07-01 14:33:49,738 - INFO - Epoch 14/150 - Train Loss: 0.225927, Val Loss: 1.125578
2025-07-01 14:34:07,066 - INFO - Epoch 15/150 - Train Loss: 0.218799, Val Loss: 0.302328
2025-07-01 14:34:24,337 - INFO - Epoch 16/150 - Train Loss: 0.208660, Val Loss: 0.212942
2025-07-01 14:34:24,354 - INFO - New best model saved with Val Loss: 0.212942
2025-07-01 14:34:41,680 - INFO - Epoch 17/150 - Train Loss: 0.205811, Val Loss: 0.586754
2025-07-01 14:34:58,899 - INFO - Epoch 18/150 - Train Loss: 0.201214, Val Loss: 0.906912
2025-07-01 14:35:16,128 - INFO - Epoch 19/150 - Train Loss: 0.195415, Val Loss: 0.579541
2025-07-01 14:35:33,340 - INFO - Epoch 20/150 - Train Loss: 0.196564, Val Loss: 0.219327
2025-07-01 14:35:50,700 - INFO - Epoch 21/150 - Train Loss: 0.186952, Val Loss: 0.299865
2025-07-01 14:36:07,969 - INFO - Epoch 22/150 - Train Loss: 0.186204, Val Loss: 0.199399
2025-07-01 14:36:07,985 - INFO - New best model saved with Val Loss: 0.199399
2025-07-01 14:36:25,215 - INFO - Epoch 23/150 - Train Loss: 0.183222, Val Loss: 0.386177
2025-07-01 14:36:42,445 - INFO - Epoch 24/150 - Train Loss: 0.183819, Val Loss: 0.233748
2025-07-01 14:36:59,642 - INFO - Epoch 25/150 - Train Loss: 0.183007, Val Loss: 0.304167
2025-07-01 14:37:16,831 - INFO - Epoch 26/150 - Train Loss: 0.174892, Val Loss: 0.233097
2025-07-01 14:37:34,100 - INFO - Epoch 27/150 - Train Loss: 0.172703, Val Loss: 0.336897
2025-07-01 14:37:51,322 - INFO - Epoch 28/150 - Train Loss: 0.170808, Val Loss: 0.269534
2025-07-01 14:38:08,547 - INFO - Epoch 29/150 - Train Loss: 0.171695, Val Loss: 0.180621
2025-07-01 14:38:08,563 - INFO - New best model saved with Val Loss: 0.180621
2025-07-01 14:38:25,951 - INFO - Epoch 30/150 - Train Loss: 0.167142, Val Loss: 0.216214
2025-07-01 14:38:43,355 - INFO - Epoch 31/150 - Train Loss: 0.161278, Val Loss: 0.182650
2025-07-01 14:39:00,618 - INFO - Epoch 32/150 - Train Loss: 0.160153, Val Loss: 0.308357
2025-07-01 14:39:17,896 - INFO - Epoch 33/150 - Train Loss: 0.163440, Val Loss: 0.658242
2025-07-01 14:39:35,248 - INFO - Epoch 34/150 - Train Loss: 0.163707, Val Loss: 0.267479
2025-07-01 14:39:52,602 - INFO - Epoch 35/150 - Train Loss: 0.158737, Val Loss: 0.214584
2025-07-01 14:40:09,912 - INFO - Epoch 36/150 - Train Loss: 0.153633, Val Loss: 0.356263
2025-07-01 14:40:27,227 - INFO - Epoch 37/150 - Train Loss: 0.154116, Val Loss: 0.208539
2025-07-01 14:40:44,535 - INFO - Epoch 38/150 - Train Loss: 0.148768, Val Loss: 0.191369
2025-07-01 14:41:01,841 - INFO - Epoch 39/150 - Train Loss: 0.149895, Val Loss: 0.465343
2025-07-01 14:41:19,055 - INFO - Epoch 40/150 - Train Loss: 0.150544, Val Loss: 0.239472
2025-07-01 14:41:36,388 - INFO - Epoch 41/150 - Train Loss: 0.140175, Val Loss: 0.139299
2025-07-01 14:41:36,403 - INFO - New best model saved with Val Loss: 0.139299
2025-07-01 14:41:53,667 - INFO - Epoch 42/150 - Train Loss: 0.137571, Val Loss: 0.124848
2025-07-01 14:41:53,682 - INFO - New best model saved with Val Loss: 0.124848
2025-07-01 14:42:10,942 - INFO - Epoch 43/150 - Train Loss: 0.136002, Val Loss: 0.123344
2025-07-01 14:42:10,958 - INFO - New best model saved with Val Loss: 0.123344
2025-07-01 14:42:28,208 - INFO - Epoch 44/150 - Train Loss: 0.135021, Val Loss: 0.125786
2025-07-01 14:42:45,445 - INFO - Epoch 45/150 - Train Loss: 0.134310, Val Loss: 0.122802
2025-07-01 14:42:45,459 - INFO - New best model saved with Val Loss: 0.122802
2025-07-01 14:43:02,659 - INFO - Epoch 46/150 - Train Loss: 0.134983, Val Loss: 0.123601
2025-07-01 14:43:19,886 - INFO - Epoch 47/150 - Train Loss: 0.134630, Val Loss: 0.127123
2025-07-01 14:43:37,160 - INFO - Epoch 48/150 - Train Loss: 0.134465, Val Loss: 0.122710
2025-07-01 14:43:37,175 - INFO - New best model saved with Val Loss: 0.122710
2025-07-01 14:43:54,470 - INFO - Epoch 49/150 - Train Loss: 0.133775, Val Loss: 0.126028
2025-07-01 14:44:11,775 - INFO - Epoch 50/150 - Train Loss: 0.132096, Val Loss: 0.124908
2025-07-01 14:44:29,128 - INFO - Epoch 51/150 - Train Loss: 0.132715, Val Loss: 0.122304
2025-07-01 14:44:29,143 - INFO - New best model saved with Val Loss: 0.122304
2025-07-01 14:44:46,457 - INFO - Epoch 52/150 - Train Loss: 0.132739, Val Loss: 0.122880
2025-07-01 14:45:03,728 - INFO - Epoch 53/150 - Train Loss: 0.131952, Val Loss: 0.122954
2025-07-01 14:45:21,017 - INFO - Epoch 54/150 - Train Loss: 0.131004, Val Loss: 0.122309
2025-07-01 14:45:38,407 - INFO - Epoch 55/150 - Train Loss: 0.132002, Val Loss: 0.135585
2025-07-01 14:45:55,704 - INFO - Epoch 56/150 - Train Loss: 0.131548, Val Loss: 0.122071
2025-07-01 14:45:55,719 - INFO - New best model saved with Val Loss: 0.122071
2025-07-01 14:46:13,041 - INFO - Epoch 57/150 - Train Loss: 0.132877, Val Loss: 0.140523
2025-07-01 14:46:30,296 - INFO - Epoch 58/150 - Train Loss: 0.132406, Val Loss: 0.120446
2025-07-01 14:46:30,316 - INFO - New best model saved with Val Loss: 0.120446
2025-07-01 14:46:47,505 - INFO - Epoch 59/150 - Train Loss: 0.131690, Val Loss: 0.121677
2025-07-01 14:47:04,727 - INFO - Epoch 60/150 - Train Loss: 0.131027, Val Loss: 0.122263
2025-07-01 14:47:22,066 - INFO - Epoch 61/150 - Train Loss: 0.131143, Val Loss: 0.133584
2025-07-01 14:47:39,274 - INFO - Epoch 62/150 - Train Loss: 0.127840, Val Loss: 0.125625
2025-07-01 14:47:56,509 - INFO - Epoch 63/150 - Train Loss: 0.131196, Val Loss: 0.138059
2025-07-01 14:48:13,742 - INFO - Epoch 64/150 - Train Loss: 0.130904, Val Loss: 0.126008
2025-07-01 14:48:30,993 - INFO - Epoch 65/150 - Train Loss: 0.130627, Val Loss: 0.134073
2025-07-01 14:48:48,287 - INFO - Epoch 66/150 - Train Loss: 0.130362, Val Loss: 0.129995
2025-07-01 14:49:05,538 - INFO - Epoch 67/150 - Train Loss: 0.129847, Val Loss: 0.122759
2025-07-01 14:49:22,786 - INFO - Epoch 68/150 - Train Loss: 0.129141, Val Loss: 0.128393
2025-07-01 14:49:40,093 - INFO - Epoch 69/150 - Train Loss: 0.129622, Val Loss: 0.140196
2025-07-01 14:49:57,370 - INFO - Epoch 70/150 - Train Loss: 0.128149, Val Loss: 0.117986
2025-07-01 14:49:57,386 - INFO - New best model saved with Val Loss: 0.117986
2025-07-01 14:50:14,855 - INFO - Epoch 71/150 - Train Loss: 0.127885, Val Loss: 0.117956
2025-07-01 14:50:14,869 - INFO - New best model saved with Val Loss: 0.117956
2025-07-01 14:50:32,145 - INFO - Epoch 72/150 - Train Loss: 0.128086, Val Loss: 0.118794
2025-07-01 14:50:50,304 - INFO - Epoch 73/150 - Train Loss: 0.128216, Val Loss: 0.118334
2025-07-01 14:51:07,648 - INFO - Epoch 74/150 - Train Loss: 0.127299, Val Loss: 0.118110
2025-07-01 14:51:24,913 - INFO - Epoch 75/150 - Train Loss: 0.128536, Val Loss: 0.118001
2025-07-01 14:51:42,176 - INFO - Epoch 76/150 - Train Loss: 0.127507, Val Loss: 0.117744
2025-07-01 14:51:42,192 - INFO - New best model saved with Val Loss: 0.117744
2025-07-01 14:51:59,560 - INFO - Epoch 77/150 - Train Loss: 0.127836, Val Loss: 0.117846
2025-07-01 14:52:16,942 - INFO - Epoch 78/150 - Train Loss: 0.126888, Val Loss: 0.118258
2025-07-01 14:52:34,227 - INFO - Epoch 79/150 - Train Loss: 0.127401, Val Loss: 0.118252
2025-07-01 14:52:51,504 - INFO - Epoch 80/150 - Train Loss: 0.127433, Val Loss: 0.118469
2025-07-01 14:53:08,855 - INFO - Epoch 81/150 - Train Loss: 0.127819, Val Loss: 0.118135
2025-07-01 14:53:26,114 - INFO - Epoch 82/150 - Train Loss: 0.127395, Val Loss: 0.117884
2025-07-01 14:53:43,318 - INFO - Epoch 83/150 - Train Loss: 0.124685, Val Loss: 0.118529
2025-07-01 14:54:00,571 - INFO - Epoch 84/150 - Train Loss: 0.127505, Val Loss: 0.117683
2025-07-01 14:54:00,587 - INFO - New best model saved with Val Loss: 0.117683
2025-07-01 14:54:17,827 - INFO - Epoch 85/150 - Train Loss: 0.126746, Val Loss: 0.117912
2025-07-01 14:54:35,095 - INFO - Epoch 86/150 - Train Loss: 0.127001, Val Loss: 0.118574
2025-07-01 14:54:52,350 - INFO - Epoch 87/150 - Train Loss: 0.127766, Val Loss: 0.117685
2025-07-01 14:55:09,607 - INFO - Epoch 88/150 - Train Loss: 0.127670, Val Loss: 0.117339
2025-07-01 14:55:09,624 - INFO - New best model saved with Val Loss: 0.117339
2025-07-01 14:55:26,993 - INFO - Epoch 89/150 - Train Loss: 0.127415, Val Loss: 0.117723
2025-07-01 14:55:44,259 - INFO - Epoch 90/150 - Train Loss: 0.127280, Val Loss: 0.117983
2025-07-01 14:56:01,604 - INFO - Epoch 91/150 - Train Loss: 0.126789, Val Loss: 0.118232
2025-07-01 14:56:18,857 - INFO - Epoch 92/150 - Train Loss: 0.127669, Val Loss: 0.117836
2025-07-01 14:56:36,081 - INFO - Epoch 93/150 - Train Loss: 0.126905, Val Loss: 0.117907
2025-07-01 14:56:53,316 - INFO - Epoch 94/150 - Train Loss: 0.126349, Val Loss: 0.117834
2025-07-01 14:57:10,611 - INFO - Epoch 95/150 - Train Loss: 0.127347, Val Loss: 0.117767
2025-07-01 14:57:27,899 - INFO - Epoch 96/150 - Train Loss: 0.127398, Val Loss: 0.118007
2025-07-01 14:57:45,182 - INFO - Epoch 97/150 - Train Loss: 0.127310, Val Loss: 0.117957
2025-07-01 14:58:02,441 - INFO - Epoch 98/150 - Train Loss: 0.127389, Val Loss: 0.117232
2025-07-01 14:58:02,474 - INFO - New best model saved with Val Loss: 0.117232
2025-07-01 14:58:19,715 - INFO - Epoch 99/150 - Train Loss: 0.123042, Val Loss: 0.117479
2025-07-01 14:58:36,997 - INFO - Epoch 100/150 - Train Loss: 0.127146, Val Loss: 0.118272
2025-07-01 14:58:54,386 - INFO - Epoch 101/150 - Train Loss: 0.127231, Val Loss: 0.117737
2025-07-01 14:59:11,668 - INFO - Epoch 102/150 - Train Loss: 0.127707, Val Loss: 0.117786
2025-07-01 14:59:28,944 - INFO - Epoch 103/150 - Train Loss: 0.127136, Val Loss: 0.117851
2025-07-01 14:59:46,209 - INFO - Epoch 104/150 - Train Loss: 0.126369, Val Loss: 0.117304
2025-07-01 15:00:03,476 - INFO - Epoch 105/150 - Train Loss: 0.127117, Val Loss: 0.117636
2025-07-01 15:00:20,754 - INFO - Epoch 106/150 - Train Loss: 0.125461, Val Loss: 0.117552
2025-07-01 15:00:38,035 - INFO - Epoch 107/150 - Train Loss: 0.126910, Val Loss: 0.117649
2025-07-01 15:00:55,309 - INFO - Epoch 108/150 - Train Loss: 0.126365, Val Loss: 0.117374
2025-07-01 15:01:12,546 - INFO - Epoch 109/150 - Train Loss: 0.127436, Val Loss: 0.117734
2025-07-01 15:01:29,779 - INFO - Epoch 110/150 - Train Loss: 0.126945, Val Loss: 0.117465
2025-07-01 15:01:47,246 - INFO - Epoch 111/150 - Train Loss: 0.127468, Val Loss: 0.117075
2025-07-01 15:01:47,261 - INFO - New best model saved with Val Loss: 0.117075
2025-07-01 15:02:04,506 - INFO - Epoch 112/150 - Train Loss: 0.127518, Val Loss: 0.117353
2025-07-01 15:02:21,765 - INFO - Epoch 113/150 - Train Loss: 0.127404, Val Loss: 0.117520
2025-07-01 15:02:39,043 - INFO - Epoch 114/150 - Train Loss: 0.127601, Val Loss: 0.117241
2025-07-01 15:02:56,305 - INFO - Epoch 115/150 - Train Loss: 0.126500, Val Loss: 0.117120
2025-07-01 15:03:13,650 - INFO - Epoch 116/150 - Train Loss: 0.127178, Val Loss: 0.117305
2025-07-01 15:03:31,032 - INFO - Epoch 117/150 - Train Loss: 0.126409, Val Loss: 0.117152
2025-07-01 15:03:48,319 - INFO - Epoch 118/150 - Train Loss: 0.127022, Val Loss: 0.117468
2025-07-01 15:04:05,595 - INFO - Epoch 119/150 - Train Loss: 0.126303, Val Loss: 0.117383
2025-07-01 15:04:22,883 - INFO - Epoch 120/150 - Train Loss: 0.126703, Val Loss: 0.117294
2025-07-01 15:04:40,237 - INFO - Epoch 121/150 - Train Loss: 0.126228, Val Loss: 0.117264
2025-07-01 15:04:57,468 - INFO - Epoch 122/150 - Train Loss: 0.127032, Val Loss: 0.117236
2025-07-01 15:05:14,688 - INFO - Epoch 123/150 - Train Loss: 0.125031, Val Loss: 0.117115
2025-07-01 15:05:31,957 - INFO - Epoch 124/150 - Train Loss: 0.127450, Val Loss: 0.117136
2025-07-01 15:05:49,175 - INFO - Epoch 125/150 - Train Loss: 0.123289, Val Loss: 0.117517
2025-07-01 15:06:06,416 - INFO - Epoch 126/150 - Train Loss: 0.124371, Val Loss: 0.117208
2025-07-01 15:06:23,659 - INFO - Epoch 127/150 - Train Loss: 0.126630, Val Loss: 0.117189
2025-07-01 15:06:40,878 - INFO - Epoch 128/150 - Train Loss: 0.126493, Val Loss: 0.117045
2025-07-01 15:06:40,893 - INFO - New best model saved with Val Loss: 0.117045
2025-07-01 15:06:58,130 - INFO - Epoch 129/150 - Train Loss: 0.126747, Val Loss: 0.117156
2025-07-01 15:07:15,396 - INFO - Epoch 130/150 - Train Loss: 0.125939, Val Loss: 0.117241
2025-07-01 15:07:32,870 - INFO - Epoch 131/150 - Train Loss: 0.126841, Val Loss: 0.117272
2025-07-01 15:07:50,086 - INFO - Epoch 132/150 - Train Loss: 0.126608, Val Loss: 0.117375
2025-07-01 15:08:07,317 - INFO - Epoch 133/150 - Train Loss: 0.126863, Val Loss: 0.117084
2025-07-01 15:08:24,646 - INFO - Epoch 134/150 - Train Loss: 0.127221, Val Loss: 0.117059
2025-07-01 15:08:41,931 - INFO - Epoch 135/150 - Train Loss: 0.127003, Val Loss: 0.117198
2025-07-01 15:08:59,212 - INFO - Epoch 136/150 - Train Loss: 0.126729, Val Loss: 0.117245
2025-07-01 15:09:16,424 - INFO - Epoch 137/150 - Train Loss: 0.126530, Val Loss: 0.117051
2025-07-01 15:09:33,754 - INFO - Epoch 138/150 - Train Loss: 0.127341, Val Loss: 0.117109
2025-07-01 15:09:50,979 - INFO - Epoch 139/150 - Train Loss: 0.126464, Val Loss: 0.117426
2025-07-01 15:10:08,206 - INFO - Epoch 140/150 - Train Loss: 0.126444, Val Loss: 0.117396
2025-07-01 15:10:25,518 - INFO - Epoch 141/150 - Train Loss: 0.127130, Val Loss: 0.116982
2025-07-01 15:10:25,534 - INFO - New best model saved with Val Loss: 0.116982
2025-07-01 15:10:42,807 - INFO - Epoch 142/150 - Train Loss: 0.126351, Val Loss: 0.117185
2025-07-01 15:11:00,104 - INFO - Epoch 143/150 - Train Loss: 0.125467, Val Loss: 0.117360
2025-07-01 15:11:17,357 - INFO - Epoch 144/150 - Train Loss: 0.126653, Val Loss: 0.117242
2025-07-01 15:11:34,683 - INFO - Epoch 145/150 - Train Loss: 0.126062, Val Loss: 0.117191
2025-07-01 15:11:52,042 - INFO - Epoch 146/150 - Train Loss: 0.127463, Val Loss: 0.117186
2025-07-01 15:12:09,300 - INFO - Epoch 147/150 - Train Loss: 0.126832, Val Loss: 0.117319
2025-07-01 15:12:26,543 - INFO - Epoch 148/150 - Train Loss: 0.126570, Val Loss: 0.117141
2025-07-01 15:12:43,805 - INFO - Epoch 149/150 - Train Loss: 0.126547, Val Loss: 0.117224
2025-07-01 15:13:01,027 - INFO - Epoch 150/150 - Train Loss: 0.125378, Val Loss: 0.117028
2025-07-01 15:13:01,156 - INFO - Final model saved to experiments/DrivAerNet_Pressure/final_model.pth
2025-07-01 15:13:01,156 - INFO - Testing the final model
2025-07-01 15:13:05,446 - INFO - Testing the best model
2025-07-02 09:29:27,674 - INFO - Arguments: Namespace(exp_name='DrivAerNet_Pressure', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data', num_points=100000, batch_size=12, epochs=150, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-07-02 09:29:27,693 - INFO - Starting training with 1 GPUs
2025-07-02 09:29:34,442 - INFO - Total trainable parameters: 1437705
2025-07-02 09:29:34,735 - INFO - Data loaded: 19 training batches, 4 validation batches, 4 test batches
2025-07-02 09:29:34,736 - INFO - Starting training for 150 epochs
2025-07-02 09:31:01,960 - INFO - Arguments: Namespace(exp_name='DrivAerNet_Pressure', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data', num_points=100000, batch_size=8, epochs=150, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-07-02 09:31:01,963 - INFO - Starting training with 1 GPUs
2025-07-02 09:31:04,232 - INFO - Total trainable parameters: 1437705
2025-07-02 09:31:04,401 - INFO - Data loaded: 29 training batches, 6 validation batches, 6 test batches
2025-07-02 09:31:04,402 - INFO - Starting training for 150 epochs
2025-07-02 09:31:38,967 - INFO - Arguments: Namespace(exp_name='DrivAerNet_Pressure', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data', num_points=100000, batch_size=6, epochs=150, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-07-02 09:31:38,970 - INFO - Starting training with 1 GPUs
2025-07-02 09:31:41,283 - INFO - Total trainable parameters: 1437705
2025-07-02 09:31:41,451 - INFO - Data loaded: 39 training batches, 8 validation batches, 9 test batches
2025-07-02 09:31:41,452 - INFO - Starting training for 150 epochs
2025-07-02 09:32:28,515 - INFO - Epoch 1/150 - Train Loss: 0.752180, Val Loss: 1.124732
2025-07-02 09:32:28,541 - INFO - New best model saved with Val Loss: 1.124732
2025-07-02 09:33:13,838 - INFO - Epoch 2/150 - Train Loss: 0.410244, Val Loss: 0.379351
2025-07-02 09:33:13,856 - INFO - New best model saved with Val Loss: 0.379351
2025-07-02 09:33:58,745 - INFO - Epoch 3/150 - Train Loss: 0.348636, Val Loss: 0.409999
2025-07-02 09:34:43,876 - INFO - Epoch 4/150 - Train Loss: 0.313532, Val Loss: 0.295374
2025-07-02 09:34:43,894 - INFO - New best model saved with Val Loss: 0.295374
2025-07-02 09:35:29,541 - INFO - Epoch 5/150 - Train Loss: 0.286809, Val Loss: 0.481297
2025-07-02 09:36:14,613 - INFO - Epoch 6/150 - Train Loss: 0.267345, Val Loss: 3.256105
2025-07-02 09:36:59,378 - INFO - Epoch 7/150 - Train Loss: 0.248175, Val Loss: 0.297765
2025-07-02 09:37:44,121 - INFO - Epoch 8/150 - Train Loss: 0.233266, Val Loss: 0.295982
2025-07-02 09:38:28,887 - INFO - Epoch 9/150 - Train Loss: 0.223489, Val Loss: 0.655006
2025-07-02 09:39:13,628 - INFO - Epoch 10/150 - Train Loss: 0.215305, Val Loss: 0.423533
2025-07-02 09:39:58,596 - INFO - Epoch 11/150 - Train Loss: 0.203425, Val Loss: 0.388887
2025-07-02 09:40:43,339 - INFO - Epoch 12/150 - Train Loss: 0.193738, Val Loss: 0.255016
2025-07-02 09:40:43,372 - INFO - New best model saved with Val Loss: 0.255016
2025-07-02 09:41:28,095 - INFO - Epoch 13/150 - Train Loss: 0.193163, Val Loss: 0.278204
2025-07-02 09:42:12,870 - INFO - Epoch 14/150 - Train Loss: 0.191126, Val Loss: 0.221406
2025-07-02 09:42:12,889 - INFO - New best model saved with Val Loss: 0.221406
2025-07-02 09:42:57,678 - INFO - Epoch 15/150 - Train Loss: 0.184478, Val Loss: 0.215028
2025-07-02 09:42:57,695 - INFO - New best model saved with Val Loss: 0.215028
2025-07-02 09:43:42,421 - INFO - Epoch 16/150 - Train Loss: 0.178109, Val Loss: 0.325122
2025-07-02 09:44:27,227 - INFO - Epoch 17/150 - Train Loss: 0.174796, Val Loss: 0.258391
2025-07-02 09:45:11,972 - INFO - Epoch 18/150 - Train Loss: 0.174784, Val Loss: 0.225220
2025-07-02 09:45:56,819 - INFO - Epoch 19/150 - Train Loss: 0.169611, Val Loss: 0.248846
2025-07-02 09:46:41,621 - INFO - Epoch 20/150 - Train Loss: 0.167436, Val Loss: 0.471155
2025-07-02 09:47:26,580 - INFO - Epoch 21/150 - Train Loss: 0.163698, Val Loss: 0.192040
2025-07-02 09:47:26,598 - INFO - New best model saved with Val Loss: 0.192040
2025-07-02 09:48:11,493 - INFO - Epoch 22/150 - Train Loss: 0.161416, Val Loss: 0.370374
2025-07-02 09:48:56,347 - INFO - Epoch 23/150 - Train Loss: 0.158124, Val Loss: 0.158734
2025-07-02 09:48:56,366 - INFO - New best model saved with Val Loss: 0.158734
2025-07-02 09:49:41,272 - INFO - Epoch 24/150 - Train Loss: 0.155866, Val Loss: 0.205952
2025-07-02 09:50:26,045 - INFO - Epoch 25/150 - Train Loss: 0.155378, Val Loss: 0.184193
2025-07-02 09:51:10,783 - INFO - Epoch 26/150 - Train Loss: 0.150835, Val Loss: 0.167461
2025-07-02 09:51:55,625 - INFO - Epoch 27/150 - Train Loss: 0.149848, Val Loss: 0.153055
2025-07-02 09:51:55,642 - INFO - New best model saved with Val Loss: 0.153055
2025-07-02 09:52:40,504 - INFO - Epoch 28/150 - Train Loss: 0.154199, Val Loss: 0.136550
2025-07-02 09:52:40,521 - INFO - New best model saved with Val Loss: 0.136550
2025-07-02 09:53:25,422 - INFO - Epoch 29/150 - Train Loss: 0.143742, Val Loss: 0.152760
2025-07-02 09:54:10,178 - INFO - Epoch 30/150 - Train Loss: 0.144288, Val Loss: 0.193623
2025-07-02 09:54:55,222 - INFO - Epoch 31/150 - Train Loss: 0.145189, Val Loss: 0.166961
2025-07-02 09:55:40,023 - INFO - Epoch 32/150 - Train Loss: 0.141460, Val Loss: 0.157264
2025-07-02 09:56:24,809 - INFO - Epoch 33/150 - Train Loss: 0.145188, Val Loss: 0.219487
2025-07-02 09:57:09,678 - INFO - Epoch 34/150 - Train Loss: 0.138041, Val Loss: 0.179359
2025-07-02 09:57:54,519 - INFO - Epoch 35/150 - Train Loss: 0.139006, Val Loss: 0.147838
2025-07-02 09:58:39,303 - INFO - Epoch 36/150 - Train Loss: 0.133996, Val Loss: 0.173444
2025-07-02 09:59:24,057 - INFO - Epoch 37/150 - Train Loss: 0.133981, Val Loss: 0.150009
2025-07-02 10:00:08,815 - INFO - Epoch 38/150 - Train Loss: 0.130496, Val Loss: 0.138145
2025-07-02 10:00:53,636 - INFO - Epoch 39/150 - Train Loss: 0.134783, Val Loss: 0.167007
2025-07-02 10:01:38,476 - INFO - Epoch 40/150 - Train Loss: 0.123822, Val Loss: 0.106565
2025-07-02 10:01:38,496 - INFO - New best model saved with Val Loss: 0.106565
2025-07-02 10:02:23,387 - INFO - Epoch 41/150 - Train Loss: 0.119583, Val Loss: 0.107501
2025-07-02 10:03:08,203 - INFO - Epoch 42/150 - Train Loss: 0.119099, Val Loss: 0.107230
2025-07-02 10:03:53,022 - INFO - Epoch 43/150 - Train Loss: 0.118426, Val Loss: 0.105269
2025-07-02 10:03:53,039 - INFO - New best model saved with Val Loss: 0.105269
2025-07-02 10:04:37,823 - INFO - Epoch 44/150 - Train Loss: 0.117692, Val Loss: 0.106267
2025-07-02 10:05:22,628 - INFO - Epoch 45/150 - Train Loss: 0.116777, Val Loss: 0.105962
2025-07-02 10:06:07,489 - INFO - Epoch 46/150 - Train Loss: 0.117086, Val Loss: 0.104997
2025-07-02 10:06:07,506 - INFO - New best model saved with Val Loss: 0.104997
2025-07-02 10:06:52,271 - INFO - Epoch 47/150 - Train Loss: 0.116806, Val Loss: 0.104811
2025-07-02 10:06:52,288 - INFO - New best model saved with Val Loss: 0.104811
2025-07-02 10:07:37,050 - INFO - Epoch 48/150 - Train Loss: 0.116484, Val Loss: 0.103583
2025-07-02 10:07:37,069 - INFO - New best model saved with Val Loss: 0.103583
2025-07-02 10:08:21,820 - INFO - Epoch 49/150 - Train Loss: 0.115938, Val Loss: 0.105950
2025-07-02 10:09:06,582 - INFO - Epoch 50/150 - Train Loss: 0.115517, Val Loss: 0.107515
2025-07-02 10:09:51,582 - INFO - Epoch 51/150 - Train Loss: 0.115423, Val Loss: 0.103660
2025-07-02 10:10:36,326 - INFO - Epoch 52/150 - Train Loss: 0.115276, Val Loss: 0.104326
2025-07-02 10:11:21,046 - INFO - Epoch 53/150 - Train Loss: 0.114554, Val Loss: 0.103713
2025-07-02 10:12:05,768 - INFO - Epoch 54/150 - Train Loss: 0.114361, Val Loss: 0.106248
2025-07-02 10:12:50,540 - INFO - Epoch 55/150 - Train Loss: 0.115308, Val Loss: 0.104109
2025-07-02 10:13:35,331 - INFO - Epoch 56/150 - Train Loss: 0.114578, Val Loss: 0.105009
2025-07-02 10:14:20,086 - INFO - Epoch 57/150 - Train Loss: 0.115096, Val Loss: 0.103757
2025-07-02 10:15:04,870 - INFO - Epoch 58/150 - Train Loss: 0.114655, Val Loss: 0.106341
2025-07-02 10:15:49,609 - INFO - Epoch 59/150 - Train Loss: 0.115159, Val Loss: 0.107205
2025-07-02 10:16:34,420 - INFO - Epoch 60/150 - Train Loss: 0.112579, Val Loss: 0.101850
2025-07-02 10:16:34,438 - INFO - New best model saved with Val Loss: 0.101850
2025-07-02 10:17:19,360 - INFO - Epoch 61/150 - Train Loss: 0.112142, Val Loss: 0.101521
2025-07-02 10:17:19,377 - INFO - New best model saved with Val Loss: 0.101521
2025-07-02 10:18:04,140 - INFO - Epoch 62/150 - Train Loss: 0.112451, Val Loss: 0.101256
2025-07-02 10:18:04,157 - INFO - New best model saved with Val Loss: 0.101256
2025-07-02 10:18:48,957 - INFO - Epoch 63/150 - Train Loss: 0.112573, Val Loss: 0.101790
2025-07-02 10:19:33,784 - INFO - Epoch 64/150 - Train Loss: 0.112334, Val Loss: 0.101467
2025-07-02 10:20:18,610 - INFO - Epoch 65/150 - Train Loss: 0.112359, Val Loss: 0.101630
2025-07-02 10:21:03,374 - INFO - Epoch 66/150 - Train Loss: 0.112317, Val Loss: 0.101602
2025-07-02 10:21:48,155 - INFO - Epoch 67/150 - Train Loss: 0.111656, Val Loss: 0.101648
2025-07-02 10:22:32,915 - INFO - Epoch 68/150 - Train Loss: 0.112325, Val Loss: 0.101424
2025-07-02 10:23:17,633 - INFO - Epoch 69/150 - Train Loss: 0.112211, Val Loss: 0.101313
2025-07-02 10:24:02,396 - INFO - Epoch 70/150 - Train Loss: 0.111580, Val Loss: 0.101064
2025-07-02 10:24:02,414 - INFO - New best model saved with Val Loss: 0.101064
2025-07-02 10:24:47,406 - INFO - Epoch 71/150 - Train Loss: 0.111994, Val Loss: 0.101423
2025-07-02 10:25:32,142 - INFO - Epoch 72/150 - Train Loss: 0.111675, Val Loss: 0.101559
2025-07-02 10:26:16,894 - INFO - Epoch 73/150 - Train Loss: 0.112274, Val Loss: 0.101257
2025-07-02 10:27:01,696 - INFO - Epoch 74/150 - Train Loss: 0.111927, Val Loss: 0.101388
2025-07-02 10:27:46,574 - INFO - Epoch 75/150 - Train Loss: 0.112268, Val Loss: 0.101364
2025-07-02 10:28:31,372 - INFO - Epoch 76/150 - Train Loss: 0.111703, Val Loss: 0.101176
2025-07-02 10:29:16,153 - INFO - Epoch 77/150 - Train Loss: 0.111602, Val Loss: 0.100929
2025-07-02 10:29:16,171 - INFO - New best model saved with Val Loss: 0.100929
2025-07-02 10:30:00,959 - INFO - Epoch 78/150 - Train Loss: 0.110812, Val Loss: 0.101396
2025-07-02 10:30:45,764 - INFO - Epoch 79/150 - Train Loss: 0.111649, Val Loss: 0.101161
2025-07-02 10:31:30,496 - INFO - Epoch 80/150 - Train Loss: 0.111938, Val Loss: 0.101558
2025-07-02 10:32:15,376 - INFO - Epoch 81/150 - Train Loss: 0.111773, Val Loss: 0.100997
2025-07-02 10:33:00,249 - INFO - Epoch 82/150 - Train Loss: 0.111186, Val Loss: 0.101250
2025-07-02 10:33:45,091 - INFO - Epoch 83/150 - Train Loss: 0.112286, Val Loss: 0.101473
2025-07-02 10:34:29,815 - INFO - Epoch 84/150 - Train Loss: 0.111227, Val Loss: 0.101389
2025-07-02 10:35:14,571 - INFO - Epoch 85/150 - Train Loss: 0.111354, Val Loss: 0.101104
2025-07-02 10:35:59,403 - INFO - Epoch 86/150 - Train Loss: 0.111357, Val Loss: 0.101038
2025-07-02 10:36:44,222 - INFO - Epoch 87/150 - Train Loss: 0.111645, Val Loss: 0.100999
2025-07-02 10:37:29,024 - INFO - Epoch 88/150 - Train Loss: 0.112036, Val Loss: 0.100978
2025-07-02 10:38:13,827 - INFO - Epoch 89/150 - Train Loss: 0.111140, Val Loss: 0.100872
2025-07-02 10:38:13,845 - INFO - New best model saved with Val Loss: 0.100872
2025-07-02 10:38:59,898 - INFO - Epoch 90/150 - Train Loss: 0.111373, Val Loss: 0.101360
2025-07-02 10:39:46,262 - INFO - Epoch 91/150 - Train Loss: 0.110803, Val Loss: 0.100967
2025-07-02 10:40:32,314 - INFO - Epoch 92/150 - Train Loss: 0.111550, Val Loss: 0.101122
2025-07-02 10:41:18,541 - INFO - Epoch 93/150 - Train Loss: 0.111214, Val Loss: 0.101079
2025-07-02 10:42:04,283 - INFO - Epoch 94/150 - Train Loss: 0.110622, Val Loss: 0.101070
2025-07-02 10:42:49,446 - INFO - Epoch 95/150 - Train Loss: 0.111025, Val Loss: 0.100847
2025-07-02 10:42:49,476 - INFO - New best model saved with Val Loss: 0.100847
2025-07-02 10:43:34,809 - INFO - Epoch 96/150 - Train Loss: 0.110931, Val Loss: 0.100946
2025-07-02 10:44:20,319 - INFO - Epoch 97/150 - Train Loss: 0.111296, Val Loss: 0.101126
2025-07-02 10:45:06,479 - INFO - Epoch 98/150 - Train Loss: 0.111636, Val Loss: 0.100806
2025-07-02 10:45:06,497 - INFO - New best model saved with Val Loss: 0.100806
2025-07-02 10:45:52,887 - INFO - Epoch 99/150 - Train Loss: 0.107761, Val Loss: 0.100924
2025-07-02 10:46:38,546 - INFO - Epoch 100/150 - Train Loss: 0.110888, Val Loss: 0.100864
2025-07-02 10:47:24,243 - INFO - Epoch 101/150 - Train Loss: 0.111423, Val Loss: 0.100831
2025-07-02 10:48:09,800 - INFO - Epoch 102/150 - Train Loss: 0.111504, Val Loss: 0.100779
2025-07-02 10:48:09,819 - INFO - New best model saved with Val Loss: 0.100779
2025-07-02 10:48:55,330 - INFO - Epoch 103/150 - Train Loss: 0.110363, Val Loss: 0.100840
2025-07-02 10:49:40,660 - INFO - Epoch 104/150 - Train Loss: 0.111284, Val Loss: 0.100882
2025-07-02 10:50:26,248 - INFO - Epoch 105/150 - Train Loss: 0.110993, Val Loss: 0.101063
2025-07-02 10:51:11,219 - INFO - Epoch 106/150 - Train Loss: 0.111335, Val Loss: 0.100919
2025-07-02 10:51:56,012 - INFO - Epoch 107/150 - Train Loss: 0.111190, Val Loss: 0.101027
2025-07-02 10:52:40,740 - INFO - Epoch 108/150 - Train Loss: 0.111392, Val Loss: 0.101150
2025-07-02 10:53:25,534 - INFO - Epoch 109/150 - Train Loss: 0.111451, Val Loss: 0.100945
2025-07-02 10:54:10,260 - INFO - Epoch 110/150 - Train Loss: 0.111334, Val Loss: 0.100793
2025-07-02 10:54:55,204 - INFO - Epoch 111/150 - Train Loss: 0.111340, Val Loss: 0.100805
2025-07-02 10:55:39,941 - INFO - Epoch 112/150 - Train Loss: 0.112088, Val Loss: 0.100891
2025-07-02 10:57:11,966 - INFO - Arguments: Namespace(exp_name='DrivAerNet_Pressure', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=6, epochs=20, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-07-02 10:57:11,967 - INFO - Starting training with 1 GPUs
2025-07-02 10:57:14,279 - INFO - Total trainable parameters: 1437705
2025-07-02 10:57:14,335 - INFO - Data loaded: 14 training batches, 3 validation batches, 4 test batches
2025-07-02 10:57:14,336 - INFO - Starting training for 20 epochs
2025-07-02 10:57:36,639 - INFO - Epoch 1/20 - Train Loss: 0.930810, Val Loss: 1.131250
2025-07-02 10:57:36,660 - INFO - New best model saved with Val Loss: 1.131250
2025-07-02 10:57:56,602 - INFO - Epoch 2/20 - Train Loss: 0.585299, Val Loss: 1.066539
2025-07-02 10:57:56,621 - INFO - New best model saved with Val Loss: 1.066539
2025-07-02 10:58:16,636 - INFO - Epoch 3/20 - Train Loss: 0.486702, Val Loss: 0.819513
2025-07-02 10:58:16,656 - INFO - New best model saved with Val Loss: 0.819513
2025-07-02 10:58:36,723 - INFO - Epoch 4/20 - Train Loss: 0.444137, Val Loss: 1.587437
2025-07-02 10:58:56,846 - INFO - Epoch 5/20 - Train Loss: 0.406975, Val Loss: 8.489146
2025-07-02 10:59:16,857 - INFO - Epoch 6/20 - Train Loss: 0.384812, Val Loss: 1.033551
2025-07-02 10:59:36,778 - INFO - Epoch 7/20 - Train Loss: 0.376831, Val Loss: 2.649909
2025-07-02 10:59:56,652 - INFO - Epoch 8/20 - Train Loss: 0.357763, Val Loss: 0.529296
2025-07-02 10:59:56,670 - INFO - New best model saved with Val Loss: 0.529296
2025-07-02 11:00:16,561 - INFO - Epoch 9/20 - Train Loss: 0.339780, Val Loss: 0.375473
2025-07-02 11:00:16,578 - INFO - New best model saved with Val Loss: 0.375473
2025-07-02 11:00:36,486 - INFO - Epoch 10/20 - Train Loss: 0.327349, Val Loss: 0.313255
2025-07-02 11:00:36,503 - INFO - New best model saved with Val Loss: 0.313255
2025-07-02 11:00:56,539 - INFO - Epoch 11/20 - Train Loss: 0.317118, Val Loss: 0.356053
2025-07-02 11:01:16,470 - INFO - Epoch 12/20 - Train Loss: 0.307357, Val Loss: 0.369187
2025-07-02 11:01:36,355 - INFO - Epoch 13/20 - Train Loss: 0.293100, Val Loss: 0.504600
2025-07-02 11:01:56,583 - INFO - Epoch 14/20 - Train Loss: 0.276621, Val Loss: 1.232062
2025-07-02 11:02:17,047 - INFO - Epoch 15/20 - Train Loss: 0.270153, Val Loss: 0.527786
2025-07-02 11:02:37,324 - INFO - Epoch 16/20 - Train Loss: 0.268686, Val Loss: 0.628549
2025-07-02 11:02:57,515 - INFO - Epoch 17/20 - Train Loss: 0.263979, Val Loss: 0.428107
2025-07-02 11:03:17,964 - INFO - Epoch 18/20 - Train Loss: 0.252787, Val Loss: 0.259835
2025-07-02 11:03:17,984 - INFO - New best model saved with Val Loss: 0.259835
2025-07-02 11:03:38,510 - INFO - Epoch 19/20 - Train Loss: 0.245284, Val Loss: 0.336924
2025-07-02 11:03:58,794 - INFO - Epoch 20/20 - Train Loss: 0.236300, Val Loss: 0.391533
2025-07-02 11:03:58,946 - INFO - Final model saved to experiments/DrivAerNet_Pressure/final_model.pth
2025-07-02 11:03:58,948 - INFO - Testing the final model
2025-07-02 11:04:03,805 - INFO - Testing the best model
2025-07-02 14:37:18,243 - INFO - Arguments: Namespace(exp_name='DrivAerNet_Pressure', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data', num_points=10000, batch_size=12, epochs=150, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-07-02 14:37:18,246 - INFO - Starting training with 1 GPUs
2025-07-02 14:37:25,531 - INFO - Total trainable parameters: 1437705
2025-07-02 14:37:25,698 - INFO - Data loaded: 19 training batches, 4 validation batches, 4 test batches
2025-07-02 14:37:25,701 - INFO - Starting training for 150 epochs
2025-07-02 14:38:59,781 - INFO - Arguments: Namespace(exp_name='DrivAerNet_Pressure', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data', num_points=10000, batch_size=6, epochs=150, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-07-02 14:38:59,809 - INFO - Starting training with 1 GPUs
2025-07-02 14:39:04,646 - INFO - Total trainable parameters: 1437705
2025-07-02 14:39:04,858 - INFO - Data loaded: 39 training batches, 8 validation batches, 9 test batches
2025-07-02 14:39:04,860 - INFO - Starting training for 150 epochs
2025-07-02 14:39:52,747 - INFO - Epoch 1/150 - Train Loss: 0.752180, Val Loss: 1.124732
2025-07-02 14:39:52,786 - INFO - New best model saved with Val Loss: 1.124732
2025-07-02 14:40:39,531 - INFO - Epoch 2/150 - Train Loss: 0.410244, Val Loss: 0.379351
2025-07-02 14:40:39,555 - INFO - New best model saved with Val Loss: 0.379351
2025-07-02 14:41:26,452 - INFO - Epoch 3/150 - Train Loss: 0.348636, Val Loss: 0.409999
2025-07-02 14:42:13,541 - INFO - Epoch 4/150 - Train Loss: 0.313532, Val Loss: 0.295374
2025-07-02 14:42:13,563 - INFO - New best model saved with Val Loss: 0.295374
2025-07-02 14:43:00,552 - INFO - Epoch 5/150 - Train Loss: 0.286809, Val Loss: 0.481297
2025-07-02 14:43:47,457 - INFO - Epoch 6/150 - Train Loss: 0.267345, Val Loss: 3.256105
2025-07-02 14:44:34,515 - INFO - Epoch 7/150 - Train Loss: 0.248175, Val Loss: 0.297765
2025-07-02 14:45:21,214 - INFO - Epoch 8/150 - Train Loss: 0.233266, Val Loss: 0.295982
2025-07-02 14:46:08,151 - INFO - Epoch 9/150 - Train Loss: 0.223489, Val Loss: 0.655006
2025-07-02 14:46:55,168 - INFO - Epoch 10/150 - Train Loss: 0.215305, Val Loss: 0.423533
2025-07-02 14:47:42,453 - INFO - Epoch 11/150 - Train Loss: 0.203425, Val Loss: 0.388887
2025-07-02 14:48:29,580 - INFO - Epoch 12/150 - Train Loss: 0.193738, Val Loss: 0.255016
2025-07-02 14:48:29,606 - INFO - New best model saved with Val Loss: 0.255016
2025-07-02 14:49:16,797 - INFO - Epoch 13/150 - Train Loss: 0.193163, Val Loss: 0.278204
2025-07-02 14:50:03,864 - INFO - Epoch 14/150 - Train Loss: 0.191126, Val Loss: 0.221406
2025-07-02 14:50:03,902 - INFO - New best model saved with Val Loss: 0.221406
2025-07-02 14:50:50,764 - INFO - Epoch 15/150 - Train Loss: 0.184478, Val Loss: 0.215028
2025-07-02 14:50:50,784 - INFO - New best model saved with Val Loss: 0.215028
2025-07-02 14:51:37,716 - INFO - Epoch 16/150 - Train Loss: 0.178109, Val Loss: 0.325122
2025-07-02 14:52:24,636 - INFO - Epoch 17/150 - Train Loss: 0.174796, Val Loss: 0.258391
2025-07-02 14:53:11,809 - INFO - Epoch 18/150 - Train Loss: 0.174784, Val Loss: 0.225220
2025-07-02 14:53:58,726 - INFO - Epoch 19/150 - Train Loss: 0.169611, Val Loss: 0.248846
2025-07-02 14:54:45,736 - INFO - Epoch 20/150 - Train Loss: 0.167436, Val Loss: 0.471155
2025-07-02 14:55:32,651 - INFO - Epoch 21/150 - Train Loss: 0.163698, Val Loss: 0.192040
2025-07-02 14:55:32,675 - INFO - New best model saved with Val Loss: 0.192040
2025-07-02 14:56:19,653 - INFO - Epoch 22/150 - Train Loss: 0.161416, Val Loss: 0.370374
2025-07-02 14:57:07,057 - INFO - Epoch 23/150 - Train Loss: 0.158124, Val Loss: 0.158734
2025-07-02 14:57:07,078 - INFO - New best model saved with Val Loss: 0.158734
2025-07-02 14:57:54,187 - INFO - Epoch 24/150 - Train Loss: 0.155866, Val Loss: 0.205952
2025-07-02 14:58:41,311 - INFO - Epoch 25/150 - Train Loss: 0.155378, Val Loss: 0.184193
2025-07-02 14:59:28,052 - INFO - Epoch 26/150 - Train Loss: 0.150835, Val Loss: 0.167461
2025-07-02 15:00:15,134 - INFO - Epoch 27/150 - Train Loss: 0.149848, Val Loss: 0.153055
2025-07-02 15:00:15,168 - INFO - New best model saved with Val Loss: 0.153055
2025-07-02 15:01:02,265 - INFO - Epoch 28/150 - Train Loss: 0.154199, Val Loss: 0.136550
2025-07-02 15:01:02,286 - INFO - New best model saved with Val Loss: 0.136550
2025-07-02 15:01:49,357 - INFO - Epoch 29/150 - Train Loss: 0.143742, Val Loss: 0.152760
2025-07-02 15:02:36,491 - INFO - Epoch 30/150 - Train Loss: 0.144288, Val Loss: 0.193623
2025-07-02 15:03:23,409 - INFO - Epoch 31/150 - Train Loss: 0.145189, Val Loss: 0.166961
2025-07-02 15:04:10,213 - INFO - Epoch 32/150 - Train Loss: 0.141460, Val Loss: 0.157264
2025-07-02 15:04:57,386 - INFO - Epoch 33/150 - Train Loss: 0.145188, Val Loss: 0.219487
2025-07-02 15:05:44,558 - INFO - Epoch 34/150 - Train Loss: 0.138041, Val Loss: 0.179359
2025-07-02 15:06:31,626 - INFO - Epoch 35/150 - Train Loss: 0.139006, Val Loss: 0.147838
2025-07-02 15:07:18,843 - INFO - Epoch 36/150 - Train Loss: 0.133996, Val Loss: 0.173444
2025-07-02 15:08:05,851 - INFO - Epoch 37/150 - Train Loss: 0.133981, Val Loss: 0.150009
2025-07-02 15:08:53,097 - INFO - Epoch 38/150 - Train Loss: 0.130496, Val Loss: 0.138145
2025-07-02 15:09:40,287 - INFO - Epoch 39/150 - Train Loss: 0.134783, Val Loss: 0.167007
2025-07-02 15:10:27,391 - INFO - Epoch 40/150 - Train Loss: 0.123822, Val Loss: 0.106565
2025-07-02 15:10:27,412 - INFO - New best model saved with Val Loss: 0.106565
2025-07-02 15:11:14,759 - INFO - Epoch 41/150 - Train Loss: 0.119583, Val Loss: 0.107501
2025-07-02 15:12:02,035 - INFO - Epoch 42/150 - Train Loss: 0.119099, Val Loss: 0.107230
2025-07-02 15:12:49,176 - INFO - Epoch 43/150 - Train Loss: 0.118426, Val Loss: 0.105269
2025-07-02 15:12:49,197 - INFO - New best model saved with Val Loss: 0.105269
2025-07-02 15:13:36,243 - INFO - Epoch 44/150 - Train Loss: 0.117692, Val Loss: 0.106267
2025-07-02 15:14:23,336 - INFO - Epoch 45/150 - Train Loss: 0.116777, Val Loss: 0.105962
2025-07-02 15:15:10,509 - INFO - Epoch 46/150 - Train Loss: 0.117086, Val Loss: 0.104997
2025-07-02 15:15:10,531 - INFO - New best model saved with Val Loss: 0.104997
2025-07-02 15:15:57,763 - INFO - Epoch 47/150 - Train Loss: 0.116806, Val Loss: 0.104811
2025-07-02 15:15:57,787 - INFO - New best model saved with Val Loss: 0.104811
2025-07-02 15:16:45,050 - INFO - Epoch 48/150 - Train Loss: 0.116484, Val Loss: 0.103583
2025-07-02 15:16:45,071 - INFO - New best model saved with Val Loss: 0.103583
2025-07-02 15:17:32,064 - INFO - Epoch 49/150 - Train Loss: 0.115938, Val Loss: 0.105950
2025-07-02 15:18:19,017 - INFO - Epoch 50/150 - Train Loss: 0.115517, Val Loss: 0.107515
2025-07-02 15:19:06,178 - INFO - Epoch 51/150 - Train Loss: 0.115423, Val Loss: 0.103660
2025-07-02 15:19:53,309 - INFO - Epoch 52/150 - Train Loss: 0.115276, Val Loss: 0.104326
2025-07-02 15:20:40,412 - INFO - Epoch 53/150 - Train Loss: 0.114554, Val Loss: 0.103713
2025-07-02 15:21:27,364 - INFO - Epoch 54/150 - Train Loss: 0.114361, Val Loss: 0.106248
2025-07-02 15:22:14,486 - INFO - Epoch 55/150 - Train Loss: 0.115308, Val Loss: 0.104109
2025-07-02 15:23:01,666 - INFO - Epoch 56/150 - Train Loss: 0.114578, Val Loss: 0.105009
2025-07-02 15:23:48,783 - INFO - Epoch 57/150 - Train Loss: 0.115096, Val Loss: 0.103757
2025-07-02 15:24:35,862 - INFO - Epoch 58/150 - Train Loss: 0.114655, Val Loss: 0.106341
2025-07-02 15:25:22,971 - INFO - Epoch 59/150 - Train Loss: 0.115159, Val Loss: 0.107205
2025-07-02 15:26:10,080 - INFO - Epoch 60/150 - Train Loss: 0.112579, Val Loss: 0.101850
2025-07-02 15:26:10,102 - INFO - New best model saved with Val Loss: 0.101850
2025-07-02 15:26:57,268 - INFO - Epoch 61/150 - Train Loss: 0.112142, Val Loss: 0.101521
2025-07-02 15:26:57,288 - INFO - New best model saved with Val Loss: 0.101521
2025-07-02 15:27:44,367 - INFO - Epoch 62/150 - Train Loss: 0.112451, Val Loss: 0.101256
2025-07-02 15:27:44,388 - INFO - New best model saved with Val Loss: 0.101256
2025-07-02 15:28:31,563 - INFO - Epoch 63/150 - Train Loss: 0.112573, Val Loss: 0.101790
2025-07-02 15:29:18,704 - INFO - Epoch 64/150 - Train Loss: 0.112334, Val Loss: 0.101467
2025-07-02 15:30:05,630 - INFO - Epoch 65/150 - Train Loss: 0.112359, Val Loss: 0.101630
2025-07-02 15:30:52,821 - INFO - Epoch 66/150 - Train Loss: 0.112317, Val Loss: 0.101602
2025-07-02 15:31:39,977 - INFO - Epoch 67/150 - Train Loss: 0.111656, Val Loss: 0.101648
2025-07-02 15:32:26,956 - INFO - Epoch 68/150 - Train Loss: 0.112325, Val Loss: 0.101424
2025-07-02 15:33:13,945 - INFO - Epoch 69/150 - Train Loss: 0.112211, Val Loss: 0.101313
2025-07-02 15:34:01,105 - INFO - Epoch 70/150 - Train Loss: 0.111580, Val Loss: 0.101064
2025-07-02 15:34:01,128 - INFO - New best model saved with Val Loss: 0.101064
2025-07-02 15:34:48,639 - INFO - Epoch 71/150 - Train Loss: 0.111994, Val Loss: 0.101423
2025-07-02 15:35:35,650 - INFO - Epoch 72/150 - Train Loss: 0.111675, Val Loss: 0.101559
2025-07-02 15:36:22,778 - INFO - Epoch 73/150 - Train Loss: 0.112274, Val Loss: 0.101257
2025-07-02 15:37:09,541 - INFO - Epoch 74/150 - Train Loss: 0.111927, Val Loss: 0.101388
2025-07-02 15:37:56,747 - INFO - Epoch 75/150 - Train Loss: 0.112268, Val Loss: 0.101364
2025-07-02 15:38:43,877 - INFO - Epoch 76/150 - Train Loss: 0.111703, Val Loss: 0.101176
2025-07-02 15:39:31,050 - INFO - Epoch 77/150 - Train Loss: 0.111602, Val Loss: 0.100929
2025-07-02 15:39:31,074 - INFO - New best model saved with Val Loss: 0.100929
2025-07-02 15:40:18,322 - INFO - Epoch 78/150 - Train Loss: 0.110812, Val Loss: 0.101396
2025-07-02 15:41:05,732 - INFO - Epoch 79/150 - Train Loss: 0.111649, Val Loss: 0.101161
2025-07-02 15:41:52,596 - INFO - Epoch 80/150 - Train Loss: 0.111938, Val Loss: 0.101558
2025-07-02 15:42:40,136 - INFO - Epoch 81/150 - Train Loss: 0.111773, Val Loss: 0.100997
2025-07-02 15:43:27,308 - INFO - Epoch 82/150 - Train Loss: 0.111186, Val Loss: 0.101250
2025-07-02 15:44:14,584 - INFO - Epoch 83/150 - Train Loss: 0.112286, Val Loss: 0.101473
2025-07-02 15:45:01,970 - INFO - Epoch 84/150 - Train Loss: 0.111227, Val Loss: 0.101389
2025-07-02 15:45:49,270 - INFO - Epoch 85/150 - Train Loss: 0.111354, Val Loss: 0.101104
2025-07-02 15:46:36,736 - INFO - Epoch 86/150 - Train Loss: 0.111357, Val Loss: 0.101038
2025-07-02 15:47:23,866 - INFO - Epoch 87/150 - Train Loss: 0.111645, Val Loss: 0.100999
2025-07-02 15:48:10,930 - INFO - Epoch 88/150 - Train Loss: 0.112036, Val Loss: 0.100978
2025-07-02 15:48:58,133 - INFO - Epoch 89/150 - Train Loss: 0.111140, Val Loss: 0.100872
2025-07-02 15:48:58,156 - INFO - New best model saved with Val Loss: 0.100872
2025-07-02 15:49:45,377 - INFO - Epoch 90/150 - Train Loss: 0.111373, Val Loss: 0.101360
2025-07-02 15:50:32,930 - INFO - Epoch 91/150 - Train Loss: 0.110803, Val Loss: 0.100967
2025-07-02 15:51:20,200 - INFO - Epoch 92/150 - Train Loss: 0.111550, Val Loss: 0.101122
2025-07-02 15:52:07,580 - INFO - Epoch 93/150 - Train Loss: 0.111214, Val Loss: 0.101079
2025-07-02 15:52:54,864 - INFO - Epoch 94/150 - Train Loss: 0.110622, Val Loss: 0.101070
2025-07-02 15:53:41,965 - INFO - Epoch 95/150 - Train Loss: 0.111025, Val Loss: 0.100847
2025-07-02 15:53:41,987 - INFO - New best model saved with Val Loss: 0.100847
2025-07-02 15:54:29,266 - INFO - Epoch 96/150 - Train Loss: 0.110931, Val Loss: 0.100946
2025-07-02 15:55:16,666 - INFO - Epoch 97/150 - Train Loss: 0.111296, Val Loss: 0.101126
2025-07-02 15:56:03,915 - INFO - Epoch 98/150 - Train Loss: 0.111636, Val Loss: 0.100806
2025-07-02 15:56:03,937 - INFO - New best model saved with Val Loss: 0.100806
2025-07-02 15:56:50,995 - INFO - Epoch 99/150 - Train Loss: 0.107761, Val Loss: 0.100924
2025-07-02 15:57:38,106 - INFO - Epoch 100/150 - Train Loss: 0.110888, Val Loss: 0.100864
2025-07-02 15:58:25,607 - INFO - Epoch 101/150 - Train Loss: 0.111423, Val Loss: 0.100831
2025-07-02 15:59:12,885 - INFO - Epoch 102/150 - Train Loss: 0.111504, Val Loss: 0.100779
2025-07-02 15:59:12,904 - INFO - New best model saved with Val Loss: 0.100779
2025-07-02 16:00:00,523 - INFO - Epoch 103/150 - Train Loss: 0.110363, Val Loss: 0.100840
2025-07-02 16:00:47,621 - INFO - Epoch 104/150 - Train Loss: 0.111284, Val Loss: 0.100882
2025-07-02 16:01:35,062 - INFO - Epoch 105/150 - Train Loss: 0.110993, Val Loss: 0.101063
2025-07-02 16:02:21,954 - INFO - Epoch 106/150 - Train Loss: 0.111335, Val Loss: 0.100919
2025-07-02 16:03:09,843 - INFO - Epoch 107/150 - Train Loss: 0.111190, Val Loss: 0.101027
2025-07-02 16:03:57,079 - INFO - Epoch 108/150 - Train Loss: 0.111392, Val Loss: 0.101150
2025-07-02 16:04:44,228 - INFO - Epoch 109/150 - Train Loss: 0.111451, Val Loss: 0.100945
2025-07-02 16:05:31,577 - INFO - Epoch 110/150 - Train Loss: 0.111334, Val Loss: 0.100793
2025-07-02 16:06:19,180 - INFO - Epoch 111/150 - Train Loss: 0.111340, Val Loss: 0.100805
2025-07-02 16:07:06,413 - INFO - Epoch 112/150 - Train Loss: 0.112088, Val Loss: 0.100891
2025-07-02 16:07:53,587 - INFO - Epoch 113/150 - Train Loss: 0.112194, Val Loss: 0.100758
2025-07-02 16:07:53,606 - INFO - New best model saved with Val Loss: 0.100758
2025-07-02 16:08:41,296 - INFO - Epoch 114/150 - Train Loss: 0.111665, Val Loss: 0.101036
2025-07-02 16:09:29,571 - INFO - Epoch 115/150 - Train Loss: 0.111541, Val Loss: 0.100667
2025-07-02 16:09:29,591 - INFO - New best model saved with Val Loss: 0.100667
2025-07-02 16:10:16,953 - INFO - Epoch 116/150 - Train Loss: 0.111737, Val Loss: 0.101022
2025-07-02 16:11:03,953 - INFO - Epoch 117/150 - Train Loss: 0.111449, Val Loss: 0.100828
2025-07-02 16:11:51,147 - INFO - Epoch 118/150 - Train Loss: 0.110879, Val Loss: 0.101010
2025-07-02 16:12:38,299 - INFO - Epoch 119/150 - Train Loss: 0.111162, Val Loss: 0.101130
2025-07-02 16:13:25,806 - INFO - Epoch 120/150 - Train Loss: 0.110652, Val Loss: 0.101108
2025-07-02 16:14:13,166 - INFO - Epoch 121/150 - Train Loss: 0.111208, Val Loss: 0.101022
2025-07-02 16:15:00,454 - INFO - Epoch 122/150 - Train Loss: 0.111119, Val Loss: 0.100764
2025-07-02 16:15:47,684 - INFO - Epoch 123/150 - Train Loss: 0.111224, Val Loss: 0.100755
2025-07-02 16:16:34,935 - INFO - Epoch 124/150 - Train Loss: 0.111680, Val Loss: 0.100771
2025-07-02 16:17:22,359 - INFO - Epoch 125/150 - Train Loss: 0.111103, Val Loss: 0.100727
2025-07-02 16:18:09,809 - INFO - Epoch 126/150 - Train Loss: 0.109218, Val Loss: 0.101016
2025-07-02 16:18:56,850 - INFO - Epoch 127/150 - Train Loss: 0.110773, Val Loss: 0.100918
2025-07-02 16:19:44,105 - INFO - Epoch 128/150 - Train Loss: 0.111515, Val Loss: 0.100885
2025-07-02 16:20:31,143 - INFO - Epoch 129/150 - Train Loss: 0.110828, Val Loss: 0.100919
2025-07-02 16:21:18,283 - INFO - Epoch 130/150 - Train Loss: 0.111200, Val Loss: 0.100731
2025-07-02 16:22:05,649 - INFO - Epoch 131/150 - Train Loss: 0.111076, Val Loss: 0.100860
2025-07-02 16:22:52,905 - INFO - Epoch 132/150 - Train Loss: 0.111362, Val Loss: 0.100931
2025-07-02 16:23:40,040 - INFO - Epoch 133/150 - Train Loss: 0.111084, Val Loss: 0.100533
2025-07-02 16:23:40,062 - INFO - New best model saved with Val Loss: 0.100533
2025-07-02 16:24:26,919 - INFO - Epoch 134/150 - Train Loss: 0.111459, Val Loss: 0.100953
2025-07-02 16:25:14,112 - INFO - Epoch 135/150 - Train Loss: 0.111771, Val Loss: 0.100807
2025-07-02 16:26:01,034 - INFO - Epoch 136/150 - Train Loss: 0.110902, Val Loss: 0.100884
2025-07-02 16:26:48,423 - INFO - Epoch 137/150 - Train Loss: 0.110943, Val Loss: 0.101010
2025-07-02 16:27:35,834 - INFO - Epoch 138/150 - Train Loss: 0.111562, Val Loss: 0.100699
2025-07-02 16:28:23,100 - INFO - Epoch 139/150 - Train Loss: 0.110941, Val Loss: 0.101229
2025-07-02 16:29:10,499 - INFO - Epoch 140/150 - Train Loss: 0.111054, Val Loss: 0.100888
2025-07-02 16:29:57,944 - INFO - Epoch 141/150 - Train Loss: 0.111287, Val Loss: 0.100840
2025-07-02 16:30:45,236 - INFO - Epoch 142/150 - Train Loss: 0.111119, Val Loss: 0.100915
2025-07-02 16:31:32,778 - INFO - Epoch 143/150 - Train Loss: 0.111254, Val Loss: 0.101041
2025-07-02 16:32:20,260 - INFO - Epoch 144/150 - Train Loss: 0.111139, Val Loss: 0.100839
2025-07-02 16:33:07,686 - INFO - Epoch 145/150 - Train Loss: 0.110496, Val Loss: 0.101012
2025-07-02 16:33:54,886 - INFO - Epoch 146/150 - Train Loss: 0.111641, Val Loss: 0.100863
2025-07-02 16:34:42,232 - INFO - Epoch 147/150 - Train Loss: 0.111523, Val Loss: 0.100461
2025-07-02 16:34:42,251 - INFO - New best model saved with Val Loss: 0.100461
2025-07-02 16:35:29,569 - INFO - Epoch 148/150 - Train Loss: 0.110912, Val Loss: 0.100984
2025-07-02 16:36:16,963 - INFO - Epoch 149/150 - Train Loss: 0.110507, Val Loss: 0.100842
2025-07-02 16:37:04,272 - INFO - Epoch 150/150 - Train Loss: 0.111389, Val Loss: 0.100568
2025-07-02 16:37:04,443 - INFO - Final model saved to experiments/DrivAerNet_Pressure/final_model.pth
2025-07-02 16:37:04,444 - INFO - Testing the final model
2025-07-02 16:37:11,795 - INFO - Testing the best model
