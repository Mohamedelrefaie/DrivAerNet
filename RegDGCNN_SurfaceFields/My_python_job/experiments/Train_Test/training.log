2025-06-24 11:16:30,620 - INFO - args.exp_name : Train_Test
2025-06-24 11:16:30,620 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=6, epochs=10, lr=0.001, num_workers=4, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-24 11:16:30,620 - INFO - Starting training with 1 GPUs
2025-06-24 11:24:59,837 - INFO - args.exp_name : Train_Test
2025-06-24 11:24:59,842 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=6, epochs=10, lr=0.001, num_workers=4, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-24 11:24:59,842 - INFO - Starting training with 1 GPUs
2025-06-24 16:00:07,086 - INFO - args.exp_name : Train_Test
2025-06-24 16:00:07,093 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=6, epochs=10, lr=0.001, num_workers=4, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-24 16:00:07,093 - INFO - Starting training with 1 GPUs
2025-06-24 16:00:07,107 - INFO - points: shape = (10000, 3), dtype = float32
2025-06-24 16:00:07,108 - INFO - pressures: shape = (10000,), dtype = float32
2025-06-25 09:37:48,977 - INFO - args.exp_name : Train_Test
2025-06-25 09:37:48,978 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=6, epochs=10, lr=0.001, num_workers=4, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-25 09:37:48,978 - INFO - Starting training with 1 GPUs
2025-06-25 09:37:48,995 - INFO - points: shape = (10000, 3), dtype = float32
2025-06-25 09:37:48,996 - INFO - pressures: shape = (10000,), dtype = float32
2025-06-25 09:39:06,417 - INFO - args.exp_name : Train_Test
2025-06-25 09:39:06,418 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=6, epochs=10, lr=0.001, num_workers=4, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-25 09:39:06,418 - INFO - Starting training with 1 GPUs
2025-06-25 09:43:55,282 - INFO - args.exp_name : Train_Test
2025-06-25 09:43:55,283 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=6, epochs=10, lr=0.001, num_workers=4, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-25 09:43:55,285 - INFO - Starting training with 1 GPUs
2025-06-25 09:43:58,808 - INFO - Total trainable parameters: 1437705
2025-06-25 10:09:51,283 - INFO - args.exp_name : Train_Test
2025-06-25 10:09:51,285 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=6, epochs=10, lr=0.001, num_workers=4, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-25 10:09:51,285 - INFO - Starting training with 1 GPUs
2025-06-25 10:09:55,578 - INFO - Total trainable parameters: 1437705
2025-06-25 10:38:38,659 - INFO - args.exp_name : Train_Test
2025-06-25 10:38:38,660 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=6, epochs=10, lr=0.001, num_workers=4, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-25 10:38:38,660 - INFO - Starting training with 1 GPUs
2025-06-25 10:38:42,390 - INFO - Total trainable parameters: 1437705
2025-06-25 10:38:42,390 - INFO - shape: , torch.Size([64])
2025-06-25 10:38:42,516 - INFO - values: , Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',
       requires_grad=True)
2025-06-25 10:38:42,516 - INFO - shape: , torch.Size([64])
2025-06-25 10:38:42,516 - INFO - values: , Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,516 - INFO - shape: , torch.Size([128])
2025-06-25 10:38:42,522 - INFO - values: , Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1.], device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,522 - INFO - shape: , torch.Size([128])
2025-06-25 10:38:42,522 - INFO - values: , Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,522 - INFO - shape: , torch.Size([1024])
2025-06-25 10:38:42,523 - INFO - values: , Parameter containing:
tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,526 - INFO - shape: , torch.Size([1024])
2025-06-25 10:38:42,526 - INFO - values: , Parameter containing:
tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,526 - INFO - shape: , torch.Size([64, 6, 1, 1])
2025-06-25 10:38:42,542 - INFO - values: , Parameter containing:
tensor([[[[ 0.2104]],

         [[-0.1802]],

         [[-0.0791]],

         [[ 0.1916]],

         [[-0.3843]],

         [[ 0.2448]]],


        [[[-0.0840]],

         [[ 0.2077]],

         [[ 0.0568]],

         [[-0.0500]],

         [[ 0.1132]],

         [[ 0.0201]]],


        [[[ 0.1491]],

         [[-0.1591]],

         [[-0.0298]],

         [[-0.0368]],

         [[ 0.0592]],

         [[-0.0016]]],


        [[[ 0.3569]],

         [[ 0.1270]],

         [[-0.1520]],

         [[-0.2466]],

         [[-0.0684]],

         [[-0.1761]]],


        [[[-0.1308]],

         [[ 0.0195]],

         [[ 0.2434]],

         [[ 0.2219]],

         [[-0.3991]],

         [[ 0.2531]]],


        [[[ 0.1140]],

         [[ 0.3872]],

         [[ 0.2695]],

         [[-0.3720]],

         [[-0.3882]],

         [[-0.1969]]],


        [[[ 0.3585]],

         [[-0.0680]],

         [[ 0.1747]],

         [[-0.1897]],

         [[ 0.4006]],

         [[-0.1727]]],


        [[[ 0.3062]],

         [[ 0.0048]],

         [[-0.2151]],

         [[ 0.2098]],

         [[-0.2167]],

         [[ 0.1201]]],


        [[[-0.1179]],

         [[-0.0448]],

         [[-0.3925]],

         [[-0.1946]],

         [[ 0.2215]],

         [[-0.0992]]],


        [[[ 0.4066]],

         [[ 0.3272]],

         [[-0.0191]],

         [[-0.2725]],

         [[ 0.2486]],

         [[ 0.1267]]],


        [[[-0.2639]],

         [[ 0.2652]],

         [[ 0.2478]],

         [[ 0.3621]],

         [[-0.2288]],

         [[-0.0672]]],


        [[[-0.0079]],

         [[ 0.0596]],

         [[-0.3098]],

         [[-0.2897]],

         [[ 0.2221]],

         [[-0.0957]]],


        [[[ 0.1994]],

         [[ 0.0233]],

         [[ 0.1340]],

         [[ 0.0898]],

         [[ 0.1484]],

         [[ 0.2024]]],


        [[[-0.3781]],

         [[ 0.2055]],

         [[-0.2870]],

         [[-0.3080]],

         [[ 0.0248]],

         [[-0.0696]]],


        [[[ 0.2398]],

         [[-0.2364]],

         [[-0.3629]],

         [[ 0.2971]],

         [[-0.0605]],

         [[ 0.2296]]],


        [[[ 0.1312]],

         [[-0.3061]],

         [[ 0.0820]],

         [[ 0.0981]],

         [[-0.2733]],

         [[-0.1937]]],


        [[[ 0.1392]],

         [[ 0.0731]],

         [[-0.1737]],

         [[-0.1236]],

         [[ 0.3739]],

         [[-0.0755]]],


        [[[ 0.2302]],

         [[ 0.1768]],

         [[-0.2639]],

         [[-0.3472]],

         [[ 0.3919]],

         [[ 0.0213]]],


        [[[ 0.2798]],

         [[ 0.0846]],

         [[ 0.1313]],

         [[ 0.3049]],

         [[ 0.3871]],

         [[-0.2709]]],


        [[[ 0.0510]],

         [[ 0.3047]],

         [[ 0.2957]],

         [[ 0.2536]],

         [[-0.2955]],

         [[-0.2940]]],


        [[[-0.2469]],

         [[ 0.0513]],

         [[ 0.4069]],

         [[-0.2579]],

         [[ 0.2175]],

         [[-0.2260]]],


        [[[-0.3838]],

         [[-0.0868]],

         [[ 0.2352]],

         [[ 0.3790]],

         [[-0.2535]],

         [[ 0.0886]]],


        [[[ 0.3523]],

         [[ 0.2705]],

         [[ 0.2544]],

         [[ 0.2901]],

         [[ 0.2582]],

         [[ 0.1054]]],


        [[[-0.2792]],

         [[-0.3428]],

         [[-0.1871]],

         [[-0.0475]],

         [[-0.2502]],

         [[ 0.1494]]],


        [[[ 0.1263]],

         [[-0.0924]],

         [[ 0.1569]],

         [[ 0.1319]],

         [[ 0.2493]],

         [[ 0.2749]]],


        [[[-0.1383]],

         [[ 0.3989]],

         [[-0.0472]],

         [[-0.0140]],

         [[-0.3853]],

         [[-0.2628]]],


        [[[-0.2385]],

         [[-0.1746]],

         [[ 0.2903]],

         [[-0.1334]],

         [[-0.3051]],

         [[ 0.1571]]],


        [[[ 0.1307]],

         [[ 0.2644]],

         [[-0.2113]],

         [[ 0.0885]],

         [[-0.1486]],

         [[-0.0917]]],


        [[[-0.3253]],

         [[-0.1861]],

         [[-0.1250]],

         [[ 0.1746]],

         [[ 0.0746]],

         [[ 0.1008]]],


        [[[ 0.4075]],

         [[ 0.3979]],

         [[ 0.2784]],

         [[ 0.0130]],

         [[-0.2824]],

         [[ 0.3190]]],


        [[[-0.1021]],

         [[-0.0330]],

         [[-0.3517]],

         [[-0.0806]],

         [[-0.2633]],

         [[ 0.3751]]],


        [[[-0.3529]],

         [[-0.3182]],

         [[-0.0139]],

         [[-0.2207]],

         [[ 0.1461]],

         [[-0.1571]]],


        [[[-0.1917]],

         [[ 0.0231]],

         [[ 0.2955]],

         [[-0.2872]],

         [[ 0.1917]],

         [[ 0.2623]]],


        [[[ 0.3993]],

         [[-0.2857]],

         [[ 0.0989]],

         [[-0.3019]],

         [[ 0.3485]],

         [[-0.1584]]],


        [[[ 0.2459]],

         [[ 0.0122]],

         [[-0.0318]],

         [[-0.0130]],

         [[ 0.0694]],

         [[ 0.1924]]],


        [[[ 0.0655]],

         [[ 0.1245]],

         [[-0.3672]],

         [[ 0.2974]],

         [[ 0.3559]],

         [[ 0.3375]]],


        [[[ 0.3018]],

         [[-0.2946]],

         [[-0.1513]],

         [[ 0.3600]],

         [[-0.3109]],

         [[ 0.3704]]],


        [[[-0.3211]],

         [[-0.2876]],

         [[ 0.1996]],

         [[-0.2933]],

         [[-0.0935]],

         [[ 0.2970]]],


        [[[ 0.3234]],

         [[ 0.3861]],

         [[-0.0828]],

         [[-0.3173]],

         [[ 0.4020]],

         [[-0.0870]]],


        [[[-0.1680]],

         [[ 0.0995]],

         [[-0.2855]],

         [[ 0.2683]],

         [[ 0.2559]],

         [[-0.3239]]],


        [[[-0.3353]],

         [[-0.0358]],

         [[ 0.1715]],

         [[-0.0118]],

         [[-0.2070]],

         [[ 0.0093]]],


        [[[-0.3837]],

         [[-0.2885]],

         [[-0.2718]],

         [[ 0.3362]],

         [[ 0.3599]],

         [[-0.1387]]],


        [[[ 0.0183]],

         [[ 0.1821]],

         [[ 0.0489]],

         [[-0.2044]],

         [[ 0.2355]],

         [[ 0.2510]]],


        [[[-0.0237]],

         [[-0.0503]],

         [[ 0.3710]],

         [[ 0.3569]],

         [[-0.2315]],

         [[ 0.3994]]],


        [[[ 0.1010]],

         [[-0.2712]],

         [[ 0.2235]],

         [[-0.3048]],

         [[ 0.3772]],

         [[-0.2625]]],


        [[[ 0.1155]],

         [[ 0.1243]],

         [[ 0.0971]],

         [[ 0.3386]],

         [[-0.1696]],

         [[-0.1724]]],


        [[[-0.3538]],

         [[-0.0168]],

         [[-0.1934]],

         [[ 0.0164]],

         [[-0.0837]],

         [[ 0.1355]]],


        [[[ 0.3532]],

         [[ 0.1205]],

         [[-0.1315]],

         [[-0.2003]],

         [[-0.3561]],

         [[ 0.3435]]],


        [[[-0.0773]],

         [[ 0.0824]],

         [[ 0.0151]],

         [[-0.2602]],

         [[ 0.2299]],

         [[ 0.2288]]],


        [[[ 0.0206]],

         [[-0.2320]],

         [[-0.1735]],

         [[ 0.0056]],

         [[-0.2332]],

         [[-0.2278]]],


        [[[-0.0609]],

         [[-0.1176]],

         [[ 0.1002]],

         [[-0.1073]],

         [[-0.0541]],

         [[-0.1558]]],


        [[[-0.3731]],

         [[ 0.3560]],

         [[ 0.0779]],

         [[ 0.3651]],

         [[-0.0658]],

         [[-0.1026]]],


        [[[-0.3838]],

         [[-0.1550]],

         [[ 0.2677]],

         [[-0.3999]],

         [[-0.1428]],

         [[ 0.2487]]],


        [[[ 0.2353]],

         [[ 0.1507]],

         [[-0.0808]],

         [[-0.0309]],

         [[-0.0775]],

         [[-0.1505]]],


        [[[ 0.1704]],

         [[-0.1391]],

         [[-0.2293]],

         [[ 0.0926]],

         [[-0.2951]],

         [[-0.0871]]],


        [[[ 0.2086]],

         [[ 0.1526]],

         [[ 0.3476]],

         [[-0.2784]],

         [[ 0.0035]],

         [[-0.1206]]],


        [[[-0.2283]],

         [[-0.2297]],

         [[ 0.1029]],

         [[ 0.0427]],

         [[-0.2084]],

         [[-0.2878]]],


        [[[-0.3382]],

         [[ 0.4001]],

         [[-0.0696]],

         [[-0.0944]],

         [[-0.1501]],

         [[-0.2042]]],


        [[[-0.3733]],

         [[-0.2397]],

         [[ 0.2495]],

         [[ 0.0895]],

         [[-0.1440]],

         [[-0.1543]]],


        [[[ 0.2608]],

         [[ 0.2943]],

         [[ 0.3933]],

         [[ 0.1191]],

         [[ 0.1972]],

         [[-0.0328]]],


        [[[-0.2387]],

         [[-0.4000]],

         [[ 0.2487]],

         [[-0.0593]],

         [[ 0.1677]],

         [[ 0.0201]]],


        [[[-0.3810]],

         [[-0.2003]],

         [[ 0.1149]],

         [[-0.0826]],

         [[-0.3942]],

         [[ 0.1432]]],


        [[[ 0.0157]],

         [[-0.1312]],

         [[ 0.1649]],

         [[ 0.0862]],

         [[-0.1506]],

         [[ 0.3667]]],


        [[[ 0.2048]],

         [[ 0.0513]],

         [[-0.0784]],

         [[-0.3458]],

         [[ 0.3152]],

         [[-0.1053]]]], device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,543 - INFO - shape: , torch.Size([128, 64, 1, 1])
2025-06-25 10:38:42,546 - INFO - values: , Parameter containing:
tensor([[[[-0.0808]],

         [[ 0.0801]],

         [[ 0.0444]],

         ...,

         [[ 0.0592]],

         [[-0.0676]],

         [[ 0.0751]]],


        [[[-0.0619]],

         [[-0.1105]],

         [[ 0.0419]],

         ...,

         [[-0.0286]],

         [[-0.0789]],

         [[ 0.0325]]],


        [[[-0.0935]],

         [[ 0.0875]],

         [[ 0.0719]],

         ...,

         [[-0.0925]],

         [[-0.0367]],

         [[-0.0277]]],


        ...,


        [[[-0.0862]],

         [[ 0.1048]],

         [[ 0.0267]],

         ...,

         [[-0.0470]],

         [[ 0.1131]],

         [[ 0.0220]]],


        [[[-0.1204]],

         [[-0.1204]],

         [[ 0.1186]],

         ...,

         [[ 0.1118]],

         [[-0.1240]],

         [[ 0.0192]]],


        [[[ 0.1208]],

         [[-0.0812]],

         [[-0.1222]],

         ...,

         [[-0.0971]],

         [[ 0.0477]],

         [[-0.0167]]]], device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,546 - INFO - shape: , torch.Size([1024, 128, 1])
2025-06-25 10:38:42,548 - INFO - values: , Parameter containing:
tensor([[[-0.0402],
         [ 0.0031],
         [-0.0203],
         ...,
         [-0.0442],
         [-0.0669],
         [ 0.0306]],

        [[ 0.0071],
         [-0.0399],
         [ 0.0881],
         ...,
         [-0.0406],
         [ 0.0702],
         [ 0.0065]],

        [[ 0.0508],
         [-0.0571],
         [ 0.0168],
         ...,
         [ 0.0142],
         [ 0.0077],
         [ 0.0860]],

        ...,

        [[-0.0339],
         [ 0.0635],
         [ 0.0569],
         ...,
         [-0.0881],
         [-0.0744],
         [-0.0128]],

        [[-0.0349],
         [-0.0430],
         [ 0.0296],
         ...,
         [-0.0136],
         [ 0.0481],
         [-0.0138]],

        [[-0.0192],
         [-0.0866],
         [-0.0157],
         ...,
         [-0.0722],
         [-0.0168],
         [ 0.0350]]], device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,548 - INFO - shape: , torch.Size([512, 1024])
2025-06-25 10:38:42,549 - INFO - values: , Parameter containing:
tensor([[-0.0092,  0.0261,  0.0006,  ..., -0.0145,  0.0162,  0.0020],
        [ 0.0020,  0.0042, -0.0021,  ...,  0.0125, -0.0189,  0.0091],
        [ 0.0237, -0.0250, -0.0020,  ..., -0.0119,  0.0226, -0.0298],
        ...,
        [ 0.0052,  0.0286,  0.0177,  ...,  0.0105, -0.0227, -0.0107],
        [-0.0106,  0.0071, -0.0291,  ...,  0.0075, -0.0022, -0.0130],
        [-0.0216, -0.0093,  0.0104,  ..., -0.0306, -0.0012, -0.0045]],
       device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,549 - INFO - shape: , torch.Size([512])
2025-06-25 10:38:42,569 - INFO - values: , Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,570 - INFO - shape: , torch.Size([512])
2025-06-25 10:38:42,570 - INFO - values: , Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,571 - INFO - shape: , torch.Size([256, 512])
2025-06-25 10:38:42,573 - INFO - values: , Parameter containing:
tensor([[ 0.0095,  0.0058, -0.0355,  ..., -0.0400,  0.0399,  0.0425],
        [ 0.0262,  0.0091, -0.0043,  ...,  0.0402, -0.0261,  0.0349],
        [-0.0207, -0.0270,  0.0177,  ...,  0.0219, -0.0286, -0.0340],
        ...,
        [-0.0006,  0.0054,  0.0166,  ...,  0.0381,  0.0380,  0.0036],
        [-0.0321, -0.0181,  0.0030,  ...,  0.0080, -0.0127, -0.0304],
        [-0.0316, -0.0410,  0.0307,  ..., -0.0245,  0.0197,  0.0032]],
       device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,573 - INFO - shape: , torch.Size([256])
2025-06-25 10:38:42,583 - INFO - values: , Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,583 - INFO - shape: , torch.Size([256])
2025-06-25 10:38:42,583 - INFO - values: , Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,583 - INFO - shape: , torch.Size([9, 256])
2025-06-25 10:38:42,584 - INFO - values: , Parameter containing:
tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,585 - INFO - shape: , torch.Size([9])
2025-06-25 10:38:42,585 - INFO - values: , Parameter containing:
tensor([1., 0., 0., 0., 1., 0., 0., 0., 1.], device='cuda:0',
       requires_grad=True)
2025-06-25 10:38:42,585 - INFO - shape: , torch.Size([64])
2025-06-25 10:38:42,588 - INFO - values: , Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',
       requires_grad=True)
2025-06-25 10:38:42,588 - INFO - shape: , torch.Size([64])
2025-06-25 10:38:42,589 - INFO - values: , Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,589 - INFO - shape: , torch.Size([64])
2025-06-25 10:38:42,591 - INFO - values: , Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',
       requires_grad=True)
2025-06-25 10:38:42,592 - INFO - shape: , torch.Size([64])
2025-06-25 10:38:42,592 - INFO - values: , Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,592 - INFO - shape: , torch.Size([64])
2025-06-25 10:38:42,595 - INFO - values: , Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',
       requires_grad=True)
2025-06-25 10:38:42,595 - INFO - shape: , torch.Size([64])
2025-06-25 10:38:42,595 - INFO - values: , Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,595 - INFO - shape: , torch.Size([64])
2025-06-25 10:38:42,598 - INFO - values: , Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',
       requires_grad=True)
2025-06-25 10:38:42,598 - INFO - shape: , torch.Size([64])
2025-06-25 10:38:42,598 - INFO - values: , Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,598 - INFO - shape: , torch.Size([64])
2025-06-25 10:38:42,601 - INFO - values: , Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',
       requires_grad=True)
2025-06-25 10:38:42,602 - INFO - shape: , torch.Size([64])
2025-06-25 10:38:42,602 - INFO - values: , Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,603 - INFO - shape: , torch.Size([1024])
2025-06-25 10:38:42,603 - INFO - values: , Parameter containing:
tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,603 - INFO - shape: , torch.Size([1024])
2025-06-25 10:38:42,604 - INFO - values: , Parameter containing:
tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,604 - INFO - shape: , torch.Size([64])
2025-06-25 10:38:42,607 - INFO - values: , Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',
       requires_grad=True)
2025-06-25 10:38:42,607 - INFO - shape: , torch.Size([64])
2025-06-25 10:38:42,607 - INFO - values: , Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,607 - INFO - shape: , torch.Size([256])
2025-06-25 10:38:42,617 - INFO - values: , Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,617 - INFO - shape: , torch.Size([256])
2025-06-25 10:38:42,617 - INFO - values: , Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,618 - INFO - shape: , torch.Size([256])
2025-06-25 10:38:42,628 - INFO - values: , Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1.], device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,628 - INFO - shape: , torch.Size([256])
2025-06-25 10:38:42,629 - INFO - values: , Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,629 - INFO - shape: , torch.Size([128])
2025-06-25 10:38:42,634 - INFO - values: , Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1.], device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,634 - INFO - shape: , torch.Size([128])
2025-06-25 10:38:42,634 - INFO - values: , Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,635 - INFO - shape: , torch.Size([64, 6, 1, 1])
2025-06-25 10:38:42,651 - INFO - values: , Parameter containing:
tensor([[[[-2.3897e-02]],

         [[-2.6691e-01]],

         [[ 2.6319e-01]],

         [[ 3.0958e-01]],

         [[ 3.7575e-01]],

         [[-3.9579e-02]]],


        [[[ 1.9809e-01]],

         [[-1.4374e-02]],

         [[-3.1675e-02]],

         [[-1.5718e-01]],

         [[-1.2557e-01]],

         [[-3.9615e-05]]],


        [[[-1.0764e-01]],

         [[ 7.1315e-02]],

         [[ 2.7186e-01]],

         [[-2.1235e-01]],

         [[ 2.9650e-03]],

         [[ 3.5170e-01]]],


        [[[-3.4056e-01]],

         [[ 1.5578e-01]],

         [[ 6.2605e-02]],

         [[-1.3101e-01]],

         [[-1.8446e-01]],

         [[ 3.1537e-01]]],


        [[[ 3.7144e-01]],

         [[ 8.5806e-02]],

         [[-2.6967e-01]],

         [[ 8.7051e-02]],

         [[ 1.0699e-01]],

         [[-5.0443e-02]]],


        [[[ 7.8117e-02]],

         [[ 1.9789e-01]],

         [[-3.5183e-01]],

         [[-1.0784e-01]],

         [[-1.3014e-01]],

         [[ 1.4937e-01]]],


        [[[ 2.0766e-01]],

         [[ 1.9663e-01]],

         [[-3.6546e-02]],

         [[-3.3927e-01]],

         [[-1.0464e-01]],

         [[-2.6392e-01]]],


        [[[ 2.0106e-01]],

         [[-1.6703e-01]],

         [[ 4.8410e-02]],

         [[-1.2239e-01]],

         [[ 2.1513e-01]],

         [[ 2.0170e-01]]],


        [[[ 1.5108e-01]],

         [[ 3.4691e-01]],

         [[ 3.1370e-01]],

         [[ 4.0201e-01]],

         [[ 3.3610e-01]],

         [[ 1.2566e-01]]],


        [[[ 5.2043e-02]],

         [[-2.4462e-01]],

         [[-1.9471e-01]],

         [[-2.9193e-01]],

         [[ 1.6357e-01]],

         [[ 2.1119e-01]]],


        [[[-2.0600e-01]],

         [[-3.9069e-01]],

         [[-1.0320e-01]],

         [[-2.2157e-01]],

         [[-2.9827e-01]],

         [[-8.9723e-02]]],


        [[[-1.6268e-01]],

         [[ 1.7052e-01]],

         [[-8.9852e-02]],

         [[ 1.6352e-01]],

         [[-3.6650e-01]],

         [[ 8.8876e-02]]],


        [[[-1.0254e-01]],

         [[ 3.9242e-01]],

         [[ 1.3591e-01]],

         [[-1.0763e-01]],

         [[-2.5106e-01]],

         [[-3.3839e-01]]],


        [[[ 2.4748e-01]],

         [[ 4.0582e-02]],

         [[ 3.6023e-01]],

         [[-1.0688e-01]],

         [[ 3.4530e-01]],

         [[-2.9733e-01]]],


        [[[-2.3852e-01]],

         [[-1.7447e-01]],

         [[ 6.4518e-02]],

         [[-1.3465e-02]],

         [[ 1.7623e-01]],

         [[ 3.8281e-01]]],


        [[[-1.7709e-01]],

         [[-1.1235e-01]],

         [[-3.3109e-01]],

         [[-3.7451e-02]],

         [[ 2.1286e-01]],

         [[-3.2901e-01]]],


        [[[ 3.3842e-01]],

         [[-9.2302e-02]],

         [[ 1.9910e-01]],

         [[-2.4930e-01]],

         [[-2.0211e-01]],

         [[-9.0722e-02]]],


        [[[ 2.3433e-01]],

         [[ 2.7550e-01]],

         [[ 2.2412e-01]],

         [[ 2.6615e-01]],

         [[ 6.8556e-02]],

         [[-2.3972e-01]]],


        [[[ 3.9010e-01]],

         [[ 3.4596e-01]],

         [[-2.0139e-01]],

         [[-2.9431e-01]],

         [[-2.9951e-01]],

         [[ 3.8906e-01]]],


        [[[ 4.0014e-03]],

         [[ 7.4538e-04]],

         [[-3.1093e-01]],

         [[ 2.9039e-01]],

         [[-2.4449e-01]],

         [[-3.8507e-01]]],


        [[[ 3.1466e-01]],

         [[ 3.2916e-01]],

         [[-2.0693e-01]],

         [[ 1.0920e-01]],

         [[ 3.3846e-01]],

         [[ 4.6913e-02]]],


        [[[-8.2591e-02]],

         [[ 3.2818e-01]],

         [[-2.0800e-02]],

         [[ 1.5455e-01]],

         [[ 3.3976e-01]],

         [[-3.0195e-01]]],


        [[[ 9.6929e-02]],

         [[-8.1165e-02]],

         [[ 3.7005e-01]],

         [[ 8.0938e-02]],

         [[-1.8604e-01]],

         [[ 6.9150e-02]]],


        [[[-1.4221e-01]],

         [[-5.1671e-02]],

         [[ 1.5591e-01]],

         [[-3.8185e-01]],

         [[-2.7183e-01]],

         [[-1.0323e-01]]],


        [[[-1.2691e-01]],

         [[-2.5710e-01]],

         [[ 2.9997e-01]],

         [[ 1.2104e-01]],

         [[ 3.8371e-01]],

         [[-6.2674e-02]]],


        [[[ 3.4903e-02]],

         [[-3.7368e-02]],

         [[-2.0989e-01]],

         [[ 3.7366e-02]],

         [[ 2.0184e-01]],

         [[-2.3241e-01]]],


        [[[ 3.1655e-01]],

         [[ 4.3376e-02]],

         [[-2.2861e-02]],

         [[ 2.5815e-01]],

         [[-7.1605e-02]],

         [[ 3.6285e-01]]],


        [[[ 5.0046e-02]],

         [[ 3.1143e-01]],

         [[-2.1707e-01]],

         [[ 2.8023e-01]],

         [[ 3.6164e-01]],

         [[ 2.0079e-01]]],


        [[[-2.5034e-01]],

         [[ 1.7979e-02]],

         [[-3.7212e-01]],

         [[ 2.8625e-01]],

         [[ 1.2489e-01]],

         [[-2.8700e-01]]],


        [[[-2.6047e-01]],

         [[-2.1583e-01]],

         [[ 3.3932e-01]],

         [[ 3.7298e-01]],

         [[-3.8783e-01]],

         [[ 2.4400e-01]]],


        [[[ 8.3056e-02]],

         [[-1.7710e-01]],

         [[ 2.7769e-01]],

         [[-7.8093e-03]],

         [[-3.8622e-01]],

         [[ 1.4350e-01]]],


        [[[ 1.7717e-01]],

         [[-2.8561e-01]],

         [[-5.9110e-02]],

         [[ 1.1660e-01]],

         [[ 1.7459e-01]],

         [[ 3.9873e-01]]],


        [[[-2.6478e-01]],

         [[-2.3541e-01]],

         [[ 3.4933e-01]],

         [[ 1.2196e-02]],

         [[ 3.2850e-01]],

         [[ 3.1418e-01]]],


        [[[ 2.6525e-02]],

         [[ 2.0564e-01]],

         [[ 3.1708e-01]],

         [[-1.1602e-01]],

         [[-5.3004e-02]],

         [[ 3.4775e-01]]],


        [[[-2.0917e-01]],

         [[-2.3996e-01]],

         [[ 1.9946e-01]],

         [[-6.8574e-02]],

         [[-8.3004e-02]],

         [[-2.6785e-01]]],


        [[[ 2.4027e-02]],

         [[ 2.1725e-01]],

         [[ 2.0970e-01]],

         [[ 1.9579e-01]],

         [[-2.9326e-01]],

         [[-3.6482e-01]]],


        [[[ 2.4783e-01]],

         [[-3.3369e-01]],

         [[ 3.3089e-01]],

         [[ 2.9333e-01]],

         [[ 2.4027e-01]],

         [[ 1.6839e-01]]],


        [[[ 6.2790e-02]],

         [[-1.5485e-02]],

         [[ 1.5180e-02]],

         [[-3.4462e-01]],

         [[-3.5259e-01]],

         [[ 1.7493e-01]]],


        [[[ 4.3916e-02]],

         [[-2.7516e-01]],

         [[-3.7192e-01]],

         [[ 1.2046e-01]],

         [[-2.2444e-01]],

         [[-2.3717e-02]]],


        [[[ 3.3488e-01]],

         [[ 7.3388e-02]],

         [[-2.6783e-01]],

         [[ 1.3627e-01]],

         [[ 9.4766e-03]],

         [[-3.0235e-01]]],


        [[[-3.5475e-01]],

         [[ 2.2280e-01]],

         [[-1.8068e-01]],

         [[ 3.4876e-01]],

         [[-2.0582e-01]],

         [[-8.0397e-02]]],


        [[[-5.4861e-02]],

         [[ 1.6743e-01]],

         [[ 7.5067e-02]],

         [[-3.7207e-01]],

         [[ 3.7336e-01]],

         [[-9.3957e-02]]],


        [[[ 1.0395e-01]],

         [[-1.5793e-01]],

         [[ 3.1547e-01]],

         [[-4.2108e-02]],

         [[ 1.2027e-02]],

         [[ 1.1006e-01]]],


        [[[-2.5192e-01]],

         [[ 3.6272e-01]],

         [[ 1.7334e-01]],

         [[-5.3914e-02]],

         [[ 3.7598e-01]],

         [[-2.5667e-01]]],


        [[[ 2.3943e-02]],

         [[-2.2848e-01]],

         [[-1.1305e-01]],

         [[-3.4343e-01]],

         [[-4.6663e-02]],

         [[-3.4263e-01]]],


        [[[-3.3581e-01]],

         [[ 3.8743e-01]],

         [[-1.2060e-01]],

         [[ 1.7991e-02]],

         [[ 2.3054e-01]],

         [[ 2.4792e-01]]],


        [[[ 2.7606e-02]],

         [[ 2.7995e-01]],

         [[ 2.1753e-01]],

         [[-2.0385e-01]],

         [[-2.5343e-01]],

         [[ 4.0808e-01]]],


        [[[ 3.9389e-01]],

         [[ 2.7841e-01]],

         [[-1.7579e-01]],

         [[-3.9785e-01]],

         [[ 2.0461e-01]],

         [[-1.9326e-01]]],


        [[[-2.6450e-01]],

         [[ 2.8254e-01]],

         [[-2.7032e-01]],

         [[-9.5179e-02]],

         [[-7.1349e-03]],

         [[ 2.1132e-01]]],


        [[[ 3.1241e-01]],

         [[ 4.0481e-02]],

         [[ 5.6559e-02]],

         [[ 1.3851e-02]],

         [[ 1.1459e-01]],

         [[ 2.5119e-01]]],


        [[[-3.6372e-01]],

         [[-6.9620e-02]],

         [[ 2.0942e-01]],

         [[ 8.0481e-02]],

         [[-2.5990e-01]],

         [[ 2.7889e-01]]],


        [[[-3.0713e-01]],

         [[-3.6285e-01]],

         [[ 3.8107e-02]],

         [[ 2.1847e-01]],

         [[ 1.8798e-01]],

         [[-7.0681e-03]]],


        [[[-2.9493e-01]],

         [[-2.4616e-01]],

         [[-2.4293e-01]],

         [[ 2.4175e-01]],

         [[ 3.0435e-01]],

         [[ 3.2484e-01]]],


        [[[ 3.1054e-01]],

         [[ 3.6393e-01]],

         [[ 1.5452e-01]],

         [[ 2.2048e-01]],

         [[ 3.6895e-01]],

         [[ 3.2268e-02]]],


        [[[-2.2169e-01]],

         [[ 3.8471e-01]],

         [[ 5.6197e-02]],

         [[ 2.0913e-01]],

         [[ 3.4629e-01]],

         [[ 1.8342e-01]]],


        [[[-5.1384e-02]],

         [[-1.5985e-01]],

         [[-7.4092e-03]],

         [[ 1.1119e-01]],

         [[ 3.3349e-01]],

         [[-2.5655e-01]]],


        [[[-3.3514e-01]],

         [[ 3.9779e-01]],

         [[-1.8797e-01]],

         [[-2.5098e-01]],

         [[ 1.0416e-01]],

         [[ 3.1438e-01]]],


        [[[ 2.9934e-01]],

         [[ 7.4722e-02]],

         [[-2.3987e-01]],

         [[ 3.6604e-02]],

         [[ 3.1932e-01]],

         [[ 1.6386e-01]]],


        [[[-2.5528e-01]],

         [[-1.3581e-01]],

         [[-3.7130e-01]],

         [[ 1.1091e-01]],

         [[ 8.7793e-03]],

         [[-2.4222e-01]]],


        [[[-2.1799e-01]],

         [[ 1.1598e-01]],

         [[ 3.0744e-01]],

         [[-1.3358e-01]],

         [[ 3.3512e-02]],

         [[-2.4386e-01]]],


        [[[-2.6588e-01]],

         [[-2.8783e-01]],

         [[ 3.0375e-01]],

         [[ 1.6312e-02]],

         [[ 4.0121e-01]],

         [[-4.3093e-02]]],


        [[[-2.2502e-01]],

         [[-2.4819e-01]],

         [[-1.5412e-02]],

         [[ 1.3704e-01]],

         [[-3.7049e-01]],

         [[ 2.8949e-01]]],


        [[[-3.6665e-01]],

         [[ 3.7638e-01]],

         [[ 2.3239e-01]],

         [[ 1.7782e-01]],

         [[ 9.6222e-02]],

         [[-2.7082e-01]]],


        [[[ 4.5406e-02]],

         [[ 1.6287e-01]],

         [[ 3.7475e-01]],

         [[-1.2406e-01]],

         [[ 2.5560e-01]],

         [[ 3.4433e-01]]]], device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,651 - INFO - shape: , torch.Size([64, 64, 1, 1])
2025-06-25 10:38:42,654 - INFO - values: , Parameter containing:
tensor([[[[-0.0994]],

         [[-0.0949]],

         [[ 0.0298]],

         ...,

         [[-0.0310]],

         [[ 0.1048]],

         [[ 0.0933]]],


        [[[ 0.0449]],

         [[-0.0706]],

         [[-0.1218]],

         ...,

         [[ 0.1152]],

         [[-0.0056]],

         [[ 0.0720]]],


        [[[ 0.0797]],

         [[-0.1226]],

         [[-0.0525]],

         ...,

         [[-0.0373]],

         [[ 0.0948]],

         [[-0.0960]]],


        ...,


        [[[-0.0069]],

         [[ 0.1041]],

         [[ 0.0592]],

         ...,

         [[ 0.0395]],

         [[ 0.0608]],

         [[-0.0543]]],


        [[[ 0.0662]],

         [[ 0.0101]],

         [[ 0.0928]],

         ...,

         [[ 0.0875]],

         [[ 0.1216]],

         [[ 0.0746]]],


        [[[ 0.0277]],

         [[-0.0398]],

         [[ 0.0075]],

         ...,

         [[-0.1092]],

         [[ 0.0873]],

         [[-0.0638]]]], device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,654 - INFO - shape: , torch.Size([64, 128, 1, 1])
2025-06-25 10:38:42,658 - INFO - values: , Parameter containing:
tensor([[[[-0.0457]],

         [[ 0.0069]],

         [[-0.0066]],

         ...,

         [[ 0.0123]],

         [[-0.0610]],

         [[ 0.0790]]],


        [[[-0.0127]],

         [[-0.0824]],

         [[-0.0305]],

         ...,

         [[ 0.0324]],

         [[-0.0152]],

         [[ 0.0456]]],


        [[[-0.0714]],

         [[ 0.0153]],

         [[-0.0155]],

         ...,

         [[-0.0803]],

         [[-0.0663]],

         [[-0.0741]]],


        ...,


        [[[ 0.0574]],

         [[ 0.0446]],

         [[ 0.0500]],

         ...,

         [[ 0.0878]],

         [[ 0.0301]],

         [[-0.0837]]],


        [[[-0.0643]],

         [[-0.0268]],

         [[ 0.0362]],

         ...,

         [[-0.0627]],

         [[-0.0429]],

         [[-0.0046]]],


        [[[ 0.0066]],

         [[ 0.0852]],

         [[-0.0869]],

         ...,

         [[-0.0464]],

         [[ 0.0516]],

         [[ 0.0848]]]], device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,658 - INFO - shape: , torch.Size([64, 64, 1, 1])
2025-06-25 10:38:42,661 - INFO - values: , Parameter containing:
tensor([[[[ 0.1086]],

         [[ 0.0671]],

         [[-0.0518]],

         ...,

         [[ 0.0604]],

         [[ 0.0906]],

         [[-0.1109]]],


        [[[ 0.0940]],

         [[-0.1075]],

         [[-0.0139]],

         ...,

         [[ 0.1097]],

         [[-0.0161]],

         [[ 0.0208]]],


        [[[ 0.0571]],

         [[-0.0632]],

         [[-0.0797]],

         ...,

         [[-0.0529]],

         [[-0.0730]],

         [[ 0.0834]]],


        ...,


        [[[-0.0405]],

         [[ 0.0479]],

         [[-0.1224]],

         ...,

         [[-0.1102]],

         [[ 0.0326]],

         [[ 0.1133]]],


        [[[-0.0581]],

         [[ 0.0892]],

         [[-0.0993]],

         ...,

         [[-0.1188]],

         [[ 0.0627]],

         [[ 0.0338]]],


        [[[ 0.1140]],

         [[ 0.0285]],

         [[ 0.0330]],

         ...,

         [[ 0.0500]],

         [[-0.0302]],

         [[ 0.0686]]]], device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,661 - INFO - shape: , torch.Size([64, 128, 1, 1])
2025-06-25 10:38:42,663 - INFO - values: , Parameter containing:
tensor([[[[ 0.0220]],

         [[ 0.0619]],

         [[-0.0067]],

         ...,

         [[-0.0331]],

         [[-0.0562]],

         [[ 0.0365]]],


        [[[-0.0301]],

         [[-0.0823]],

         [[-0.0733]],

         ...,

         [[ 0.0106]],

         [[ 0.0752]],

         [[-0.0727]]],


        [[[ 0.0596]],

         [[-0.0545]],

         [[ 0.0096]],

         ...,

         [[-0.0862]],

         [[ 0.0386]],

         [[-0.0814]]],


        ...,


        [[[ 0.0266]],

         [[-0.0156]],

         [[-0.0359]],

         ...,

         [[ 0.0854]],

         [[ 0.0834]],

         [[-0.0253]]],


        [[[-0.0778]],

         [[ 0.0859]],

         [[-0.0323]],

         ...,

         [[ 0.0865]],

         [[-0.0414]],

         [[-0.0454]]],


        [[[ 0.0695]],

         [[-0.0433]],

         [[-0.0714]],

         ...,

         [[ 0.0545]],

         [[ 0.0749]],

         [[-0.0181]]]], device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,663 - INFO - shape: , torch.Size([1024, 192, 1])
2025-06-25 10:38:42,665 - INFO - values: , Parameter containing:
tensor([[[ 0.0003],
         [ 0.0135],
         [-0.0149],
         ...,
         [-0.0082],
         [ 0.0508],
         [-0.0172]],

        [[ 0.0194],
         [ 0.0282],
         [-0.0225],
         ...,
         [-0.0385],
         [ 0.0104],
         [ 0.0414]],

        [[ 0.0130],
         [-0.0249],
         [-0.0551],
         ...,
         [-0.0126],
         [-0.0489],
         [-0.0162]],

        ...,

        [[ 0.0319],
         [ 0.0665],
         [ 0.0591],
         ...,
         [-0.0094],
         [-0.0433],
         [ 0.0534]],

        [[ 0.0150],
         [ 0.0439],
         [-0.0030],
         ...,
         [ 0.0033],
         [ 0.0324],
         [ 0.0096]],

        [[-0.0555],
         [-0.0511],
         [ 0.0314],
         ...,
         [-0.0042],
         [-0.0425],
         [ 0.0536]]], device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,666 - INFO - shape: , torch.Size([64, 16, 1])
2025-06-25 10:38:42,668 - INFO - values: , Parameter containing:
tensor([[[ 0.1007],
         [-0.0574],
         [-0.0414],
         ...,
         [-0.0379],
         [ 0.2423],
         [ 0.1333]],

        [[ 0.1576],
         [ 0.0932],
         [-0.0702],
         ...,
         [ 0.1092],
         [-0.0735],
         [ 0.1162]],

        [[-0.0314],
         [-0.0033],
         [ 0.0704],
         ...,
         [ 0.0184],
         [ 0.0483],
         [-0.2117]],

        ...,

        [[ 0.0765],
         [-0.2088],
         [-0.0608],
         ...,
         [-0.0596],
         [-0.2131],
         [-0.0600]],

        [[-0.0705],
         [-0.0434],
         [-0.1741],
         ...,
         [ 0.1960],
         [ 0.1586],
         [ 0.2274]],

        [[-0.1057],
         [ 0.0211],
         [-0.1496],
         ...,
         [ 0.1945],
         [ 0.2066],
         [ 0.2240]]], device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,668 - INFO - shape: , torch.Size([256, 1216, 1])
2025-06-25 10:38:42,670 - INFO - values: , Parameter containing:
tensor([[[ 0.0260],
         [ 0.0159],
         [-0.0236],
         ...,
         [-0.0123],
         [-0.0285],
         [-0.0244]],

        [[-0.0112],
         [-0.0204],
         [-0.0180],
         ...,
         [ 0.0196],
         [-0.0228],
         [ 0.0198]],

        [[-0.0148],
         [-0.0054],
         [-0.0080],
         ...,
         [-0.0252],
         [-0.0212],
         [-0.0253]],

        ...,

        [[ 0.0133],
         [-0.0180],
         [ 0.0246],
         ...,
         [ 0.0271],
         [-0.0063],
         [ 0.0017]],

        [[ 0.0082],
         [-0.0200],
         [-0.0256],
         ...,
         [ 0.0261],
         [ 0.0082],
         [-0.0039]],

        [[-0.0236],
         [ 0.0136],
         [ 0.0178],
         ...,
         [ 0.0052],
         [-0.0040],
         [-0.0030]]], device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,670 - INFO - shape: , torch.Size([256, 256, 1])
2025-06-25 10:38:42,672 - INFO - values: , Parameter containing:
tensor([[[ 0.0408],
         [ 0.0296],
         [ 0.0549],
         ...,
         [ 0.0092],
         [ 0.0017],
         [ 0.0536]],

        [[ 0.0324],
         [-0.0265],
         [ 0.0373],
         ...,
         [-0.0258],
         [ 0.0152],
         [ 0.0304]],

        [[ 0.0409],
         [-0.0599],
         [ 0.0131],
         ...,
         [ 0.0267],
         [ 0.0087],
         [ 0.0361]],

        ...,

        [[-0.0104],
         [ 0.0095],
         [ 0.0621],
         ...,
         [ 0.0463],
         [-0.0310],
         [-0.0573]],

        [[-0.0518],
         [ 0.0009],
         [-0.0042],
         ...,
         [ 0.0049],
         [ 0.0304],
         [ 0.0583]],

        [[-0.0026],
         [ 0.0406],
         [-0.0219],
         ...,
         [ 0.0615],
         [-0.0095],
         [ 0.0415]]], device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,672 - INFO - shape: , torch.Size([128, 256, 1])
2025-06-25 10:38:42,674 - INFO - values: , Parameter containing:
tensor([[[ 0.0256],
         [ 0.0395],
         [-0.0311],
         ...,
         [ 0.0432],
         [ 0.0211],
         [-0.0005]],

        [[ 0.0102],
         [ 0.0392],
         [-0.0098],
         ...,
         [-0.0545],
         [-0.0143],
         [-0.0322]],

        [[ 0.0042],
         [ 0.0356],
         [-0.0462],
         ...,
         [ 0.0441],
         [-0.0501],
         [-0.0058]],

        ...,

        [[-0.0602],
         [-0.0575],
         [-0.0398],
         ...,
         [ 0.0253],
         [ 0.0204],
         [ 0.0014]],

        [[-0.0341],
         [-0.0396],
         [-0.0335],
         ...,
         [-0.0424],
         [ 0.0034],
         [-0.0104]],

        [[ 0.0258],
         [ 0.0233],
         [ 0.0078],
         ...,
         [ 0.0463],
         [-0.0465],
         [ 0.0272]]], device='cuda:0', requires_grad=True)
2025-06-25 10:38:42,675 - INFO - shape: , torch.Size([1, 128, 1])
2025-06-25 10:38:42,680 - INFO - values: , Parameter containing:
tensor([[[-0.0301],
         [-0.0044],
         [ 0.0655],
         [ 0.0767],
         [-0.0431],
         [-0.0802],
         [ 0.0069],
         [ 0.0256],
         [ 0.0109],
         [-0.0405],
         [ 0.0571],
         [-0.0292],
         [-0.0125],
         [ 0.0075],
         [ 0.0425],
         [ 0.0851],
         [-0.0748],
         [ 0.0222],
         [-0.0863],
         [-0.0632],
         [-0.0287],
         [-0.0264],
         [ 0.0135],
         [ 0.0385],
         [-0.0118],
         [-0.0756],
         [-0.0115],
         [ 0.0001],
         [-0.0819],
         [ 0.0295],
         [-0.0811],
         [-0.0348],
         [ 0.0079],
         [ 0.0770],
         [-0.0338],
         [ 0.0609],
         [-0.0508],
         [ 0.0202],
         [ 0.0512],
         [ 0.0855],
         [-0.0123],
         [ 0.0610],
         [-0.0716],
         [-0.0008],
         [ 0.0067],
         [-0.0455],
         [ 0.0282],
         [-0.0082],
         [-0.0080],
         [-0.0778],
         [ 0.0844],
         [-0.0547],
         [-0.0045],
         [-0.0494],
         [ 0.0404],
         [ 0.0436],
         [-0.0460],
         [ 0.0286],
         [-0.0112],
         [ 0.0720],
         [-0.0330],
         [ 0.0325],
         [ 0.0628],
         [-0.0325],
         [-0.0705],
         [ 0.0658],
         [-0.0703],
         [-0.0358],
         [-0.0527],
         [-0.0183],
         [ 0.0128],
         [-0.0154],
         [-0.0877],
         [-0.0098],
         [-0.0734],
         [ 0.0080],
         [ 0.0199],
         [ 0.0228],
         [ 0.0703],
         [ 0.0756],
         [-0.0249],
         [ 0.0822],
         [-0.0334],
         [-0.0785],
         [-0.0511],
         [ 0.0746],
         [-0.0015],
         [ 0.0832],
         [ 0.0698],
         [ 0.0636],
         [-0.0155],
         [-0.0503],
         [ 0.0105],
         [ 0.0238],
         [ 0.0527],
         [-0.0284],
         [ 0.0041],
         [ 0.0154],
         [-0.0388],
         [ 0.0444],
         [ 0.0523],
         [ 0.0201],
         [-0.0384],
         [ 0.0403],
         [-0.0805],
         [-0.0407],
         [-0.0254],
         [ 0.0554],
         [-0.0435],
         [ 0.0074],
         [-0.0115],
         [ 0.0855],
         [-0.0026],
         [ 0.0277],
         [-0.0727],
         [-0.0244],
         [-0.0264],
         [-0.0144],
         [-0.0364],
         [ 0.0139],
         [ 0.0350],
         [-0.0669],
         [-0.0142],
         [-0.0820],
         [ 0.0096],
         [ 0.0068],
         [-0.0126],
         [ 0.0386]]], device='cuda:0', requires_grad=True)
2025-06-25 15:15:27,084 - INFO - args.exp_name : Train_Test
2025-06-25 15:15:27,084 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=6, epochs=10, lr=0.001, num_workers=4, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-25 15:15:27,084 - INFO - Starting training with 1 GPUs
2025-06-25 15:15:31,343 - INFO - Total trainable parameters: 1437705
2025-06-25 15:15:31,349 - ERROR - No matching VTK files found for IDs in /work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits/val_design_ids.txt.
2025-06-25 15:15:31,351 - INFO - Data loaded: 0 training batches, 0 validation batches, 0 test batches
2025-06-25 16:41:17,856 - INFO - args.exp_name : Train_Test
2025-06-25 16:41:17,858 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=6, epochs=10, lr=0.001, num_workers=4, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-25 16:41:17,858 - INFO - Starting training with 1 GPUs
2025-06-25 16:41:20,100 - INFO - Total trainable parameters: 1437705
2025-06-25 16:41:20,107 - ERROR - No matching VTK files found for IDs in /work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits/val_design_ids.txt.
2025-06-25 16:41:20,109 - INFO - Data loaded: 0 training batches, 0 validation batches, 0 test batches
2025-06-25 16:47:35,076 - INFO - args.exp_name : Train_Test
2025-06-25 16:47:35,076 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=2, epochs=10, lr=0.001, num_workers=4, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-25 16:47:35,077 - INFO - Starting training with 1 GPUs
2025-06-25 16:47:37,397 - INFO - Total trainable parameters: 1437705
2025-06-25 16:47:37,403 - ERROR - No matching VTK files found for IDs in /work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits/val_design_ids.txt.
2025-06-25 16:47:37,405 - INFO - Data loaded: 1 training batches, 0 validation batches, 1 test batches
2025-06-25 16:52:48,111 - INFO - args.exp_name : Train_Test
2025-06-25 16:52:48,112 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=2, epochs=10, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-25 16:52:48,112 - INFO - Starting training with 1 GPUs
2025-06-25 16:52:50,742 - INFO - Total trainable parameters: 1437705
2025-06-25 16:52:50,750 - ERROR - No matching VTK files found for IDs in /work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits/val_design_ids.txt.
2025-06-25 16:52:54,543 - INFO - Batch 0
2025-06-25 16:52:54,543 - INFO -  Points Shape: torch.Size([2, 1, 3, 10000])
2025-06-25 16:52:54,543 - INFO -  Pressure shape:  torch.Size([2, 1, 10000])
2025-06-25 16:52:55,314 - INFO - Data loaded: 1 training batches, 0 validation batches, 1 test batches
2025-06-26 10:08:57,031 - INFO - args.exp_name : Train_Test
2025-06-26 10:08:57,032 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=2, epochs=10, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-26 10:08:57,032 - INFO - Starting training with 1 GPUs
2025-06-26 10:09:04,180 - INFO - Total trainable parameters: 1437705
2025-06-26 10:09:04,185 - ERROR - No matching VTK files found for IDs in /work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits/val_design_ids.txt.
2025-06-26 10:09:04,187 - INFO - Type of dataset: <class 'torch.utils.data.dataset.Subset'>
2025-06-26 10:09:04,187 - INFO - Number of samples in full_dataset: 3
2025-06-26 10:17:42,973 - INFO - args.exp_name : Train_Test
2025-06-26 10:17:42,974 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=2, epochs=10, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-26 10:17:42,974 - INFO - Starting training with 1 GPUs
2025-06-26 10:17:45,581 - INFO - Total trainable parameters: 1437705
2025-06-26 10:17:45,587 - ERROR - No matching VTK files found for IDs in /work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits/val_design_ids.txt.
2025-06-26 10:17:45,588 - INFO - Type of dataset: <class 'torch.utils.data.dataset.Subset'>
2025-06-26 10:17:45,588 - INFO - Number of samples in full_dataset: 3
2025-06-26 10:17:45,588 - INFO - Number of samples in train_dataset: 1
2025-06-26 10:17:45,588 - INFO - Data loaded: 1 training batches, 0 validation batches, 1 test batches
2025-06-26 10:23:10,944 - INFO - args.exp_name : Train_Test
2025-06-26 10:23:10,945 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=2, epochs=10, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-26 10:23:10,945 - INFO - Starting training with 1 GPUs
2025-06-26 10:23:13,287 - INFO - Total trainable parameters: 1437705
2025-06-26 10:23:13,293 - ERROR - No matching VTK files found for IDs in /work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits/val_design_ids.txt.
2025-06-26 10:23:13,294 - INFO - Type of dataset: <class 'torch.utils.data.dataset.Subset'>
2025-06-26 10:23:13,294 - INFO - Number of samples in full_dataset: 3
2025-06-26 10:26:04,645 - INFO - args.exp_name : Train_Test
2025-06-26 10:26:04,645 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=2, epochs=10, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-26 10:26:04,645 - INFO - Starting training with 1 GPUs
2025-06-26 10:26:06,869 - INFO - Total trainable parameters: 1437705
2025-06-26 10:26:06,874 - ERROR - No matching VTK files found for IDs in /work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits/val_design_ids.txt.
2025-06-26 10:26:06,875 - INFO - Type of dataset: <class 'torch.utils.data.dataset.Subset'>
2025-06-26 10:26:06,876 - INFO - Number of samples in full_dataset: 3
2025-06-26 10:26:06,876 - INFO - List all methods and attributs: ['__add__', '__annotations__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getitems__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_is_protocol', 'dataset', 'indices']
2025-06-26 10:26:06,876 - INFO - Number of samples in train_dataset: 1
2025-06-26 10:26:06,876 - INFO - Data loaded: 1 training batches, 0 validation batches, 1 test batches
2025-06-26 10:29:01,617 - INFO - args.exp_name : Train_Test
2025-06-26 10:29:01,617 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=2, epochs=10, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-26 10:29:01,618 - INFO - Starting training with 1 GPUs
2025-06-26 10:29:03,817 - INFO - Total trainable parameters: 1437705
2025-06-26 10:29:03,822 - ERROR - No matching VTK files found for IDs in /work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits/val_design_ids.txt.
2025-06-26 10:29:03,824 - INFO - Type of dataset: <class 'torch.utils.data.dataset.Subset'>
2025-06-26 10:29:03,824 - INFO - Type of train_dataloader: <class 'torch.utils.data.dataloader.DataLoader'>
2025-06-26 10:29:03,824 - INFO - Number of samples in full_dataset: 3
2025-06-26 10:29:03,824 - INFO - List all methods and attributs: ['__add__', '__annotations__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getitems__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_is_protocol', 'dataset', 'indices']
2025-06-26 10:29:03,824 - INFO - Number of samples in train_dataset: 1
2025-06-26 10:29:03,824 - INFO - Data loaded: 1 training batches, 0 validation batches, 1 test batches
2025-06-26 10:43:51,594 - INFO - args.exp_name : Train_Test
2025-06-26 10:43:51,595 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=2, epochs=10, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-26 10:43:51,595 - INFO - Starting training with 1 GPUs
2025-06-26 10:43:54,222 - INFO - Total trainable parameters: 1437705
2025-06-26 10:43:54,227 - ERROR - No matching VTK files found for IDs in /work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits/val_design_ids.txt.
2025-06-26 10:43:54,229 - INFO - Type of dataset: <class 'data_loader.SurfacePressureDataset'>
2025-06-26 10:43:54,229 - INFO - Type of train_dataloader: <class 'torch.utils.data.dataloader.DataLoader'>
2025-06-26 10:43:54,229 - INFO - Number of samples in full_dataset: 5
2025-06-26 10:43:54,229 - INFO - List all methods and attributs: ['__add__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_get_cache_path', '_is_protocol', '_load_from_cache', '_save_to_cache', 'cache_dir', 'num_points', 'preprocess', 'root_dir', 'sample_point_cloud_with_pressure', 'vtk_files']
2025-06-26 10:43:54,229 - INFO - Number of samples in train_dataset: 1
2025-06-26 10:43:54,229 - INFO - Data loaded: 1 training batches, 0 validation batches, 1 test batches
2025-06-26 10:56:27,885 - INFO - args.exp_name : Train_Test
2025-06-26 10:56:27,886 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=2, epochs=10, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-26 10:56:27,886 - INFO - Starting training with 1 GPUs
2025-06-26 10:56:30,290 - INFO - Total trainable parameters: 1437705
2025-06-26 10:56:30,295 - ERROR - No matching VTK files found for IDs in /work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits/val_design_ids.txt.
2025-06-26 10:56:30,297 - INFO - Type of dataset: <class 'data_loader.SurfacePressureDataset'>
2025-06-26 10:56:30,297 - INFO - Type of train_dataloader: <class 'torch.utils.data.dataloader.DataLoader'>
2025-06-26 10:56:30,297 - INFO - Number of samples in full_dataset: 5
2025-06-26 10:56:30,297 - INFO - List all methods and attributs: ['__add__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_get_cache_path', '_is_protocol', '_load_from_cache', '_save_to_cache', 'cache_dir', 'num_points', 'preprocess', 'root_dir', 'sample_point_cloud_with_pressure', 'vtk_files']
2025-06-26 10:56:30,297 - INFO - Root Dir: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK
2025-06-26 10:56:30,297 - INFO - Number of .vtk files: 5
2025-06-26 11:06:34,241 - INFO - args.exp_name : Train_Test
2025-06-26 11:06:34,242 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=2, epochs=10, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-26 11:06:34,242 - INFO - Starting training with 1 GPUs
2025-06-26 11:06:36,686 - INFO - Total trainable parameters: 1437705
2025-06-26 11:06:36,691 - ERROR - No matching VTK files found for IDs in /work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits/val_design_ids.txt.
2025-06-26 11:06:36,694 - INFO - Type of dataset: <class 'torch.utils.data.dataloader.DataLoader'>
2025-06-26 11:06:36,694 - INFO - Number of samples in full_dataset: 1
2025-06-26 11:06:36,694 - INFO - List all methods and attributs: ['_DataLoader__initialized', '_DataLoader__multiprocessing_context', '_IterableDataset_len_called', '__annotations__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_auto_collation', '_dataset_kind', '_get_iterator', '_index_sampler', '_is_protocol', '_iterator', 'batch_sampler', 'batch_size', 'check_worker_number_rationality', 'collate_fn', 'dataset', 'drop_last', 'generator', 'multiprocessing_context', 'num_workers', 'persistent_workers', 'pin_memory', 'pin_memory_device', 'prefetch_factor', 'sampler', 'timeout', 'worker_init_fn']
2025-06-26 11:06:36,694 - INFO - Data loaded: 1 training batches, 0 validation batches, 1 test batches
2025-06-26 11:07:56,846 - INFO - args.exp_name : Train_Test
2025-06-26 11:07:56,847 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=2, epochs=10, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-26 11:07:56,847 - INFO - Starting training with 1 GPUs
2025-06-26 11:07:59,164 - INFO - Total trainable parameters: 1437705
2025-06-26 11:07:59,169 - ERROR - No matching VTK files found for IDs in /work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits/val_design_ids.txt.
2025-06-26 11:07:59,171 - INFO - Type of dataset: <class 'torch.utils.data.dataloader.DataLoader'>
2025-06-26 11:07:59,171 - INFO - Number of samples in full_dataset: 1
2025-06-26 11:07:59,171 - INFO - List all methods and attributs: ['_DataLoader__initialized', '_DataLoader__multiprocessing_context', '_IterableDataset_len_called', '__annotations__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_auto_collation', '_dataset_kind', '_get_iterator', '_index_sampler', '_is_protocol', '_iterator', 'batch_sampler', 'batch_size', 'check_worker_number_rationality', 'collate_fn', 'dataset', 'drop_last', 'generator', 'multiprocessing_context', 'num_workers', 'persistent_workers', 'pin_memory', 'pin_memory_device', 'prefetch_factor', 'sampler', 'timeout', 'worker_init_fn']
2025-06-26 11:07:59,171 - INFO - Data loaded: 1 training batches, 0 validation batches, 1 test batches
2025-06-26 11:08:21,969 - INFO - args.exp_name : Train_Test
2025-06-26 11:08:21,970 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=2, epochs=10, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-26 11:08:21,970 - INFO - Starting training with 1 GPUs
2025-06-26 11:08:24,248 - INFO - Total trainable parameters: 1437705
2025-06-26 11:08:24,253 - ERROR - No matching VTK files found for IDs in /work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits/val_design_ids.txt.
2025-06-26 11:08:24,254 - INFO - Type of dataset: <class 'torch.utils.data.dataloader.DataLoader'>
2025-06-26 11:08:24,254 - INFO - Number of samples in full_dataset: 1
2025-06-26 11:08:24,255 - INFO - List all methods and attributs: ['_DataLoader__initialized', '_DataLoader__multiprocessing_context', '_IterableDataset_len_called', '__annotations__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_auto_collation', '_dataset_kind', '_get_iterator', '_index_sampler', '_is_protocol', '_iterator', 'batch_sampler', 'batch_size', 'check_worker_number_rationality', 'collate_fn', 'dataset', 'drop_last', 'generator', 'multiprocessing_context', 'num_workers', 'persistent_workers', 'pin_memory', 'pin_memory_device', 'prefetch_factor', 'sampler', 'timeout', 'worker_init_fn']
2025-06-26 11:08:24,255 - INFO - Data loaded: 1 training batches, 0 validation batches, 1 test batches
2025-06-26 11:20:04,681 - INFO - args.exp_name : Train_Test
2025-06-26 11:20:04,682 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=2, epochs=10, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-26 11:20:04,682 - INFO - Starting training with 1 GPUs
2025-06-26 11:20:07,150 - INFO - Total trainable parameters: 1437705
2025-06-26 11:20:07,155 - ERROR - No matching VTK files found for IDs in /work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits/val_design_ids.txt.
2025-06-26 11:20:07,157 - INFO - Type of dataset: <class 'torch.utils.data.dataloader.DataLoader'>
2025-06-26 11:20:07,157 - INFO - Number of samples in full_dataset: 1
2025-06-26 11:20:07,157 - INFO - List all methods and attributs: ['_DataLoader__initialized', '_DataLoader__multiprocessing_context', '_IterableDataset_len_called', '__annotations__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_auto_collation', '_dataset_kind', '_get_iterator', '_index_sampler', '_is_protocol', '_iterator', 'batch_sampler', 'batch_size', 'check_worker_number_rationality', 'collate_fn', 'dataset', 'drop_last', 'generator', 'multiprocessing_context', 'num_workers', 'persistent_workers', 'pin_memory', 'pin_memory_device', 'prefetch_factor', 'sampler', 'timeout', 'worker_init_fn']
2025-06-26 11:20:10,940 - INFO - Batch: tensor([[[[-3.1358e-03,  3.7210e+00,  3.7106e+00,  ..., -5.3803e-01,
            1.7617e+00,  1.4177e+00],
          [ 5.4775e-01, -2.0625e-01, -6.1869e-01,  ...,  3.5577e-01,
           -7.1609e-01, -8.8304e-01],
          [ 6.8388e-01,  3.4406e-01,  8.5621e-01,  ...,  7.4636e-01,
            1.0855e+00,  4.9376e-01]]],


        [[[ 2.0024e+00,  2.6824e+00, -5.8603e-01,  ...,  5.5839e-01,
            2.7609e+00,  3.2322e+00],
          [-6.1381e-01,  6.7716e-01,  8.0544e-01,  ..., -7.6071e-01,
            8.1247e-01,  8.5958e-01],
          [ 1.2874e+00,  3.8066e-01,  4.5000e-01,  ...,  8.8547e-01,
            6.8198e-01,  5.7108e-01]]]])
2025-06-26 11:25:24,191 - INFO - args.exp_name : Train_Test
2025-06-26 11:25:24,191 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=2, epochs=10, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-26 11:25:24,192 - INFO - Starting training with 1 GPUs
2025-06-26 11:25:26,538 - INFO - Total trainable parameters: 1437705
2025-06-26 11:25:26,543 - ERROR - No matching VTK files found for IDs in /work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits/val_design_ids.txt.
2025-06-26 11:25:26,545 - INFO - Type of dataset: <class 'torch.utils.data.dataloader.DataLoader'>
2025-06-26 11:25:26,545 - INFO - Number of samples in full_dataset: 1
2025-06-26 11:25:26,545 - INFO - List all methods and attributs: ['_DataLoader__initialized', '_DataLoader__multiprocessing_context', '_IterableDataset_len_called', '__annotations__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_auto_collation', '_dataset_kind', '_get_iterator', '_index_sampler', '_is_protocol', '_iterator', 'batch_sampler', 'batch_size', 'check_worker_number_rationality', 'collate_fn', 'dataset', 'drop_last', 'generator', 'multiprocessing_context', 'num_workers', 'persistent_workers', 'pin_memory', 'pin_memory_device', 'prefetch_factor', 'sampler', 'timeout', 'worker_init_fn']
2025-06-26 11:25:30,308 - INFO - Batch: 0
2025-06-26 11:25:30,312 - INFO - Batch.points: tensor([[[[-3.1358e-03,  3.7210e+00,  3.7106e+00,  ..., -5.3803e-01,
            1.7617e+00,  1.4177e+00],
          [ 5.4775e-01, -2.0625e-01, -6.1869e-01,  ...,  3.5577e-01,
           -7.1609e-01, -8.8304e-01],
          [ 6.8388e-01,  3.4406e-01,  8.5621e-01,  ...,  7.4636e-01,
            1.0855e+00,  4.9376e-01]]],


        [[[ 2.0024e+00,  2.6824e+00, -5.8603e-01,  ...,  5.5839e-01,
            2.7609e+00,  3.2322e+00],
          [-6.1381e-01,  6.7716e-01,  8.0544e-01,  ..., -7.6071e-01,
            8.1247e-01,  8.5958e-01],
          [ 1.2874e+00,  3.8066e-01,  4.5000e-01,  ...,  8.8547e-01,
            6.8198e-01,  5.7108e-01]]]])
2025-06-26 11:25:30,312 - INFO - Batch.Pressure: tensor([[[-149.8820,  -47.8371,  -30.8754,  ..., -213.2100, -296.0330,
           -58.6534]],

        [[ -88.2562,  -86.5040, -322.1380,  ...,   -8.5429,  -83.1721,
          -153.7220]]])
2025-06-26 11:25:30,780 - INFO - Data loaded: 1 training batches, 0 validation batches, 1 test batches
2025-06-26 17:04:28,780 - INFO - args.exp_name : Train_Test
2025-06-26 17:04:28,780 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=2, epochs=10, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-26 17:04:28,780 - INFO - Starting training with 1 GPUs
2025-06-26 17:04:35,373 - INFO - Total trainable parameters: 1437705
2025-06-26 17:04:35,378 - ERROR - No matching VTK files found for IDs in /work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits/val_design_ids.txt.
2025-06-26 17:04:35,380 - INFO - Type of train_dataloader: <class 'torch.utils.data.dataloader.DataLoader'>
2025-06-26 17:04:35,380 - INFO - Number of train_dataloader: 1
2025-06-26 17:04:35,380 - INFO - List all methods and attributs of Dataloader: ['_DataLoader__initialized', '_DataLoader__multiprocessing_context', '_IterableDataset_len_called', '__annotations__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_auto_collation', '_dataset_kind', '_get_iterator', '_index_sampler', '_is_protocol', '_iterator', 'batch_sampler', 'batch_size', 'check_worker_number_rationality', 'collate_fn', 'dataset', 'drop_last', 'generator', 'multiprocessing_context', 'num_workers', 'persistent_workers', 'pin_memory', 'pin_memory_device', 'prefetch_factor', 'sampler', 'timeout', 'worker_init_fn']
2025-06-26 17:04:39,574 - INFO - Batch: 0
2025-06-26 17:04:39,578 - INFO - Batch.points: tensor([[[[-3.1358e-03,  3.7210e+00,  3.7106e+00,  ..., -5.3803e-01,
            1.7617e+00,  1.4177e+00],
          [ 5.4775e-01, -2.0625e-01, -6.1869e-01,  ...,  3.5577e-01,
           -7.1609e-01, -8.8304e-01],
          [ 6.8388e-01,  3.4406e-01,  8.5621e-01,  ...,  7.4636e-01,
            1.0855e+00,  4.9376e-01]]],


        [[[ 2.0024e+00,  2.6824e+00, -5.8603e-01,  ...,  5.5839e-01,
            2.7609e+00,  3.2322e+00],
          [-6.1381e-01,  6.7716e-01,  8.0544e-01,  ..., -7.6071e-01,
            8.1247e-01,  8.5958e-01],
          [ 1.2874e+00,  3.8066e-01,  4.5000e-01,  ...,  8.8547e-01,
            6.8198e-01,  5.7108e-01]]]])
2025-06-26 17:04:39,579 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-26 17:04:39,579 - INFO - Batch.Pressure: tensor([[[-149.8820,  -47.8371,  -30.8754,  ..., -213.2100, -296.0330,
           -58.6534]],

        [[ -88.2562,  -86.5040, -322.1380,  ...,   -8.5429,  -83.1721,
          -153.7220]]])
2025-06-26 17:04:39,579 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-26 17:04:40,349 - INFO - Type of dataset: <class 'torch.utils.data.dataset.Subset'>
2025-06-26 17:04:40,353 - INFO - Number of samples of subset : 3
2025-06-26 17:04:40,353 - INFO - Subset indices: [1, 2, 4]
2025-06-26 17:04:40,353 - INFO - List all methods and attributs of subset: ['__add__', '__annotations__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getitems__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slotnames__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_is_protocol', 'dataset', 'indices'])
2025-06-26 17:04:40,353 - INFO - Data loaded: 1 training batches, 0 validation batches, 1 test batches
2025-06-26 17:08:47,931 - INFO - args.exp_name : Train_Test
2025-06-26 17:08:47,932 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=2, epochs=10, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-26 17:08:47,932 - INFO - Starting training with 1 GPUs
2025-06-26 17:08:52,223 - INFO - Total trainable parameters: 1437705
2025-06-26 17:08:52,228 - ERROR - No matching VTK files found for IDs in /work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits/val_design_ids.txt.
2025-06-26 17:08:52,230 - INFO - Type of train_dataloader: <class 'torch.utils.data.dataloader.DataLoader'>
2025-06-26 17:08:52,230 - INFO - Number of train_dataloader: 1
2025-06-26 17:08:52,230 - INFO - List all methods and attributs of Dataloader: ['_DataLoader__initialized', '_DataLoader__multiprocessing_context', '_IterableDataset_len_called', '__annotations__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_auto_collation', '_dataset_kind', '_get_iterator', '_index_sampler', '_is_protocol', '_iterator', 'batch_sampler', 'batch_size', 'check_worker_number_rationality', 'collate_fn', 'dataset', 'drop_last', 'generator', 'multiprocessing_context', 'num_workers', 'persistent_workers', 'pin_memory', 'pin_memory_device', 'prefetch_factor', 'sampler', 'timeout', 'worker_init_fn']
2025-06-26 17:08:56,813 - INFO - Batch: 0
2025-06-26 17:08:56,818 - INFO - Batch.points: tensor([[[[-3.1358e-03,  3.7210e+00,  3.7106e+00,  ..., -5.3803e-01,
            1.7617e+00,  1.4177e+00],
          [ 5.4775e-01, -2.0625e-01, -6.1869e-01,  ...,  3.5577e-01,
           -7.1609e-01, -8.8304e-01],
          [ 6.8388e-01,  3.4406e-01,  8.5621e-01,  ...,  7.4636e-01,
            1.0855e+00,  4.9376e-01]]],


        [[[ 2.0024e+00,  2.6824e+00, -5.8603e-01,  ...,  5.5839e-01,
            2.7609e+00,  3.2322e+00],
          [-6.1381e-01,  6.7716e-01,  8.0544e-01,  ..., -7.6071e-01,
            8.1247e-01,  8.5958e-01],
          [ 1.2874e+00,  3.8066e-01,  4.5000e-01,  ...,  8.8547e-01,
            6.8198e-01,  5.7108e-01]]]])
2025-06-26 17:08:56,819 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-26 17:08:56,819 - INFO - Batch.Pressure: tensor([[[-149.8820,  -47.8371,  -30.8754,  ..., -213.2100, -296.0330,
           -58.6534]],

        [[ -88.2562,  -86.5040, -322.1380,  ...,   -8.5429,  -83.1721,
          -153.7220]]])
2025-06-26 17:08:56,819 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-26 17:08:58,092 - INFO - Type of dataset: <class 'torch.utils.data.dataset.Subset'>
2025-06-26 17:08:58,095 - INFO - Number of samples of subset : 3
2025-06-26 17:08:58,095 - INFO - Subset indices: [1, 2, 4]
2025-06-26 17:08:58,095 - INFO - List the train_dataset vtk files:
2025-06-26 17:08:58,095 - INFO -   0: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_003.vtk
2025-06-26 17:08:58,096 - INFO -   1: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_005.vtk
2025-06-26 17:08:58,096 - INFO -   2: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_001.vtk
2025-06-26 17:08:58,096 - INFO - List all methods and attributs of subset: ['__add__', '__annotations__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getitems__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slotnames__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_is_protocol', 'dataset', 'indices'])
2025-06-26 17:08:58,096 - INFO - Data loaded: 1 training batches, 0 validation batches, 1 test batches
2025-06-27 09:58:41,782 - INFO - args.exp_name : Train_Test
2025-06-27 09:58:41,783 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=2, epochs=10, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-27 09:58:41,783 - INFO - Starting training with 1 GPUs
2025-06-27 09:58:50,184 - INFO - Total trainable parameters: 1437705
2025-06-27 09:58:50,191 - ERROR - No matching VTK files found for IDs in /work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits/val_design_ids.txt.
2025-06-27 09:58:50,193 - INFO - Type of train_dataloader: <class 'torch.utils.data.dataloader.DataLoader'>
2025-06-27 09:58:50,193 - INFO - Number of train_dataloader: 1
2025-06-27 10:00:22,563 - INFO - args.exp_name : Train_Test
2025-06-27 10:00:22,564 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=2, epochs=10, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-27 10:00:22,564 - INFO - Starting training with 1 GPUs
2025-06-27 10:00:25,666 - INFO - Total trainable parameters: 1437705
2025-06-27 10:00:25,674 - ERROR - No matching VTK files found for IDs in /work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits/val_design_ids.txt.
2025-06-27 10:00:25,676 - INFO - Type of train_dataloader: <class 'torch.utils.data.dataloader.DataLoader'>
2025-06-27 10:00:25,677 - INFO - Number of train_dataloader: 1
2025-06-27 10:00:25,677 - INFO - List all methods and attributs of Dataloader: ['_DataLoader__initialized', '_DataLoader__multiprocessing_context', '_IterableDataset_len_called', '__annotations__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_auto_collation', '_dataset_kind', '_get_iterator', '_index_sampler', '_is_protocol', '_iterator', 'batch_sampler', 'batch_size', 'check_worker_number_rationality', 'collate_fn', 'dataset', 'drop_last', 'generator', 'multiprocessing_context', 'num_workers', 'persistent_workers', 'pin_memory', 'pin_memory_device', 'prefetch_factor', 'sampler', 'timeout', 'worker_init_fn']
2025-06-27 10:00:25,677 - INFO - We can access the internal conetnt by dataloader: 
2025-06-27 10:00:29,671 - INFO - Batch: 0
2025-06-27 10:00:29,675 - INFO - Batch.points: tensor([[[[-3.1358e-03,  3.7210e+00,  3.7106e+00,  ..., -5.3803e-01,
            1.7617e+00,  1.4177e+00],
          [ 5.4775e-01, -2.0625e-01, -6.1869e-01,  ...,  3.5577e-01,
           -7.1609e-01, -8.8304e-01],
          [ 6.8388e-01,  3.4406e-01,  8.5621e-01,  ...,  7.4636e-01,
            1.0855e+00,  4.9376e-01]]],


        [[[ 2.0024e+00,  2.6824e+00, -5.8603e-01,  ...,  5.5839e-01,
            2.7609e+00,  3.2322e+00],
          [-6.1381e-01,  6.7716e-01,  8.0544e-01,  ..., -7.6071e-01,
            8.1247e-01,  8.5958e-01],
          [ 1.2874e+00,  3.8066e-01,  4.5000e-01,  ...,  8.8547e-01,
            6.8198e-01,  5.7108e-01]]]])
2025-06-27 10:00:29,675 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 10:00:29,675 - INFO - Batch.Pressure: tensor([[[-149.8820,  -47.8371,  -30.8754,  ..., -213.2100, -296.0330,
           -58.6534]],

        [[ -88.2562,  -86.5040, -322.1380,  ...,   -8.5429,  -83.1721,
          -153.7220]]])
2025-06-27 10:00:29,676 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 10:00:30,174 - INFO - Type of dataset: <class 'torch.utils.data.dataset.Subset'>
2025-06-27 10:00:30,174 - INFO - Number of samples of subset : 3
2025-06-27 10:00:30,175 - INFO - Subset indices: [1, 2, 4]
2025-06-27 10:00:30,175 - INFO - List the train_dataset vtk files:
2025-06-27 10:00:30,175 - INFO -   0: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_003.vtk
2025-06-27 10:00:30,175 - INFO -   1: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_005.vtk
2025-06-27 10:00:30,175 - INFO -   2: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_001.vtk
2025-06-27 10:00:30,175 - INFO - List all methods and attributs of subset: ['__add__', '__annotations__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getitems__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slotnames__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_is_protocol', 'dataset', 'indices'])
2025-06-27 10:00:30,175 - INFO - Data loaded: 1 training batches, 0 validation batches, 1 test batches
2025-06-27 10:41:56,752 - INFO - args.exp_name : Train_Test
2025-06-27 10:41:56,753 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=2, epochs=10, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-27 10:41:56,754 - INFO - Starting training with 1 GPUs
2025-06-27 10:42:00,358 - INFO - Total trainable parameters: 1437705
2025-06-27 10:42:00,364 - ERROR - No matching VTK files found for IDs in /work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits/val_design_ids.txt.
2025-06-27 10:42:00,365 - INFO - Type of train_dataloader: <class 'torch.utils.data.dataloader.DataLoader'>
2025-06-27 10:42:00,365 - INFO - Number of train_dataloader: 1
2025-06-27 10:42:00,365 - INFO - List all methods and attributs of Dataloader: ['_DataLoader__initialized', '_DataLoader__multiprocessing_context', '_IterableDataset_len_called', '__annotations__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_auto_collation', '_dataset_kind', '_get_iterator', '_index_sampler', '_is_protocol', '_iterator', 'batch_sampler', 'batch_size', 'check_worker_number_rationality', 'collate_fn', 'dataset', 'drop_last', 'generator', 'multiprocessing_context', 'num_workers', 'persistent_workers', 'pin_memory', 'pin_memory_device', 'prefetch_factor', 'sampler', 'timeout', 'worker_init_fn']
2025-06-27 10:42:00,365 - INFO - We can access the internal conetnt by dataloader: 
2025-06-27 10:42:04,914 - INFO - Batch: 0
2025-06-27 10:42:04,914 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 10:42:04,914 - INFO - sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 10:42:04,915 - INFO - sample_0.shape: torch.Size([3, 10000])
2025-06-27 10:42:04,919 - INFO - The first 10 points in x_coor: tensor([-3.1358e-03,  3.7210e+00,  3.7106e+00,  1.5323e+00, -1.1745e-01,
         1.4169e+00,  2.9957e+00, -2.5156e-02, -2.6220e-02,  1.2272e-01])
2025-06-27 10:42:04,919 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 10:42:05,347 - INFO - Type of dataset: <class 'torch.utils.data.dataset.Subset'>
2025-06-27 10:42:05,347 - INFO - Number of samples of subset : 3
2025-06-27 10:42:05,347 - INFO - Subset indices: [1, 2, 4]
2025-06-27 10:42:05,347 - INFO - List the train_dataset vtk files:
2025-06-27 10:42:05,347 - INFO -   0: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_003.vtk
2025-06-27 10:42:05,347 - INFO -   1: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_005.vtk
2025-06-27 10:42:05,349 - INFO -   2: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_001.vtk
2025-06-27 10:42:05,349 - INFO - List all methods and attributs of subset: ['__add__', '__annotations__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getitems__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slotnames__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_is_protocol', 'dataset', 'indices'])
2025-06-27 10:42:05,349 - INFO - Data loaded: 1 training batches, 0 validation batches, 1 test batches
2025-06-27 10:46:20,014 - INFO - args.exp_name : Train_Test
2025-06-27 10:46:20,015 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=2, epochs=10, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-27 10:46:20,015 - INFO - Starting training with 1 GPUs
2025-06-27 10:46:22,932 - INFO - Total trainable parameters: 1437705
2025-06-27 10:46:22,938 - ERROR - No matching VTK files found for IDs in /work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits/val_design_ids.txt.
2025-06-27 10:46:22,939 - INFO - Type of train_dataloader: <class 'torch.utils.data.dataloader.DataLoader'>
2025-06-27 10:46:22,939 - INFO - Number of train_dataloader: 1
2025-06-27 10:46:22,939 - INFO - We can access the internal conetnt by dataloader: 
2025-06-27 10:46:27,409 - INFO - Batch: 0
2025-06-27 10:46:27,409 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 10:46:27,409 - INFO - sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 10:46:27,410 - INFO - sample_0.shape: torch.Size([3, 10000])
2025-06-27 10:46:27,460 - INFO - The first 10 points in x_coor for the sample_0: tensor([-3.1358e-03,  3.7210e+00,  3.7106e+00,  1.5323e+00, -1.1745e-01,
         1.4169e+00,  2.9957e+00, -2.5156e-02, -2.6220e-02,  1.2272e-01])
2025-06-27 10:46:27,460 - INFO - The first 10 points in x_coor for the sample_1: tensor([-3.1358e-03,  3.7210e+00,  3.7106e+00,  1.5323e+00, -1.1745e-01,
         1.4169e+00,  2.9957e+00, -2.5156e-02, -2.6220e-02,  1.2272e-01])
2025-06-27 10:46:27,460 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 10:46:27,930 - INFO - Type of dataset: <class 'torch.utils.data.dataset.Subset'>
2025-06-27 10:46:27,930 - INFO - Number of samples of subset : 3
2025-06-27 10:46:27,930 - INFO - Subset indices: [1, 2, 4]
2025-06-27 10:46:27,930 - INFO - List the train_dataset vtk files:
2025-06-27 10:46:27,930 - INFO -   0: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_003.vtk
2025-06-27 10:46:27,930 - INFO -   1: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_005.vtk
2025-06-27 10:46:27,930 - INFO -   2: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_001.vtk
2025-06-27 10:46:27,930 - INFO - Data loaded: 1 training batches, 0 validation batches, 1 test batches
2025-06-27 10:49:46,093 - INFO - args.exp_name : Train_Test
2025-06-27 10:49:46,095 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=2, epochs=10, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-27 10:49:46,095 - INFO - Starting training with 1 GPUs
2025-06-27 10:49:48,563 - INFO - Total trainable parameters: 1437705
2025-06-27 10:49:48,569 - ERROR - No matching VTK files found for IDs in /work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits/val_design_ids.txt.
2025-06-27 10:49:48,570 - INFO - Type of train_dataloader: <class 'torch.utils.data.dataloader.DataLoader'>
2025-06-27 10:49:48,570 - INFO - Number of train_dataloader: 1
2025-06-27 10:49:48,570 - INFO - We can access the internal conetnt by dataloader: 
2025-06-27 10:49:53,438 - INFO - Batch: 0
2025-06-27 10:49:53,439 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 10:49:53,439 - INFO - sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 10:49:53,439 - INFO - sample_0.shape: torch.Size([3, 10000])
2025-06-27 10:49:53,443 - INFO - The first 10 points in x_coor for the sample_0: tensor([-3.1358e-03,  3.7210e+00,  3.7106e+00,  1.5323e+00, -1.1745e-01,
         1.4169e+00,  2.9957e+00, -2.5156e-02, -2.6220e-02,  1.2272e-01])
2025-06-27 10:49:53,444 - INFO - The first 10 points in x_coor for the sample_1: tensor([[ 2.0024,  2.6824, -0.5860,  ...,  0.5584,  2.7609,  3.2322],
        [-0.6138,  0.6772,  0.8054,  ..., -0.7607,  0.8125,  0.8596],
        [ 1.2874,  0.3807,  0.4500,  ...,  0.8855,  0.6820,  0.5711]])
2025-06-27 10:49:53,444 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 10:49:53,855 - INFO - Type of dataset: <class 'torch.utils.data.dataset.Subset'>
2025-06-27 10:49:53,856 - INFO - Number of samples of subset : 3
2025-06-27 10:49:53,856 - INFO - Subset indices: [1, 2, 4]
2025-06-27 10:49:53,856 - INFO - List the train_dataset vtk files:
2025-06-27 10:49:53,856 - INFO -   0: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_003.vtk
2025-06-27 10:49:53,856 - INFO -   1: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_005.vtk
2025-06-27 10:49:53,856 - INFO -   2: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_001.vtk
2025-06-27 10:49:53,856 - INFO - Data loaded: 1 training batches, 0 validation batches, 1 test batches
2025-06-27 10:56:27,773 - INFO - args.exp_name : Train_Test
2025-06-27 10:56:27,773 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=2, epochs=10, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-27 10:56:27,773 - INFO - Starting training with 1 GPUs
2025-06-27 10:56:30,420 - INFO - Total trainable parameters: 1437705
2025-06-27 10:56:30,426 - ERROR - No matching VTK files found for IDs in /work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits/val_design_ids.txt.
2025-06-27 10:56:30,428 - INFO - Type of train_dataloader: <class 'torch.utils.data.dataloader.DataLoader'>
2025-06-27 10:56:30,428 - INFO - Number of train_dataloader: 1
2025-06-27 10:56:30,428 - INFO - We can access the internal conetnt by dataloader: 
2025-06-27 10:56:34,780 - INFO - Batch: 0
2025-06-27 10:56:34,780 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 10:56:34,780 - INFO - sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 10:56:34,780 - INFO - sample_0.shape: torch.Size([3, 10000])
2025-06-27 10:56:34,785 - INFO - The first 10 points in x_coor for the sample_0: tensor([-3.1358e-03,  3.7210e+00,  3.7106e+00,  1.5323e+00, -1.1745e-01,
         1.4169e+00,  2.9957e+00, -2.5156e-02, -2.6220e-02,  1.2272e-01])
2025-06-27 10:56:34,785 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 2.0024,  2.6824, -0.5860,  3.1021,  0.9962, -0.3762,  0.0654, -0.5734,
         0.3521, -0.9314])
2025-06-27 10:56:34,785 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 10:56:35,218 - INFO - Type of dataset: <class 'torch.utils.data.dataset.Subset'>
2025-06-27 10:56:35,218 - INFO - Number of samples of subset : 3
2025-06-27 10:56:35,218 - INFO - Subset indices: [1, 2, 4]
2025-06-27 10:56:35,218 - INFO - List the train_dataset vtk files:
2025-06-27 10:56:35,218 - INFO -   0: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_003.vtk
2025-06-27 10:56:35,218 - INFO -   1: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_005.vtk
2025-06-27 10:56:35,218 - INFO -   2: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_001.vtk
2025-06-27 10:56:35,218 - INFO - Data loaded: 1 training batches, 0 validation batches, 1 test batches
2025-06-27 11:02:55,623 - INFO - args.exp_name : Train_Test
2025-06-27 11:02:55,624 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=2, epochs=10, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-27 11:02:55,624 - INFO - Starting training with 1 GPUs
2025-06-27 11:02:58,254 - INFO - Total trainable parameters: 1437705
2025-06-27 11:02:58,263 - ERROR - No matching VTK files found for IDs in /work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits/val_design_ids.txt.
2025-06-27 11:02:58,266 - INFO - Type of train_dataloader: <class 'torch.utils.data.dataloader.DataLoader'>
2025-06-27 11:02:58,266 - INFO - Number of train_dataloader: 1
2025-06-27 11:02:58,266 - INFO - We can access the internal conetnt by dataloader: 
2025-06-27 11:03:02,882 - INFO - Batch: 0
2025-06-27 11:03:02,882 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 11:03:02,883 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 11:03:02,883 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 11:03:02,886 - INFO - The first 10 points in x_coor for the sample_0: tensor([-3.1358e-03,  3.7210e+00,  3.7106e+00,  1.5323e+00, -1.1745e-01,
         1.4169e+00,  2.9957e+00, -2.5156e-02, -2.6220e-02,  1.2272e-01])
2025-06-27 11:03:02,886 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 2.0024,  2.6824, -0.5860,  3.1021,  0.9962, -0.3762,  0.0654, -0.5734,
         0.3521, -0.9314])
2025-06-27 11:03:02,886 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 11:03:02,886 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 11:03:02,886 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 11:06:25,820 - INFO - args.exp_name : Train_Test
2025-06-27 11:06:25,821 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=2, epochs=10, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-27 11:06:25,821 - INFO - Starting training with 1 GPUs
2025-06-27 11:06:28,334 - INFO - Total trainable parameters: 1437705
2025-06-27 11:06:28,343 - ERROR - No matching VTK files found for IDs in /work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits/val_design_ids.txt.
2025-06-27 11:06:28,346 - INFO - Type of train_dataloader: <class 'torch.utils.data.dataloader.DataLoader'>
2025-06-27 11:06:28,346 - INFO - Number of train_dataloader: 1
2025-06-27 11:06:28,346 - INFO - We can access the internal conetnt by dataloader: 
2025-06-27 11:06:32,805 - INFO - Batch: 0
2025-06-27 11:06:32,805 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 11:06:32,805 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 11:06:32,805 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 11:06:32,824 - INFO - The first 10 points in x_coor for the sample_0: tensor([-3.1358e-03,  3.7210e+00,  3.7106e+00,  1.5323e+00, -1.1745e-01,
         1.4169e+00,  2.9957e+00, -2.5156e-02, -2.6220e-02,  1.2272e-01])
2025-06-27 11:06:32,825 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 2.0024,  2.6824, -0.5860,  3.1021,  0.9962, -0.3762,  0.0654, -0.5734,
         0.3521, -0.9314])
2025-06-27 11:06:32,825 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 11:06:32,825 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 11:06:32,825 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 11:06:32,825 - INFO - The first 10 points pressure for the sample_0: tensor([-149.8820,  -47.8371,  -30.8754,  -61.2213, -179.6550, -269.8940,
         -65.7033, -205.9630, -144.7190, -148.6480])
2025-06-27 11:06:32,826 - INFO - The first 10 points pressure for the sample_1: tensor([-8.8256e+01, -8.6504e+01, -3.2214e+02, -3.3256e+02, -5.7983e+02,
        -8.2140e+01, -1.0871e+02,  4.1819e-02, -1.4809e+02,  2.5899e+02])
2025-06-27 11:06:33,312 - INFO - Type of dataset: <class 'torch.utils.data.dataset.Subset'>
2025-06-27 11:06:33,313 - INFO - Number of samples of subset : 3
2025-06-27 11:06:33,313 - INFO - Subset indices: [1, 2, 4]
2025-06-27 11:06:33,313 - INFO - List the train_dataset vtk files:
2025-06-27 11:06:33,313 - INFO -   0: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_003.vtk
2025-06-27 11:06:33,313 - INFO -   1: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_005.vtk
2025-06-27 11:06:33,313 - INFO -   2: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_001.vtk
2025-06-27 11:06:33,315 - INFO - Data loaded: 1 training batches, 0 validation batches, 1 test batches
2025-06-27 11:20:43,167 - INFO - args.exp_name : Train_Test
2025-06-27 11:20:43,168 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=2, epochs=10, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-27 11:20:43,168 - INFO - Starting training with 1 GPUs
2025-06-27 11:20:45,727 - INFO - Total trainable parameters: 1437705
2025-06-27 11:20:45,733 - ERROR - No matching VTK files found for IDs in /work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits/val_design_ids.txt.
2025-06-27 11:20:45,734 - INFO - Type of train_dataloader: <class 'torch.utils.data.dataloader.DataLoader'>
2025-06-27 11:20:45,734 - INFO - Number of train_dataloader: 1
2025-06-27 11:20:45,734 - INFO - We can access the internal conetnt by dataloader: 
2025-06-27 11:20:50,283 - INFO - Batch: 0
2025-06-27 11:20:50,283 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 11:20:50,283 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 11:20:50,283 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 11:20:50,290 - INFO - The first 10 points in x_coor for the sample_0: tensor([-3.1358e-03,  3.7210e+00,  3.7106e+00,  1.5323e+00, -1.1745e-01,
         1.4169e+00,  2.9957e+00, -2.5156e-02, -2.6220e-02,  1.2272e-01])
2025-06-27 11:20:50,290 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 2.0024,  2.6824, -0.5860,  3.1021,  0.9962, -0.3762,  0.0654, -0.5734,
         0.3521, -0.9314])
2025-06-27 11:20:50,290 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 11:20:50,290 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 11:20:50,290 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 11:20:50,291 - INFO - The first 10 points pressure for the sample_0: tensor([-149.8820,  -47.8371,  -30.8754,  -61.2213, -179.6550, -269.8940,
         -65.7033, -205.9630, -144.7190, -148.6480])
2025-06-27 11:20:50,291 - INFO - The first 10 points pressure for the sample_1: tensor([-8.8256e+01, -8.6504e+01, -3.2214e+02, -3.3256e+02, -5.7983e+02,
        -8.2140e+01, -1.0871e+02,  4.1819e-02, -1.4809e+02,  2.5899e+02])
2025-06-27 11:20:50,719 - INFO - Type of train_subset: <class 'torch.utils.data.dataset.Subset'>
2025-06-27 11:20:50,719 - INFO - Number of samples of train_subset : 3
2025-06-27 11:20:50,720 - INFO - Subset indices: [1, 2, 4]
2025-06-27 11:20:50,720 - INFO - List the train_subset vtk files:
2025-06-27 11:20:50,720 - INFO -   0: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_003.vtk
2025-06-27 11:20:50,720 - INFO -   1: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_005.vtk
2025-06-27 11:20:50,720 - INFO -   2: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_001.vtk
2025-06-27 11:20:50,722 - INFO - Type of full_dataset: <class 'data_loader.SurfacePressureDataset'>
2025-06-27 11:20:50,722 - INFO - Number of samples of full_dataset: 5
2025-06-27 12:34:58,883 - INFO - args.exp_name : Train_Test
2025-06-27 12:34:58,884 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=2, epochs=10, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-27 12:34:58,884 - INFO - Starting training with 1 GPUs
2025-06-27 12:35:01,570 - INFO - Total trainable parameters: 1437705
2025-06-27 12:35:01,576 - ERROR - No matching VTK files found for IDs in /work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits/val_design_ids.txt.
2025-06-27 12:35:01,577 - INFO - Type of train_dataloader: <class 'torch.utils.data.dataloader.DataLoader'>
2025-06-27 12:35:01,577 - INFO - Number of train_dataloader: 1
2025-06-27 12:35:01,578 - INFO - We can access the internal conetnt by dataloader: 
2025-06-27 12:35:05,924 - INFO - Batch: 0
2025-06-27 12:35:05,924 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 12:35:05,924 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 12:35:05,924 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 12:35:05,929 - INFO - The first 10 points in x_coor for the sample_0: tensor([-3.1358e-03,  3.7210e+00,  3.7106e+00,  1.5323e+00, -1.1745e-01,
         1.4169e+00,  2.9957e+00, -2.5156e-02, -2.6220e-02,  1.2272e-01])
2025-06-27 12:35:05,929 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 2.0024,  2.6824, -0.5860,  3.1021,  0.9962, -0.3762,  0.0654, -0.5734,
         0.3521, -0.9314])
2025-06-27 12:35:05,929 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 12:35:05,929 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 12:35:05,929 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 12:35:05,930 - INFO - The first 10 points pressure for the sample_0: tensor([-149.8820,  -47.8371,  -30.8754,  -61.2213, -179.6550, -269.8940,
         -65.7033, -205.9630, -144.7190, -148.6480])
2025-06-27 12:35:05,930 - INFO - The first 10 points pressure for the sample_1: tensor([-8.8256e+01, -8.6504e+01, -3.2214e+02, -3.3256e+02, -5.7983e+02,
        -8.2140e+01, -1.0871e+02,  4.1819e-02, -1.4809e+02,  2.5899e+02])
2025-06-27 12:35:06,408 - INFO - Type of train_subset: <class 'torch.utils.data.dataset.Subset'>
2025-06-27 12:35:06,408 - INFO - Number of samples of train_subset : 3
2025-06-27 12:35:06,408 - INFO - Subset indices: [1, 2, 4]
2025-06-27 12:35:06,408 - INFO - List the train_subset vtk files:
2025-06-27 12:35:06,408 - INFO -   0: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_003.vtk
2025-06-27 12:35:06,408 - INFO -   1: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_005.vtk
2025-06-27 12:35:06,408 - INFO -   2: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_001.vtk
2025-06-27 12:35:06,414 - INFO - Type of full_dataset: <class 'data_loader.SurfacePressureDataset'>
2025-06-27 12:35:06,414 - INFO - Number of samples of full_dataset: 5
2025-06-27 12:35:06,414 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_009.vtk: 0
2025-06-27 12:35:06,414 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_003.vtk: 1
2025-06-27 12:35:06,417 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_005.vtk: 2
2025-06-27 12:35:06,418 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_002.vtk: 3
2025-06-27 12:35:06,418 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_001.vtk: 4
2025-06-27 12:35:06,418 - INFO - Data loaded: 1 training batches, 0 validation batches, 1 test batches
2025-06-27 14:22:56,383 - INFO - args.exp_name : Train_Test
2025-06-27 14:22:56,384 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=2, epochs=10, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-27 14:22:56,384 - INFO - Starting training with 1 GPUs
2025-06-27 14:22:59,237 - INFO - Total trainable parameters: 1437705
2025-06-27 14:22:59,243 - ERROR - No matching VTK files found for IDs in /work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits/val_design_ids.txt.
2025-06-27 14:22:59,244 - INFO - Type of train_dataloader: <class 'torch.utils.data.dataloader.DataLoader'>
2025-06-27 14:22:59,244 - INFO - Number of train_dataloader: 1
2025-06-27 14:22:59,244 - INFO - We can access the internal conetnt by dataloader: 
2025-06-27 14:23:03,473 - INFO - Batch: 0
2025-06-27 14:23:03,473 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:23:03,473 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:23:03,473 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:23:03,476 - INFO - The first 10 points in x_coor for the sample_0: tensor([-3.1358e-03,  3.7210e+00,  3.7106e+00,  1.5323e+00, -1.1745e-01,
         1.4169e+00,  2.9957e+00, -2.5156e-02, -2.6220e-02,  1.2272e-01])
2025-06-27 14:23:03,477 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 2.0024,  2.6824, -0.5860,  3.1021,  0.9962, -0.3762,  0.0654, -0.5734,
         0.3521, -0.9314])
2025-06-27 14:23:03,477 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:23:03,477 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:23:03,477 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:23:03,477 - INFO - The first 10 points pressure for the sample_0: tensor([-149.8820,  -47.8371,  -30.8754,  -61.2213, -179.6550, -269.8940,
         -65.7033, -205.9630, -144.7190, -148.6480])
2025-06-27 14:23:03,478 - INFO - The first 10 points pressure for the sample_1: tensor([-8.8256e+01, -8.6504e+01, -3.2214e+02, -3.3256e+02, -5.7983e+02,
        -8.2140e+01, -1.0871e+02,  4.1819e-02, -1.4809e+02,  2.5899e+02])
2025-06-27 14:23:03,936 - INFO - Type of train_subset: <class 'torch.utils.data.dataset.Subset'>
2025-06-27 14:23:03,936 - INFO - Number of samples of train_subset : 3
2025-06-27 14:23:03,936 - INFO - Subset indices: [1, 2, 4]
2025-06-27 14:23:03,936 - INFO - List the train_subset vtk files:
2025-06-27 14:23:03,936 - INFO -   0: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_003.vtk
2025-06-27 14:23:03,936 - INFO -   1: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_005.vtk
2025-06-27 14:23:03,936 - INFO -   2: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_001.vtk
2025-06-27 14:23:03,938 - INFO - Type of full_dataset: <class 'data_loader.SurfacePressureDataset'>
2025-06-27 14:23:03,938 - INFO - Number of samples of full_dataset: 5
2025-06-27 14:23:03,938 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_009.vtk: 0
2025-06-27 14:23:03,938 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_003.vtk: 1
2025-06-27 14:23:03,939 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_005.vtk: 2
2025-06-27 14:23:03,939 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_002.vtk: 3
2025-06-27 14:23:03,939 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_001.vtk: 4
2025-06-27 14:23:03,939 - INFO - Data loaded: 1 training batches, 0 validation batches, 1 test batches
2025-06-27 14:32:10,788 - INFO - args.exp_name : Train_Test
2025-06-27 14:32:10,788 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=2, epochs=10, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-27 14:32:10,788 - INFO - Starting training with 1 GPUs
2025-06-27 14:32:13,702 - INFO - Total trainable parameters: 1437705
2025-06-27 14:32:13,707 - ERROR - No matching VTK files found for IDs in /work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits/val_design_ids.txt.
2025-06-27 14:32:13,709 - INFO - Type of train_dataloader: <class 'torch.utils.data.dataloader.DataLoader'>
2025-06-27 14:32:13,709 - INFO - Number of train_dataloader: 1
2025-06-27 14:32:13,709 - INFO - We can access the internal conetnt by dataloader: 
2025-06-27 14:32:17,927 - INFO - Batch: 0
2025-06-27 14:32:17,928 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:32:17,928 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:32:17,928 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:32:17,932 - INFO - The first 10 points in x_coor for the sample_0: tensor([-3.1358e-03,  3.7210e+00,  3.7106e+00,  1.5323e+00, -1.1745e-01,
         1.4169e+00,  2.9957e+00, -2.5156e-02, -2.6220e-02,  1.2272e-01])
2025-06-27 14:32:17,932 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 2.0024,  2.6824, -0.5860,  3.1021,  0.9962, -0.3762,  0.0654, -0.5734,
         0.3521, -0.9314])
2025-06-27 14:32:17,932 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:32:17,932 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:32:17,932 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:32:17,933 - INFO - The first 10 points pressure for the sample_0: tensor([-149.8820,  -47.8371,  -30.8754,  -61.2213, -179.6550, -269.8940,
         -65.7033, -205.9630, -144.7190, -148.6480])
2025-06-27 14:32:17,933 - INFO - The first 10 points pressure for the sample_1: tensor([-8.8256e+01, -8.6504e+01, -3.2214e+02, -3.3256e+02, -5.7983e+02,
        -8.2140e+01, -1.0871e+02,  4.1819e-02, -1.4809e+02,  2.5899e+02])
2025-06-27 14:32:18,694 - INFO - Type of train_subset: <class 'torch.utils.data.dataset.Subset'>
2025-06-27 14:32:18,694 - INFO - Number of samples of train_subset : 3
2025-06-27 14:32:18,694 - INFO - Subset indices: [1, 2, 4]
2025-06-27 14:32:18,694 - INFO - List the train_subset vtk files:
2025-06-27 14:32:18,695 - INFO -   0: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_003.vtk
2025-06-27 14:32:18,695 - INFO -   1: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_005.vtk
2025-06-27 14:32:18,695 - INFO -   2: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_001.vtk
2025-06-27 14:32:18,700 - INFO - Type of full_dataset: <class 'data_loader.SurfacePressureDataset'>
2025-06-27 14:32:18,701 - INFO - Number of samples of full_dataset: 5
2025-06-27 14:32:18,701 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_009.vtk: 0
2025-06-27 14:32:18,701 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_003.vtk: 1
2025-06-27 14:32:18,701 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_005.vtk: 2
2025-06-27 14:32:18,701 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_002.vtk: 3
2025-06-27 14:32:18,701 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_001.vtk: 4
2025-06-27 14:32:18,701 - INFO - Data loaded: 1 training batches, 0 validation batches, 1 test batches
2025-06-27 14:32:18,703 - INFO - Demonstrate the parameters: <generator object Module.parameters at 0x14b0fbb81d20>
2025-06-27 14:58:55,273 - INFO - args.exp_name : Train_Test
2025-06-27 14:58:55,274 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=2, epochs=10, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-27 14:58:55,274 - INFO - Starting training with 1 GPUs
2025-06-27 14:58:58,073 - INFO - Total trainable parameters: 1437705
2025-06-27 14:58:58,128 - INFO - Type of train_dataloader: <class 'torch.utils.data.dataloader.DataLoader'>
2025-06-27 14:58:58,128 - INFO - Number of train_dataloader: 42
2025-06-27 14:58:58,128 - INFO - We can access the internal conetnt by dataloader: 
2025-06-27 14:59:03,483 - INFO - Batch: 0
2025-06-27 14:59:03,483 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,483 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,483 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,498 - INFO - The first 10 points in x_coor for the sample_0: tensor([-0.0485, -0.5382,  0.8928, -0.5284,  0.1444,  2.6208,  2.9762,  3.6200,
        -0.3787,  1.3031])
2025-06-27 14:59:03,498 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 0.2833,  2.6895,  2.9486,  1.6583, -0.7939,  2.0023,  3.1221, -0.4969,
         1.6010,  3.6084])
2025-06-27 14:59:03,498 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,499 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,499 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,499 - INFO - The first 10 points pressure for the sample_0: tensor([-338.8030, -198.2250, -328.4480, -501.5070, -109.0920,  -77.5971,
         -91.8080,  -29.4908, -284.0090,  -91.4154])
2025-06-27 14:59:03,499 - INFO - The first 10 points pressure for the sample_1: tensor([-184.4790,  -81.4952, -111.3050,  -65.2745,  262.2230, -241.2780,
         -14.4769, -133.4740,  -90.2832,  -18.6696])
2025-06-27 14:59:03,501 - INFO - Batch: 1
2025-06-27 14:59:03,501 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,501 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,501 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,501 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 0.3513,  1.2264,  2.3647,  0.1573, -0.5166,  0.6042,  2.8162,  3.3206,
         2.9534,  3.4002])
2025-06-27 14:59:03,502 - INFO - The first 10 points in x_coor for the sample_1: tensor([-0.3273,  2.5158,  1.0972,  3.1233,  2.9517,  0.5927,  1.0853,  2.0020,
         1.7042,  1.0168])
2025-06-27 14:59:03,502 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,502 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,502 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,503 - INFO - The first 10 points pressure for the sample_0: tensor([-148.8720, -323.1080, -107.6920, -145.9240, -122.9890, -107.0480,
         -73.7163,  -52.5742,  -81.2839,  -54.2815])
2025-06-27 14:59:03,506 - INFO - The first 10 points pressure for the sample_1: tensor([-162.1830, -182.7360,  -78.5279,  -28.9796,  -74.6324, -160.5080,
         -74.9221, -181.3020,  -57.2525, -253.2530])
2025-06-27 14:59:03,507 - INFO - Batch: 2
2025-06-27 14:59:03,507 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,507 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,507 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,507 - INFO - The first 10 points in x_coor for the sample_0: tensor([-0.6993,  2.4030,  0.8899,  2.0135,  3.2732,  2.8507, -0.0716,  1.6125,
         2.9042,  0.3750])
2025-06-27 14:59:03,508 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 0.1687,  0.1376,  1.5781,  2.6907, -0.8913,  3.2266, -0.2999,  1.4406,
         3.1044,  0.3440])
2025-06-27 14:59:03,508 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,508 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,508 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,508 - INFO - The first 10 points pressure for the sample_0: tensor([-208.3020,  -73.5788, -553.2300, -180.9300,  -24.8334, -148.6590,
        -183.7780,  -86.4613, -121.7070, -128.1350])
2025-06-27 14:59:03,509 - INFO - The first 10 points pressure for the sample_1: tensor([-165.9060, -261.3880,  -70.9110, -124.4570,  266.7510,  -80.9190,
         -47.6652,  -66.3573,  -81.4829, -123.6120])
2025-06-27 14:59:03,530 - INFO - Batch: 3
2025-06-27 14:59:03,530 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,530 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,530 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,531 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 1.6583,  2.0797, -0.6899,  2.9531, -0.5864,  2.2427,  1.3490, -0.5493,
        -0.0602, -0.4740])
2025-06-27 14:59:03,531 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 2.3746,  1.6812,  2.2774,  1.6584,  1.9345,  2.5699, -0.2872,  1.8989,
         0.3043, -0.3038])
2025-06-27 14:59:03,531 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,531 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,531 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,532 - INFO - The first 10 points pressure for the sample_0: tensor([ -57.7625, -188.2780,  -41.3928,  -56.4165, -216.8250,  -48.8867,
         -71.5313, -197.1700, -160.1030, -137.5480])
2025-06-27 14:59:03,532 - INFO - The first 10 points pressure for the sample_1: tensor([ -94.1245,  -81.8525,  -96.1851,  -76.5446,  -79.7430,  -61.4083,
        -213.5430, -109.7750, -182.5630,  287.5700])
2025-06-27 14:59:03,541 - INFO - Batch: 4
2025-06-27 14:59:03,541 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,542 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,542 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,542 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 0.2684,  0.2005,  2.4938, -0.8517, -0.1792,  1.2573,  3.1068,  3.0116,
         0.9479,  1.2227])
2025-06-27 14:59:03,543 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 0.2343,  1.0350, -0.3204,  0.1797,  1.8875,  0.1917, -0.0378,  2.6067,
         2.1969,  1.3375])
2025-06-27 14:59:03,543 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,543 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,543 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,544 - INFO - The first 10 points pressure for the sample_0: tensor([-173.1780, -202.8530,  -80.9509,  327.1650, -128.7190, -326.8660,
         -40.6500,  -19.0033, -106.4500, -370.2060])
2025-06-27 14:59:03,544 - INFO - The first 10 points pressure for the sample_1: tensor([-131.4480, -711.7170,  -99.5009,   28.7482,  -64.0691, -150.5970,
        -155.0720, -118.3460,  -41.2665,  -54.1201])
2025-06-27 14:59:03,551 - INFO - Batch: 5
2025-06-27 14:59:03,551 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,551 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,551 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,551 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 2.5521,  2.6666,  0.5497,  0.1573,  2.8155,  2.9984, -0.1173,  2.5646,
        -0.9318,  0.5025])
2025-06-27 14:59:03,552 - INFO - The first 10 points in x_coor for the sample_1: tensor([-0.3631,  3.3885,  0.4810, -0.2440,  1.7385, -0.4245, -0.0946, -0.6986,
         2.2198,  2.6981])
2025-06-27 14:59:03,552 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,552 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,552 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,552 - INFO - The first 10 points pressure for the sample_0: tensor([ -84.8091,  -77.7356,   97.0457, -153.8820, -132.9120,  -61.9000,
        -132.3560,  -76.8720,  436.0530,   81.3881])
2025-06-27 14:59:03,552 - INFO - The first 10 points pressure for the sample_1: tensor([-102.3700,  -15.2985,   80.3081, -129.9610,  -95.3753,  -90.2176,
        -133.5760,   22.5415, -142.7650,  -88.9344])
2025-06-27 14:59:03,561 - INFO - Batch: 6
2025-06-27 14:59:03,561 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,561 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,561 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,561 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 1.6010,  1.1225,  1.3490,  2.9752,  0.3980,  1.9333, -0.0454,  3.7736,
         0.4439,  2.0478])
2025-06-27 14:59:03,562 - INFO - The first 10 points in x_coor for the sample_1: tensor([0.2603, 2.6326, 0.7668, 0.3881, 0.9500, 0.7333, 2.7462, 3.3095, 0.7302,
        1.3604])
2025-06-27 14:59:03,562 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,562 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,562 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,562 - INFO - The first 10 points pressure for the sample_0: tensor([ -72.9790, -519.1740, -101.6530,  -85.5379,   82.8267, -191.4840,
         -87.2200,  -25.2302,  -84.1994,  -76.7869])
2025-06-27 14:59:03,563 - INFO - The first 10 points pressure for the sample_1: tensor([-356.8900,  -64.7882,   63.8028,  -26.0867, -324.4070,   48.0206,
        -399.5770, -150.6780,  -78.1401,  -75.5552])
2025-06-27 14:59:03,571 - INFO - Batch: 7
2025-06-27 14:59:03,571 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,571 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,571 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,572 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 1.5431e+00,  3.2020e+00,  3.6874e+00,  1.5438e+00,  5.2393e-01,
         2.0708e+00,  3.3398e+00,  1.2687e+00,  3.7581e+00, -3.0862e-03])
2025-06-27 14:59:03,572 - INFO - The first 10 points in x_coor for the sample_1: tensor([-0.3220,  0.0083,  3.5499,  2.8617,  1.1195,  3.0793, -0.1098,  2.8404,
         2.3572,  3.3744])
2025-06-27 14:59:03,572 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,572 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,572 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,573 - INFO - The first 10 points pressure for the sample_0: tensor([ -41.2135,  -13.3389,  -55.2665, -199.9300, -107.1490,  -49.8250,
         -57.6707,  -68.3031,  -34.3428, -156.1310])
2025-06-27 14:59:03,573 - INFO - The first 10 points pressure for the sample_1: tensor([-186.6740, -176.6460,   28.5065,  -86.4264, -184.2440, -153.2230,
        -161.5000,   55.2674,  -68.8246,   50.5586])
2025-06-27 14:59:03,581 - INFO - Batch: 8
2025-06-27 14:59:03,581 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,581 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,581 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,582 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 0.2492,  0.2958,  0.0304,  0.3405, -0.1605,  2.1281,  0.0187,  1.7500,
         0.7300,  1.3520])
2025-06-27 14:59:03,582 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 2.2083,  2.9885,  3.2353,  1.7729,  3.8352,  3.5629,  0.2343, -0.1897,
        -0.1860,  0.8676])
2025-06-27 14:59:03,582 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,582 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,582 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,583 - INFO - The first 10 points pressure for the sample_0: tensor([-399.0650, -154.6710, -195.3250,  -35.4192, -752.6250, -166.1940,
         -32.8515,  -81.4531,   85.0086, -146.5700])
2025-06-27 14:59:03,583 - INFO - The first 10 points pressure for the sample_1: tensor([ -85.3987,  -75.0366,  -75.1776,  -76.2214,  -25.3767,  -48.0276,
        -294.6700, -621.4550,  -99.7808, -125.2340])
2025-06-27 14:59:03,591 - INFO - Batch: 9
2025-06-27 14:59:03,591 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,591 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,591 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,592 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 1.6813,  0.9128,  2.3372,  2.3220,  2.5514,  2.5759,  2.3228,  2.6669,
        -0.1183,  0.7985])
2025-06-27 14:59:03,592 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 3.8912,  0.3833,  2.2885, -0.3175,  3.1891, -0.0260, -0.5542,  1.2801,
         3.1246,  2.3803])
2025-06-27 14:59:03,592 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,592 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,592 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,593 - INFO - The first 10 points pressure for the sample_0: tensor([ -74.5930, -468.5290,  -17.8253, -111.4660, -279.8660,  -89.8917,
         -81.7025, -230.2680, -153.5960,   18.8863])
2025-06-27 14:59:03,593 - INFO - The first 10 points pressure for the sample_1: tensor([ -62.1802,   95.3592,  -73.3089, -172.8170,  -41.2741, -161.2840,
         -57.3265, -262.5780, -101.2380,  -39.0603])
2025-06-27 14:59:03,601 - INFO - Batch: 10
2025-06-27 14:59:03,601 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,602 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,602 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,602 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 1.0061,  0.3184,  1.2802,  1.1238,  2.8385, -0.5982,  2.9736,  3.1936,
         2.8499, -0.7896])
2025-06-27 14:59:03,603 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 2.7120, -0.3803,  2.9076,  2.5315,  1.9188, -0.3108,  3.8506,  0.5791,
         2.8501,  0.2604])
2025-06-27 14:59:03,603 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,603 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,603 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,603 - INFO - The first 10 points pressure for the sample_0: tensor([-119.4090,   -7.9263,  -97.0791, -215.6410,  -71.9722,  -38.5220,
         -76.4743,    1.0474,  -67.6804,  296.0490])
2025-06-27 14:59:03,604 - INFO - The first 10 points pressure for the sample_1: tensor([-112.9390, -178.6530, -134.2990,  -31.5704,  -71.9506, -192.3010,
         -16.1056,  163.5570, -113.4070, -174.5600])
2025-06-27 14:59:03,611 - INFO - Batch: 11
2025-06-27 14:59:03,612 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,612 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,612 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,612 - INFO - The first 10 points in x_coor for the sample_0: tensor([-0.1075,  3.8310,  2.6669,  2.5005,  0.5240, -0.3776,  0.1010, -0.0613,
         0.8792,  2.9784])
2025-06-27 14:59:03,613 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 3.8087,  0.8565,  2.6422,  2.0250, -0.7496, -0.1292,  0.1458,  0.0684,
         1.5663, -0.0601])
2025-06-27 14:59:03,613 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,613 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,613 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,613 - INFO - The first 10 points pressure for the sample_0: tensor([-159.9450,  -22.9807,  -89.1701,  -74.5420,  -94.6650, -170.8510,
        -145.5740, -175.5390,  -95.2538,  -97.0740])
2025-06-27 14:59:03,614 - INFO - The first 10 points pressure for the sample_1: tensor([ -69.0255,  -82.4216,  -41.9460,  -69.3559,  318.6280, -154.0390,
          65.4091, -241.1140,  -95.6229, -201.5230])
2025-06-27 14:59:03,622 - INFO - Batch: 12
2025-06-27 14:59:03,622 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,622 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,622 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,623 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 2.4883,  3.8665,  3.0949,  1.4288,  0.8677,  1.4062, -0.1070, -0.1792,
        -0.7087,  1.6583])
2025-06-27 14:59:03,623 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 1.4521, -0.3804,  2.6021,  2.8123,  0.8792, -0.3793,  0.6042, -0.6245,
         0.3771,  0.4348])
2025-06-27 14:59:03,623 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,623 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,623 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,624 - INFO - The first 10 points pressure for the sample_0: tensor([ -86.7106,  -19.0995, -112.9440, -238.0560, -190.9050, -137.6680,
         -31.7392, -184.7600,  -52.8803,  -75.6506])
2025-06-27 14:59:03,624 - INFO - The first 10 points pressure for the sample_1: tensor([ -74.8531,  -72.0747,  -79.8344, -177.5810, -144.1570,  -77.6853,
         -70.6408, -160.1670, -128.4620,  102.3960])
2025-06-27 14:59:03,634 - INFO - Batch: 13
2025-06-27 14:59:03,634 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,634 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,634 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,635 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 0.1904,  1.5466,  0.2231, -0.7438, -0.6833,  2.7010,  3.1388, -0.5140,
         0.0188,  0.3035])
2025-06-27 14:59:03,635 - INFO - The first 10 points in x_coor for the sample_1: tensor([-0.9523,  3.2254, -0.8287,  2.6178,  0.3874, -0.4131,  1.7728,  2.4983,
        -0.7710,  2.7925])
2025-06-27 14:59:03,635 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,635 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,635 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,635 - INFO - The first 10 points pressure for the sample_0: tensor([ -11.0432, -181.9940, -209.9080,  334.9540,  -21.7079, -117.5570,
        -177.2140, -252.7250, -114.8210, -136.9090])
2025-06-27 14:59:03,636 - INFO - The first 10 points pressure for the sample_1: tensor([ 376.2220,  -66.3437,  -79.2989,  -83.8929,   84.3352, -319.6010,
        -209.7620, -110.9740, -149.2000, -128.4940])
2025-06-27 14:59:03,643 - INFO - Batch: 14
2025-06-27 14:59:03,643 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,643 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,643 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,644 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 1.9188,  1.9219, -0.2439, -0.2003,  3.6165,  3.7250, -0.6370, -0.1329,
         1.4949,  1.0856])
2025-06-27 14:59:03,644 - INFO - The first 10 points in x_coor for the sample_1: tensor([0.9479, 0.2294, 0.2146, 1.4291, 2.4146, 0.3630, 3.1962, 3.5604, 2.1624,
        2.9073])
2025-06-27 14:59:03,644 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,644 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,644 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,644 - INFO - The first 10 points pressure for the sample_0: tensor([ -63.7926, -202.4660, -114.2120, -170.5030,  -25.9001,  -14.2671,
         202.1390, -156.5060,  -74.7689, -302.7870])
2025-06-27 14:59:03,645 - INFO - The first 10 points pressure for the sample_1: tensor([-101.0460, -168.4900, -162.7870, -163.8160,  -32.0137, -122.1340,
         -70.1305,   61.3782, -206.4840,  -77.4960])
2025-06-27 14:59:03,653 - INFO - Batch: 15
2025-06-27 14:59:03,653 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,653 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,653 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,653 - INFO - The first 10 points in x_coor for the sample_0: tensor([1.6354, 2.7358, 3.0108, 2.9425, 0.5582, 3.3426, 1.6927, 2.6554, 1.1885,
        2.9646])
2025-06-27 14:59:03,654 - INFO - The first 10 points in x_coor for the sample_1: tensor([0.7073, 2.6755, 0.4456, 0.2009, 3.9422, 2.2771, 2.5980, 2.0823, 1.0969,
        0.8215])
2025-06-27 14:59:03,654 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,654 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,654 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,654 - INFO - The first 10 points pressure for the sample_0: tensor([ -53.3478, -249.1540, -217.1740,  -38.3287,  -57.3577,  -39.5899,
         -53.4930, -198.4300,  -62.9154,  -72.7477])
2025-06-27 14:59:03,655 - INFO - The first 10 points pressure for the sample_1: tensor([ -69.7244, -171.5290,   77.3724, -124.6980,  -16.5869,  -37.1627,
        -110.4390,  -50.8352,  -93.0625,   35.6096])
2025-06-27 14:59:03,662 - INFO - Batch: 16
2025-06-27 14:59:03,662 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,662 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,662 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,663 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 1.0866,  3.0906,  2.8814,  3.3540,  0.1802,  3.5031, -0.4595,  2.9398,
        -0.6862,  2.8402])
2025-06-27 14:59:03,663 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 1.3375,  2.6600,  0.9213, -0.2852,  3.8668,  3.6532,  0.0999, -0.0257,
        -0.4694,  3.0822])
2025-06-27 14:59:03,663 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,663 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,663 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,663 - INFO - The first 10 points pressure for the sample_0: tensor([-139.3840,  -76.1815,  -77.5190,  -45.6850, -198.1980,   18.8768,
        -231.3870,  -84.9075,  368.2710,  -40.0785])
2025-06-27 14:59:03,664 - INFO - The first 10 points pressure for the sample_1: tensor([ -64.3042,  -57.6938, -522.9560,  408.5530,  -19.7023,  -25.3357,
        -126.2210,  -57.5550, -155.8810,   95.9221])
2025-06-27 14:59:03,674 - INFO - Batch: 17
2025-06-27 14:59:03,674 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,674 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,674 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,675 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 0.1838,  1.5781, -0.1521,  0.9625,  1.6583,  0.0083, -0.0349,  3.1378,
         2.3802,  0.3751])
2025-06-27 14:59:03,675 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 1.6692,  3.0700,  3.6759,  3.8323, -0.6323,  0.4708, -0.5861,  2.3115,
        -0.5990, -0.3932])
2025-06-27 14:59:03,675 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,675 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,675 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,676 - INFO - The first 10 points pressure for the sample_0: tensor([-211.8480,  -64.9082, -183.0390, -291.3150,  -68.5615, -128.2960,
        -151.9780,  -87.9528,  -53.8223,   52.7714])
2025-06-27 14:59:03,676 - INFO - The first 10 points pressure for the sample_1: tensor([-188.8770,  -90.7600, -102.9600,  -74.7353, -238.1230,   93.8826,
        -216.2530, -112.1910,    4.2031, -268.9180])
2025-06-27 14:59:03,683 - INFO - Batch: 18
2025-06-27 14:59:03,683 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,683 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,683 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,684 - INFO - The first 10 points in x_coor for the sample_0: tensor([-0.4499,  3.2238,  0.0198, -0.8947,  0.1846,  0.3769,  2.5953,  0.1344,
         2.6005,  2.5104])
2025-06-27 14:59:03,684 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 3.6021, -0.4711,  0.2979, -0.4244,  0.1350,  3.0414, -0.7052,  2.4948,
         0.1110,  0.1914])
2025-06-27 14:59:03,684 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,684 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,684 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,685 - INFO - The first 10 points pressure for the sample_0: tensor([ -76.2705, -109.5390, -188.3260,  252.8330, -176.8290, -152.6550,
         -65.6192, -174.7490, -241.6180,  -97.7168])
2025-06-27 14:59:03,685 - INFO - The first 10 points pressure for the sample_1: tensor([ -18.4898, -178.5000, -314.8540, -146.0690, -120.9740,  -48.0461,
         289.0650, -100.6570, -146.2480,  -62.3305])
2025-06-27 14:59:03,693 - INFO - Batch: 19
2025-06-27 14:59:03,693 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,693 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,693 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,694 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 2.6556,  0.7761,  2.6521, -0.1636,  3.1249, -0.1745,  2.7500,  3.6731,
         3.3997,  2.8615])
2025-06-27 14:59:03,694 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 3.1495, -0.2890, -0.9955,  0.1877,  2.8025,  2.8040, -0.9255,  3.0113,
         2.6665,  0.9294])
2025-06-27 14:59:03,694 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,694 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,694 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,695 - INFO - The first 10 points pressure for the sample_0: tensor([ -90.2428,  -87.7525, -174.1110, -156.8580,  -88.2660, -195.9300,
        -256.0310,   -8.6092, -122.2230,  -52.9257])
2025-06-27 14:59:03,695 - INFO - The first 10 points pressure for the sample_1: tensor([ -55.0505, -122.1260,  396.7610,  -90.2323, -152.7490,  -82.5651,
         328.6670, -427.7260, -100.4770,  -27.4212])
2025-06-27 14:59:03,703 - INFO - Batch: 20
2025-06-27 14:59:03,703 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,703 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,703 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,704 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 2.7703,  3.6288, -0.0146,  0.1477,  2.8393,  2.8385,  1.3833,  3.0913,
         2.8498, -0.1425])
2025-06-27 14:59:03,705 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 0.3972,  3.9183,  3.2692,  3.7785, -0.1782,  2.5976, -0.3481,  3.4233,
         3.6062,  0.2469])
2025-06-27 14:59:03,705 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,705 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,705 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,705 - INFO - The first 10 points pressure for the sample_0: tensor([ -83.3786,  -22.5281, -175.6870, -139.1320,  -77.1722,  -71.0416,
         -81.8121,  -42.6166, -128.7640, -126.2550])
2025-06-27 14:59:03,705 - INFO - The first 10 points pressure for the sample_1: tensor([-201.5640,  -16.7136, -106.6490,  -42.4794, -175.8160,   -8.5266,
        -134.5120, -136.8020,  -58.7743, -206.3970])
2025-06-27 14:59:03,713 - INFO - Batch: 21
2025-06-27 14:59:03,713 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,713 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,714 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,714 - INFO - The first 10 points in x_coor for the sample_0: tensor([-0.0842,  2.7824, -0.2797,  2.4688,  0.8248,  1.1311, -0.4703,  0.1026,
         2.5978,  1.4177])
2025-06-27 14:59:03,715 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 2.4264,  2.8696,  1.6240,  2.9751,  2.6334,  0.5618,  0.1458,  0.3647,
        -0.0344,  0.9135])
2025-06-27 14:59:03,715 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,715 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,715 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,715 - INFO - The first 10 points pressure for the sample_0: tensor([-185.7600,  -93.9326, -159.4260,  -93.3238,   33.1694, -555.6100,
         -83.0041,    6.0518,  -82.7327, -174.1910])
2025-06-27 14:59:03,715 - INFO - The first 10 points pressure for the sample_1: tensor([ -98.1512,  -98.8278,  -70.9374,  -85.9046, -191.0780,  112.1150,
        -187.3720, -214.2010, -247.4480, -105.1760])
2025-06-27 14:59:03,723 - INFO - Batch: 22
2025-06-27 14:59:03,724 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,724 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,724 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,724 - INFO - The first 10 points in x_coor for the sample_0: tensor([-0.2349,  0.9135, -0.1889,  0.2861,  1.0193,  1.2458, -0.4257,  0.1707,
         2.7322,  2.7668])
2025-06-27 14:59:03,725 - INFO - The first 10 points in x_coor for the sample_1: tensor([-0.9975, -0.4127,  3.8528,  2.7812,  0.0457,  1.7387, -0.1865,  2.7813,
         0.2707, -0.6109])
2025-06-27 14:59:03,725 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,725 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,725 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,725 - INFO - The first 10 points pressure for the sample_0: tensor([ 132.8470,  -74.3528, -155.9420, -174.4330, -338.2300,  -73.8055,
        -185.3560, -112.9740,  -96.7461, -106.6330])
2025-06-27 14:59:03,726 - INFO - The first 10 points pressure for the sample_1: tensor([-373.3540, -141.6460,   25.1866,  -86.2460, -147.9350, -224.0500,
        -198.4290,  -63.9653,   87.9137,  -98.6002])
2025-06-27 14:59:03,741 - INFO - Batch: 23
2025-06-27 14:59:03,741 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,741 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,741 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,742 - INFO - The first 10 points in x_coor for the sample_0: tensor([-0.4362,  2.1394, -0.8130, -0.2289, -0.2236,  3.2831, -0.0146, -0.4587,
         1.9986,  2.7975])
2025-06-27 14:59:03,743 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 0.2382,  2.4836,  0.0085,  1.8302,  2.6476,  3.4547,  2.7562, -0.8593,
         3.8241,  0.0800])
2025-06-27 14:59:03,743 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,743 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,743 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,743 - INFO - The first 10 points pressure for the sample_0: tensor([-285.9120, -143.0830,  447.8620, -818.7190, -206.1260, -203.6470,
        -181.9760,  -92.8544,  -55.5424,  -15.3260])
2025-06-27 14:59:03,744 - INFO - The first 10 points pressure for the sample_1: tensor([ -97.2788,  -92.2684, -135.6480,  -96.3057,  -67.3315, -145.7940,
         -66.4935,  439.0400,   -4.7178, -107.6100])
2025-06-27 14:59:03,751 - INFO - Batch: 24
2025-06-27 14:59:03,751 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,751 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,751 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,751 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 2.6553, -0.2362,  3.2621,  3.5150,  3.2970, -0.3015,  1.3146,  3.5571,
         2.3335,  0.9049])
2025-06-27 14:59:03,752 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 3.6814,  2.5220,  2.0823,  3.5908,  0.2836,  0.8439,  3.6716, -0.1743,
         2.4019,  2.6665])
2025-06-27 14:59:03,752 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,752 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,752 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,752 - INFO - The first 10 points pressure for the sample_0: tensor([ -74.1879, -109.2970,  -83.0217,  -42.2152,  -95.3424, -155.8450,
         -83.9559,  -30.1028,  -67.7424,  -12.2910])
2025-06-27 14:59:03,753 - INFO - The first 10 points pressure for the sample_1: tensor([  -7.6114,  -59.0061,  -47.3247,  -30.2943,  -39.4249, -351.7790,
         -19.8623, -195.5630,  -50.2555, -120.2700])
2025-06-27 14:59:03,760 - INFO - Batch: 25
2025-06-27 14:59:03,760 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,760 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,761 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,761 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 2.0024,  2.6824, -0.5860,  3.1021,  0.9962, -0.3762,  0.0654, -0.5734,
         0.3521, -0.9314])
2025-06-27 14:59:03,761 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 1.0195,  3.0786, -0.9305,  3.6379, -0.0828,  1.6584,  0.9161,  0.9135,
        -0.0261,  0.5813])
2025-06-27 14:59:03,761 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,761 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,761 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,762 - INFO - The first 10 points pressure for the sample_0: tensor([-8.8256e+01, -8.6504e+01, -3.2214e+02, -3.3256e+02, -5.7983e+02,
        -8.2140e+01, -1.0871e+02,  4.1819e-02, -1.4809e+02,  2.5899e+02])
2025-06-27 14:59:03,762 - INFO - The first 10 points pressure for the sample_1: tensor([ -91.5531,  -88.4385,  420.0560,  -11.4785, -138.2240, -229.8700,
        -425.4430,  -91.2196, -150.3880, -118.3980])
2025-06-27 14:59:03,773 - INFO - Batch: 26
2025-06-27 14:59:03,773 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,773 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,773 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,773 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 3.2496,  0.8104, -0.5261, -0.2329,  0.4323,  3.6518,  3.7327,  1.9652,
        -0.4947, -0.5774])
2025-06-27 14:59:03,774 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 3.8151,  0.9867,  0.0400,  0.2850,  0.4326,  3.5833, -0.0836, -0.7234,
        -0.7741,  1.5676])
2025-06-27 14:59:03,774 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,774 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,774 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,775 - INFO - The first 10 points pressure for the sample_0: tensor([  32.1262,  -80.0883, -123.9470, -195.3070, -100.2010,   29.2670,
         -16.8960,  -86.8586,    3.6613,   54.4899])
2025-06-27 14:59:03,775 - INFO - The first 10 points pressure for the sample_1: tensor([ -59.2862,  -21.4684, -132.8340, -111.0530,  -52.8657,   50.1366,
        -194.1660,  113.6450,  358.9430, -226.3790])
2025-06-27 14:59:03,781 - INFO - Batch: 27
2025-06-27 14:59:03,781 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,781 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,781 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,781 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 0.3280,  0.9479,  0.6844,  0.5470, -0.5607,  0.8677,  2.4142,  1.2802,
         0.9326,  2.3344])
2025-06-27 14:59:03,782 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 3.4468,  2.4833,  2.7102,  3.8827,  3.1250,  1.1427,  1.0396, -0.1865,
         2.7696,  0.5240])
2025-06-27 14:59:03,782 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,782 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,782 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,782 - INFO - The first 10 points pressure for the sample_0: tensor([-172.0560,  -57.6567, -102.8640, -106.8040, -207.4080,  -38.4566,
         -56.6369,  -76.8144, -486.2720,  -36.1637])
2025-06-27 14:59:03,783 - INFO - The first 10 points pressure for the sample_1: tensor([  16.2851, -143.7690,  -95.7955,  -35.1342,  -63.5244,  -93.4655,
         -68.2843, -181.9770,  -75.4459,  -66.5618])
2025-06-27 14:59:03,790 - INFO - Batch: 28
2025-06-27 14:59:03,790 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,790 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,790 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,791 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 0.1690,  3.0182, -0.3117,  1.0167,  0.8448,  0.3865, -0.6800,  0.1000,
        -0.8942,  2.8359])
2025-06-27 14:59:03,791 - INFO - The first 10 points in x_coor for the sample_1: tensor([-3.1358e-03,  3.7210e+00,  3.7106e+00,  1.5323e+00, -1.1745e-01,
         1.4169e+00,  2.9957e+00, -2.5156e-02, -2.6220e-02,  1.2272e-01])
2025-06-27 14:59:03,791 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,791 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,791 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,791 - INFO - The first 10 points pressure for the sample_0: tensor([ -71.8076,  -28.2225, -180.3700,  -69.3480,  -93.5420, -103.9380,
         -31.1451, -282.2930, -208.7450, -186.7030])
2025-06-27 14:59:03,792 - INFO - The first 10 points pressure for the sample_1: tensor([-149.8820,  -47.8371,  -30.8754,  -61.2213, -179.6550, -269.8940,
         -65.7033, -205.9630, -144.7190, -148.6480])
2025-06-27 14:59:03,799 - INFO - Batch: 29
2025-06-27 14:59:03,799 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,799 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,799 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,799 - INFO - The first 10 points in x_coor for the sample_0: tensor([0.1459, 1.8531, 0.2792, 1.1312, 0.3291, 1.7615, 0.3698, 0.2260, 2.2655,
        0.0992])
2025-06-27 14:59:03,800 - INFO - The first 10 points in x_coor for the sample_1: tensor([-0.2671,  0.0199,  0.9527,  1.0279,  3.4555,  1.6812,  2.3703, -0.1861,
         3.2626,  0.0304])
2025-06-27 14:59:03,800 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,800 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,800 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,801 - INFO - The first 10 points pressure for the sample_0: tensor([-176.4800,  -56.3783,  -66.4860, -107.8410, -189.6050,  -66.6120,
         -43.6896, -199.4750, -179.7610, -173.2540])
2025-06-27 14:59:03,801 - INFO - The first 10 points pressure for the sample_1: tensor([-137.7900, -144.6510, -590.5480, -509.6860,  -54.0269, -106.7610,
         -76.1703, -273.7640, -135.9330, -154.3830])
2025-06-27 14:59:03,807 - INFO - Batch: 30
2025-06-27 14:59:03,807 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,807 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,807 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,807 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 0.9479,  0.3987, -0.1521,  1.9906, -0.0118, -0.5948,  2.6331,  0.5215,
         2.7021,  0.5607])
2025-06-27 14:59:03,808 - INFO - The first 10 points in x_coor for the sample_1: tensor([-0.5999,  1.7842,  3.0147,  2.8585,  2.1510,  1.4178, -0.8385,  0.4896,
         3.3658,  2.4531])
2025-06-27 14:59:03,808 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,808 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,808 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,808 - INFO - The first 10 points pressure for the sample_0: tensor([ -50.8184,  107.2220, -172.7260,  -58.7541, -100.8550,  -93.4919,
        -255.4690, -141.1370,  -97.2591,  154.2220])
2025-06-27 14:59:03,808 - INFO - The first 10 points pressure for the sample_1: tensor([ -92.1932,  -75.5878, -113.2290, -145.7610,  -83.5426, -248.8180,
         267.4870, -147.7300,  -47.9468,  -80.9790])
2025-06-27 14:59:03,815 - INFO - Batch: 31
2025-06-27 14:59:03,815 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,815 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,816 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,816 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 1.4635, -0.1174,  0.6167, -0.9828,  1.6812,  1.0847,  1.7729, -0.1520,
         2.5627,  3.0302])
2025-06-27 14:59:03,816 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 0.3752,  0.2724, -0.4835,  0.9250,  3.6627,  2.8386,  0.8557,  3.9218,
         3.1210, -0.3901])
2025-06-27 14:59:03,816 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,816 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,816 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,817 - INFO - The first 10 points pressure for the sample_0: tensor([ -95.1635, -107.9970,  137.8990, -377.8830,  -94.7552,  -76.7119,
         -94.5342,  -96.3450,  -94.3630,  -47.7246])
2025-06-27 14:59:03,817 - INFO - The first 10 points pressure for the sample_1: tensor([  26.8221, -139.6480,  -68.4088,  -78.4813,  -92.9359, -102.2890,
        -458.8600,  -51.0210,  -36.5807, -119.5220])
2025-06-27 14:59:03,824 - INFO - Batch: 32
2025-06-27 14:59:03,824 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,824 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,824 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,824 - INFO - The first 10 points in x_coor for the sample_0: tensor([2.6552, 2.8621, 3.0570, 2.2725, 2.7130, 3.0448, 0.1232, 2.8604, 3.6765,
        0.7417])
2025-06-27 14:59:03,824 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 3.7915,  0.4004,  0.1917,  3.7563, -0.1262,  2.2084,  3.2492,  1.6240,
        -0.9586,  0.3788])
2025-06-27 14:59:03,825 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,825 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,825 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,825 - INFO - The first 10 points pressure for the sample_0: tensor([-142.5580, -140.2040,  -94.3418,  -85.5900, -165.3290,   -8.9998,
        -434.2130,   24.8030,  -15.0267,  -87.2577])
2025-06-27 14:59:03,826 - INFO - The first 10 points pressure for the sample_1: tensor([ -33.3455,   82.1770, -196.9200,  -72.2047,  -49.2621,  -23.6994,
         -41.9599,  -72.0221,  442.1610,  -72.5108])
2025-06-27 14:59:03,950 - INFO - Batch: 33
2025-06-27 14:59:03,951 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,951 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,951 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,951 - INFO - The first 10 points in x_coor for the sample_0: tensor([-0.3813, -0.6180,  2.7117, -0.0955,  2.3878,  1.8990, -0.2204, -0.1854,
         2.4366, -0.0807])
2025-06-27 14:59:03,952 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 1.4519,  0.0771,  0.2691, -0.4843,  2.0249,  3.3312,  3.5800,  2.7106,
         2.6875, -0.5732])
2025-06-27 14:59:03,952 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,952 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,952 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,952 - INFO - The first 10 points pressure for the sample_0: tensor([-334.7100, -208.6040,  -78.3032, -196.7590,  -80.4406,  -74.0066,
         -64.5444, -148.8190, -204.1940,  -21.9310])
2025-06-27 14:59:03,952 - INFO - The first 10 points pressure for the sample_1: tensor([ -52.1155, -159.1580, -123.9140,  -49.3530, -202.4540,   45.0232,
         -26.4776,  -63.7452,  -51.6638, -429.7930])
2025-06-27 14:59:03,960 - INFO - Batch: 34
2025-06-27 14:59:03,960 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,960 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,961 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,961 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 2.6435,  3.1134,  1.0625,  1.1242,  0.7875,  0.9040,  2.9080, -0.8353,
        -0.2323,  2.7696])
2025-06-27 14:59:03,961 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 3.1132,  1.8528,  3.9148, -0.2349,  3.9169,  1.4979,  1.2687,  0.0887,
         1.0622,  3.4802])
2025-06-27 14:59:03,961 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,961 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,961 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,962 - INFO - The first 10 points pressure for the sample_0: tensor([-122.1790,  -83.9981, -116.2120, -243.7820, -167.9570,  -46.7163,
         -56.8178,  326.6480, -345.4950, -143.3180])
2025-06-27 14:59:03,962 - INFO - The first 10 points pressure for the sample_1: tensor([ -90.0224,  -93.3419,  -30.0798, -173.1290,  -79.8611,  -52.6971,
         -87.8026,  -31.6445, -235.4820,   70.6987])
2025-06-27 14:59:03,968 - INFO - Batch: 35
2025-06-27 14:59:03,968 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,968 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,968 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,969 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 1.8641,  0.8677,  1.8042,  0.1116, -0.8959,  3.5810,  0.5146,  3.5696,
         1.7614,  2.7114])
2025-06-27 14:59:03,969 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 0.0964,  2.4975,  2.4031,  1.5668, -0.8922,  3.7699,  1.2573,  0.2626,
         0.5347, -0.2470])
2025-06-27 14:59:03,969 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,969 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,969 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,970 - INFO - The first 10 points pressure for the sample_0: tensor([-111.9880, -129.0600,  -73.4888, -137.5430,  341.9980,  -36.2054,
         107.2540,  -18.7434,  -79.0948,  -57.4639])
2025-06-27 14:59:03,970 - INFO - The first 10 points pressure for the sample_1: tensor([-118.6720,  -88.8445, -147.5880, -248.5680,  302.8140,    0.5286,
         -86.7859, -110.4070,   12.7982, -160.6780])
2025-06-27 14:59:03,977 - INFO - Batch: 36
2025-06-27 14:59:03,977 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,977 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,977 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,978 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 0.1916, -0.3633,  0.0083,  0.6492,  1.6015,  3.7575,  2.5296,  2.8156,
         2.3077,  2.9862])
2025-06-27 14:59:03,978 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 2.5868,  0.0720,  3.6466,  2.0823, -0.1516,  3.5156,  1.3031,  1.5552,
         2.6781,  2.8837])
2025-06-27 14:59:03,978 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,978 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,978 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,979 - INFO - The first 10 points pressure for the sample_0: tensor([ -13.6639, -159.2940, -155.5510,  184.0170,  -97.3904,  -22.4263,
        -407.6130,  -40.0012, -152.1620,  -24.3921])
2025-06-27 14:59:03,979 - INFO - The first 10 points pressure for the sample_1: tensor([ -96.5537, -158.0490,  -23.8407,  -73.7478,  -86.8836,    4.4890,
         -81.7787,  -66.9959, -205.5900,  -51.5440])
2025-06-27 14:59:03,987 - INFO - Batch: 37
2025-06-27 14:59:03,987 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,987 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,988 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,988 - INFO - The first 10 points in x_coor for the sample_0: tensor([2.6894, 0.8658, 1.3604, 1.4868, 3.7887, 0.5710, 0.5009, 2.9438, 2.0263,
        3.3437])
2025-06-27 14:59:03,989 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 3.0557,  0.5470, -0.3219, -0.7490, -0.5760,  2.0250,  1.9906, -0.1979,
         0.0991, -0.6017])
2025-06-27 14:59:03,989 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,989 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,989 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,989 - INFO - The first 10 points pressure for the sample_0: tensor([-103.9700,  370.8800,  -77.0428,  -54.8544,  -41.9449,  105.4260,
         -92.5658,  -44.6539,  -78.3615,  -40.8942])
2025-06-27 14:59:03,989 - INFO - The first 10 points pressure for the sample_1: tensor([ -53.7789, -136.5090, -105.3350,  409.5120, -203.6270, -100.4900,
         -98.7160, -204.2220,  -43.8484,   83.2925])
2025-06-27 14:59:03,996 - INFO - Batch: 38
2025-06-27 14:59:03,997 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:03,997 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:03,997 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:03,997 - INFO - The first 10 points in x_coor for the sample_0: tensor([-0.3117,  0.4094,  0.0427,  3.1248,  2.7575,  2.6631,  0.5927,  2.8988,
         1.4521,  1.1771])
2025-06-27 14:59:03,997 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 2.3688, -0.0817,  1.5323,  1.9906,  3.0661,  0.7188,  2.2313,  2.3115,
         3.2123,  0.4782])
2025-06-27 14:59:03,998 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:03,998 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:03,998 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:03,998 - INFO - The first 10 points pressure for the sample_0: tensor([-268.5310, -283.7720, -251.0730, -140.5760,  -87.6902, -242.1250,
         -80.3776,  -84.8839,  -90.4834,  -90.0195])
2025-06-27 14:59:03,998 - INFO - The first 10 points pressure for the sample_1: tensor([-126.9870, -168.7350, -169.6220,  -70.4165,  -45.4687, -118.2910,
         -72.3663,  -65.5506,  -84.8359,  -71.2502])
2025-06-27 14:59:04,004 - INFO - Batch: 39
2025-06-27 14:59:04,005 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:04,005 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:04,005 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:04,005 - INFO - The first 10 points in x_coor for the sample_0: tensor([-0.6710,  1.9803,  1.3950,  2.8383,  0.8219,  1.8760,  0.0427,  0.6495,
         0.3333,  2.8042])
2025-06-27 14:59:04,005 - INFO - The first 10 points in x_coor for the sample_1: tensor([-0.3143,  2.9865,  2.9771,  2.9417,  1.0311,  3.5053,  1.4050,  0.1797,
         2.7006, -0.0968])
2025-06-27 14:59:04,006 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:04,006 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:04,006 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:04,006 - INFO - The first 10 points pressure for the sample_0: tensor([ -95.5753,  -94.2381, -310.8570, -109.1800,  -81.4626,  -70.8335,
        -153.2640,  -75.0069,   33.6827,  -70.6522])
2025-06-27 14:59:04,006 - INFO - The first 10 points pressure for the sample_1: tensor([-175.4440, -149.5730, -123.9650,  -90.3130, -144.0810,  -50.9281,
        -253.8000,  -57.1164, -173.6610, -177.1350])
2025-06-27 14:59:04,016 - INFO - Batch: 40
2025-06-27 14:59:04,016 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:04,016 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:04,016 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:04,017 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 2.7469,  2.7587,  0.7073,  2.7011,  3.4110,  2.1052,  2.5066,  3.0369,
        -0.5161,  2.3114])
2025-06-27 14:59:04,017 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 0.4209,  0.4208,  1.7844, -0.3690,  0.4459,  1.6354,  3.5461,  2.6436,
         1.8417,  1.7042])
2025-06-27 14:59:04,017 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:04,017 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:04,017 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:04,017 - INFO - The first 10 points pressure for the sample_0: tensor([ -71.5105,  -83.9507, -115.8100,  -88.5756,  -51.6981,  -55.6062,
         -33.3012,  -96.3630, -220.3480, -136.4290])
2025-06-27 14:59:04,018 - INFO - The first 10 points pressure for the sample_1: tensor([ -49.1153, -110.7010,  -76.5956,  -86.4747,  126.2600, -100.9660,
         -14.0673,  -63.5962,  -83.5589,  -76.9001])
2025-06-27 14:59:04,024 - INFO - Batch: 41
2025-06-27 14:59:04,024 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 14:59:04,024 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 14:59:04,024 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 14:59:04,025 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 3.1197, -0.7715,  4.0171,  3.3372,  0.6860,  1.1312,  0.2249, -0.3013,
         4.0153,  3.0571])
2025-06-27 14:59:04,025 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 0.2488, -0.1749, -0.5541,  3.5946,  3.1490, -0.4508,  2.4746,  1.0854,
         1.8416,  1.2000])
2025-06-27 14:59:04,025 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 14:59:04,025 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 14:59:04,025 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 14:59:04,025 - INFO - The first 10 points pressure for the sample_0: tensor([-139.8260,   26.5946,  -19.0641, -114.9630,  187.9530,  -74.7365,
          26.5352, -145.7950,  -19.5303, -161.1850])
2025-06-27 14:59:04,026 - INFO - The first 10 points pressure for the sample_1: tensor([  43.5840, -199.3970, -144.1050,   10.0279,  -68.8296, -107.1940,
         -66.7033,  -66.0018,  -68.5476,  -84.6221])
2025-06-27 14:59:04,901 - INFO - Type of train_subset: <class 'torch.utils.data.dataset.Subset'>
2025-06-27 14:59:04,901 - INFO - Number of samples of train_subset : 85
2025-06-27 14:59:04,901 - INFO - Subset indices: [0, 1, 2, 4, 6]
2025-06-27 14:59:04,901 - INFO - List the train_subset vtk files:
2025-06-27 14:59:04,901 - INFO -   0: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_073.vtk
2025-06-27 14:59:04,901 - INFO -   1: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_051.vtk
2025-06-27 14:59:04,901 - INFO -   2: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_099.vtk
2025-06-27 14:59:04,901 - INFO -   3: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_164.vtk
2025-06-27 14:59:04,901 - INFO -   4: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_030.vtk
2025-06-27 14:59:04,901 - INFO -   5: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_132.vtk
2025-06-27 14:59:04,902 - INFO -   6: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_107.vtk
2025-06-27 14:59:04,902 - INFO -   7: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_186.vtk
2025-06-27 14:59:04,902 - INFO -   8: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_079.vtk
2025-06-27 14:59:04,902 - INFO -   9: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_018.vtk
2025-06-27 14:59:04,902 - INFO -  10: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_015.vtk
2025-06-27 14:59:04,902 - INFO -  11: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_191.vtk
2025-06-27 14:59:04,902 - INFO -  12: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_084.vtk
2025-06-27 14:59:04,902 - INFO -  13: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_129.vtk
2025-06-27 14:59:04,902 - INFO -  14: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_080.vtk
2025-06-27 14:59:04,902 - INFO -  15: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_010.vtk
2025-06-27 14:59:04,902 - INFO -  16: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_094.vtk
2025-06-27 14:59:04,902 - INFO -  17: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_035.vtk
2025-06-27 14:59:04,902 - INFO -  18: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_003.vtk
2025-06-27 14:59:04,902 - INFO -  19: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_142.vtk
2025-06-27 14:59:04,902 - INFO -  20: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_005.vtk
2025-06-27 14:59:04,902 - INFO -  21: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_024.vtk
2025-06-27 14:59:04,902 - INFO -  22: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_106.vtk
2025-06-27 14:59:04,902 - INFO -  23: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_161.vtk
2025-06-27 14:59:04,902 - INFO -  24: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_171.vtk
2025-06-27 14:59:04,902 - INFO -  25: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_156.vtk
2025-06-27 14:59:04,903 - INFO -  26: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_053.vtk
2025-06-27 14:59:04,903 - INFO -  27: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_059.vtk
2025-06-27 14:59:04,903 - INFO -  28: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_082.vtk
2025-06-27 14:59:04,903 - INFO -  29: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_109.vtk
2025-06-27 14:59:04,903 - INFO -  30: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_139.vtk
2025-06-27 14:59:04,903 - INFO -  31: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_055.vtk
2025-06-27 14:59:04,903 - INFO -  32: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_088.vtk
2025-06-27 14:59:04,903 - INFO -  33: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_174.vtk
2025-06-27 14:59:04,903 - INFO -  34: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_104.vtk
2025-06-27 14:59:04,903 - INFO -  35: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_014.vtk
2025-06-27 14:59:04,903 - INFO -  36: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_072.vtk
2025-06-27 14:59:04,903 - INFO -  37: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_146.vtk
2025-06-27 14:59:04,904 - INFO -  38: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_194.vtk
2025-06-27 14:59:04,904 - INFO -  39: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_066.vtk
2025-06-27 14:59:04,904 - INFO -  40: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_067.vtk
2025-06-27 14:59:04,904 - INFO -  41: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_130.vtk
2025-06-27 14:59:04,904 - INFO -  42: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_131.vtk
2025-06-27 14:59:04,904 - INFO -  43: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_182.vtk
2025-06-27 14:59:04,904 - INFO -  44: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_049.vtk
2025-06-27 14:59:04,904 - INFO -  45: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_022.vtk
2025-06-27 14:59:04,904 - INFO -  46: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_042.vtk
2025-06-27 14:59:04,904 - INFO -  47: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_036.vtk
2025-06-27 14:59:04,904 - INFO -  48: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_137.vtk
2025-06-27 14:59:04,904 - INFO -  49: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_187.vtk
2025-06-27 14:59:04,904 - INFO -  50: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_195.vtk
2025-06-27 14:59:04,904 - INFO -  51: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_180.vtk
2025-06-27 14:59:04,904 - INFO -  52: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_119.vtk
2025-06-27 14:59:04,905 - INFO -  53: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_169.vtk
2025-06-27 14:59:04,905 - INFO -  54: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_092.vtk
2025-06-27 14:59:04,905 - INFO -  55: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_001.vtk
2025-06-27 14:59:04,905 - INFO -  56: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_021.vtk
2025-06-27 14:59:04,905 - INFO -  57: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_192.vtk
2025-06-27 14:59:04,905 - INFO -  58: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_100.vtk
2025-06-27 14:59:04,905 - INFO -  59: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_108.vtk
2025-06-27 14:59:04,905 - INFO -  60: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_093.vtk
2025-06-27 14:59:04,905 - INFO -  61: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_149.vtk
2025-06-27 14:59:04,905 - INFO -  62: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_060.vtk
2025-06-27 14:59:04,905 - INFO -  63: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_027.vtk
2025-06-27 14:59:04,905 - INFO -  64: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_061.vtk
2025-06-27 14:59:04,905 - INFO -  65: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_096.vtk
2025-06-27 14:59:04,905 - INFO -  66: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_039.vtk
2025-06-27 14:59:04,905 - INFO -  67: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_118.vtk
2025-06-27 14:59:04,905 - INFO -  68: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_122.vtk
2025-06-27 14:59:04,905 - INFO -  69: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_153.vtk
2025-06-27 14:59:04,905 - INFO -  70: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_144.vtk
2025-06-27 14:59:04,905 - INFO -  71: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_138.vtk
2025-06-27 14:59:04,905 - INFO -  72: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_068.vtk
2025-06-27 14:59:04,905 - INFO -  73: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_115.vtk
2025-06-27 14:59:04,905 - INFO -  74: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_028.vtk
2025-06-27 14:59:04,905 - INFO -  75: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_136.vtk
2025-06-27 14:59:04,905 - INFO -  76: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_085.vtk
2025-06-27 14:59:04,905 - INFO -  77: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_097.vtk
2025-06-27 14:59:04,906 - INFO -  78: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_140.vtk
2025-06-27 14:59:04,906 - INFO -  79: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_190.vtk
2025-06-27 14:59:04,906 - INFO -  80: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_150.vtk
2025-06-27 14:59:04,906 - INFO -  81: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_170.vtk
2025-06-27 14:59:04,906 - INFO -  82: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_095.vtk
2025-06-27 14:59:04,906 - INFO -  83: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_071.vtk
2025-06-27 14:59:04,906 - INFO -  84: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_155.vtk
2025-06-27 14:59:04,906 - INFO - Type of full_dataset: <class 'data_loader.SurfacePressureDataset'>
2025-06-27 14:59:04,906 - INFO - Number of samples of full_dataset: 130
2025-06-27 14:59:04,906 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_073.vtk: 0
2025-06-27 14:59:04,907 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_051.vtk: 1
2025-06-27 14:59:04,907 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_099.vtk: 2
2025-06-27 14:59:04,907 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_009.vtk: 3
2025-06-27 14:59:04,907 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_164.vtk: 4
2025-06-27 14:59:04,907 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_166.vtk: 5
2025-06-27 14:59:04,907 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_030.vtk: 6
2025-06-27 14:59:04,907 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_132.vtk: 7
2025-06-27 14:59:04,907 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_114.vtk: 8
2025-06-27 14:59:04,907 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_107.vtk: 9
2025-06-27 14:59:04,907 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_186.vtk: 10
2025-06-27 14:59:04,907 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_175.vtk: 11
2025-06-27 14:59:04,907 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_079.vtk: 12
2025-06-27 14:59:04,907 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_018.vtk: 13
2025-06-27 14:59:04,907 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_015.vtk: 14
2025-06-27 14:59:04,907 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_191.vtk: 15
2025-06-27 14:59:04,907 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_084.vtk: 16
2025-06-27 14:59:04,907 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_032.vtk: 17
2025-06-27 14:59:04,907 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_129.vtk: 18
2025-06-27 14:59:04,907 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_080.vtk: 19
2025-06-27 14:59:04,907 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_010.vtk: 20
2025-06-27 14:59:04,907 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_094.vtk: 21
2025-06-27 14:59:04,908 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_078.vtk: 22
2025-06-27 14:59:04,908 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_035.vtk: 23
2025-06-27 14:59:04,908 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_003.vtk: 24
2025-06-27 14:59:04,908 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_020.vtk: 25
2025-06-27 14:59:04,908 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_142.vtk: 26
2025-06-27 14:59:04,908 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_005.vtk: 27
2025-06-27 14:59:04,908 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_112.vtk: 28
2025-06-27 14:59:04,908 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_125.vtk: 29
2025-06-27 14:59:04,908 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_024.vtk: 30
2025-06-27 14:59:04,908 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_106.vtk: 31
2025-06-27 14:59:04,908 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_161.vtk: 32
2025-06-27 14:59:04,908 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_171.vtk: 33
2025-06-27 14:59:04,908 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_156.vtk: 34
2025-06-27 14:59:04,908 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_053.vtk: 35
2025-06-27 14:59:04,908 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_160.vtk: 36
2025-06-27 14:59:04,908 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_059.vtk: 37
2025-06-27 14:59:04,908 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_082.vtk: 38
2025-06-27 14:59:04,908 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_109.vtk: 39
2025-06-27 14:59:04,908 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_026.vtk: 40
2025-06-27 14:59:04,908 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_139.vtk: 41
2025-06-27 14:59:04,908 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_055.vtk: 42
2025-06-27 14:59:04,908 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_088.vtk: 43
2025-06-27 14:59:04,909 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_174.vtk: 44
2025-06-27 14:59:04,909 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_104.vtk: 45
2025-06-27 14:59:04,909 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_168.vtk: 46
2025-06-27 14:59:04,909 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_014.vtk: 47
2025-06-27 14:59:04,909 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_072.vtk: 48
2025-06-27 14:59:04,909 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_147.vtk: 49
2025-06-27 14:59:04,909 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_146.vtk: 50
2025-06-27 14:59:04,909 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_194.vtk: 51
2025-06-27 14:59:04,909 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_141.vtk: 52
2025-06-27 14:59:04,909 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_002.vtk: 53
2025-06-27 14:59:04,910 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_066.vtk: 54
2025-06-27 14:59:04,910 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_050.vtk: 55
2025-06-27 14:59:04,910 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_067.vtk: 56
2025-06-27 14:59:04,910 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_130.vtk: 57
2025-06-27 14:59:04,910 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_025.vtk: 58
2025-06-27 14:59:04,910 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_019.vtk: 59
2025-06-27 14:59:04,910 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_131.vtk: 60
2025-06-27 14:59:04,910 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_182.vtk: 61
2025-06-27 14:59:04,910 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_049.vtk: 62
2025-06-27 14:59:04,910 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_022.vtk: 63
2025-06-27 14:59:04,910 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_042.vtk: 64
2025-06-27 14:59:04,910 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_177.vtk: 65
2025-06-27 14:59:04,910 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_036.vtk: 66
2025-06-27 14:59:04,910 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_137.vtk: 67
2025-06-27 14:59:04,910 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_187.vtk: 68
2025-06-27 14:59:04,910 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_195.vtk: 69
2025-06-27 14:59:04,910 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_180.vtk: 70
2025-06-27 14:59:04,910 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_178.vtk: 71
2025-06-27 14:59:04,910 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_119.vtk: 72
2025-06-27 14:59:04,910 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_169.vtk: 73
2025-06-27 14:59:04,910 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_189.vtk: 74
2025-06-27 14:59:04,910 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_092.vtk: 75
2025-06-27 14:59:04,910 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_116.vtk: 76
2025-06-27 14:59:04,911 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_001.vtk: 77
2025-06-27 14:59:04,911 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_029.vtk: 78
2025-06-27 14:59:04,911 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_021.vtk: 79
2025-06-27 14:59:04,911 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_192.vtk: 80
2025-06-27 14:59:04,911 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_100.vtk: 81
2025-06-27 14:59:04,911 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_087.vtk: 82
2025-06-27 14:59:04,911 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_108.vtk: 83
2025-06-27 14:59:04,911 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_093.vtk: 84
2025-06-27 14:59:04,911 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_034.vtk: 85
2025-06-27 14:59:04,911 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_159.vtk: 86
2025-06-27 14:59:04,911 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_089.vtk: 87
2025-06-27 14:59:04,911 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_065.vtk: 88
2025-06-27 14:59:04,911 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_149.vtk: 89
2025-06-27 14:59:04,911 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_075.vtk: 90
2025-06-27 14:59:04,911 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_060.vtk: 91
2025-06-27 14:59:04,911 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_148.vtk: 92
2025-06-27 14:59:04,911 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_027.vtk: 93
2025-06-27 14:59:04,911 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_061.vtk: 94
2025-06-27 14:59:04,911 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_096.vtk: 95
2025-06-27 14:59:04,911 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_039.vtk: 96
2025-06-27 14:59:04,912 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_058.vtk: 97
2025-06-27 14:59:04,912 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_118.vtk: 98
2025-06-27 14:59:04,912 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_091.vtk: 99
2025-06-27 14:59:04,912 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_057.vtk: 100
2025-06-27 14:59:04,912 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_122.vtk: 101
2025-06-27 14:59:04,912 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_153.vtk: 102
2025-06-27 14:59:04,912 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_144.vtk: 103
2025-06-27 14:59:04,912 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_138.vtk: 104
2025-06-27 14:59:04,912 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_068.vtk: 105
2025-06-27 14:59:04,912 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_115.vtk: 106
2025-06-27 14:59:04,912 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_135.vtk: 107
2025-06-27 14:59:04,912 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_044.vtk: 108
2025-06-27 14:59:04,912 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_028.vtk: 109
2025-06-27 14:59:04,912 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_136.vtk: 110
2025-06-27 14:59:04,912 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_085.vtk: 111
2025-06-27 14:59:04,913 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_097.vtk: 112
2025-06-27 14:59:04,913 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_121.vtk: 113
2025-06-27 14:59:04,913 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_017.vtk: 114
2025-06-27 14:59:04,913 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_140.vtk: 115
2025-06-27 14:59:04,913 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_190.vtk: 116
2025-06-27 14:59:04,913 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_023.vtk: 117
2025-06-27 14:59:04,913 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_047.vtk: 118
2025-06-27 14:59:04,913 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_150.vtk: 119
2025-06-27 14:59:04,913 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_070.vtk: 120
2025-06-27 14:59:04,913 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_170.vtk: 121
2025-06-27 14:59:04,913 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_110.vtk: 122
2025-06-27 14:59:04,913 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_081.vtk: 123
2025-06-27 14:59:04,913 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_172.vtk: 124
2025-06-27 14:59:04,913 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_095.vtk: 125
2025-06-27 14:59:04,913 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_071.vtk: 126
2025-06-27 14:59:04,913 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_117.vtk: 127
2025-06-27 14:59:04,913 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_155.vtk: 128
2025-06-27 14:59:04,913 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_043.vtk: 129
2025-06-27 14:59:04,913 - INFO - Data loaded: 42 training batches, 10 validation batches, 12 test batches
2025-06-27 14:59:04,916 - INFO - Staring training for 10 epochs
2025-06-27 14:59:40,988 - INFO - args.exp_name : Train_Test
2025-06-27 14:59:40,988 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=2, epochs=10, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-27 14:59:40,988 - INFO - Starting training with 1 GPUs
2025-06-27 14:59:57,654 - INFO - Total trainable parameters: 1437705
2025-06-27 14:59:57,800 - INFO - Type of train_dataloader: <class 'torch.utils.data.dataloader.DataLoader'>
2025-06-27 14:59:57,801 - INFO - Number of train_dataloader: 42
2025-06-27 14:59:57,801 - INFO - We can access the internal conetnt by dataloader: 
2025-06-27 15:01:35,623 - INFO - args.exp_name : Train_Test
2025-06-27 15:01:35,624 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Cache_data', num_points=10000, batch_size=2, epochs=10, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-27 15:01:35,624 - INFO - Starting training with 1 GPUs
2025-06-27 15:01:38,313 - INFO - Total trainable parameters: 1437705
2025-06-27 15:01:38,364 - INFO - Type of train_dataloader: <class 'torch.utils.data.dataloader.DataLoader'>
2025-06-27 15:01:38,364 - INFO - Number of train_dataloader: 42
2025-06-27 15:01:38,364 - INFO - We can access the internal conetnt by dataloader: 
2025-06-27 15:01:42,229 - INFO - Batch: 0
2025-06-27 15:01:42,229 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,229 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,229 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,235 - INFO - The first 10 points in x_coor for the sample_0: tensor([-0.0485, -0.5382,  0.8928, -0.5284,  0.1444,  2.6208,  2.9762,  3.6200,
        -0.3787,  1.3031])
2025-06-27 15:01:42,235 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 0.2833,  2.6895,  2.9486,  1.6583, -0.7939,  2.0023,  3.1221, -0.4969,
         1.6010,  3.6084])
2025-06-27 15:01:42,235 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,235 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,235 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,236 - INFO - The first 10 points pressure for the sample_0: tensor([-338.8030, -198.2250, -328.4480, -501.5070, -109.0920,  -77.5971,
         -91.8080,  -29.4908, -284.0090,  -91.4154])
2025-06-27 15:01:42,236 - INFO - The first 10 points pressure for the sample_1: tensor([-184.4790,  -81.4952, -111.3050,  -65.2745,  262.2230, -241.2780,
         -14.4769, -133.4740,  -90.2832,  -18.6696])
2025-06-27 15:01:42,237 - INFO - Batch: 1
2025-06-27 15:01:42,237 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,237 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,237 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,238 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 0.3513,  1.2264,  2.3647,  0.1573, -0.5166,  0.6042,  2.8162,  3.3206,
         2.9534,  3.4002])
2025-06-27 15:01:42,238 - INFO - The first 10 points in x_coor for the sample_1: tensor([-0.3273,  2.5158,  1.0972,  3.1233,  2.9517,  0.5927,  1.0853,  2.0020,
         1.7042,  1.0168])
2025-06-27 15:01:42,238 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,238 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,241 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,241 - INFO - The first 10 points pressure for the sample_0: tensor([-148.8720, -323.1080, -107.6920, -145.9240, -122.9890, -107.0480,
         -73.7163,  -52.5742,  -81.2839,  -54.2815])
2025-06-27 15:01:42,243 - INFO - The first 10 points pressure for the sample_1: tensor([-162.1830, -182.7360,  -78.5279,  -28.9796,  -74.6324, -160.5080,
         -74.9221, -181.3020,  -57.2525, -253.2530])
2025-06-27 15:01:42,259 - INFO - Batch: 2
2025-06-27 15:01:42,259 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,259 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,259 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,260 - INFO - The first 10 points in x_coor for the sample_0: tensor([-0.6993,  2.4030,  0.8899,  2.0135,  3.2732,  2.8507, -0.0716,  1.6125,
         2.9042,  0.3750])
2025-06-27 15:01:42,260 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 0.1687,  0.1376,  1.5781,  2.6907, -0.8913,  3.2266, -0.2999,  1.4406,
         3.1044,  0.3440])
2025-06-27 15:01:42,260 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,260 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,260 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,261 - INFO - The first 10 points pressure for the sample_0: tensor([-208.3020,  -73.5788, -553.2300, -180.9300,  -24.8334, -148.6590,
        -183.7780,  -86.4613, -121.7070, -128.1350])
2025-06-27 15:01:42,261 - INFO - The first 10 points pressure for the sample_1: tensor([-165.9060, -261.3880,  -70.9110, -124.4570,  266.7510,  -80.9190,
         -47.6652,  -66.3573,  -81.4829, -123.6120])
2025-06-27 15:01:42,271 - INFO - Batch: 3
2025-06-27 15:01:42,271 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,271 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,271 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,272 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 1.6583,  2.0797, -0.6899,  2.9531, -0.5864,  2.2427,  1.3490, -0.5493,
        -0.0602, -0.4740])
2025-06-27 15:01:42,272 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 2.3746,  1.6812,  2.2774,  1.6584,  1.9345,  2.5699, -0.2872,  1.8989,
         0.3043, -0.3038])
2025-06-27 15:01:42,273 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,273 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,273 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,273 - INFO - The first 10 points pressure for the sample_0: tensor([ -57.7625, -188.2780,  -41.3928,  -56.4165, -216.8250,  -48.8867,
         -71.5313, -197.1700, -160.1030, -137.5480])
2025-06-27 15:01:42,273 - INFO - The first 10 points pressure for the sample_1: tensor([ -94.1245,  -81.8525,  -96.1851,  -76.5446,  -79.7430,  -61.4083,
        -213.5430, -109.7750, -182.5630,  287.5700])
2025-06-27 15:01:42,295 - INFO - Batch: 4
2025-06-27 15:01:42,295 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,295 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,295 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,296 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 0.2684,  0.2005,  2.4938, -0.8517, -0.1792,  1.2573,  3.1068,  3.0116,
         0.9479,  1.2227])
2025-06-27 15:01:42,296 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 0.2343,  1.0350, -0.3204,  0.1797,  1.8875,  0.1917, -0.0378,  2.6067,
         2.1969,  1.3375])
2025-06-27 15:01:42,296 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,296 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,296 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,297 - INFO - The first 10 points pressure for the sample_0: tensor([-173.1780, -202.8530,  -80.9509,  327.1650, -128.7190, -326.8660,
         -40.6500,  -19.0033, -106.4500, -370.2060])
2025-06-27 15:01:42,297 - INFO - The first 10 points pressure for the sample_1: tensor([-131.4480, -711.7170,  -99.5009,   28.7482,  -64.0691, -150.5970,
        -155.0720, -118.3460,  -41.2665,  -54.1201])
2025-06-27 15:01:42,305 - INFO - Batch: 5
2025-06-27 15:01:42,305 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,305 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,305 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,306 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 2.5521,  2.6666,  0.5497,  0.1573,  2.8155,  2.9984, -0.1173,  2.5646,
        -0.9318,  0.5025])
2025-06-27 15:01:42,306 - INFO - The first 10 points in x_coor for the sample_1: tensor([-0.3631,  3.3885,  0.4810, -0.2440,  1.7385, -0.4245, -0.0946, -0.6986,
         2.2198,  2.6981])
2025-06-27 15:01:42,306 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,306 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,307 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,307 - INFO - The first 10 points pressure for the sample_0: tensor([ -84.8091,  -77.7356,   97.0457, -153.8820, -132.9120,  -61.9000,
        -132.3560,  -76.8720,  436.0530,   81.3881])
2025-06-27 15:01:42,307 - INFO - The first 10 points pressure for the sample_1: tensor([-102.3700,  -15.2985,   80.3081, -129.9610,  -95.3753,  -90.2176,
        -133.5760,   22.5415, -142.7650,  -88.9344])
2025-06-27 15:01:42,314 - INFO - Batch: 6
2025-06-27 15:01:42,314 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,314 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,314 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,314 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 1.6010,  1.1225,  1.3490,  2.9752,  0.3980,  1.9333, -0.0454,  3.7736,
         0.4439,  2.0478])
2025-06-27 15:01:42,314 - INFO - The first 10 points in x_coor for the sample_1: tensor([0.2603, 2.6326, 0.7668, 0.3881, 0.9500, 0.7333, 2.7462, 3.3095, 0.7302,
        1.3604])
2025-06-27 15:01:42,315 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,315 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,315 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,315 - INFO - The first 10 points pressure for the sample_0: tensor([ -72.9790, -519.1740, -101.6530,  -85.5379,   82.8267, -191.4840,
         -87.2200,  -25.2302,  -84.1994,  -76.7869])
2025-06-27 15:01:42,315 - INFO - The first 10 points pressure for the sample_1: tensor([-356.8900,  -64.7882,   63.8028,  -26.0867, -324.4070,   48.0206,
        -399.5770, -150.6780,  -78.1401,  -75.5552])
2025-06-27 15:01:42,334 - INFO - Batch: 7
2025-06-27 15:01:42,335 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,335 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,335 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,335 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 1.5431e+00,  3.2020e+00,  3.6874e+00,  1.5438e+00,  5.2393e-01,
         2.0708e+00,  3.3398e+00,  1.2687e+00,  3.7581e+00, -3.0862e-03])
2025-06-27 15:01:42,336 - INFO - The first 10 points in x_coor for the sample_1: tensor([-0.3220,  0.0083,  3.5499,  2.8617,  1.1195,  3.0793, -0.1098,  2.8404,
         2.3572,  3.3744])
2025-06-27 15:01:42,336 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,336 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,336 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,336 - INFO - The first 10 points pressure for the sample_0: tensor([ -41.2135,  -13.3389,  -55.2665, -199.9300, -107.1490,  -49.8250,
         -57.6707,  -68.3031,  -34.3428, -156.1310])
2025-06-27 15:01:42,337 - INFO - The first 10 points pressure for the sample_1: tensor([-186.6740, -176.6460,   28.5065,  -86.4264, -184.2440, -153.2230,
        -161.5000,   55.2674,  -68.8246,   50.5586])
2025-06-27 15:01:42,345 - INFO - Batch: 8
2025-06-27 15:01:42,345 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,345 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,345 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,346 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 0.2492,  0.2958,  0.0304,  0.3405, -0.1605,  2.1281,  0.0187,  1.7500,
         0.7300,  1.3520])
2025-06-27 15:01:42,347 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 2.2083,  2.9885,  3.2353,  1.7729,  3.8352,  3.5629,  0.2343, -0.1897,
        -0.1860,  0.8676])
2025-06-27 15:01:42,347 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,347 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,347 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,347 - INFO - The first 10 points pressure for the sample_0: tensor([-399.0650, -154.6710, -195.3250,  -35.4192, -752.6250, -166.1940,
         -32.8515,  -81.4531,   85.0086, -146.5700])
2025-06-27 15:01:42,348 - INFO - The first 10 points pressure for the sample_1: tensor([ -85.3987,  -75.0366,  -75.1776,  -76.2214,  -25.3767,  -48.0276,
        -294.6700, -621.4550,  -99.7808, -125.2340])
2025-06-27 15:01:42,356 - INFO - Batch: 9
2025-06-27 15:01:42,356 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,356 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,356 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,357 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 1.6813,  0.9128,  2.3372,  2.3220,  2.5514,  2.5759,  2.3228,  2.6669,
        -0.1183,  0.7985])
2025-06-27 15:01:42,357 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 3.8912,  0.3833,  2.2885, -0.3175,  3.1891, -0.0260, -0.5542,  1.2801,
         3.1246,  2.3803])
2025-06-27 15:01:42,357 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,357 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,357 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,358 - INFO - The first 10 points pressure for the sample_0: tensor([ -74.5930, -468.5290,  -17.8253, -111.4660, -279.8660,  -89.8917,
         -81.7025, -230.2680, -153.5960,   18.8863])
2025-06-27 15:01:42,358 - INFO - The first 10 points pressure for the sample_1: tensor([ -62.1802,   95.3592,  -73.3089, -172.8170,  -41.2741, -161.2840,
         -57.3265, -262.5780, -101.2380,  -39.0603])
2025-06-27 15:01:42,365 - INFO - Batch: 10
2025-06-27 15:01:42,365 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,365 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,365 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,366 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 1.0061,  0.3184,  1.2802,  1.1238,  2.8385, -0.5982,  2.9736,  3.1936,
         2.8499, -0.7896])
2025-06-27 15:01:42,366 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 2.7120, -0.3803,  2.9076,  2.5315,  1.9188, -0.3108,  3.8506,  0.5791,
         2.8501,  0.2604])
2025-06-27 15:01:42,366 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,366 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,366 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,367 - INFO - The first 10 points pressure for the sample_0: tensor([-119.4090,   -7.9263,  -97.0791, -215.6410,  -71.9722,  -38.5220,
         -76.4743,    1.0474,  -67.6804,  296.0490])
2025-06-27 15:01:42,367 - INFO - The first 10 points pressure for the sample_1: tensor([-112.9390, -178.6530, -134.2990,  -31.5704,  -71.9506, -192.3010,
         -16.1056,  163.5570, -113.4070, -174.5600])
2025-06-27 15:01:42,395 - INFO - Batch: 11
2025-06-27 15:01:42,395 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,396 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,396 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,396 - INFO - The first 10 points in x_coor for the sample_0: tensor([-0.1075,  3.8310,  2.6669,  2.5005,  0.5240, -0.3776,  0.1010, -0.0613,
         0.8792,  2.9784])
2025-06-27 15:01:42,397 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 3.8087,  0.8565,  2.6422,  2.0250, -0.7496, -0.1292,  0.1458,  0.0684,
         1.5663, -0.0601])
2025-06-27 15:01:42,397 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,397 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,397 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,397 - INFO - The first 10 points pressure for the sample_0: tensor([-159.9450,  -22.9807,  -89.1701,  -74.5420,  -94.6650, -170.8510,
        -145.5740, -175.5390,  -95.2538,  -97.0740])
2025-06-27 15:01:42,397 - INFO - The first 10 points pressure for the sample_1: tensor([ -69.0255,  -82.4216,  -41.9460,  -69.3559,  318.6280, -154.0390,
          65.4091, -241.1140,  -95.6229, -201.5230])
2025-06-27 15:01:42,403 - INFO - Batch: 12
2025-06-27 15:01:42,404 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,404 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,404 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,404 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 2.4883,  3.8665,  3.0949,  1.4288,  0.8677,  1.4062, -0.1070, -0.1792,
        -0.7087,  1.6583])
2025-06-27 15:01:42,404 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 1.4521, -0.3804,  2.6021,  2.8123,  0.8792, -0.3793,  0.6042, -0.6245,
         0.3771,  0.4348])
2025-06-27 15:01:42,405 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,405 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,405 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,405 - INFO - The first 10 points pressure for the sample_0: tensor([ -86.7106,  -19.0995, -112.9440, -238.0560, -190.9050, -137.6680,
         -31.7392, -184.7600,  -52.8803,  -75.6506])
2025-06-27 15:01:42,405 - INFO - The first 10 points pressure for the sample_1: tensor([ -74.8531,  -72.0747,  -79.8344, -177.5810, -144.1570,  -77.6853,
         -70.6408, -160.1670, -128.4620,  102.3960])
2025-06-27 15:01:42,413 - INFO - Batch: 13
2025-06-27 15:01:42,413 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,413 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,414 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,414 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 0.1904,  1.5466,  0.2231, -0.7438, -0.6833,  2.7010,  3.1388, -0.5140,
         0.0188,  0.3035])
2025-06-27 15:01:42,415 - INFO - The first 10 points in x_coor for the sample_1: tensor([-0.9523,  3.2254, -0.8287,  2.6178,  0.3874, -0.4131,  1.7728,  2.4983,
        -0.7710,  2.7925])
2025-06-27 15:01:42,415 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,415 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,415 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,415 - INFO - The first 10 points pressure for the sample_0: tensor([ -11.0432, -181.9940, -209.9080,  334.9540,  -21.7079, -117.5570,
        -177.2140, -252.7250, -114.8210, -136.9090])
2025-06-27 15:01:42,416 - INFO - The first 10 points pressure for the sample_1: tensor([ 376.2220,  -66.3437,  -79.2989,  -83.8929,   84.3352, -319.6010,
        -209.7620, -110.9740, -149.2000, -128.4940])
2025-06-27 15:01:42,441 - INFO - Batch: 14
2025-06-27 15:01:42,442 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,442 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,442 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,443 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 1.9188,  1.9219, -0.2439, -0.2003,  3.6165,  3.7250, -0.6370, -0.1329,
         1.4949,  1.0856])
2025-06-27 15:01:42,443 - INFO - The first 10 points in x_coor for the sample_1: tensor([0.9479, 0.2294, 0.2146, 1.4291, 2.4146, 0.3630, 3.1962, 3.5604, 2.1624,
        2.9073])
2025-06-27 15:01:42,443 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,443 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,443 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,444 - INFO - The first 10 points pressure for the sample_0: tensor([ -63.7926, -202.4660, -114.2120, -170.5030,  -25.9001,  -14.2671,
         202.1390, -156.5060,  -74.7689, -302.7870])
2025-06-27 15:01:42,444 - INFO - The first 10 points pressure for the sample_1: tensor([-101.0460, -168.4900, -162.7870, -163.8160,  -32.0137, -122.1340,
         -70.1305,   61.3782, -206.4840,  -77.4960])
2025-06-27 15:01:42,451 - INFO - Batch: 15
2025-06-27 15:01:42,451 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,451 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,451 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,451 - INFO - The first 10 points in x_coor for the sample_0: tensor([1.6354, 2.7358, 3.0108, 2.9425, 0.5582, 3.3426, 1.6927, 2.6554, 1.1885,
        2.9646])
2025-06-27 15:01:42,452 - INFO - The first 10 points in x_coor for the sample_1: tensor([0.7073, 2.6755, 0.4456, 0.2009, 3.9422, 2.2771, 2.5980, 2.0823, 1.0969,
        0.8215])
2025-06-27 15:01:42,452 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,452 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,452 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,452 - INFO - The first 10 points pressure for the sample_0: tensor([ -53.3478, -249.1540, -217.1740,  -38.3287,  -57.3577,  -39.5899,
         -53.4930, -198.4300,  -62.9154,  -72.7477])
2025-06-27 15:01:42,452 - INFO - The first 10 points pressure for the sample_1: tensor([ -69.7244, -171.5290,   77.3724, -124.6980,  -16.5869,  -37.1627,
        -110.4390,  -50.8352,  -93.0625,   35.6096])
2025-06-27 15:01:42,458 - INFO - Batch: 16
2025-06-27 15:01:42,459 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,459 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,459 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,459 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 1.0866,  3.0906,  2.8814,  3.3540,  0.1802,  3.5031, -0.4595,  2.9398,
        -0.6862,  2.8402])
2025-06-27 15:01:42,460 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 1.3375,  2.6600,  0.9213, -0.2852,  3.8668,  3.6532,  0.0999, -0.0257,
        -0.4694,  3.0822])
2025-06-27 15:01:42,460 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,460 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,460 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,460 - INFO - The first 10 points pressure for the sample_0: tensor([-139.3840,  -76.1815,  -77.5190,  -45.6850, -198.1980,   18.8768,
        -231.3870,  -84.9075,  368.2710,  -40.0785])
2025-06-27 15:01:42,460 - INFO - The first 10 points pressure for the sample_1: tensor([ -64.3042,  -57.6938, -522.9560,  408.5530,  -19.7023,  -25.3357,
        -126.2210,  -57.5550, -155.8810,   95.9221])
2025-06-27 15:01:42,470 - INFO - Batch: 17
2025-06-27 15:01:42,470 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,471 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,471 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,472 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 0.1838,  1.5781, -0.1521,  0.9625,  1.6583,  0.0083, -0.0349,  3.1378,
         2.3802,  0.3751])
2025-06-27 15:01:42,472 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 1.6692,  3.0700,  3.6759,  3.8323, -0.6323,  0.4708, -0.5861,  2.3115,
        -0.5990, -0.3932])
2025-06-27 15:01:42,472 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,472 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,472 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,472 - INFO - The first 10 points pressure for the sample_0: tensor([-211.8480,  -64.9082, -183.0390, -291.3150,  -68.5615, -128.2960,
        -151.9780,  -87.9528,  -53.8223,   52.7714])
2025-06-27 15:01:42,473 - INFO - The first 10 points pressure for the sample_1: tensor([-188.8770,  -90.7600, -102.9600,  -74.7353, -238.1230,   93.8826,
        -216.2530, -112.1910,    4.2031, -268.9180])
2025-06-27 15:01:42,478 - INFO - Batch: 18
2025-06-27 15:01:42,478 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,479 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,479 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,479 - INFO - The first 10 points in x_coor for the sample_0: tensor([-0.4499,  3.2238,  0.0198, -0.8947,  0.1846,  0.3769,  2.5953,  0.1344,
         2.6005,  2.5104])
2025-06-27 15:01:42,479 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 3.6021, -0.4711,  0.2979, -0.4244,  0.1350,  3.0414, -0.7052,  2.4948,
         0.1110,  0.1914])
2025-06-27 15:01:42,479 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,479 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,480 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,480 - INFO - The first 10 points pressure for the sample_0: tensor([ -76.2705, -109.5390, -188.3260,  252.8330, -176.8290, -152.6550,
         -65.6192, -174.7490, -241.6180,  -97.7168])
2025-06-27 15:01:42,480 - INFO - The first 10 points pressure for the sample_1: tensor([ -18.4898, -178.5000, -314.8540, -146.0690, -120.9740,  -48.0461,
         289.0650, -100.6570, -146.2480,  -62.3305])
2025-06-27 15:01:42,486 - INFO - Batch: 19
2025-06-27 15:01:42,486 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,487 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,487 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,487 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 2.6556,  0.7761,  2.6521, -0.1636,  3.1249, -0.1745,  2.7500,  3.6731,
         3.3997,  2.8615])
2025-06-27 15:01:42,487 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 3.1495, -0.2890, -0.9955,  0.1877,  2.8025,  2.8040, -0.9255,  3.0113,
         2.6665,  0.9294])
2025-06-27 15:01:42,488 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,488 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,488 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,488 - INFO - The first 10 points pressure for the sample_0: tensor([ -90.2428,  -87.7525, -174.1110, -156.8580,  -88.2660, -195.9300,
        -256.0310,   -8.6092, -122.2230,  -52.9257])
2025-06-27 15:01:42,488 - INFO - The first 10 points pressure for the sample_1: tensor([ -55.0505, -122.1260,  396.7610,  -90.2323, -152.7490,  -82.5651,
         328.6670, -427.7260, -100.4770,  -27.4212])
2025-06-27 15:01:42,495 - INFO - Batch: 20
2025-06-27 15:01:42,495 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,495 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,495 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,496 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 2.7703,  3.6288, -0.0146,  0.1477,  2.8393,  2.8385,  1.3833,  3.0913,
         2.8498, -0.1425])
2025-06-27 15:01:42,496 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 0.3972,  3.9183,  3.2692,  3.7785, -0.1782,  2.5976, -0.3481,  3.4233,
         3.6062,  0.2469])
2025-06-27 15:01:42,497 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,497 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,497 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,497 - INFO - The first 10 points pressure for the sample_0: tensor([ -83.3786,  -22.5281, -175.6870, -139.1320,  -77.1722,  -71.0416,
         -81.8121,  -42.6166, -128.7640, -126.2550])
2025-06-27 15:01:42,497 - INFO - The first 10 points pressure for the sample_1: tensor([-201.5640,  -16.7136, -106.6490,  -42.4794, -175.8160,   -8.5266,
        -134.5120, -136.8020,  -58.7743, -206.3970])
2025-06-27 15:01:42,503 - INFO - Batch: 21
2025-06-27 15:01:42,503 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,503 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,503 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,504 - INFO - The first 10 points in x_coor for the sample_0: tensor([-0.0842,  2.7824, -0.2797,  2.4688,  0.8248,  1.1311, -0.4703,  0.1026,
         2.5978,  1.4177])
2025-06-27 15:01:42,504 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 2.4264,  2.8696,  1.6240,  2.9751,  2.6334,  0.5618,  0.1458,  0.3647,
        -0.0344,  0.9135])
2025-06-27 15:01:42,504 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,504 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,504 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,505 - INFO - The first 10 points pressure for the sample_0: tensor([-185.7600,  -93.9326, -159.4260,  -93.3238,   33.1694, -555.6100,
         -83.0041,    6.0518,  -82.7327, -174.1910])
2025-06-27 15:01:42,505 - INFO - The first 10 points pressure for the sample_1: tensor([ -98.1512,  -98.8278,  -70.9374,  -85.9046, -191.0780,  112.1150,
        -187.3720, -214.2010, -247.4480, -105.1760])
2025-06-27 15:01:42,513 - INFO - Batch: 22
2025-06-27 15:01:42,513 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,513 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,513 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,514 - INFO - The first 10 points in x_coor for the sample_0: tensor([-0.2349,  0.9135, -0.1889,  0.2861,  1.0193,  1.2458, -0.4257,  0.1707,
         2.7322,  2.7668])
2025-06-27 15:01:42,514 - INFO - The first 10 points in x_coor for the sample_1: tensor([-0.9975, -0.4127,  3.8528,  2.7812,  0.0457,  1.7387, -0.1865,  2.7813,
         0.2707, -0.6109])
2025-06-27 15:01:42,514 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,514 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,514 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,515 - INFO - The first 10 points pressure for the sample_0: tensor([ 132.8470,  -74.3528, -155.9420, -174.4330, -338.2300,  -73.8055,
        -185.3560, -112.9740,  -96.7461, -106.6330])
2025-06-27 15:01:42,515 - INFO - The first 10 points pressure for the sample_1: tensor([-373.3540, -141.6460,   25.1866,  -86.2460, -147.9350, -224.0500,
        -198.4290,  -63.9653,   87.9137,  -98.6002])
2025-06-27 15:01:42,523 - INFO - Batch: 23
2025-06-27 15:01:42,523 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,523 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,523 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,524 - INFO - The first 10 points in x_coor for the sample_0: tensor([-0.4362,  2.1394, -0.8130, -0.2289, -0.2236,  3.2831, -0.0146, -0.4587,
         1.9986,  2.7975])
2025-06-27 15:01:42,524 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 0.2382,  2.4836,  0.0085,  1.8302,  2.6476,  3.4547,  2.7562, -0.8593,
         3.8241,  0.0800])
2025-06-27 15:01:42,527 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,527 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,527 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,528 - INFO - The first 10 points pressure for the sample_0: tensor([-285.9120, -143.0830,  447.8620, -818.7190, -206.1260, -203.6470,
        -181.9760,  -92.8544,  -55.5424,  -15.3260])
2025-06-27 15:01:42,528 - INFO - The first 10 points pressure for the sample_1: tensor([ -97.2788,  -92.2684, -135.6480,  -96.3057,  -67.3315, -145.7940,
         -66.4935,  439.0400,   -4.7178, -107.6100])
2025-06-27 15:01:42,533 - INFO - Batch: 24
2025-06-27 15:01:42,533 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,533 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,534 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,534 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 2.6553, -0.2362,  3.2621,  3.5150,  3.2970, -0.3015,  1.3146,  3.5571,
         2.3335,  0.9049])
2025-06-27 15:01:42,535 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 3.6814,  2.5220,  2.0823,  3.5908,  0.2836,  0.8439,  3.6716, -0.1743,
         2.4019,  2.6665])
2025-06-27 15:01:42,535 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,535 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,535 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,535 - INFO - The first 10 points pressure for the sample_0: tensor([ -74.1879, -109.2970,  -83.0217,  -42.2152,  -95.3424, -155.8450,
         -83.9559,  -30.1028,  -67.7424,  -12.2910])
2025-06-27 15:01:42,535 - INFO - The first 10 points pressure for the sample_1: tensor([  -7.6114,  -59.0061,  -47.3247,  -30.2943,  -39.4249, -351.7790,
         -19.8623, -195.5630,  -50.2555, -120.2700])
2025-06-27 15:01:42,544 - INFO - Batch: 25
2025-06-27 15:01:42,544 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,544 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,544 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,545 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 2.0024,  2.6824, -0.5860,  3.1021,  0.9962, -0.3762,  0.0654, -0.5734,
         0.3521, -0.9314])
2025-06-27 15:01:42,545 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 1.0195,  3.0786, -0.9305,  3.6379, -0.0828,  1.6584,  0.9161,  0.9135,
        -0.0261,  0.5813])
2025-06-27 15:01:42,545 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,545 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,545 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,546 - INFO - The first 10 points pressure for the sample_0: tensor([-8.8256e+01, -8.6504e+01, -3.2214e+02, -3.3256e+02, -5.7983e+02,
        -8.2140e+01, -1.0871e+02,  4.1819e-02, -1.4809e+02,  2.5899e+02])
2025-06-27 15:01:42,546 - INFO - The first 10 points pressure for the sample_1: tensor([ -91.5531,  -88.4385,  420.0560,  -11.4785, -138.2240, -229.8700,
        -425.4430,  -91.2196, -150.3880, -118.3980])
2025-06-27 15:01:42,553 - INFO - Batch: 26
2025-06-27 15:01:42,553 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,553 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,553 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,554 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 3.2496,  0.8104, -0.5261, -0.2329,  0.4323,  3.6518,  3.7327,  1.9652,
        -0.4947, -0.5774])
2025-06-27 15:01:42,554 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 3.8151,  0.9867,  0.0400,  0.2850,  0.4326,  3.5833, -0.0836, -0.7234,
        -0.7741,  1.5676])
2025-06-27 15:01:42,554 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,554 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,555 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,555 - INFO - The first 10 points pressure for the sample_0: tensor([  32.1262,  -80.0883, -123.9470, -195.3070, -100.2010,   29.2670,
         -16.8960,  -86.8586,    3.6613,   54.4899])
2025-06-27 15:01:42,555 - INFO - The first 10 points pressure for the sample_1: tensor([ -59.2862,  -21.4684, -132.8340, -111.0530,  -52.8657,   50.1366,
        -194.1660,  113.6450,  358.9430, -226.3790])
2025-06-27 15:01:42,563 - INFO - Batch: 27
2025-06-27 15:01:42,563 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,563 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,563 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,564 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 0.3280,  0.9479,  0.6844,  0.5470, -0.5607,  0.8677,  2.4142,  1.2802,
         0.9326,  2.3344])
2025-06-27 15:01:42,565 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 3.4468,  2.4833,  2.7102,  3.8827,  3.1250,  1.1427,  1.0396, -0.1865,
         2.7696,  0.5240])
2025-06-27 15:01:42,565 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,565 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,565 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,565 - INFO - The first 10 points pressure for the sample_0: tensor([-172.0560,  -57.6567, -102.8640, -106.8040, -207.4080,  -38.4566,
         -56.6369,  -76.8144, -486.2720,  -36.1637])
2025-06-27 15:01:42,565 - INFO - The first 10 points pressure for the sample_1: tensor([  16.2851, -143.7690,  -95.7955,  -35.1342,  -63.5244,  -93.4655,
         -68.2843, -181.9770,  -75.4459,  -66.5618])
2025-06-27 15:01:42,574 - INFO - Batch: 28
2025-06-27 15:01:42,574 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,574 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,574 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,574 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 0.1690,  3.0182, -0.3117,  1.0167,  0.8448,  0.3865, -0.6800,  0.1000,
        -0.8942,  2.8359])
2025-06-27 15:01:42,575 - INFO - The first 10 points in x_coor for the sample_1: tensor([-3.1358e-03,  3.7210e+00,  3.7106e+00,  1.5323e+00, -1.1745e-01,
         1.4169e+00,  2.9957e+00, -2.5156e-02, -2.6220e-02,  1.2272e-01])
2025-06-27 15:01:42,575 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,575 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,575 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,575 - INFO - The first 10 points pressure for the sample_0: tensor([ -71.8076,  -28.2225, -180.3700,  -69.3480,  -93.5420, -103.9380,
         -31.1451, -282.2930, -208.7450, -186.7030])
2025-06-27 15:01:42,576 - INFO - The first 10 points pressure for the sample_1: tensor([-149.8820,  -47.8371,  -30.8754,  -61.2213, -179.6550, -269.8940,
         -65.7033, -205.9630, -144.7190, -148.6480])
2025-06-27 15:01:42,583 - INFO - Batch: 29
2025-06-27 15:01:42,583 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,583 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,583 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,584 - INFO - The first 10 points in x_coor for the sample_0: tensor([0.1459, 1.8531, 0.2792, 1.1312, 0.3291, 1.7615, 0.3698, 0.2260, 2.2655,
        0.0992])
2025-06-27 15:01:42,585 - INFO - The first 10 points in x_coor for the sample_1: tensor([-0.2671,  0.0199,  0.9527,  1.0279,  3.4555,  1.6812,  2.3703, -0.1861,
         3.2626,  0.0304])
2025-06-27 15:01:42,585 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,585 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,585 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,585 - INFO - The first 10 points pressure for the sample_0: tensor([-176.4800,  -56.3783,  -66.4860, -107.8410, -189.6050,  -66.6120,
         -43.6896, -199.4750, -179.7610, -173.2540])
2025-06-27 15:01:42,585 - INFO - The first 10 points pressure for the sample_1: tensor([-137.7900, -144.6510, -590.5480, -509.6860,  -54.0269, -106.7610,
         -76.1703, -273.7640, -135.9330, -154.3830])
2025-06-27 15:01:42,592 - INFO - Batch: 30
2025-06-27 15:01:42,592 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,592 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,592 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,593 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 0.9479,  0.3987, -0.1521,  1.9906, -0.0118, -0.5948,  2.6331,  0.5215,
         2.7021,  0.5607])
2025-06-27 15:01:42,593 - INFO - The first 10 points in x_coor for the sample_1: tensor([-0.5999,  1.7842,  3.0147,  2.8585,  2.1510,  1.4178, -0.8385,  0.4896,
         3.3658,  2.4531])
2025-06-27 15:01:42,593 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,593 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,593 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,594 - INFO - The first 10 points pressure for the sample_0: tensor([ -50.8184,  107.2220, -172.7260,  -58.7541, -100.8550,  -93.4919,
        -255.4690, -141.1370,  -97.2591,  154.2220])
2025-06-27 15:01:42,594 - INFO - The first 10 points pressure for the sample_1: tensor([ -92.1932,  -75.5878, -113.2290, -145.7610,  -83.5426, -248.8180,
         267.4870, -147.7300,  -47.9468,  -80.9790])
2025-06-27 15:01:42,600 - INFO - Batch: 31
2025-06-27 15:01:42,601 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,601 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,601 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,601 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 1.4635, -0.1174,  0.6167, -0.9828,  1.6812,  1.0847,  1.7729, -0.1520,
         2.5627,  3.0302])
2025-06-27 15:01:42,601 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 0.3752,  0.2724, -0.4835,  0.9250,  3.6627,  2.8386,  0.8557,  3.9218,
         3.1210, -0.3901])
2025-06-27 15:01:42,602 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,602 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,602 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,602 - INFO - The first 10 points pressure for the sample_0: tensor([ -95.1635, -107.9970,  137.8990, -377.8830,  -94.7552,  -76.7119,
         -94.5342,  -96.3450,  -94.3630,  -47.7246])
2025-06-27 15:01:42,602 - INFO - The first 10 points pressure for the sample_1: tensor([  26.8221, -139.6480,  -68.4088,  -78.4813,  -92.9359, -102.2890,
        -458.8600,  -51.0210,  -36.5807, -119.5220])
2025-06-27 15:01:42,609 - INFO - Batch: 32
2025-06-27 15:01:42,609 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,609 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,609 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,610 - INFO - The first 10 points in x_coor for the sample_0: tensor([2.6552, 2.8621, 3.0570, 2.2725, 2.7130, 3.0448, 0.1232, 2.8604, 3.6765,
        0.7417])
2025-06-27 15:01:42,610 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 3.7915,  0.4004,  0.1917,  3.7563, -0.1262,  2.2084,  3.2492,  1.6240,
        -0.9586,  0.3788])
2025-06-27 15:01:42,610 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,610 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,610 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,611 - INFO - The first 10 points pressure for the sample_0: tensor([-142.5580, -140.2040,  -94.3418,  -85.5900, -165.3290,   -8.9998,
        -434.2130,   24.8030,  -15.0267,  -87.2577])
2025-06-27 15:01:42,611 - INFO - The first 10 points pressure for the sample_1: tensor([ -33.3455,   82.1770, -196.9200,  -72.2047,  -49.2621,  -23.6994,
         -41.9599,  -72.0221,  442.1610,  -72.5108])
2025-06-27 15:01:42,763 - INFO - Batch: 33
2025-06-27 15:01:42,764 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,764 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,764 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,765 - INFO - The first 10 points in x_coor for the sample_0: tensor([-0.3813, -0.6180,  2.7117, -0.0955,  2.3878,  1.8990, -0.2204, -0.1854,
         2.4366, -0.0807])
2025-06-27 15:01:42,765 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 1.4519,  0.0771,  0.2691, -0.4843,  2.0249,  3.3312,  3.5800,  2.7106,
         2.6875, -0.5732])
2025-06-27 15:01:42,765 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,765 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,765 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,766 - INFO - The first 10 points pressure for the sample_0: tensor([-334.7100, -208.6040,  -78.3032, -196.7590,  -80.4406,  -74.0066,
         -64.5444, -148.8190, -204.1940,  -21.9310])
2025-06-27 15:01:42,766 - INFO - The first 10 points pressure for the sample_1: tensor([ -52.1155, -159.1580, -123.9140,  -49.3530, -202.4540,   45.0232,
         -26.4776,  -63.7452,  -51.6638, -429.7930])
2025-06-27 15:01:42,773 - INFO - Batch: 34
2025-06-27 15:01:42,773 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,773 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,773 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,774 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 2.6435,  3.1134,  1.0625,  1.1242,  0.7875,  0.9040,  2.9080, -0.8353,
        -0.2323,  2.7696])
2025-06-27 15:01:42,774 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 3.1132,  1.8528,  3.9148, -0.2349,  3.9169,  1.4979,  1.2687,  0.0887,
         1.0622,  3.4802])
2025-06-27 15:01:42,774 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,774 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,774 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,775 - INFO - The first 10 points pressure for the sample_0: tensor([-122.1790,  -83.9981, -116.2120, -243.7820, -167.9570,  -46.7163,
         -56.8178,  326.6480, -345.4950, -143.3180])
2025-06-27 15:01:42,775 - INFO - The first 10 points pressure for the sample_1: tensor([ -90.0224,  -93.3419,  -30.0798, -173.1290,  -79.8611,  -52.6971,
         -87.8026,  -31.6445, -235.4820,   70.6987])
2025-06-27 15:01:42,782 - INFO - Batch: 35
2025-06-27 15:01:42,782 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,782 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,782 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,782 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 1.8641,  0.8677,  1.8042,  0.1116, -0.8959,  3.5810,  0.5146,  3.5696,
         1.7614,  2.7114])
2025-06-27 15:01:42,783 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 0.0964,  2.4975,  2.4031,  1.5668, -0.8922,  3.7699,  1.2573,  0.2626,
         0.5347, -0.2470])
2025-06-27 15:01:42,783 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,783 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,783 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,783 - INFO - The first 10 points pressure for the sample_0: tensor([-111.9880, -129.0600,  -73.4888, -137.5430,  341.9980,  -36.2054,
         107.2540,  -18.7434,  -79.0948,  -57.4639])
2025-06-27 15:01:42,783 - INFO - The first 10 points pressure for the sample_1: tensor([-118.6720,  -88.8445, -147.5880, -248.5680,  302.8140,    0.5286,
         -86.7859, -110.4070,   12.7982, -160.6780])
2025-06-27 15:01:42,790 - INFO - Batch: 36
2025-06-27 15:01:42,790 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,790 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,790 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,790 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 0.1916, -0.3633,  0.0083,  0.6492,  1.6015,  3.7575,  2.5296,  2.8156,
         2.3077,  2.9862])
2025-06-27 15:01:42,791 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 2.5868,  0.0720,  3.6466,  2.0823, -0.1516,  3.5156,  1.3031,  1.5552,
         2.6781,  2.8837])
2025-06-27 15:01:42,791 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,791 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,791 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,791 - INFO - The first 10 points pressure for the sample_0: tensor([ -13.6639, -159.2940, -155.5510,  184.0170,  -97.3904,  -22.4263,
        -407.6130,  -40.0012, -152.1620,  -24.3921])
2025-06-27 15:01:42,791 - INFO - The first 10 points pressure for the sample_1: tensor([ -96.5537, -158.0490,  -23.8407,  -73.7478,  -86.8836,    4.4890,
         -81.7787,  -66.9959, -205.5900,  -51.5440])
2025-06-27 15:01:42,797 - INFO - Batch: 37
2025-06-27 15:01:42,797 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,797 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,797 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,798 - INFO - The first 10 points in x_coor for the sample_0: tensor([2.6894, 0.8658, 1.3604, 1.4868, 3.7887, 0.5710, 0.5009, 2.9438, 2.0263,
        3.3437])
2025-06-27 15:01:42,798 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 3.0557,  0.5470, -0.3219, -0.7490, -0.5760,  2.0250,  1.9906, -0.1979,
         0.0991, -0.6017])
2025-06-27 15:01:42,798 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,798 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,798 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,799 - INFO - The first 10 points pressure for the sample_0: tensor([-103.9700,  370.8800,  -77.0428,  -54.8544,  -41.9449,  105.4260,
         -92.5658,  -44.6539,  -78.3615,  -40.8942])
2025-06-27 15:01:42,799 - INFO - The first 10 points pressure for the sample_1: tensor([ -53.7789, -136.5090, -105.3350,  409.5120, -203.6270, -100.4900,
         -98.7160, -204.2220,  -43.8484,   83.2925])
2025-06-27 15:01:42,805 - INFO - Batch: 38
2025-06-27 15:01:42,805 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,805 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,805 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,806 - INFO - The first 10 points in x_coor for the sample_0: tensor([-0.3117,  0.4094,  0.0427,  3.1248,  2.7575,  2.6631,  0.5927,  2.8988,
         1.4521,  1.1771])
2025-06-27 15:01:42,806 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 2.3688, -0.0817,  1.5323,  1.9906,  3.0661,  0.7188,  2.2313,  2.3115,
         3.2123,  0.4782])
2025-06-27 15:01:42,806 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,806 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,806 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,807 - INFO - The first 10 points pressure for the sample_0: tensor([-268.5310, -283.7720, -251.0730, -140.5760,  -87.6902, -242.1250,
         -80.3776,  -84.8839,  -90.4834,  -90.0195])
2025-06-27 15:01:42,807 - INFO - The first 10 points pressure for the sample_1: tensor([-126.9870, -168.7350, -169.6220,  -70.4165,  -45.4687, -118.2910,
         -72.3663,  -65.5506,  -84.8359,  -71.2502])
2025-06-27 15:01:42,813 - INFO - Batch: 39
2025-06-27 15:01:42,813 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,813 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,813 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,814 - INFO - The first 10 points in x_coor for the sample_0: tensor([-0.6710,  1.9803,  1.3950,  2.8383,  0.8219,  1.8760,  0.0427,  0.6495,
         0.3333,  2.8042])
2025-06-27 15:01:42,814 - INFO - The first 10 points in x_coor for the sample_1: tensor([-0.3143,  2.9865,  2.9771,  2.9417,  1.0311,  3.5053,  1.4050,  0.1797,
         2.7006, -0.0968])
2025-06-27 15:01:42,814 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,814 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,814 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,815 - INFO - The first 10 points pressure for the sample_0: tensor([ -95.5753,  -94.2381, -310.8570, -109.1800,  -81.4626,  -70.8335,
        -153.2640,  -75.0069,   33.6827,  -70.6522])
2025-06-27 15:01:42,815 - INFO - The first 10 points pressure for the sample_1: tensor([-175.4440, -149.5730, -123.9650,  -90.3130, -144.0810,  -50.9281,
        -253.8000,  -57.1164, -173.6610, -177.1350])
2025-06-27 15:01:42,821 - INFO - Batch: 40
2025-06-27 15:01:42,821 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,821 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,821 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,821 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 2.7469,  2.7587,  0.7073,  2.7011,  3.4110,  2.1052,  2.5066,  3.0369,
        -0.5161,  2.3114])
2025-06-27 15:01:42,821 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 0.4209,  0.4208,  1.7844, -0.3690,  0.4459,  1.6354,  3.5461,  2.6436,
         1.8417,  1.7042])
2025-06-27 15:01:42,822 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,822 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,822 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,822 - INFO - The first 10 points pressure for the sample_0: tensor([ -71.5105,  -83.9507, -115.8100,  -88.5756,  -51.6981,  -55.6062,
         -33.3012,  -96.3630, -220.3480, -136.4290])
2025-06-27 15:01:42,822 - INFO - The first 10 points pressure for the sample_1: tensor([ -49.1153, -110.7010,  -76.5956,  -86.4747,  126.2600, -100.9660,
         -14.0673,  -63.5962,  -83.5589,  -76.9001])
2025-06-27 15:01:42,828 - INFO - Batch: 41
2025-06-27 15:01:42,828 - INFO - Batch.points.shape: torch.Size([2, 1, 3, 10000])
2025-06-27 15:01:42,828 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:01:42,828 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:01:42,829 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 3.1197, -0.7715,  4.0171,  3.3372,  0.6860,  1.1312,  0.2249, -0.3013,
         4.0153,  3.0571])
2025-06-27 15:01:42,829 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 0.2488, -0.1749, -0.5541,  3.5946,  3.1490, -0.4508,  2.4746,  1.0854,
         1.8416,  1.2000])
2025-06-27 15:01:42,829 - INFO - Batch.Pressure.shape: torch.Size([2, 1, 10000])
2025-06-27 15:01:42,829 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:01:42,829 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:01:42,829 - INFO - The first 10 points pressure for the sample_0: tensor([-139.8260,   26.5946,  -19.0641, -114.9630,  187.9530,  -74.7365,
          26.5352, -145.7950,  -19.5303, -161.1850])
2025-06-27 15:01:42,830 - INFO - The first 10 points pressure for the sample_1: tensor([  43.5840, -199.3970, -144.1050,   10.0279,  -68.8296, -107.1940,
         -66.7033,  -66.0018,  -68.5476,  -84.6221])
2025-06-27 15:01:43,477 - INFO - Type of train_subset: <class 'torch.utils.data.dataset.Subset'>
2025-06-27 15:01:43,477 - INFO - Number of samples of train_subset : 85
2025-06-27 15:01:43,477 - INFO - Subset indices: [0, 1, 2, 4, 6]
2025-06-27 15:01:43,477 - INFO - List the train_subset vtk files:
2025-06-27 15:01:43,478 - INFO -   0: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_073.vtk
2025-06-27 15:01:43,478 - INFO -   1: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_051.vtk
2025-06-27 15:01:43,478 - INFO -   2: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_099.vtk
2025-06-27 15:01:43,478 - INFO -   3: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_164.vtk
2025-06-27 15:01:43,478 - INFO -   4: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_030.vtk
2025-06-27 15:01:43,478 - INFO -   5: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_132.vtk
2025-06-27 15:01:43,478 - INFO -   6: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_107.vtk
2025-06-27 15:01:43,478 - INFO -   7: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_186.vtk
2025-06-27 15:01:43,478 - INFO -   8: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_079.vtk
2025-06-27 15:01:43,478 - INFO -   9: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_018.vtk
2025-06-27 15:01:43,478 - INFO -  10: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_015.vtk
2025-06-27 15:01:43,478 - INFO -  11: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_191.vtk
2025-06-27 15:01:43,478 - INFO -  12: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_084.vtk
2025-06-27 15:01:43,478 - INFO -  13: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_129.vtk
2025-06-27 15:01:43,478 - INFO -  14: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_080.vtk
2025-06-27 15:01:43,478 - INFO -  15: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_010.vtk
2025-06-27 15:01:43,478 - INFO -  16: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_094.vtk
2025-06-27 15:01:43,478 - INFO -  17: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_035.vtk
2025-06-27 15:01:43,478 - INFO -  18: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_003.vtk
2025-06-27 15:01:43,478 - INFO -  19: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_142.vtk
2025-06-27 15:01:43,478 - INFO -  20: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_005.vtk
2025-06-27 15:01:43,478 - INFO -  21: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_024.vtk
2025-06-27 15:01:43,478 - INFO -  22: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_106.vtk
2025-06-27 15:01:43,478 - INFO -  23: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_161.vtk
2025-06-27 15:01:43,478 - INFO -  24: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_171.vtk
2025-06-27 15:01:43,478 - INFO -  25: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_156.vtk
2025-06-27 15:01:43,478 - INFO -  26: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_053.vtk
2025-06-27 15:01:43,478 - INFO -  27: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_059.vtk
2025-06-27 15:01:43,479 - INFO -  28: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_082.vtk
2025-06-27 15:01:43,479 - INFO -  29: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_109.vtk
2025-06-27 15:01:43,479 - INFO -  30: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_139.vtk
2025-06-27 15:01:43,479 - INFO -  31: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_055.vtk
2025-06-27 15:01:43,479 - INFO -  32: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_088.vtk
2025-06-27 15:01:43,479 - INFO -  33: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_174.vtk
2025-06-27 15:01:43,479 - INFO -  34: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_104.vtk
2025-06-27 15:01:43,479 - INFO -  35: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_014.vtk
2025-06-27 15:01:43,479 - INFO -  36: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_072.vtk
2025-06-27 15:01:43,479 - INFO -  37: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_146.vtk
2025-06-27 15:01:43,479 - INFO -  38: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_194.vtk
2025-06-27 15:01:43,479 - INFO -  39: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_066.vtk
2025-06-27 15:01:43,479 - INFO -  40: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_067.vtk
2025-06-27 15:01:43,479 - INFO -  41: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_130.vtk
2025-06-27 15:01:43,479 - INFO -  42: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_131.vtk
2025-06-27 15:01:43,479 - INFO -  43: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_182.vtk
2025-06-27 15:01:43,479 - INFO -  44: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_049.vtk
2025-06-27 15:01:43,479 - INFO -  45: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_022.vtk
2025-06-27 15:01:43,479 - INFO -  46: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_042.vtk
2025-06-27 15:01:43,479 - INFO -  47: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_036.vtk
2025-06-27 15:01:43,479 - INFO -  48: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_137.vtk
2025-06-27 15:01:43,479 - INFO -  49: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_187.vtk
2025-06-27 15:01:43,479 - INFO -  50: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_195.vtk
2025-06-27 15:01:43,479 - INFO -  51: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_180.vtk
2025-06-27 15:01:43,479 - INFO -  52: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_119.vtk
2025-06-27 15:01:43,479 - INFO -  53: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_169.vtk
2025-06-27 15:01:43,479 - INFO -  54: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_092.vtk
2025-06-27 15:01:43,480 - INFO -  55: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_001.vtk
2025-06-27 15:01:43,480 - INFO -  56: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_021.vtk
2025-06-27 15:01:43,480 - INFO -  57: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_192.vtk
2025-06-27 15:01:43,480 - INFO -  58: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_100.vtk
2025-06-27 15:01:43,480 - INFO -  59: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_108.vtk
2025-06-27 15:01:43,480 - INFO -  60: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_093.vtk
2025-06-27 15:01:43,480 - INFO -  61: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_149.vtk
2025-06-27 15:01:43,480 - INFO -  62: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_060.vtk
2025-06-27 15:01:43,480 - INFO -  63: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_027.vtk
2025-06-27 15:01:43,480 - INFO -  64: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_061.vtk
2025-06-27 15:01:43,480 - INFO -  65: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_096.vtk
2025-06-27 15:01:43,480 - INFO -  66: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_039.vtk
2025-06-27 15:01:43,480 - INFO -  67: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_118.vtk
2025-06-27 15:01:43,480 - INFO -  68: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_122.vtk
2025-06-27 15:01:43,480 - INFO -  69: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_153.vtk
2025-06-27 15:01:43,480 - INFO -  70: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_144.vtk
2025-06-27 15:01:43,480 - INFO -  71: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_138.vtk
2025-06-27 15:01:43,480 - INFO -  72: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_068.vtk
2025-06-27 15:01:43,480 - INFO -  73: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_115.vtk
2025-06-27 15:01:43,480 - INFO -  74: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_028.vtk
2025-06-27 15:01:43,480 - INFO -  75: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_136.vtk
2025-06-27 15:01:43,480 - INFO -  76: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_085.vtk
2025-06-27 15:01:43,480 - INFO -  77: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_097.vtk
2025-06-27 15:01:43,480 - INFO -  78: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_140.vtk
2025-06-27 15:01:43,480 - INFO -  79: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_190.vtk
2025-06-27 15:01:43,480 - INFO -  80: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_150.vtk
2025-06-27 15:01:43,480 - INFO -  81: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_170.vtk
2025-06-27 15:01:43,480 - INFO -  82: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_095.vtk
2025-06-27 15:01:43,480 - INFO -  83: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_071.vtk
2025-06-27 15:01:43,481 - INFO -  84: /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_155.vtk
2025-06-27 15:01:43,481 - INFO - Type of full_dataset: <class 'data_loader.SurfacePressureDataset'>
2025-06-27 15:01:43,481 - INFO - Number of samples of full_dataset: 130
2025-06-27 15:01:43,481 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_073.vtk: 0
2025-06-27 15:01:43,481 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_051.vtk: 1
2025-06-27 15:01:43,481 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_099.vtk: 2
2025-06-27 15:01:43,481 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_009.vtk: 3
2025-06-27 15:01:43,481 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_164.vtk: 4
2025-06-27 15:01:43,481 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_166.vtk: 5
2025-06-27 15:01:43,481 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_030.vtk: 6
2025-06-27 15:01:43,481 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_132.vtk: 7
2025-06-27 15:01:43,481 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_114.vtk: 8
2025-06-27 15:01:43,481 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_107.vtk: 9
2025-06-27 15:01:43,481 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_186.vtk: 10
2025-06-27 15:01:43,481 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_175.vtk: 11
2025-06-27 15:01:43,481 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_079.vtk: 12
2025-06-27 15:01:43,481 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_018.vtk: 13
2025-06-27 15:01:43,481 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_015.vtk: 14
2025-06-27 15:01:43,481 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_191.vtk: 15
2025-06-27 15:01:43,481 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_084.vtk: 16
2025-06-27 15:01:43,481 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_032.vtk: 17
2025-06-27 15:01:43,481 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_129.vtk: 18
2025-06-27 15:01:43,481 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_080.vtk: 19
2025-06-27 15:01:43,481 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_010.vtk: 20
2025-06-27 15:01:43,481 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_094.vtk: 21
2025-06-27 15:01:43,481 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_078.vtk: 22
2025-06-27 15:01:43,481 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_035.vtk: 23
2025-06-27 15:01:43,481 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_003.vtk: 24
2025-06-27 15:01:43,481 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_020.vtk: 25
2025-06-27 15:01:43,482 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_142.vtk: 26
2025-06-27 15:01:43,482 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_005.vtk: 27
2025-06-27 15:01:43,482 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_112.vtk: 28
2025-06-27 15:01:43,482 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_125.vtk: 29
2025-06-27 15:01:43,482 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_024.vtk: 30
2025-06-27 15:01:43,482 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_106.vtk: 31
2025-06-27 15:01:43,482 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_161.vtk: 32
2025-06-27 15:01:43,482 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_171.vtk: 33
2025-06-27 15:01:43,482 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_156.vtk: 34
2025-06-27 15:01:43,482 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_053.vtk: 35
2025-06-27 15:01:43,482 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_160.vtk: 36
2025-06-27 15:01:43,482 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_059.vtk: 37
2025-06-27 15:01:43,482 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_082.vtk: 38
2025-06-27 15:01:43,482 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_109.vtk: 39
2025-06-27 15:01:43,482 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_026.vtk: 40
2025-06-27 15:01:43,482 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_139.vtk: 41
2025-06-27 15:01:43,482 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_055.vtk: 42
2025-06-27 15:01:43,482 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_088.vtk: 43
2025-06-27 15:01:43,482 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_174.vtk: 44
2025-06-27 15:01:43,482 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_104.vtk: 45
2025-06-27 15:01:43,482 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_168.vtk: 46
2025-06-27 15:01:43,482 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_014.vtk: 47
2025-06-27 15:01:43,482 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_072.vtk: 48
2025-06-27 15:01:43,482 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_147.vtk: 49
2025-06-27 15:01:43,483 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_146.vtk: 50
2025-06-27 15:01:43,483 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_194.vtk: 51
2025-06-27 15:01:43,483 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_141.vtk: 52
2025-06-27 15:01:43,483 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_002.vtk: 53
2025-06-27 15:01:43,483 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_066.vtk: 54
2025-06-27 15:01:43,483 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_050.vtk: 55
2025-06-27 15:01:43,483 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_067.vtk: 56
2025-06-27 15:01:43,483 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_130.vtk: 57
2025-06-27 15:01:43,483 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_025.vtk: 58
2025-06-27 15:01:43,483 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_019.vtk: 59
2025-06-27 15:01:43,483 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_131.vtk: 60
2025-06-27 15:01:43,483 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_182.vtk: 61
2025-06-27 15:01:43,483 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_049.vtk: 62
2025-06-27 15:01:43,483 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_022.vtk: 63
2025-06-27 15:01:43,483 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_042.vtk: 64
2025-06-27 15:01:43,483 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_177.vtk: 65
2025-06-27 15:01:43,483 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_036.vtk: 66
2025-06-27 15:01:43,483 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_137.vtk: 67
2025-06-27 15:01:43,483 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_187.vtk: 68
2025-06-27 15:01:43,483 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_195.vtk: 69
2025-06-27 15:01:43,483 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_180.vtk: 70
2025-06-27 15:01:43,483 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_178.vtk: 71
2025-06-27 15:01:43,483 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_119.vtk: 72
2025-06-27 15:01:43,483 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_169.vtk: 73
2025-06-27 15:01:43,484 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_189.vtk: 74
2025-06-27 15:01:43,484 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_092.vtk: 75
2025-06-27 15:01:43,484 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_116.vtk: 76
2025-06-27 15:01:43,484 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_001.vtk: 77
2025-06-27 15:01:43,484 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_029.vtk: 78
2025-06-27 15:01:43,484 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_021.vtk: 79
2025-06-27 15:01:43,484 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_192.vtk: 80
2025-06-27 15:01:43,484 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_100.vtk: 81
2025-06-27 15:01:43,484 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_087.vtk: 82
2025-06-27 15:01:43,484 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_108.vtk: 83
2025-06-27 15:01:43,484 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_093.vtk: 84
2025-06-27 15:01:43,484 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_034.vtk: 85
2025-06-27 15:01:43,484 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_159.vtk: 86
2025-06-27 15:01:43,484 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_089.vtk: 87
2025-06-27 15:01:43,484 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_065.vtk: 88
2025-06-27 15:01:43,484 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_149.vtk: 89
2025-06-27 15:01:43,484 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_075.vtk: 90
2025-06-27 15:01:43,484 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_060.vtk: 91
2025-06-27 15:01:43,484 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_148.vtk: 92
2025-06-27 15:01:43,484 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_027.vtk: 93
2025-06-27 15:01:43,484 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_061.vtk: 94
2025-06-27 15:01:43,484 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_096.vtk: 95
2025-06-27 15:01:43,484 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_039.vtk: 96
2025-06-27 15:01:43,484 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_058.vtk: 97
2025-06-27 15:01:43,484 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_118.vtk: 98
2025-06-27 15:01:43,484 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_091.vtk: 99
2025-06-27 15:01:43,484 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_057.vtk: 100
2025-06-27 15:01:43,484 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_122.vtk: 101
2025-06-27 15:01:43,484 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_153.vtk: 102
2025-06-27 15:01:43,484 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_144.vtk: 103
2025-06-27 15:01:43,485 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_138.vtk: 104
2025-06-27 15:01:43,485 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_068.vtk: 105
2025-06-27 15:01:43,485 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_115.vtk: 106
2025-06-27 15:01:43,485 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_135.vtk: 107
2025-06-27 15:01:43,485 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_044.vtk: 108
2025-06-27 15:01:43,485 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_028.vtk: 109
2025-06-27 15:01:43,485 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_136.vtk: 110
2025-06-27 15:01:43,485 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_085.vtk: 111
2025-06-27 15:01:43,485 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_097.vtk: 112
2025-06-27 15:01:43,485 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_121.vtk: 113
2025-06-27 15:01:43,485 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_017.vtk: 114
2025-06-27 15:01:43,485 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_140.vtk: 115
2025-06-27 15:01:43,485 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_190.vtk: 116
2025-06-27 15:01:43,485 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_023.vtk: 117
2025-06-27 15:01:43,485 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_047.vtk: 118
2025-06-27 15:01:43,485 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_150.vtk: 119
2025-06-27 15:01:43,485 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_070.vtk: 120
2025-06-27 15:01:43,485 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_170.vtk: 121
2025-06-27 15:01:43,485 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_110.vtk: 122
2025-06-27 15:01:43,485 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_081.vtk: 123
2025-06-27 15:01:43,485 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_172.vtk: 124
2025-06-27 15:01:43,485 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_095.vtk: 125
2025-06-27 15:01:43,485 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_071.vtk: 126
2025-06-27 15:01:43,485 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_117.vtk: 127
2025-06-27 15:01:43,485 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_155.vtk: 128
2025-06-27 15:01:43,485 - INFO -   /work/mae-zhangbj/ML_Turbulent/DrivAerNet/RegDGCNN_SurfaceFields/My_python_job/Pressure_VTK/N_S_WWS_WM_043.vtk: 129
2025-06-27 15:01:43,485 - INFO - Data loaded: 42 training batches, 10 validation batches, 12 test batches
2025-06-27 15:01:43,489 - INFO - Staring training for 10 epochs
2025-06-27 15:04:09,850 - INFO - args.exp_name : Train_Test
2025-06-27 15:04:09,851 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=10, epochs=10, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-27 15:04:09,851 - INFO - Starting training with 1 GPUs
2025-06-27 15:04:12,776 - INFO - Total trainable parameters: 1437705
2025-06-27 15:04:12,841 - INFO - Type of train_dataloader: <class 'torch.utils.data.dataloader.DataLoader'>
2025-06-27 15:04:12,841 - INFO - Number of train_dataloader: 8
2025-06-27 15:04:12,841 - INFO - We can access the internal conetnt by dataloader: 
2025-06-27 15:04:16,989 - INFO - Batch: 0
2025-06-27 15:04:16,989 - INFO - Batch.points.shape: torch.Size([10, 1, 3, 10000])
2025-06-27 15:04:16,990 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:04:16,990 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:04:16,993 - INFO - The first 10 points in x_coor for the sample_0: tensor([-0.0485, -0.5382,  0.8928, -0.5284,  0.1444,  2.6208,  2.9762,  3.6200,
        -0.3787,  1.3031])
2025-06-27 15:04:16,994 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 0.2833,  2.6895,  2.9486,  1.6583, -0.7939,  2.0023,  3.1221, -0.4969,
         1.6010,  3.6084])
2025-06-27 15:04:16,994 - INFO - Batch.Pressure.shape: torch.Size([10, 1, 10000])
2025-06-27 15:04:16,994 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:04:16,994 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:04:16,994 - INFO - The first 10 points pressure for the sample_0: tensor([-338.8030, -198.2250, -328.4480, -501.5070, -109.0920,  -77.5971,
         -91.8080,  -29.4908, -284.0090,  -91.4154])
2025-06-27 15:04:16,995 - INFO - The first 10 points pressure for the sample_1: tensor([-184.4790,  -81.4952, -111.3050,  -65.2745,  262.2230, -241.2780,
         -14.4769, -133.4740,  -90.2832,  -18.6696])
2025-06-27 15:04:17,032 - INFO - Batch: 1
2025-06-27 15:04:17,032 - INFO - Batch.points.shape: torch.Size([10, 1, 3, 10000])
2025-06-27 15:04:17,032 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:04:17,032 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:04:17,033 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 2.5521,  2.6666,  0.5497,  0.1573,  2.8155,  2.9984, -0.1173,  2.5646,
        -0.9318,  0.5025])
2025-06-27 15:04:17,033 - INFO - The first 10 points in x_coor for the sample_1: tensor([-0.3631,  3.3885,  0.4810, -0.2440,  1.7385, -0.4245, -0.0946, -0.6986,
         2.2198,  2.6981])
2025-06-27 15:04:17,033 - INFO - Batch.Pressure.shape: torch.Size([10, 1, 10000])
2025-06-27 15:04:17,033 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:04:17,033 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:04:17,034 - INFO - The first 10 points pressure for the sample_0: tensor([ -84.8091,  -77.7356,   97.0457, -153.8820, -132.9120,  -61.9000,
        -132.3560,  -76.8720,  436.0530,   81.3881])
2025-06-27 15:04:17,037 - INFO - The first 10 points pressure for the sample_1: tensor([-102.3700,  -15.2985,   80.3081, -129.9610,  -95.3753,  -90.2176,
        -133.5760,   22.5415, -142.7650,  -88.9344])
2025-06-27 15:04:17,093 - INFO - Batch: 2
2025-06-27 15:04:17,093 - INFO - Batch.points.shape: torch.Size([10, 1, 3, 10000])
2025-06-27 15:04:17,093 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:04:17,094 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:04:17,094 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 1.0061,  0.3184,  1.2802,  1.1238,  2.8385, -0.5982,  2.9736,  3.1936,
         2.8499, -0.7896])
2025-06-27 15:04:17,095 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 2.7120, -0.3803,  2.9076,  2.5315,  1.9188, -0.3108,  3.8506,  0.5791,
         2.8501,  0.2604])
2025-06-27 15:04:17,095 - INFO - Batch.Pressure.shape: torch.Size([10, 1, 10000])
2025-06-27 15:04:17,095 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:04:17,095 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:04:17,096 - INFO - The first 10 points pressure for the sample_0: tensor([-119.4090,   -7.9263,  -97.0791, -215.6410,  -71.9722,  -38.5220,
         -76.4743,    1.0474,  -67.6804,  296.0490])
2025-06-27 15:04:17,096 - INFO - The first 10 points pressure for the sample_1: tensor([-112.9390, -178.6530, -134.2990,  -31.5704,  -71.9506, -192.3010,
         -16.1056,  163.5570, -113.4070, -174.5600])
2025-06-27 15:04:17,129 - INFO - Batch: 3
2025-06-27 15:04:17,130 - INFO - Batch.points.shape: torch.Size([10, 1, 3, 10000])
2025-06-27 15:04:17,130 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:04:17,130 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:04:17,131 - INFO - The first 10 points in x_coor for the sample_0: tensor([1.6354, 2.7358, 3.0108, 2.9425, 0.5582, 3.3426, 1.6927, 2.6554, 1.1885,
        2.9646])
2025-06-27 15:04:17,131 - INFO - The first 10 points in x_coor for the sample_1: tensor([0.7073, 2.6755, 0.4456, 0.2009, 3.9422, 2.2771, 2.5980, 2.0823, 1.0969,
        0.8215])
2025-06-27 15:04:17,131 - INFO - Batch.Pressure.shape: torch.Size([10, 1, 10000])
2025-06-27 15:04:17,131 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:04:17,131 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:04:17,131 - INFO - The first 10 points pressure for the sample_0: tensor([ -53.3478, -249.1540, -217.1740,  -38.3287,  -57.3577,  -39.5899,
         -53.4930, -198.4300,  -62.9154,  -72.7477])
2025-06-27 15:04:17,132 - INFO - The first 10 points pressure for the sample_1: tensor([ -69.7244, -171.5290,   77.3724, -124.6980,  -16.5869,  -37.1627,
        -110.4390,  -50.8352,  -93.0625,   35.6096])
2025-06-27 15:04:17,166 - INFO - Batch: 4
2025-06-27 15:04:17,166 - INFO - Batch.points.shape: torch.Size([10, 1, 3, 10000])
2025-06-27 15:04:17,166 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:04:17,166 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:04:17,167 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 2.7703,  3.6288, -0.0146,  0.1477,  2.8393,  2.8385,  1.3833,  3.0913,
         2.8498, -0.1425])
2025-06-27 15:04:17,167 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 0.3972,  3.9183,  3.2692,  3.7785, -0.1782,  2.5976, -0.3481,  3.4233,
         3.6062,  0.2469])
2025-06-27 15:04:17,168 - INFO - Batch.Pressure.shape: torch.Size([10, 1, 10000])
2025-06-27 15:04:17,168 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:04:17,168 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:04:17,168 - INFO - The first 10 points pressure for the sample_0: tensor([ -83.3786,  -22.5281, -175.6870, -139.1320,  -77.1722,  -71.0416,
         -81.8121,  -42.6166, -128.7640, -126.2550])
2025-06-27 15:04:17,168 - INFO - The first 10 points pressure for the sample_1: tensor([-201.5640,  -16.7136, -106.6490,  -42.4794, -175.8160,   -8.5266,
        -134.5120, -136.8020,  -58.7743, -206.3970])
2025-06-27 15:04:17,201 - INFO - Batch: 5
2025-06-27 15:04:17,202 - INFO - Batch.points.shape: torch.Size([10, 1, 3, 10000])
2025-06-27 15:04:17,202 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:04:17,202 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:04:17,203 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 2.0024,  2.6824, -0.5860,  3.1021,  0.9962, -0.3762,  0.0654, -0.5734,
         0.3521, -0.9314])
2025-06-27 15:04:17,203 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 1.0195,  3.0786, -0.9305,  3.6379, -0.0828,  1.6584,  0.9161,  0.9135,
        -0.0261,  0.5813])
2025-06-27 15:04:17,203 - INFO - Batch.Pressure.shape: torch.Size([10, 1, 10000])
2025-06-27 15:04:17,203 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:04:17,203 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:04:17,204 - INFO - The first 10 points pressure for the sample_0: tensor([-8.8256e+01, -8.6504e+01, -3.2214e+02, -3.3256e+02, -5.7983e+02,
        -8.2140e+01, -1.0871e+02,  4.1819e-02, -1.4809e+02,  2.5899e+02])
2025-06-27 15:04:17,204 - INFO - The first 10 points pressure for the sample_1: tensor([ -91.5531,  -88.4385,  420.0560,  -11.4785, -138.2240, -229.8700,
        -425.4430,  -91.2196, -150.3880, -118.3980])
2025-06-27 15:04:17,230 - INFO - Batch: 6
2025-06-27 15:04:17,231 - INFO - Batch.points.shape: torch.Size([10, 1, 3, 10000])
2025-06-27 15:04:17,231 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:04:17,231 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:04:17,232 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 0.9479,  0.3987, -0.1521,  1.9906, -0.0118, -0.5948,  2.6331,  0.5215,
         2.7021,  0.5607])
2025-06-27 15:04:17,232 - INFO - The first 10 points in x_coor for the sample_1: tensor([-0.5999,  1.7842,  3.0147,  2.8585,  2.1510,  1.4178, -0.8385,  0.4896,
         3.3658,  2.4531])
2025-06-27 15:04:17,232 - INFO - Batch.Pressure.shape: torch.Size([10, 1, 10000])
2025-06-27 15:04:17,232 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:04:17,232 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:04:17,232 - INFO - The first 10 points pressure for the sample_0: tensor([ -50.8184,  107.2220, -172.7260,  -58.7541, -100.8550,  -93.4919,
        -255.4690, -141.1370,  -97.2591,  154.2220])
2025-06-27 15:04:17,233 - INFO - The first 10 points pressure for the sample_1: tensor([ -92.1932,  -75.5878, -113.2290, -145.7610,  -83.5426, -248.8180,
         267.4870, -147.7300,  -47.9468,  -80.9790])
2025-06-27 15:04:17,396 - INFO - Batch: 7
2025-06-27 15:04:17,396 - INFO - Batch.points.shape: torch.Size([10, 1, 3, 10000])
2025-06-27 15:04:17,396 - INFO - points_sample_0.shape: torch.Size([1, 3, 10000])
2025-06-27 15:04:17,396 - INFO - points_sample_0.shape: torch.Size([3, 10000])
2025-06-27 15:04:17,397 - INFO - The first 10 points in x_coor for the sample_0: tensor([ 1.8641,  0.8677,  1.8042,  0.1116, -0.8959,  3.5810,  0.5146,  3.5696,
         1.7614,  2.7114])
2025-06-27 15:04:17,397 - INFO - The first 10 points in x_coor for the sample_1: tensor([ 0.0964,  2.4975,  2.4031,  1.5668, -0.8922,  3.7699,  1.2573,  0.2626,
         0.5347, -0.2470])
2025-06-27 15:04:17,397 - INFO - Batch.Pressure.shape: torch.Size([10, 1, 10000])
2025-06-27 15:04:17,397 - INFO - pressure_sample_0.shape: torch.Size([1, 10000])
2025-06-27 15:04:17,397 - INFO - pressure_sample_0.shape: torch.Size([10000])
2025-06-27 15:04:17,398 - INFO - The first 10 points pressure for the sample_0: tensor([-111.9880, -129.0600,  -73.4888, -137.5430,  341.9980,  -36.2054,
         107.2540,  -18.7434,  -79.0948,  -57.4639])
2025-06-27 15:04:17,398 - INFO - The first 10 points pressure for the sample_1: tensor([-118.6720,  -88.8445, -147.5880, -248.5680,  302.8140,    0.5286,
         -86.7859, -110.4070,   12.7982, -160.6780])
2025-06-27 15:04:18,007 - INFO - Type of train_subset: <class 'torch.utils.data.dataset.Subset'>
2025-06-27 15:04:18,008 - INFO - Number of samples of train_subset : 85
2025-06-27 15:04:18,008 - INFO - Subset indices: [0, 1, 2, 4, 6]
2025-06-27 15:04:18,008 - INFO - List the train_subset vtk files:
2025-06-27 15:04:18,008 - INFO -   0: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_073.vtk
2025-06-27 15:04:18,008 - INFO -   1: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_051.vtk
2025-06-27 15:04:18,008 - INFO -   2: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_099.vtk
2025-06-27 15:04:18,008 - INFO -   3: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_164.vtk
2025-06-27 15:04:18,008 - INFO -   4: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_030.vtk
2025-06-27 15:04:18,008 - INFO -   5: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_132.vtk
2025-06-27 15:04:18,008 - INFO -   6: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_107.vtk
2025-06-27 15:04:18,008 - INFO -   7: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_186.vtk
2025-06-27 15:04:18,008 - INFO -   8: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_079.vtk
2025-06-27 15:04:18,008 - INFO -   9: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_018.vtk
2025-06-27 15:04:18,009 - INFO -  10: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_015.vtk
2025-06-27 15:04:18,009 - INFO -  11: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_191.vtk
2025-06-27 15:04:18,009 - INFO -  12: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_084.vtk
2025-06-27 15:04:18,009 - INFO -  13: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_129.vtk
2025-06-27 15:04:18,009 - INFO -  14: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_080.vtk
2025-06-27 15:04:18,009 - INFO -  15: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_010.vtk
2025-06-27 15:04:18,009 - INFO -  16: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_094.vtk
2025-06-27 15:04:18,009 - INFO -  17: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_035.vtk
2025-06-27 15:04:18,009 - INFO -  18: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_003.vtk
2025-06-27 15:04:18,009 - INFO -  19: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_142.vtk
2025-06-27 15:04:18,009 - INFO -  20: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_005.vtk
2025-06-27 15:04:18,009 - INFO -  21: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_024.vtk
2025-06-27 15:04:18,009 - INFO -  22: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_106.vtk
2025-06-27 15:04:18,009 - INFO -  23: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_161.vtk
2025-06-27 15:04:18,009 - INFO -  24: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_171.vtk
2025-06-27 15:04:18,009 - INFO -  25: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_156.vtk
2025-06-27 15:04:18,009 - INFO -  26: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_053.vtk
2025-06-27 15:04:18,009 - INFO -  27: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_059.vtk
2025-06-27 15:04:18,009 - INFO -  28: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_082.vtk
2025-06-27 15:04:18,009 - INFO -  29: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_109.vtk
2025-06-27 15:04:18,009 - INFO -  30: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_139.vtk
2025-06-27 15:04:18,009 - INFO -  31: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_055.vtk
2025-06-27 15:04:18,009 - INFO -  32: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_088.vtk
2025-06-27 15:04:18,009 - INFO -  33: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_174.vtk
2025-06-27 15:04:18,009 - INFO -  34: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_104.vtk
2025-06-27 15:04:18,009 - INFO -  35: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_014.vtk
2025-06-27 15:04:18,009 - INFO -  36: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_072.vtk
2025-06-27 15:04:18,009 - INFO -  37: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_146.vtk
2025-06-27 15:04:18,010 - INFO -  38: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_194.vtk
2025-06-27 15:04:18,010 - INFO -  39: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_066.vtk
2025-06-27 15:04:18,010 - INFO -  40: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_067.vtk
2025-06-27 15:04:18,010 - INFO -  41: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_130.vtk
2025-06-27 15:04:18,010 - INFO -  42: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_131.vtk
2025-06-27 15:04:18,010 - INFO -  43: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_182.vtk
2025-06-27 15:04:18,010 - INFO -  44: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_049.vtk
2025-06-27 15:04:18,010 - INFO -  45: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_022.vtk
2025-06-27 15:04:18,010 - INFO -  46: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_042.vtk
2025-06-27 15:04:18,010 - INFO -  47: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_036.vtk
2025-06-27 15:04:18,010 - INFO -  48: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_137.vtk
2025-06-27 15:04:18,010 - INFO -  49: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_187.vtk
2025-06-27 15:04:18,010 - INFO -  50: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_195.vtk
2025-06-27 15:04:18,010 - INFO -  51: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_180.vtk
2025-06-27 15:04:18,010 - INFO -  52: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_119.vtk
2025-06-27 15:04:18,010 - INFO -  53: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_169.vtk
2025-06-27 15:04:18,010 - INFO -  54: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_092.vtk
2025-06-27 15:04:18,010 - INFO -  55: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_001.vtk
2025-06-27 15:04:18,010 - INFO -  56: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_021.vtk
2025-06-27 15:04:18,011 - INFO -  57: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_192.vtk
2025-06-27 15:04:18,011 - INFO -  58: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_100.vtk
2025-06-27 15:04:18,011 - INFO -  59: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_108.vtk
2025-06-27 15:04:18,011 - INFO -  60: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_093.vtk
2025-06-27 15:04:18,011 - INFO -  61: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_149.vtk
2025-06-27 15:04:18,011 - INFO -  62: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_060.vtk
2025-06-27 15:04:18,011 - INFO -  63: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_027.vtk
2025-06-27 15:04:18,011 - INFO -  64: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_061.vtk
2025-06-27 15:04:18,011 - INFO -  65: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_096.vtk
2025-06-27 15:04:18,011 - INFO -  66: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_039.vtk
2025-06-27 15:04:18,011 - INFO -  67: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_118.vtk
2025-06-27 15:04:18,011 - INFO -  68: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_122.vtk
2025-06-27 15:04:18,011 - INFO -  69: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_153.vtk
2025-06-27 15:04:18,011 - INFO -  70: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_144.vtk
2025-06-27 15:04:18,011 - INFO -  71: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_138.vtk
2025-06-27 15:04:18,011 - INFO -  72: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_068.vtk
2025-06-27 15:04:18,011 - INFO -  73: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_115.vtk
2025-06-27 15:04:18,011 - INFO -  74: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_028.vtk
2025-06-27 15:04:18,011 - INFO -  75: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_136.vtk
2025-06-27 15:04:18,011 - INFO -  76: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_085.vtk
2025-06-27 15:04:18,011 - INFO -  77: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_097.vtk
2025-06-27 15:04:18,011 - INFO -  78: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_140.vtk
2025-06-27 15:04:18,011 - INFO -  79: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_190.vtk
2025-06-27 15:04:18,011 - INFO -  80: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_150.vtk
2025-06-27 15:04:18,011 - INFO -  81: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_170.vtk
2025-06-27 15:04:18,011 - INFO -  82: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_095.vtk
2025-06-27 15:04:18,011 - INFO -  83: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_071.vtk
2025-06-27 15:04:18,011 - INFO -  84: /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_155.vtk
2025-06-27 15:04:18,012 - INFO - Type of full_dataset: <class 'data_loader.SurfacePressureDataset'>
2025-06-27 15:04:18,012 - INFO - Number of samples of full_dataset: 130
2025-06-27 15:04:18,012 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_073.vtk: 0
2025-06-27 15:04:18,012 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_051.vtk: 1
2025-06-27 15:04:18,012 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_099.vtk: 2
2025-06-27 15:04:18,012 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_009.vtk: 3
2025-06-27 15:04:18,012 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_164.vtk: 4
2025-06-27 15:04:18,012 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_166.vtk: 5
2025-06-27 15:04:18,012 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_030.vtk: 6
2025-06-27 15:04:18,012 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_132.vtk: 7
2025-06-27 15:04:18,012 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_114.vtk: 8
2025-06-27 15:04:18,012 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_107.vtk: 9
2025-06-27 15:04:18,012 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_186.vtk: 10
2025-06-27 15:04:18,012 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_175.vtk: 11
2025-06-27 15:04:18,012 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_079.vtk: 12
2025-06-27 15:04:18,012 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_018.vtk: 13
2025-06-27 15:04:18,012 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_015.vtk: 14
2025-06-27 15:04:18,012 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_191.vtk: 15
2025-06-27 15:04:18,012 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_084.vtk: 16
2025-06-27 15:04:18,013 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_032.vtk: 17
2025-06-27 15:04:18,013 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_129.vtk: 18
2025-06-27 15:04:18,013 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_080.vtk: 19
2025-06-27 15:04:18,013 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_010.vtk: 20
2025-06-27 15:04:18,013 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_094.vtk: 21
2025-06-27 15:04:18,013 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_078.vtk: 22
2025-06-27 15:04:18,013 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_035.vtk: 23
2025-06-27 15:04:18,013 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_003.vtk: 24
2025-06-27 15:04:18,013 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_020.vtk: 25
2025-06-27 15:04:18,013 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_142.vtk: 26
2025-06-27 15:04:18,013 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_005.vtk: 27
2025-06-27 15:04:18,013 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_112.vtk: 28
2025-06-27 15:04:18,013 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_125.vtk: 29
2025-06-27 15:04:18,013 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_024.vtk: 30
2025-06-27 15:04:18,013 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_106.vtk: 31
2025-06-27 15:04:18,013 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_161.vtk: 32
2025-06-27 15:04:18,013 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_171.vtk: 33
2025-06-27 15:04:18,013 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_156.vtk: 34
2025-06-27 15:04:18,013 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_053.vtk: 35
2025-06-27 15:04:18,013 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_160.vtk: 36
2025-06-27 15:04:18,013 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_059.vtk: 37
2025-06-27 15:04:18,013 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_082.vtk: 38
2025-06-27 15:04:18,014 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_109.vtk: 39
2025-06-27 15:04:18,014 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_026.vtk: 40
2025-06-27 15:04:18,014 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_139.vtk: 41
2025-06-27 15:04:18,014 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_055.vtk: 42
2025-06-27 15:04:18,014 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_088.vtk: 43
2025-06-27 15:04:18,014 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_174.vtk: 44
2025-06-27 15:04:18,014 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_104.vtk: 45
2025-06-27 15:04:18,014 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_168.vtk: 46
2025-06-27 15:04:18,014 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_014.vtk: 47
2025-06-27 15:04:18,014 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_072.vtk: 48
2025-06-27 15:04:18,014 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_147.vtk: 49
2025-06-27 15:04:18,014 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_146.vtk: 50
2025-06-27 15:04:18,014 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_194.vtk: 51
2025-06-27 15:04:18,014 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_141.vtk: 52
2025-06-27 15:04:18,014 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_002.vtk: 53
2025-06-27 15:04:18,014 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_066.vtk: 54
2025-06-27 15:04:18,014 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_050.vtk: 55
2025-06-27 15:04:18,014 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_067.vtk: 56
2025-06-27 15:04:18,014 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_130.vtk: 57
2025-06-27 15:04:18,014 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_025.vtk: 58
2025-06-27 15:04:18,014 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_019.vtk: 59
2025-06-27 15:04:18,014 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_131.vtk: 60
2025-06-27 15:04:18,015 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_182.vtk: 61
2025-06-27 15:04:18,015 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_049.vtk: 62
2025-06-27 15:04:18,015 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_022.vtk: 63
2025-06-27 15:04:18,015 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_042.vtk: 64
2025-06-27 15:04:18,015 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_177.vtk: 65
2025-06-27 15:04:18,015 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_036.vtk: 66
2025-06-27 15:04:18,015 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_137.vtk: 67
2025-06-27 15:04:18,015 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_187.vtk: 68
2025-06-27 15:04:18,015 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_195.vtk: 69
2025-06-27 15:04:18,015 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_180.vtk: 70
2025-06-27 15:04:18,015 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_178.vtk: 71
2025-06-27 15:04:18,015 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_119.vtk: 72
2025-06-27 15:04:18,015 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_169.vtk: 73
2025-06-27 15:04:18,015 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_189.vtk: 74
2025-06-27 15:04:18,015 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_092.vtk: 75
2025-06-27 15:04:18,015 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_116.vtk: 76
2025-06-27 15:04:18,015 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_001.vtk: 77
2025-06-27 15:04:18,015 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_029.vtk: 78
2025-06-27 15:04:18,015 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_021.vtk: 79
2025-06-27 15:04:18,015 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_192.vtk: 80
2025-06-27 15:04:18,015 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_100.vtk: 81
2025-06-27 15:04:18,016 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_087.vtk: 82
2025-06-27 15:04:18,016 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_108.vtk: 83
2025-06-27 15:04:18,016 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_093.vtk: 84
2025-06-27 15:04:18,016 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_034.vtk: 85
2025-06-27 15:04:18,016 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_159.vtk: 86
2025-06-27 15:04:18,016 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_089.vtk: 87
2025-06-27 15:04:18,016 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_065.vtk: 88
2025-06-27 15:04:18,016 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_149.vtk: 89
2025-06-27 15:04:18,016 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_075.vtk: 90
2025-06-27 15:04:18,016 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_060.vtk: 91
2025-06-27 15:04:18,016 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_148.vtk: 92
2025-06-27 15:04:18,016 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_027.vtk: 93
2025-06-27 15:04:18,016 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_061.vtk: 94
2025-06-27 15:04:18,016 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_096.vtk: 95
2025-06-27 15:04:18,016 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_039.vtk: 96
2025-06-27 15:04:18,016 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_058.vtk: 97
2025-06-27 15:04:18,016 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_118.vtk: 98
2025-06-27 15:04:18,016 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_091.vtk: 99
2025-06-27 15:04:18,016 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_057.vtk: 100
2025-06-27 15:04:18,016 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_122.vtk: 101
2025-06-27 15:04:18,016 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_153.vtk: 102
2025-06-27 15:04:18,016 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_144.vtk: 103
2025-06-27 15:04:18,016 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_138.vtk: 104
2025-06-27 15:04:18,016 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_068.vtk: 105
2025-06-27 15:04:18,016 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_115.vtk: 106
2025-06-27 15:04:18,016 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_135.vtk: 107
2025-06-27 15:04:18,016 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_044.vtk: 108
2025-06-27 15:04:18,016 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_028.vtk: 109
2025-06-27 15:04:18,017 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_136.vtk: 110
2025-06-27 15:04:18,017 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_085.vtk: 111
2025-06-27 15:04:18,017 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_097.vtk: 112
2025-06-27 15:04:18,017 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_121.vtk: 113
2025-06-27 15:04:18,017 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_017.vtk: 114
2025-06-27 15:04:18,017 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_140.vtk: 115
2025-06-27 15:04:18,017 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_190.vtk: 116
2025-06-27 15:04:18,017 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_023.vtk: 117
2025-06-27 15:04:18,017 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_047.vtk: 118
2025-06-27 15:04:18,017 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_150.vtk: 119
2025-06-27 15:04:18,017 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_070.vtk: 120
2025-06-27 15:04:18,017 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_170.vtk: 121
2025-06-27 15:04:18,017 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_110.vtk: 122
2025-06-27 15:04:18,017 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_081.vtk: 123
2025-06-27 15:04:18,017 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_172.vtk: 124
2025-06-27 15:04:18,017 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_095.vtk: 125
2025-06-27 15:04:18,017 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_071.vtk: 126
2025-06-27 15:04:18,017 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_117.vtk: 127
2025-06-27 15:04:18,017 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_155.vtk: 128
2025-06-27 15:04:18,017 - INFO -   /work/mae-zhangbj/Data_Pressure/Pressure_VTK/N_S_WWS_WM_043.vtk: 129
2025-06-27 15:04:18,017 - INFO - Data loaded: 8 training batches, 2 validation batches, 2 test batches
2025-06-27 15:04:18,019 - INFO - Staring training for 10 epochs
2025-06-27 15:43:58,579 - INFO - args.exp_name : Train_Test
2025-06-27 15:43:58,580 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=10, epochs=10, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-27 15:43:58,580 - INFO - Starting training with 1 GPUs
2025-06-27 15:44:01,742 - INFO - Total trainable parameters: 1437705
2025-06-27 15:44:01,804 - INFO - Data loaded: 8 training batches, 2 validation batches, 2 test batches
2025-06-27 15:44:01,806 - INFO - Staring training for 10 epochs
2025-06-27 15:49:40,636 - INFO - args.exp_name : Train_Test
2025-06-27 15:49:40,637 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=16, epochs=50, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-27 15:49:40,637 - INFO - Starting training with 1 GPUs
2025-06-27 15:49:44,651 - INFO - Total trainable parameters: 1437705
2025-06-27 15:49:44,720 - INFO - Data loaded: 5 training batches, 1 validation batches, 1 test batches
2025-06-27 15:49:44,727 - INFO - Staring training for 50 epochs
2025-06-27 17:44:02,011 - INFO - args.exp_name : Train_Test
2025-06-27 17:44:02,013 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=16, epochs=50, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-27 17:44:02,013 - INFO - Starting training with 1 GPUs
2025-06-27 17:44:04,501 - INFO - Total trainable parameters: 1437705
2025-06-27 17:44:04,571 - INFO - Data loaded: 5 training batches, 1 validation batches, 1 test batches
2025-06-27 17:44:04,572 - INFO - Staring training for 50 epochs
2025-06-27 18:12:48,070 - INFO - args.exp_name : Train_Test
2025-06-27 18:12:48,070 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=16, epochs=50, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-27 18:12:48,071 - INFO - Starting training with 1 GPUs
2025-06-27 18:12:51,413 - INFO - Total trainable parameters: 1437705
2025-06-27 18:12:51,477 - INFO - Data loaded: 5 training batches, 1 validation batches, 1 test batches
2025-06-27 18:12:51,479 - INFO - Staring training for 50 epochs
2025-06-27 21:53:16,557 - INFO - args.exp_name : Train_Test
2025-06-27 21:53:16,558 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=16, epochs=50, lr=0.001, num_workers=2, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-27 21:53:16,558 - INFO - Starting training with 1 GPUs
2025-06-27 21:53:19,645 - INFO - Total trainable parameters: 1437705
2025-06-27 21:53:19,698 - INFO - Data loaded: 5 training batches, 1 validation batches, 1 test batches
2025-06-27 21:53:19,700 - INFO - Staring training for 50 epochs
2025-06-28 11:02:55,132 - INFO - args.exp_name : Train_Test
2025-06-28 11:02:55,132 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=16, epochs=50, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-28 11:02:55,133 - INFO - Starting training with 1 GPUs
2025-06-28 11:03:03,324 - INFO - Total trainable parameters: 1437705
2025-06-28 11:03:03,418 - INFO - Data loaded: 5 training batches, 1 validation batches, 1 test batches
2025-06-28 11:03:03,420 - INFO - Staring training for 50 epochs
2025-06-28 11:06:12,746 - INFO - args.exp_name : Train_Test
2025-06-28 11:06:12,747 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=16, epochs=50, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-28 11:06:12,747 - INFO - Starting training with 1 GPUs
2025-06-28 11:06:16,128 - INFO - Total trainable parameters: 1437705
2025-06-28 11:06:16,172 - INFO - Data loaded: 5 training batches, 1 validation batches, 1 test batches
2025-06-28 11:06:16,174 - INFO - Staring training for 50 epochs
2025-06-28 11:09:32,911 - INFO - args.exp_name : Train_Test
2025-06-28 11:09:32,912 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=16, epochs=50, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-28 11:09:32,912 - INFO - Starting training with 1 GPUs
2025-06-28 11:09:35,225 - INFO - Total trainable parameters: 1437705
2025-06-28 11:09:35,267 - INFO - Data loaded: 5 training batches, 1 validation batches, 1 test batches
2025-06-28 11:09:35,269 - INFO - Staring training for 50 epochs
2025-06-28 11:18:10,980 - INFO - args.exp_name : Train_Test
2025-06-28 11:18:10,981 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=16, epochs=50, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-28 11:18:10,981 - INFO - Starting training with 1 GPUs
2025-06-28 11:18:13,412 - INFO - Total trainable parameters: 1437705
2025-06-28 11:18:13,459 - INFO - Data loaded: 5 training batches, 1 validation batches, 1 test batches
2025-06-28 11:18:13,461 - INFO - Staring training for 50 epochs
2025-06-28 11:22:54,036 - INFO - args.exp_name : Train_Test
2025-06-28 11:22:54,037 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=16, epochs=50, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-28 11:22:54,037 - INFO - Starting training with 1 GPUs
2025-06-28 11:22:56,720 - INFO - Total trainable parameters: 1437705
2025-06-28 11:22:56,763 - INFO - Data loaded: 5 training batches, 1 validation batches, 1 test batches
2025-06-28 11:22:56,765 - INFO - Staring training for 50 epochs
2025-06-28 11:23:01,378 - INFO - outputs.shape: torch.Size([16, 1, 10000])
2025-06-28 11:25:43,742 - INFO - args.exp_name : Train_Test
2025-06-28 11:25:43,743 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=16, epochs=50, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-28 11:25:43,743 - INFO - Starting training with 1 GPUs
2025-06-28 11:25:46,092 - INFO - Total trainable parameters: 1437705
2025-06-28 11:25:46,136 - INFO - Data loaded: 5 training batches, 1 validation batches, 1 test batches
2025-06-28 11:25:46,138 - INFO - Staring training for 50 epochs
2025-06-28 11:25:50,267 - INFO - outputs.shape: torch.Size([16, 1, 10000])
2025-06-28 11:34:47,559 - INFO - args.exp_name : Train_Test
2025-06-28 11:34:47,564 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=16, epochs=50, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-28 11:34:47,564 - INFO - Starting training with 1 GPUs
2025-06-28 11:34:55,849 - INFO - Total trainable parameters: 1437705
2025-06-28 11:34:55,909 - INFO - Data loaded: 5 training batches, 1 validation batches, 1 test batches
2025-06-28 11:34:55,914 - INFO - Staring training for 50 epochs
2025-06-28 11:35:08,690 - INFO - outputs.shape: torch.Size([16, 1, 10000])
2025-06-28 11:39:15,633 - INFO - args.exp_name : Train_Test
2025-06-28 11:39:15,636 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=16, epochs=50, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-28 11:39:15,636 - INFO - Starting training with 1 GPUs
2025-06-28 11:39:21,776 - INFO - Total trainable parameters: 1437705
2025-06-28 11:39:21,831 - INFO - Data loaded: 5 training batches, 1 validation batches, 1 test batches
2025-06-28 11:39:21,842 - INFO - Staring training for 50 epochs
2025-06-28 11:39:30,600 - INFO - outputs.shape: torch.Size([16, 1, 10000])
2025-06-28 11:59:22,911 - INFO - args.exp_name : Train_Test
2025-06-28 11:59:22,913 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=8, epochs=50, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-28 11:59:22,913 - INFO - Starting training with 1 GPUs
2025-06-28 11:59:28,699 - INFO - Total trainable parameters: 1437705
2025-06-28 11:59:28,758 - INFO - Data loaded: 10 training batches, 2 validation batches, 3 test batches
2025-06-28 11:59:28,764 - INFO - Staring training for 50 epochs
2025-06-28 11:59:37,355 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 11:59:37,400 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 11:59:37,638 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 11:59:37,887 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 11:59:38,132 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 11:59:38,377 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 11:59:38,624 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 11:59:38,868 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 11:59:39,111 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 11:59:39,356 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 11:59:44,646 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 11:59:44,906 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 11:59:45,150 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 11:59:45,395 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 11:59:45,640 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 11:59:45,885 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 11:59:46,129 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 11:59:46,374 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 11:59:46,618 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 11:59:46,863 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 11:59:52,069 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 11:59:52,330 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 11:59:52,575 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 11:59:52,819 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 11:59:53,063 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 11:59:53,308 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 11:59:53,553 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 11:59:53,797 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 11:59:54,043 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 11:59:54,287 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 11:59:58,308 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 11:59:58,568 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 11:59:58,813 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 11:59:59,057 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 11:59:59,302 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 11:59:59,547 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 11:59:59,791 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:00,036 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:00,281 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:00,525 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:04,756 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:05,015 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:05,259 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:05,504 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:05,749 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:05,993 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:06,238 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:06,482 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:06,727 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:06,972 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:11,802 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:12,059 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:12,304 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:12,549 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:12,793 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:13,038 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:13,283 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:13,528 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:13,772 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:14,017 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:18,747 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:19,013 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:19,258 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:19,502 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:19,747 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:19,992 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:20,236 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:20,481 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:20,725 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:20,970 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:23,928 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:24,198 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:24,443 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:24,687 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:24,932 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:25,177 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:25,421 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:25,666 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:25,911 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:26,155 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:29,211 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:29,476 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:29,722 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:29,966 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:30,211 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:30,455 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:30,700 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:30,945 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:31,189 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:31,434 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:36,549 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:36,810 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:37,055 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:37,300 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:37,545 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:37,789 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:38,034 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:38,279 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:38,523 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:38,768 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:43,714 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:43,977 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:44,222 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:44,466 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:44,711 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:44,956 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:45,200 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:45,445 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:45,689 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:45,934 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:50,584 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:50,844 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:51,089 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:51,333 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:51,578 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:51,822 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:52,067 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:52,312 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:52,557 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:52,801 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:57,860 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:58,127 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:58,373 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:58,618 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:58,863 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:59,107 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:59,352 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:59,597 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:00:59,841 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:00,086 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:09,331 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:09,603 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:09,847 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:10,092 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:10,337 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:10,581 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:10,826 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:11,070 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:11,315 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:11,560 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:20,314 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:20,575 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:20,819 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:21,064 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:21,308 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:21,553 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:21,820 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:22,065 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:22,309 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:22,554 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:28,372 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:28,631 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:28,876 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:29,121 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:29,365 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:29,610 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:29,855 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:30,099 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:30,344 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:30,588 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:37,979 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:38,242 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:38,487 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:38,732 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:38,978 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:39,224 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:39,469 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:39,713 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:39,959 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:40,203 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:47,944 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:48,215 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:48,460 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:48,704 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:48,949 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:49,194 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:49,438 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:49,683 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:49,927 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:50,172 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:57,069 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:57,335 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:57,580 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:57,825 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:58,070 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:58,315 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:58,565 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:58,806 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:59,049 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:01:59,293 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:06,431 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:06,701 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:06,948 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:07,191 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:07,437 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:07,680 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:07,925 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:08,169 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:08,414 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:08,659 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:17,114 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:17,381 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:17,625 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:17,870 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:18,114 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:18,359 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:18,604 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:18,849 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:19,095 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:19,338 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:23,749 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:24,015 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:24,260 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:24,504 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:24,749 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:24,994 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:25,238 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:25,483 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:25,727 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:25,972 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:30,140 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:30,410 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:30,655 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:30,900 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:31,144 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:31,389 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:31,634 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:31,878 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:32,123 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:32,368 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:36,401 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:36,669 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:36,913 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:37,158 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:37,402 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:37,647 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:37,892 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:38,136 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:38,381 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:38,625 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:44,232 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:44,501 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:44,746 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:44,991 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:45,236 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:45,481 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:45,725 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:45,970 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:46,214 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:46,459 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:51,072 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:51,340 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:51,584 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:51,829 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:52,074 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:52,318 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:52,563 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:52,808 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:53,052 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:53,297 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:57,838 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:58,104 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:58,350 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:58,595 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:58,840 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:59,084 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:59,329 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:59,574 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:02:59,818 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:00,063 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:02,917 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:03,187 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:03,432 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:03,677 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:03,921 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:04,166 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:04,411 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:04,655 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:04,900 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:05,145 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:08,462 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:08,720 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:08,965 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:09,210 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:09,454 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:09,699 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:09,943 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:10,188 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:10,433 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:10,677 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:15,261 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:15,523 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:15,767 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:16,011 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:16,256 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:16,501 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:16,745 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:16,990 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:17,235 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:17,479 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:20,558 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:20,825 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:21,071 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:21,315 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:21,560 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:21,805 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:22,049 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:22,294 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:22,538 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:22,783 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:26,025 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:26,295 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:26,540 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:26,784 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:27,029 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:27,274 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:27,519 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:27,763 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:28,008 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:28,253 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:33,128 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:33,392 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:33,636 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:33,881 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:34,125 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:34,370 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:34,615 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:34,859 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:35,104 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:35,348 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:39,987 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:40,249 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:40,494 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:40,738 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:40,983 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:41,228 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:41,472 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:41,717 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:41,962 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:42,206 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:45,167 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:45,433 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:45,678 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:45,923 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:46,168 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:46,412 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:46,657 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:46,901 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:47,146 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:47,391 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:51,498 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:51,754 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:51,999 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:52,244 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:52,488 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:52,733 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:52,978 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:53,222 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:53,467 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:53,712 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:57,043 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:57,307 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:57,551 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:57,796 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:58,041 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:58,286 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:58,530 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:58,775 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:59,019 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:03:59,264 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:03,654 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:03,921 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:04,165 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:04,410 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:04,654 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:04,899 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:05,144 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:05,388 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:05,633 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:05,878 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:09,953 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:10,213 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:10,458 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:10,703 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:10,948 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:11,192 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:11,437 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:11,682 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:11,926 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:12,171 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:15,099 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:15,367 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:15,611 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:15,856 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:16,101 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:16,346 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:16,590 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:16,835 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:17,080 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:17,325 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:22,045 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:22,302 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:22,546 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:22,791 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:23,036 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:23,280 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:23,525 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:23,769 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:24,014 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:24,259 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:27,576 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:27,842 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:28,087 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:28,332 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:28,576 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:28,821 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:29,066 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:29,310 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:29,555 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:29,799 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:32,816 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:33,082 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:33,327 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:33,571 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:33,816 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:34,061 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:34,305 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:34,550 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:34,795 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:35,039 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:38,476 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:38,739 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:38,984 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:39,228 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:39,473 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:39,718 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:39,962 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:40,207 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:40,452 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:40,696 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:46,141 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:46,401 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:46,646 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:46,891 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:47,135 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:47,380 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:47,625 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:47,869 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:48,114 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:48,359 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:51,994 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:52,252 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:52,497 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:52,741 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:52,986 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:53,231 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:53,475 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:53,720 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:53,964 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:54,209 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:58,213 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:58,472 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:58,716 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:58,961 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:59,206 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:59,450 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:59,695 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:04:59,939 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:05:00,184 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:05:00,429 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:05:04,847 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:05:05,106 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:05:05,351 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:05:05,595 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:05:05,840 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:05:06,085 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:05:06,330 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:05:06,574 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:05:06,819 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:05:07,064 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:05:10,145 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:05:10,416 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:05:10,661 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:05:10,905 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:05:11,150 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:05:11,394 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:05:11,639 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:05:11,884 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:05:12,128 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:05:12,373 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:05:16,738 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:05:16,997 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:05:17,243 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:05:17,488 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:05:17,732 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:05:17,976 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:05:18,221 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:05:18,466 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:05:18,711 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:05:18,955 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:35:43,879 - INFO - args.exp_name : Train_Test
2025-06-28 12:35:43,880 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=8, epochs=50, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-28 12:35:43,880 - INFO - Starting training with 1 GPUs
2025-06-28 12:35:49,317 - INFO - Total trainable parameters: 1437705
2025-06-28 12:35:49,371 - INFO - Data loaded: 10 training batches, 2 validation batches, 3 test batches
2025-06-28 12:35:49,375 - INFO - Staring training for 50 epochs
2025-06-28 12:35:58,644 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:35:58,671 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:35:59,024 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:35:59,024 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:35:59,403 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:35:59,403 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:35:59,783 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:35:59,783 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:00,165 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:00,165 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:00,549 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:00,549 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:00,929 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:00,930 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:01,331 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:01,331 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:01,718 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:01,719 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:02,102 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:02,102 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:07,652 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:07,653 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:08,048 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:08,048 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:08,428 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:08,428 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:08,808 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:08,808 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:09,188 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:09,188 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:09,568 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:09,568 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:09,948 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:09,948 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:10,328 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:10,328 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:10,709 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:10,709 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:11,089 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:11,090 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:15,948 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:15,948 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:16,352 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:16,352 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:16,732 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:16,732 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:17,112 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:17,112 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:17,491 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:17,491 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:17,872 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:17,873 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:18,252 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:18,253 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:18,632 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:18,632 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:19,013 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:19,013 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:19,393 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:19,394 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:22,998 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:22,999 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:23,407 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:23,407 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:23,787 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:23,787 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:24,167 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:24,167 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:24,547 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:24,548 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:24,927 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:24,927 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:25,307 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:25,308 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:25,688 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:25,688 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:26,068 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:26,069 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:26,449 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:26,449 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:30,990 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:30,990 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:31,384 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:31,384 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:31,764 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:31,764 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:32,144 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:32,144 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:32,524 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:32,524 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:32,904 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:32,904 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:33,285 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:33,285 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:33,665 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:33,665 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:34,045 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:34,046 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:34,425 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:34,425 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:38,239 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:38,240 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:38,631 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:38,631 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:39,011 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:39,011 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:39,393 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:39,393 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:39,772 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:39,772 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:40,152 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:40,153 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:40,533 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:40,533 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:40,913 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:40,913 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:41,293 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:41,293 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:41,673 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:41,674 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:45,662 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:45,665 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:46,057 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:46,057 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:46,437 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:46,437 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:46,817 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:46,817 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:47,198 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:47,198 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:47,578 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:47,578 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:47,958 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:47,959 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:48,339 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:48,339 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:48,719 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:48,719 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:49,099 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:49,099 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:54,826 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:54,826 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:55,227 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:55,228 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:55,607 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:55,608 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:55,987 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:55,988 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:56,368 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:56,368 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:56,748 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:56,748 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:57,128 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:57,129 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:57,509 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:57,522 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:57,889 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:57,889 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:36:58,269 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:36:58,269 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:03,081 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:03,083 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:03,481 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:03,481 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:03,862 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:03,863 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:04,242 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:04,242 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:04,622 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:04,622 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:05,002 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:05,002 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:05,382 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:05,382 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:05,762 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:05,763 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:06,142 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:06,142 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:06,523 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:06,523 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:14,332 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:14,334 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:14,734 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:14,734 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:15,114 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:15,114 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:15,494 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:15,495 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:15,875 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:15,875 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:16,255 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:16,255 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:16,635 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:16,635 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:17,015 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:17,016 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:17,395 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:17,396 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:17,776 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:17,776 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:23,342 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:23,345 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:23,746 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:23,747 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:24,127 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:24,127 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:24,507 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:24,507 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:24,887 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:24,888 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:25,268 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:25,268 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:25,648 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:25,649 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:26,028 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:26,029 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:26,408 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:26,409 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:26,789 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:26,789 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:30,373 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:30,378 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:30,778 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:30,778 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:31,159 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:31,159 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:31,539 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:31,539 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:31,919 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:31,919 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:32,299 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:32,299 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:32,681 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:32,681 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:33,061 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:33,061 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:33,441 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:33,441 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:33,822 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:33,822 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:37,620 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:37,620 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:38,024 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:38,024 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:38,404 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:38,404 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:38,784 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:38,784 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:39,165 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:39,165 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:39,545 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:39,545 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:39,925 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:39,925 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:40,305 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:40,306 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:40,686 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:40,686 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:41,066 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:41,066 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:48,497 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:48,499 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:48,902 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:48,902 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:49,282 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:49,282 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:49,663 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:49,663 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:50,043 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:50,043 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:50,423 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:50,424 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:50,803 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:50,804 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:51,184 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:51,185 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:51,564 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:51,564 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:51,944 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:51,944 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:59,320 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:59,323 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:37:59,725 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:37:59,725 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:00,105 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:00,105 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:00,485 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:00,486 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:00,866 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:00,866 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:01,246 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:01,246 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:01,626 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:01,626 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:02,006 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:02,006 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:02,386 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:02,386 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:02,767 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:02,767 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:07,937 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:07,938 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:08,347 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:08,348 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:08,727 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:08,728 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:09,110 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:09,110 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:09,494 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:09,494 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:09,878 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:09,879 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:10,258 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:10,258 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:10,640 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:10,640 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:11,021 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:11,022 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:11,401 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:11,401 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:14,939 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:14,939 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:15,343 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:15,344 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:15,723 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:15,723 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:16,103 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:16,104 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:16,484 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:16,484 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:16,864 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:16,864 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:17,244 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:17,244 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:17,625 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:17,625 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:18,005 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:18,005 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:18,385 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:18,385 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:23,456 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:23,465 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:23,858 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:23,859 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:24,238 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:24,239 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:24,618 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:24,619 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:24,999 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:24,999 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:25,379 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:25,379 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:25,760 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:25,760 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:26,139 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:26,140 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:26,520 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:26,520 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:26,900 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:26,900 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:32,211 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:32,211 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:32,604 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:32,605 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:32,985 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:32,985 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:33,365 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:33,365 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:33,745 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:33,745 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:34,126 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:34,126 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:34,506 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:34,506 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:34,886 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:34,886 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:35,266 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:35,266 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:35,646 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:35,646 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:40,838 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:40,838 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:41,230 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:41,231 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:41,611 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:41,611 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:41,991 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:41,992 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:42,371 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:42,372 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:42,752 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:42,752 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:43,132 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:43,132 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:43,512 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:43,512 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:43,892 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:43,892 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:44,272 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:44,273 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:49,446 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:49,448 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:49,842 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:49,843 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:50,223 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:50,223 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:50,604 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:50,605 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:50,984 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:50,984 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:51,365 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:51,365 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:51,745 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:51,745 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:52,125 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:52,125 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:52,505 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:52,506 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:52,885 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:52,886 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:56,431 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:56,431 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:56,832 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:56,832 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:57,212 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:57,212 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:57,592 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:57,593 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:57,973 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:57,973 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:58,353 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:58,353 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:58,733 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:58,733 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:59,113 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:59,114 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:59,493 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:59,494 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:38:59,874 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:38:59,874 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:04,843 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:04,843 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:05,247 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:05,248 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:05,627 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:05,628 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:06,008 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:06,008 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:06,388 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:06,388 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:06,768 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:06,769 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:07,148 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:07,149 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:07,529 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:07,529 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:07,909 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:07,909 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:08,289 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:08,289 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:13,667 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:13,669 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:14,073 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:14,073 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:14,453 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:14,453 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:14,833 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:14,834 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:15,213 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:15,214 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:15,597 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:15,597 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:15,977 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:15,978 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:16,357 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:16,358 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:16,738 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:16,738 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:17,118 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:17,118 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:22,307 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:22,308 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:22,713 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:22,713 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:23,093 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:23,094 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:23,474 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:23,474 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:23,854 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:23,855 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:24,234 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:24,235 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:24,615 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:24,615 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:24,996 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:24,997 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:25,377 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:25,377 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:25,756 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:25,757 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:29,774 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:29,774 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:30,177 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:30,178 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:30,558 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:30,558 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:30,939 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:30,939 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:31,318 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:31,319 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:31,698 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:31,699 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:32,079 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:32,079 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:32,459 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:32,459 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:32,841 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:32,841 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:33,221 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:33,221 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:36,603 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:36,603 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:37,007 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:37,007 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:37,387 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:37,387 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:37,767 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:37,767 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:38,147 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:38,147 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:38,529 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:38,529 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:38,909 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:38,909 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:39,289 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:39,289 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:39,669 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:39,670 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:40,049 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:40,050 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:45,319 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:45,319 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:45,716 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:45,716 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:46,096 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:46,096 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:46,476 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:46,476 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:46,856 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:46,857 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:47,237 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:47,237 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:47,617 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:47,617 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:47,997 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:47,997 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:48,377 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:48,378 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:48,758 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:48,758 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:54,202 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:54,202 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:54,595 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:54,595 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:54,975 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:54,975 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:55,355 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:55,358 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:55,735 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:55,736 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:56,116 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:56,116 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:56,496 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:56,496 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:56,876 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:56,876 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:57,256 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:57,257 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:39:57,636 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:39:57,637 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:02,399 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:02,399 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:02,796 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:02,796 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:03,176 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:03,176 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:03,556 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:03,556 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:03,937 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:03,937 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:04,317 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:04,317 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:04,697 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:04,697 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:05,077 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:05,078 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:05,458 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:05,458 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:05,838 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:05,838 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:11,059 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:11,060 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:11,454 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:11,456 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:11,834 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:11,834 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:12,214 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:12,215 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:12,595 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:12,595 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:12,975 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:12,975 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:13,355 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:13,356 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:13,736 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:13,736 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:14,116 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:14,116 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:14,496 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:14,496 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:17,943 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:17,943 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:18,351 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:18,351 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:18,731 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:18,731 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:19,111 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:19,111 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:19,491 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:19,492 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:19,871 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:19,872 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:20,251 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:20,252 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:20,632 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:20,632 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:21,013 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:21,014 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:21,393 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:21,394 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:24,969 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:24,969 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:25,367 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:25,367 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:25,747 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:25,747 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:26,127 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:26,127 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:26,507 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:26,507 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:26,887 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:26,888 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:27,268 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:27,268 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:27,648 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:27,648 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:28,028 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:28,028 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:28,408 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:28,408 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:33,738 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:33,738 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:34,136 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:34,136 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:34,517 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:34,517 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:34,897 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:34,897 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:35,277 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:35,277 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:35,657 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:35,658 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:36,038 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:36,038 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:36,418 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:36,418 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:36,798 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:36,799 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:37,178 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:37,178 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:42,092 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:42,092 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:42,498 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:42,498 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:42,878 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:42,878 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:43,258 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:43,258 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:43,638 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:43,639 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:44,019 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:44,019 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:44,399 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:44,399 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:44,779 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:44,779 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:45,159 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:45,160 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:45,539 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:45,540 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:50,334 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:50,334 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:50,739 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:50,740 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:51,120 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:51,120 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:51,500 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:51,500 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:51,880 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:51,880 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:52,260 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:52,260 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:52,640 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:52,642 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:53,020 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:53,021 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:53,401 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:53,401 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:53,781 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:53,782 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:57,133 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:57,133 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:57,539 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:57,539 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:57,919 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:57,919 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:58,299 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:58,299 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:58,679 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:58,680 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:59,059 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:59,060 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:59,439 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:59,440 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:40:59,819 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:40:59,820 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:00,199 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:00,200 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:00,580 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:00,580 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:05,588 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:05,589 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:05,996 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:05,996 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:06,376 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:06,376 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:06,756 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:06,757 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:07,137 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:07,137 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:07,517 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:07,517 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:07,897 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:07,897 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:08,277 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:08,277 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:08,657 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:08,658 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:09,038 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:09,038 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:13,894 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:13,894 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:14,296 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:14,297 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:14,676 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:14,677 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:15,056 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:15,057 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:15,437 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:15,437 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:15,817 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:15,817 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:16,197 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:16,197 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:16,577 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:16,577 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:16,957 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:16,957 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:17,337 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:17,338 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:21,878 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:21,878 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:22,284 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:22,284 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:22,664 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:22,665 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:23,044 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:23,045 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:23,425 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:23,425 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:23,805 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:23,805 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:24,185 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:24,185 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:24,565 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:24,565 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:24,945 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:24,946 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:25,325 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:25,326 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:29,711 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:29,711 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:30,117 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:30,117 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:30,497 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:30,498 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:30,877 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:30,878 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:31,257 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:31,258 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:31,638 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:31,638 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:32,018 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:32,018 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:32,399 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:32,399 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:32,779 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:32,779 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:33,159 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:33,159 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:36,530 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:36,530 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:36,937 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:36,938 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:37,318 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:37,318 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:37,698 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:37,698 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:38,078 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:38,078 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:38,458 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:38,459 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:38,838 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:38,839 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:39,219 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:39,219 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:39,599 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:39,599 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:39,979 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:39,979 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:44,476 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:44,476 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:44,874 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:44,875 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:45,254 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:45,255 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:45,635 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:45,635 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:46,015 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:46,015 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:46,395 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:46,396 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:46,776 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:46,778 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:47,156 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:47,156 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:47,536 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:47,536 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:47,916 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:47,916 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:52,382 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:52,383 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:52,774 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:52,774 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:53,154 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:53,154 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:53,534 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:53,535 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:53,915 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:53,915 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:54,295 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:54,295 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:54,675 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:54,675 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:55,055 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:55,056 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:55,436 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:55,436 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:41:55,816 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:41:55,816 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:03,909 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:03,910 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:04,316 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:04,316 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:04,696 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:04,697 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:05,079 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:05,079 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:05,461 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:05,461 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:05,841 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:05,842 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:06,222 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:06,222 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:06,620 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:06,620 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:07,018 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:07,018 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:07,414 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:07,414 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:12,479 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:12,481 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:12,871 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:12,871 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:13,251 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:13,251 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:13,631 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:13,632 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:14,012 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:14,012 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:14,392 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:14,393 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:14,772 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:14,772 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:15,152 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:15,152 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:15,532 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:15,533 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:15,913 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:15,913 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:21,026 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:21,026 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:21,427 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:21,427 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:21,807 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:21,808 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:22,188 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:22,188 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:22,568 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:22,568 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:22,948 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:22,948 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:23,329 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:23,329 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:23,709 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:23,709 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:24,089 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:24,090 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:24,469 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:24,470 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:28,415 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:28,415 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:28,821 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:28,821 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:29,201 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:29,201 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:29,581 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:29,582 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:29,961 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:29,962 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:30,342 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:30,342 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:30,721 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:30,722 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:31,103 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:31,103 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:31,483 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:31,483 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:31,863 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:31,863 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:36,073 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:36,079 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:36,477 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:36,477 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:36,857 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:36,857 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:37,237 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:37,237 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:37,618 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:37,624 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:37,999 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:37,999 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:38,379 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:38,379 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:38,759 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:38,759 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:39,139 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:39,140 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:39,520 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:39,520 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:43,699 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:43,699 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:44,104 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:44,104 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:44,485 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:44,485 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:44,865 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:44,865 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:45,245 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:45,245 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:45,625 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:45,625 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:46,005 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:46,006 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:46,386 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:46,386 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:46,766 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:46,767 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 12:42:47,146 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 12:42:47,147 - INFO - loss type: <class 'torch.Tensor'>
2025-06-28 13:00:25,137 - INFO - args.exp_name : Train_Test
2025-06-28 13:00:25,139 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=8, epochs=50, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-28 13:00:25,139 - INFO - Starting training with 1 GPUs
2025-06-28 13:00:29,871 - INFO - Total trainable parameters: 1437705
2025-06-28 13:00:29,924 - INFO - Data loaded: 10 training batches, 2 validation batches, 3 test batches
2025-06-28 13:00:29,928 - INFO - Staring training for 50 epochs
2025-06-28 13:00:37,426 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:00:37,426 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:00:37,791 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:00:37,791 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:00:38,171 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:00:38,171 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:00:38,551 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:00:38,551 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:00:38,932 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:00:38,932 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:00:39,312 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:00:39,313 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:00:39,693 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:00:39,693 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:00:40,073 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:00:40,074 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:00:40,453 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:00:40,453 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:00:40,835 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:00:40,835 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:00:47,607 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:00:47,610 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:00:48,003 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:00:48,003 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:00:48,383 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:00:48,383 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:00:48,763 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:00:48,763 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:00:49,143 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:00:49,143 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:00:49,523 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:00:49,523 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:00:49,903 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:00:49,904 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:00:50,284 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:00:50,284 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:00:50,664 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:00:50,664 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:00:51,044 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:00:51,044 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:00:56,456 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:00:56,458 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:00:56,852 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:00:56,852 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:00:57,232 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:00:57,232 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:00:57,612 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:00:57,612 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:00:57,992 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:00:57,992 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:00:58,372 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:00:58,373 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:00:58,754 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:00:58,754 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:00:59,134 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:00:59,134 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:00:59,514 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:00:59,514 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:00:59,894 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:00:59,894 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:03,887 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:03,888 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:04,284 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:04,284 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:04,664 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:04,664 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:05,043 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:05,043 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:05,424 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:05,424 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:05,804 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:05,804 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:06,184 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:06,187 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:06,564 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:06,565 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:06,945 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:06,945 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:07,325 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:07,325 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:11,518 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:11,521 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:11,914 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:11,914 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:12,294 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:12,294 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:12,674 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:12,674 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:13,055 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:13,055 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:13,435 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:13,435 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:13,815 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:13,816 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:14,196 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:14,196 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:14,576 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:14,576 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:14,956 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:14,957 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:19,136 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:19,136 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:19,534 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:19,535 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:19,914 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:19,914 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:20,294 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:20,294 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:20,673 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:20,674 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:21,053 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:21,054 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:21,433 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:21,433 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:21,813 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:21,814 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:22,194 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:22,194 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:22,574 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:22,574 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:29,750 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:29,751 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:30,152 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:30,152 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:30,532 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:30,532 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:30,912 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:30,912 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:31,292 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:31,292 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:31,672 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:31,673 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:32,053 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:32,053 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:32,433 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:32,434 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:32,813 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:32,814 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:33,194 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:33,194 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:37,464 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:37,470 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:37,859 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:37,859 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:38,239 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:38,239 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:38,619 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:38,619 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:38,999 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:38,999 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:39,380 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:39,380 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:39,760 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:39,761 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:40,141 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:40,141 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:40,521 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:40,521 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:40,901 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:40,901 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:45,382 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:45,384 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:45,788 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:45,788 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:46,168 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:46,168 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:46,548 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:46,548 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:46,929 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:46,929 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:47,309 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:47,309 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:47,689 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:47,689 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:48,071 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:48,071 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:48,451 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:48,451 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:48,831 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:48,831 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:53,331 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:53,336 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:53,727 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:53,727 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:54,108 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:54,108 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:54,487 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:54,488 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:54,868 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:54,872 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:55,248 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:55,248 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:55,628 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:55,628 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:56,008 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:56,009 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:56,389 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:56,389 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:01:56,769 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:01:56,769 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:00,909 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:00,911 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:01,320 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:01,320 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:01,703 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:01,703 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:02,083 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:02,083 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:02,464 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:02,464 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:02,854 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:02,854 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:03,234 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:03,234 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:03,614 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:03,614 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:03,994 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:03,994 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:04,374 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:04,374 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:08,502 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:08,502 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:08,908 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:08,908 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:09,288 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:09,288 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:09,669 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:09,669 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:10,049 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:10,049 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:10,429 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:10,429 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:10,809 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:10,809 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:11,190 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:11,190 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:11,570 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:11,570 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:11,950 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:11,950 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:16,308 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:16,308 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:16,716 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:16,716 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:17,096 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:17,096 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:17,476 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:17,477 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:17,858 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:17,858 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:18,238 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:18,238 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:18,618 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:18,618 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:18,999 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:18,999 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:19,379 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:19,379 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:19,759 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:19,759 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:23,983 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:23,985 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:24,388 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:24,388 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:24,768 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:24,768 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:25,149 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:25,149 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:25,529 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:25,529 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:25,909 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:25,909 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:26,289 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:26,289 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:26,670 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:26,670 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:27,050 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:27,050 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:27,430 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:27,430 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:35,795 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:35,798 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:36,206 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:36,206 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:36,586 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:36,586 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:36,966 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:36,966 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:37,347 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:37,347 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:37,726 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:37,727 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:38,107 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:38,107 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:38,487 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:38,487 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:38,867 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:38,867 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:39,247 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:39,247 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:45,734 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:45,735 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:46,134 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:46,134 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:46,514 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:46,514 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:46,895 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:46,895 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:47,275 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:47,275 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:47,655 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:47,655 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:48,036 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:48,036 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:48,416 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:48,416 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:48,796 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:48,796 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:49,176 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:49,176 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:53,783 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:53,783 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:54,181 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:54,181 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:54,562 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:54,562 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:54,942 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:54,942 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:55,322 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:55,322 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:55,704 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:55,704 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:56,084 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:56,084 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:56,464 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:56,464 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:56,844 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:56,844 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:02:57,225 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:02:57,225 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:01,436 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:01,436 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:01,835 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:01,835 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:02,215 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:02,215 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:02,595 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:02,595 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:02,976 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:02,976 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:03,355 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:03,355 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:03,736 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:03,736 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:04,116 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:04,116 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:04,496 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:04,496 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:04,876 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:04,876 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:08,081 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:08,081 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:08,477 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:08,477 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:08,858 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:08,858 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:09,238 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:09,238 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:09,618 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:09,618 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:09,998 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:09,998 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:10,378 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:10,379 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:10,759 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:10,759 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:11,139 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:11,139 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:11,519 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:11,519 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:14,745 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:14,745 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:15,139 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:15,139 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:15,519 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:15,519 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:15,899 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:15,899 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:16,280 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:16,280 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:16,660 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:16,660 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:17,040 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:17,040 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:17,421 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:17,421 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:17,801 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:17,801 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:18,181 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:18,181 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:22,712 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:22,712 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:23,112 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:23,112 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:23,492 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:23,492 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:23,872 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:23,872 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:24,253 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:24,253 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:24,633 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:24,633 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:25,013 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:25,013 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:25,394 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:25,394 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:25,774 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:25,774 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:26,154 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:26,155 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:30,035 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:30,035 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:30,430 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:30,430 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:30,810 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:30,810 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:31,191 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:31,191 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:31,571 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:31,572 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:31,952 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:31,952 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:32,332 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:32,332 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:32,712 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:32,712 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:33,092 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:33,092 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:33,472 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:33,472 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:37,977 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:37,977 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:38,379 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:38,379 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:38,759 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:38,759 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:39,139 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:39,139 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:39,520 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:39,520 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:39,900 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:39,900 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:40,280 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:40,280 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:40,660 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:40,660 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:41,041 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:41,041 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:41,420 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:41,421 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:45,695 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:45,695 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:46,089 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:46,089 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:46,469 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:46,470 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:46,850 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:46,850 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:47,230 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:47,230 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:47,610 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:47,610 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:47,990 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:47,990 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:48,370 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:48,370 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:48,751 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:48,752 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:49,131 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:49,131 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:52,412 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:52,412 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:52,818 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:52,818 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:53,198 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:53,198 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:53,578 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:53,578 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:53,958 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:53,959 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:54,339 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:54,339 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:54,719 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:54,719 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:55,099 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:55,099 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:55,479 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:55,480 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:03:55,859 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:03:55,860 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:00,776 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:00,777 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:01,170 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:01,170 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:01,550 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:01,550 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:01,930 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:01,930 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:02,311 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:02,311 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:02,691 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:02,691 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:03,071 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:03,071 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:03,451 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:03,451 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:03,831 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:03,831 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:04,212 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:04,212 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:07,740 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:07,740 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:08,139 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:08,139 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:08,519 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:08,519 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:08,899 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:08,899 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:09,280 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:09,280 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:09,660 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:09,660 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:10,040 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:10,041 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:10,421 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:10,433 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:10,801 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:10,801 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:11,181 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:11,181 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:14,896 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:14,896 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:15,303 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:15,303 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:15,684 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:15,684 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:16,064 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:16,064 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:16,444 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:16,444 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:16,824 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:16,824 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:17,205 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:17,205 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:17,585 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:17,585 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:17,965 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:17,965 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:18,345 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:18,345 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:37,631 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:37,639 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:38,035 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:38,035 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:38,417 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:38,418 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:38,800 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:38,800 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:39,182 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:39,182 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:39,562 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:39,563 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:39,942 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:39,943 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:40,325 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:40,325 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:40,707 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:40,707 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:41,095 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:41,095 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:48,409 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:48,409 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:48,804 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:48,804 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:49,184 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:49,184 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:49,564 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:49,564 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:49,945 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:49,945 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:50,325 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:50,325 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:50,705 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:50,706 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:51,086 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:51,086 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:51,466 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:51,466 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:51,846 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:51,846 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:56,005 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:56,005 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:56,400 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:56,401 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:56,780 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:56,781 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:57,161 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:57,161 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:57,541 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:57,541 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:57,921 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:57,921 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:58,301 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:58,302 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:58,682 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:58,682 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:59,062 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:59,062 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:04:59,442 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:04:59,442 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:03,168 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:03,168 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:03,570 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:03,571 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:03,951 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:03,951 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:04,331 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:04,331 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:04,711 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:04,711 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:05,091 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:05,091 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:05,472 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:05,472 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:05,852 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:05,852 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:06,233 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:06,233 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:06,613 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:06,613 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:10,615 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:10,615 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:11,016 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:11,017 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:11,396 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:11,396 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:11,777 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:11,777 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:12,157 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:12,157 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:12,537 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:12,537 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:12,917 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:12,917 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:13,297 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:13,297 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:13,677 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:13,677 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:14,057 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:14,057 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:18,025 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:18,025 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:18,429 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:18,429 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:18,821 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:18,821 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:19,201 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:19,201 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:19,581 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:19,581 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:19,961 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:19,962 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:20,342 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:20,342 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:20,722 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:20,722 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:21,102 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:21,102 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:21,482 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:21,482 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:24,918 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:24,918 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:25,316 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:25,316 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:25,697 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:25,698 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:26,078 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:26,078 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:26,458 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:26,458 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:26,838 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:26,838 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:27,218 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:27,218 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:27,599 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:27,599 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:27,979 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:27,979 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:28,359 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:28,359 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:34,074 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:34,075 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:34,522 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:34,522 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:34,902 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:34,902 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:35,337 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:35,337 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:35,720 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:35,720 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:36,108 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:36,108 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:36,513 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:36,513 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:36,895 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:36,895 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:37,276 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:37,276 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:37,698 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:37,698 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:41,903 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:41,903 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:42,310 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:42,311 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:42,691 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:42,691 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:43,071 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:43,071 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:43,451 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:43,451 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:43,831 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:43,831 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:44,212 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:44,212 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:44,592 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:44,592 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:44,973 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:44,973 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:45,353 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:45,353 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:49,667 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:49,667 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:50,062 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:50,063 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:50,443 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:50,443 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:50,823 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:50,823 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:51,203 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:51,203 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:51,584 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:51,584 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:51,964 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:51,964 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:52,344 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:52,344 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:52,724 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:52,724 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:53,104 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:53,104 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:56,882 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:56,882 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:57,280 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:57,280 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:57,660 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:57,660 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:58,041 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:58,041 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:58,421 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:58,421 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:58,801 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:58,801 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:59,181 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:59,181 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:59,561 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:59,562 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:05:59,941 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:05:59,942 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:00,322 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:00,322 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:04,473 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:04,473 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:04,875 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:04,875 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:05,255 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:05,255 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:05,635 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:05,635 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:06,015 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:06,015 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:06,395 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:06,395 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:06,776 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:06,776 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:07,156 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:07,156 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:07,537 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:07,537 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:07,917 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:07,917 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:11,922 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:11,922 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:12,321 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:12,321 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:12,701 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:12,701 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:13,082 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:13,082 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:13,462 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:13,462 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:13,842 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:13,842 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:14,223 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:14,223 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:14,603 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:14,603 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:14,984 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:14,984 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:15,364 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:15,365 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:18,924 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:18,924 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:19,328 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:19,328 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:19,708 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:19,708 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:20,088 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:20,088 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:20,468 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:20,469 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:20,849 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:20,849 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:21,229 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:21,229 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:21,609 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:21,609 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:21,989 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:21,989 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:22,369 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:22,369 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:26,039 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:26,039 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:26,435 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:26,435 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:26,815 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:26,815 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:27,195 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:27,195 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:27,575 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:27,575 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:27,955 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:27,955 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:28,337 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:28,337 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:28,717 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:28,717 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:29,097 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:29,097 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:29,477 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:29,477 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:32,773 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:32,773 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:33,178 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:33,178 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:33,558 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:33,559 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:33,952 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:33,952 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:34,332 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:34,333 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:34,712 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:34,713 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:35,093 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:35,093 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:35,473 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:35,473 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:35,853 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:35,853 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:36,233 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:36,233 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:39,529 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:39,530 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:39,922 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:39,922 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:40,302 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:40,302 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:40,682 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:40,683 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:41,063 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:41,063 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:41,443 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:41,443 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:41,823 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:41,823 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:42,203 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:42,204 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:42,584 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:42,584 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:42,964 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:42,964 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:49,804 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:49,804 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:50,203 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:50,203 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:50,584 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:50,584 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:50,964 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:50,964 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:51,344 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:51,344 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:51,724 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:51,724 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:52,104 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:52,104 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:52,498 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:52,498 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:52,878 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:52,878 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:53,257 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:53,258 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:57,665 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:57,665 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:58,073 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:58,073 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:58,453 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:58,453 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:58,833 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:58,833 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:59,213 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:59,213 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:59,593 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:59,594 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:06:59,974 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:06:59,974 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:07:00,354 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:07:00,354 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:07:00,734 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:07:00,734 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:07:01,118 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:07:01,118 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:07:04,911 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:07:04,912 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:07:05,318 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:07:05,318 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:07:05,699 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:07:05,699 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:07:06,082 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:07:06,082 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:07:06,462 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:07:06,462 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:07:06,843 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:07:06,843 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:07:07,223 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:07:07,223 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:07:07,603 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:07:07,603 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:07:07,983 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:07:07,984 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:07:08,363 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:07:08,363 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:07:12,462 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:07:12,462 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:07:12,858 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:07:12,859 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:07:13,239 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:07:13,239 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:07:13,619 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:07:13,619 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:07:13,999 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:07:13,999 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:07:14,380 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:07:14,380 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:07:14,760 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:07:14,760 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:07:15,140 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:07:15,140 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:07:15,520 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:07:15,520 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:07:15,900 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:07:15,901 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:07:19,157 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:07:19,157 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:07:19,558 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:07:19,559 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:07:19,939 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:07:19,939 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:07:20,318 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:07:20,318 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:07:20,699 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:07:20,699 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:07:21,079 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:07:21,079 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:07:21,459 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:07:21,459 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:07:21,839 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:07:21,839 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:07:22,219 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:07:22,220 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:07:22,599 - INFO - outputs.shape: torch.Size([8, 1, 10000])
2025-06-28 13:07:22,599 - INFO - outputs type: <class 'torch.Size'>
2025-06-28 13:55:53,492 - INFO - args.exp_name : Train_Test
2025-06-28 13:55:53,494 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=8, epochs=50, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-28 13:55:53,494 - INFO - Starting training with 1 GPUs
2025-06-28 13:55:59,335 - INFO - Total trainable parameters: 1437705
2025-06-28 13:55:59,394 - INFO - Data loaded: 10 training batches, 2 validation batches, 3 test batches
2025-06-28 13:55:59,399 - INFO - Staring training for 50 epochs
2025-06-28 13:56:11,867 - INFO - type of train_loss: <class 'float'>
2025-06-28 14:00:45,985 - INFO - args.exp_name : Train_Test
2025-06-28 14:00:45,986 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=8, epochs=50, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-28 14:00:45,986 - INFO - Starting training with 1 GPUs
2025-06-28 14:00:50,736 - INFO - Total trainable parameters: 1437705
2025-06-28 14:00:50,792 - INFO - Data loaded: 10 training batches, 2 validation batches, 3 test batches
2025-06-28 14:00:50,796 - INFO - Staring training for 50 epochs
2025-06-28 14:00:58,698 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:00:58,698 - INFO - total_loss value: 1.2830595970153809
2025-06-28 14:00:58,698 - INFO - length of train_dataloader: 10
2025-06-28 14:00:59,084 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:00:59,084 - INFO - total_loss value: 2.7383272647857666
2025-06-28 14:00:59,084 - INFO - length of train_dataloader: 10
2025-06-28 14:00:59,464 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:00:59,464 - INFO - total_loss value: 3.9416478872299194
2025-06-28 14:00:59,464 - INFO - length of train_dataloader: 10
2025-06-28 14:00:59,845 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:00:59,845 - INFO - total_loss value: 5.303300380706787
2025-06-28 14:00:59,845 - INFO - length of train_dataloader: 10
2025-06-28 14:01:00,225 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:01:00,226 - INFO - total_loss value: 6.532232999801636
2025-06-28 14:01:00,226 - INFO - length of train_dataloader: 10
2025-06-28 14:01:00,606 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:01:00,606 - INFO - total_loss value: 7.6904706954956055
2025-06-28 14:01:00,606 - INFO - length of train_dataloader: 10
2025-06-28 14:01:00,986 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:01:00,986 - INFO - total_loss value: 8.918874979019165
2025-06-28 14:01:00,986 - INFO - length of train_dataloader: 10
2025-06-28 14:01:01,370 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:01:01,370 - INFO - total_loss value: 10.084421396255493
2025-06-28 14:01:01,370 - INFO - length of train_dataloader: 10
2025-06-28 14:01:01,750 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:01:01,750 - INFO - total_loss value: 11.2518949508667
2025-06-28 14:01:01,751 - INFO - length of train_dataloader: 10
2025-06-28 14:01:02,131 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:01:02,131 - INFO - total_loss value: 12.53324019908905
2025-06-28 14:01:02,131 - INFO - length of train_dataloader: 10
2025-06-28 14:01:07,628 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:01:07,629 - INFO - total_loss value: 1.1851657629013062
2025-06-28 14:01:07,630 - INFO - length of train_dataloader: 10
2025-06-28 14:01:08,010 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:01:08,010 - INFO - total_loss value: 2.3786693811416626
2025-06-28 14:01:08,010 - INFO - length of train_dataloader: 10
2025-06-28 14:01:08,391 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:01:08,391 - INFO - total_loss value: 3.5073537826538086
2025-06-28 14:01:08,391 - INFO - length of train_dataloader: 10
2025-06-28 14:01:08,771 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:01:08,771 - INFO - total_loss value: 4.666755557060242
2025-06-28 14:01:08,771 - INFO - length of train_dataloader: 10
2025-06-28 14:01:09,152 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:01:09,152 - INFO - total_loss value: 5.821822285652161
2025-06-28 14:01:09,152 - INFO - length of train_dataloader: 10
2025-06-28 14:01:09,532 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:01:09,532 - INFO - total_loss value: 7.113649845123291
2025-06-28 14:01:09,532 - INFO - length of train_dataloader: 10
2025-06-28 14:01:09,912 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:01:09,913 - INFO - total_loss value: 8.341907858848572
2025-06-28 14:01:09,913 - INFO - length of train_dataloader: 10
2025-06-28 14:01:10,293 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:01:10,293 - INFO - total_loss value: 9.507506847381592
2025-06-28 14:01:10,293 - INFO - length of train_dataloader: 10
2025-06-28 14:01:10,673 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:01:10,674 - INFO - total_loss value: 10.727226853370667
2025-06-28 14:01:10,674 - INFO - length of train_dataloader: 10
2025-06-28 14:01:11,054 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:01:11,054 - INFO - total_loss value: 11.883892893791199
2025-06-28 14:01:11,054 - INFO - length of train_dataloader: 10
2025-06-28 14:30:54,618 - INFO - args.exp_name : Train_Test
2025-06-28 14:30:54,620 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=8, epochs=50, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-28 14:30:54,620 - INFO - Starting training with 1 GPUs
2025-06-28 14:30:59,877 - INFO - Total trainable parameters: 1437705
2025-06-28 14:30:59,930 - INFO - Data loaded: 10 training batches, 2 validation batches, 3 test batches
2025-06-28 14:30:59,934 - INFO - Staring training for 50 epochs
2025-06-28 14:31:13,391 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:31:13,391 - INFO - total_loss value: 12.53324019908905
2025-06-28 14:31:13,391 - INFO - length of train_dataloader: 10
2025-06-28 14:33:56,525 - INFO - args.exp_name : Train_Test
2025-06-28 14:33:56,527 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=8, epochs=50, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-28 14:33:56,527 - INFO - Starting training with 1 GPUs
2025-06-28 14:34:02,326 - INFO - Total trainable parameters: 1437705
2025-06-28 14:34:02,391 - INFO - Data loaded: 10 training batches, 2 validation batches, 3 test batches
2025-06-28 14:34:02,395 - INFO - Staring training for 50 epochs
2025-06-28 14:34:14,519 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:34:14,519 - INFO - total_loss value: 12.53324019908905
2025-06-28 14:34:14,519 - INFO - length of train_dataloader: 10
2025-06-28 14:34:19,192 - INFO - Epoch 1/50 - Train Loss: 1.253324, Val Loss: 1.131323
2025-06-28 14:34:26,002 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:34:26,002 - INFO - total_loss value: 11.883323550224304
2025-06-28 14:34:26,003 - INFO - length of train_dataloader: 10
2025-06-28 14:34:29,365 - INFO - Epoch 2/50 - Train Loss: 1.188332, Val Loss: 1.119962
2025-06-28 14:34:36,476 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:34:36,476 - INFO - total_loss value: 11.823585867881775
2025-06-28 14:34:36,476 - INFO - length of train_dataloader: 10
2025-06-28 14:34:40,682 - INFO - Epoch 3/50 - Train Loss: 1.182359, Val Loss: 1.114902
2025-06-28 14:34:47,283 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:34:47,283 - INFO - total_loss value: 11.843237161636353
2025-06-28 14:34:47,283 - INFO - length of train_dataloader: 10
2025-06-28 14:34:50,649 - INFO - Epoch 4/50 - Train Loss: 1.184324, Val Loss: 1.109728
2025-06-28 14:34:57,268 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:34:57,269 - INFO - total_loss value: 11.776811599731445
2025-06-28 14:34:57,269 - INFO - length of train_dataloader: 10
2025-06-28 14:35:02,517 - INFO - Epoch 5/50 - Train Loss: 1.177681, Val Loss: 1.104723
2025-06-28 14:35:09,777 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:35:09,777 - INFO - total_loss value: 11.750238299369812
2025-06-28 14:35:09,777 - INFO - length of train_dataloader: 10
2025-06-28 14:35:13,971 - INFO - Epoch 6/50 - Train Loss: 1.175024, Val Loss: 1.096504
2025-06-28 14:35:21,083 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:35:21,083 - INFO - total_loss value: 11.775049209594727
2025-06-28 14:35:21,083 - INFO - length of train_dataloader: 10
2025-06-28 14:35:24,974 - INFO - Epoch 7/50 - Train Loss: 1.177505, Val Loss: 1.082989
2025-06-28 14:35:31,548 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:35:31,548 - INFO - total_loss value: 11.75777268409729
2025-06-28 14:35:31,548 - INFO - length of train_dataloader: 10
2025-06-28 14:35:35,718 - INFO - Epoch 8/50 - Train Loss: 1.175777, Val Loss: 1.058120
2025-06-28 14:35:42,543 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:35:42,544 - INFO - total_loss value: 11.703246235847473
2025-06-28 14:35:42,544 - INFO - length of train_dataloader: 10
2025-06-28 14:35:45,945 - INFO - Epoch 9/50 - Train Loss: 1.170325, Val Loss: 1.028193
2025-06-28 14:35:52,544 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:35:52,544 - INFO - total_loss value: 11.609472751617432
2025-06-28 14:35:52,544 - INFO - length of train_dataloader: 10
2025-06-28 14:35:56,999 - INFO - Epoch 10/50 - Train Loss: 1.160947, Val Loss: 1.010467
2025-06-28 14:36:04,372 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:36:04,372 - INFO - total_loss value: 11.738473534584045
2025-06-28 14:36:04,372 - INFO - length of train_dataloader: 10
2025-06-28 14:36:07,761 - INFO - Epoch 11/50 - Train Loss: 1.173847, Val Loss: 0.980210
2025-06-28 14:36:14,332 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:36:14,332 - INFO - total_loss value: 11.720927715301514
2025-06-28 14:36:14,332 - INFO - length of train_dataloader: 10
2025-06-28 14:36:17,747 - INFO - Epoch 12/50 - Train Loss: 1.172093, Val Loss: 1.007287
2025-06-28 14:36:25,145 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:36:25,145 - INFO - total_loss value: 11.553749322891235
2025-06-28 14:36:25,145 - INFO - length of train_dataloader: 10
2025-06-28 14:36:31,979 - INFO - Epoch 13/50 - Train Loss: 1.155375, Val Loss: 0.980951
2025-06-28 14:36:39,729 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:36:39,729 - INFO - total_loss value: 11.684824585914612
2025-06-28 14:36:39,729 - INFO - length of train_dataloader: 10
2025-06-28 14:36:43,199 - INFO - Epoch 14/50 - Train Loss: 1.168482, Val Loss: 0.981301
2025-06-28 14:36:50,208 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:36:50,209 - INFO - total_loss value: 11.664612531661987
2025-06-28 14:36:50,209 - INFO - length of train_dataloader: 10
2025-06-28 14:36:53,733 - INFO - Epoch 15/50 - Train Loss: 1.166461, Val Loss: 0.970300
2025-06-28 14:37:00,281 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:37:00,282 - INFO - total_loss value: 11.67478322982788
2025-06-28 14:37:00,282 - INFO - length of train_dataloader: 10
2025-06-28 14:37:04,576 - INFO - Epoch 16/50 - Train Loss: 1.167478, Val Loss: 0.976532
2025-06-28 14:37:15,039 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:37:15,039 - INFO - total_loss value: 11.674216032028198
2025-06-28 14:37:15,039 - INFO - length of train_dataloader: 10
2025-06-28 14:37:19,651 - INFO - Epoch 17/50 - Train Loss: 1.167422, Val Loss: 0.979567
2025-06-28 14:37:26,237 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:37:26,237 - INFO - total_loss value: 11.67242169380188
2025-06-28 14:37:26,237 - INFO - length of train_dataloader: 10
2025-06-28 14:37:30,199 - INFO - Epoch 18/50 - Train Loss: 1.167242, Val Loss: 0.970081
2025-06-28 14:37:36,865 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:37:36,865 - INFO - total_loss value: 11.638634324073792
2025-06-28 14:37:36,865 - INFO - length of train_dataloader: 10
2025-06-28 14:37:40,164 - INFO - Epoch 19/50 - Train Loss: 1.163863, Val Loss: 0.967578
2025-06-28 14:37:46,789 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:37:46,790 - INFO - total_loss value: 11.648188829421997
2025-06-28 14:37:46,790 - INFO - length of train_dataloader: 10
2025-06-28 14:37:51,610 - INFO - Epoch 20/50 - Train Loss: 1.164819, Val Loss: 0.955320
2025-06-28 14:37:58,649 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:37:58,649 - INFO - total_loss value: 11.66547679901123
2025-06-28 14:37:58,649 - INFO - length of train_dataloader: 10
2025-06-28 14:38:02,507 - INFO - Epoch 21/50 - Train Loss: 1.166548, Val Loss: 0.952791
2025-06-28 14:38:09,604 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:38:09,604 - INFO - total_loss value: 11.666450500488281
2025-06-28 14:38:09,604 - INFO - length of train_dataloader: 10
2025-06-28 14:38:12,946 - INFO - Epoch 22/50 - Train Loss: 1.166645, Val Loss: 0.953860
2025-06-28 14:38:19,666 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:38:19,666 - INFO - total_loss value: 11.671009302139282
2025-06-28 14:38:19,666 - INFO - length of train_dataloader: 10
2025-06-28 14:38:24,317 - INFO - Epoch 23/50 - Train Loss: 1.167101, Val Loss: 0.951229
2025-06-28 14:38:31,048 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:38:31,048 - INFO - total_loss value: 11.672417163848877
2025-06-28 14:38:31,048 - INFO - length of train_dataloader: 10
2025-06-28 14:38:34,499 - INFO - Epoch 24/50 - Train Loss: 1.167242, Val Loss: 0.957333
2025-06-28 14:38:41,942 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:38:41,942 - INFO - total_loss value: 11.652331113815308
2025-06-28 14:38:41,942 - INFO - length of train_dataloader: 10
2025-06-28 14:38:46,164 - INFO - Epoch 25/50 - Train Loss: 1.165233, Val Loss: 0.958300
2025-06-28 14:38:52,785 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:38:52,785 - INFO - total_loss value: 11.66399097442627
2025-06-28 14:38:52,786 - INFO - length of train_dataloader: 10
2025-06-28 14:38:56,735 - INFO - Epoch 26/50 - Train Loss: 1.166399, Val Loss: 0.944509
2025-06-28 14:39:04,158 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:39:04,158 - INFO - total_loss value: 11.5212641954422
2025-06-28 14:39:04,158 - INFO - length of train_dataloader: 10
2025-06-28 14:39:07,534 - INFO - Epoch 27/50 - Train Loss: 1.152126, Val Loss: 0.949081
2025-06-28 14:39:14,132 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:39:14,132 - INFO - total_loss value: 11.659118175506592
2025-06-28 14:39:14,133 - INFO - length of train_dataloader: 10
2025-06-28 14:39:18,620 - INFO - Epoch 28/50 - Train Loss: 1.165912, Val Loss: 0.953573
2025-06-28 14:39:26,011 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:39:26,011 - INFO - total_loss value: 11.656983256340027
2025-06-28 14:39:26,011 - INFO - length of train_dataloader: 10
2025-06-28 14:39:30,475 - INFO - Epoch 29/50 - Train Loss: 1.165698, Val Loss: 0.954406
2025-06-28 14:39:37,252 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:39:37,252 - INFO - total_loss value: 11.692601919174194
2025-06-28 14:39:37,252 - INFO - length of train_dataloader: 10
2025-06-28 14:39:40,564 - INFO - Epoch 30/50 - Train Loss: 1.169260, Val Loss: 0.953179
2025-06-28 14:39:47,800 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:39:47,800 - INFO - total_loss value: 11.533832788467407
2025-06-28 14:39:47,800 - INFO - length of train_dataloader: 10
2025-06-28 14:39:51,886 - INFO - Epoch 31/50 - Train Loss: 1.153383, Val Loss: 0.956231
2025-06-28 14:39:58,888 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:39:58,888 - INFO - total_loss value: 11.666002988815308
2025-06-28 14:39:58,888 - INFO - length of train_dataloader: 10
2025-06-28 14:40:02,782 - INFO - Epoch 32/50 - Train Loss: 1.166600, Val Loss: 0.951611
2025-06-28 14:40:09,390 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:40:09,390 - INFO - total_loss value: 11.666587829589844
2025-06-28 14:40:09,390 - INFO - length of train_dataloader: 10
2025-06-28 14:40:10,448 - INFO - args.exp_name : Train_Test
2025-06-28 14:40:10,453 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=8, epochs=50, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-28 14:40:10,453 - INFO - Starting training with 1 GPUs
2025-06-28 14:40:13,091 - INFO - Total trainable parameters: 1437705
2025-06-28 14:40:13,135 - INFO - Data loaded: 10 training batches, 2 validation batches, 3 test batches
2025-06-28 14:40:13,137 - INFO - Staring training for 50 epochs
2025-06-28 14:40:13,978 - INFO - Epoch 33/50 - Train Loss: 1.166659, Val Loss: 0.942014
2025-06-28 14:40:21,253 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:40:21,253 - INFO - total_loss value: 11.67379629611969
2025-06-28 14:40:21,253 - INFO - length of train_dataloader: 10
2025-06-28 14:40:22,771 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:40:22,775 - INFO - total_loss value: 12.53324019908905
2025-06-28 14:40:22,775 - INFO - length of train_dataloader: 10
2025-06-28 14:40:24,855 - INFO - Epoch 34/50 - Train Loss: 1.167380, Val Loss: 0.929979
2025-06-28 14:40:26,852 - INFO - Epoch 1/50 - Train Loss: 1.253324, Val Loss: 1.131323
2025-06-28 14:40:26,884 - INFO - New best model saved with Val Loss: 1.131323
2025-06-28 14:40:31,896 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:40:31,902 - INFO - total_loss value: 11.541240930557251
2025-06-28 14:40:31,902 - INFO - length of train_dataloader: 10
2025-06-28 14:40:33,690 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:40:33,695 - INFO - total_loss value: 11.883323550224304
2025-06-28 14:40:33,696 - INFO - length of train_dataloader: 10
2025-06-28 14:40:36,540 - INFO - Epoch 35/50 - Train Loss: 1.154124, Val Loss: 0.935797
2025-06-28 14:40:37,444 - INFO - Epoch 2/50 - Train Loss: 1.188332, Val Loss: 1.119962
2025-06-28 14:40:37,480 - INFO - New best model saved with Val Loss: 1.119962
2025-06-28 14:40:43,997 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:40:44,001 - INFO - total_loss value: 11.633399605751038
2025-06-28 14:40:44,001 - INFO - length of train_dataloader: 10
2025-06-28 14:40:44,234 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:40:44,255 - INFO - total_loss value: 11.823585867881775
2025-06-28 14:40:44,255 - INFO - length of train_dataloader: 10
2025-06-28 14:40:47,418 - INFO - Epoch 36/50 - Train Loss: 1.163340, Val Loss: 0.937645
2025-06-28 14:40:47,933 - INFO - Epoch 3/50 - Train Loss: 1.182359, Val Loss: 1.114902
2025-06-28 14:40:47,963 - INFO - New best model saved with Val Loss: 1.114902
2025-06-28 14:40:54,034 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:40:54,041 - INFO - total_loss value: 11.65716278553009
2025-06-28 14:40:54,041 - INFO - length of train_dataloader: 10
2025-06-28 14:40:55,094 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:40:55,102 - INFO - total_loss value: 11.843237161636353
2025-06-28 14:40:55,102 - INFO - length of train_dataloader: 10
2025-06-28 14:40:57,826 - INFO - Epoch 37/50 - Train Loss: 1.165716, Val Loss: 0.934001
2025-06-28 14:40:58,623 - INFO - Epoch 4/50 - Train Loss: 1.184324, Val Loss: 1.109728
2025-06-28 14:40:58,656 - INFO - New best model saved with Val Loss: 1.109728
2025-06-28 14:41:05,483 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:41:05,483 - INFO - total_loss value: 11.776811599731445
2025-06-28 14:41:05,483 - INFO - length of train_dataloader: 10
2025-06-28 14:41:05,583 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:41:05,589 - INFO - total_loss value: 11.701975703239441
2025-06-28 14:41:05,589 - INFO - length of train_dataloader: 10
2025-06-28 14:41:09,072 - INFO - Epoch 5/50 - Train Loss: 1.177681, Val Loss: 1.104723
2025-06-28 14:41:09,101 - INFO - New best model saved with Val Loss: 1.104723
2025-06-28 14:41:09,156 - INFO - Epoch 38/50 - Train Loss: 1.170198, Val Loss: 0.939264
2025-06-28 14:41:15,892 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:41:15,892 - INFO - total_loss value: 11.589049220085144
2025-06-28 14:41:15,892 - INFO - length of train_dataloader: 10
2025-06-28 14:41:15,932 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:41:15,939 - INFO - total_loss value: 11.750238299369812
2025-06-28 14:41:15,939 - INFO - length of train_dataloader: 10
2025-06-28 14:41:19,456 - INFO - Epoch 6/50 - Train Loss: 1.175024, Val Loss: 1.096504
2025-06-28 14:41:19,481 - INFO - New best model saved with Val Loss: 1.096504
2025-06-28 14:41:20,368 - INFO - Epoch 39/50 - Train Loss: 1.158905, Val Loss: 0.932368
2025-06-28 14:41:26,522 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:41:26,525 - INFO - total_loss value: 11.775049209594727
2025-06-28 14:41:26,525 - INFO - length of train_dataloader: 10
2025-06-28 14:41:27,718 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:41:27,724 - INFO - total_loss value: 11.677146792411804
2025-06-28 14:41:27,724 - INFO - length of train_dataloader: 10
2025-06-28 14:41:30,484 - INFO - Epoch 7/50 - Train Loss: 1.177505, Val Loss: 1.082989
2025-06-28 14:41:30,514 - INFO - New best model saved with Val Loss: 1.082989
2025-06-28 14:41:31,148 - INFO - Epoch 40/50 - Train Loss: 1.167715, Val Loss: 0.936677
2025-06-28 14:41:37,328 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:41:37,331 - INFO - total_loss value: 11.75777268409729
2025-06-28 14:41:37,331 - INFO - length of train_dataloader: 10
2025-06-28 14:41:38,811 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:41:38,817 - INFO - total_loss value: 11.620135068893433
2025-06-28 14:41:38,817 - INFO - length of train_dataloader: 10
2025-06-28 14:41:41,042 - INFO - Epoch 8/50 - Train Loss: 1.175777, Val Loss: 1.058120
2025-06-28 14:41:41,072 - INFO - New best model saved with Val Loss: 1.058120
2025-06-28 14:41:43,222 - INFO - Epoch 41/50 - Train Loss: 1.162014, Val Loss: 0.933867
2025-06-28 14:41:47,873 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:41:47,876 - INFO - total_loss value: 11.703246235847473
2025-06-28 14:41:47,876 - INFO - length of train_dataloader: 10
2025-06-28 14:41:50,492 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:41:50,498 - INFO - total_loss value: 11.648094654083252
2025-06-28 14:41:50,498 - INFO - length of train_dataloader: 10
2025-06-28 14:41:51,580 - INFO - Epoch 9/50 - Train Loss: 1.170325, Val Loss: 1.028193
2025-06-28 14:41:51,609 - INFO - New best model saved with Val Loss: 1.028193
2025-06-28 14:41:54,670 - INFO - Epoch 42/50 - Train Loss: 1.164809, Val Loss: 0.930149
2025-06-28 14:41:58,580 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:41:58,583 - INFO - total_loss value: 11.609472751617432
2025-06-28 14:41:58,583 - INFO - length of train_dataloader: 10
2025-06-28 14:42:01,638 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:42:01,643 - INFO - total_loss value: 11.515152335166931
2025-06-28 14:42:01,643 - INFO - length of train_dataloader: 10
2025-06-28 14:42:02,316 - INFO - Epoch 10/50 - Train Loss: 1.160947, Val Loss: 1.010467
2025-06-28 14:42:02,347 - INFO - New best model saved with Val Loss: 1.010467
2025-06-28 14:42:04,976 - INFO - Epoch 43/50 - Train Loss: 1.151515, Val Loss: 0.921296
2025-06-28 14:42:09,219 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:42:09,221 - INFO - total_loss value: 11.738473534584045
2025-06-28 14:42:09,222 - INFO - length of train_dataloader: 10
2025-06-28 14:42:12,746 - INFO - Epoch 11/50 - Train Loss: 1.173847, Val Loss: 0.980210
2025-06-28 14:42:12,764 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:42:12,771 - INFO - total_loss value: 11.655946016311646
2025-06-28 14:42:12,771 - INFO - length of train_dataloader: 10
2025-06-28 14:42:12,771 - INFO - New best model saved with Val Loss: 0.980210
2025-06-28 14:42:17,573 - INFO - Epoch 44/50 - Train Loss: 1.165595, Val Loss: 0.919199
2025-06-28 14:42:19,616 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:42:19,624 - INFO - total_loss value: 11.720927715301514
2025-06-28 14:42:19,624 - INFO - length of train_dataloader: 10
2025-06-28 14:42:23,340 - INFO - Epoch 12/50 - Train Loss: 1.172093, Val Loss: 1.007287
2025-06-28 14:42:29,255 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:42:29,259 - INFO - total_loss value: 11.615602850914001
2025-06-28 14:42:29,259 - INFO - length of train_dataloader: 10
2025-06-28 14:42:30,334 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:42:30,340 - INFO - total_loss value: 11.553749322891235
2025-06-28 14:42:30,340 - INFO - length of train_dataloader: 10
2025-06-28 14:42:33,872 - INFO - Epoch 13/50 - Train Loss: 1.155375, Val Loss: 0.980951
2025-06-28 14:42:35,101 - INFO - Epoch 45/50 - Train Loss: 1.161560, Val Loss: 0.922296
2025-06-28 14:42:40,791 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:42:40,795 - INFO - total_loss value: 11.684824585914612
2025-06-28 14:42:40,795 - INFO - length of train_dataloader: 10
2025-06-28 14:42:42,060 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:42:42,065 - INFO - total_loss value: 11.579261660575867
2025-06-28 14:42:42,066 - INFO - length of train_dataloader: 10
2025-06-28 14:42:44,550 - INFO - Epoch 14/50 - Train Loss: 1.168482, Val Loss: 0.981301
2025-06-28 14:42:46,269 - INFO - Epoch 46/50 - Train Loss: 1.157926, Val Loss: 0.921191
2025-06-28 14:42:51,411 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:42:51,414 - INFO - total_loss value: 11.664612531661987
2025-06-28 14:42:51,414 - INFO - length of train_dataloader: 10
2025-06-28 14:42:53,259 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:42:53,264 - INFO - total_loss value: 11.64852499961853
2025-06-28 14:42:53,264 - INFO - length of train_dataloader: 10
2025-06-28 14:42:55,156 - INFO - Epoch 15/50 - Train Loss: 1.166461, Val Loss: 0.970300
2025-06-28 14:42:55,185 - INFO - New best model saved with Val Loss: 0.970300
2025-06-28 14:42:56,548 - INFO - Epoch 47/50 - Train Loss: 1.164852, Val Loss: 0.932208
2025-06-28 14:43:02,263 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:43:02,267 - INFO - total_loss value: 11.67478322982788
2025-06-28 14:43:02,267 - INFO - length of train_dataloader: 10
2025-06-28 14:43:05,724 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:43:05,733 - INFO - total_loss value: 11.659417510032654
2025-06-28 14:43:05,733 - INFO - length of train_dataloader: 10
2025-06-28 14:43:05,763 - INFO - Epoch 16/50 - Train Loss: 1.167478, Val Loss: 0.976532
2025-06-28 14:43:11,421 - INFO - Epoch 48/50 - Train Loss: 1.165942, Val Loss: 0.941657
2025-06-28 14:43:12,622 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:43:12,628 - INFO - total_loss value: 11.674216032028198
2025-06-28 14:43:12,628 - INFO - length of train_dataloader: 10
2025-06-28 14:43:16,383 - INFO - Epoch 17/50 - Train Loss: 1.167422, Val Loss: 0.979567
2025-06-28 14:43:18,681 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:43:18,688 - INFO - total_loss value: 11.51139783859253
2025-06-28 14:43:18,688 - INFO - length of train_dataloader: 10
2025-06-28 14:43:22,166 - INFO - Epoch 49/50 - Train Loss: 1.151140, Val Loss: 0.926594
2025-06-28 14:43:23,304 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:43:23,311 - INFO - total_loss value: 11.67242169380188
2025-06-28 14:43:23,311 - INFO - length of train_dataloader: 10
2025-06-28 14:43:26,987 - INFO - Epoch 18/50 - Train Loss: 1.167242, Val Loss: 0.970081
2025-06-28 14:43:27,011 - INFO - New best model saved with Val Loss: 0.970081
2025-06-28 14:43:28,758 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:43:28,767 - INFO - total_loss value: 11.644763588905334
2025-06-28 14:43:28,767 - INFO - length of train_dataloader: 10
2025-06-28 14:43:32,167 - INFO - Epoch 50/50 - Train Loss: 1.164476, Val Loss: 0.927823
2025-06-28 14:43:34,035 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:43:34,040 - INFO - total_loss value: 11.638634324073792
2025-06-28 14:43:34,040 - INFO - length of train_dataloader: 10
2025-06-28 14:43:37,555 - INFO - Epoch 19/50 - Train Loss: 1.163863, Val Loss: 0.967578
2025-06-28 14:43:37,580 - INFO - New best model saved with Val Loss: 0.967578
2025-06-28 14:43:44,613 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:43:44,613 - INFO - total_loss value: 11.648188829421997
2025-06-28 14:43:44,613 - INFO - length of train_dataloader: 10
2025-06-28 14:43:48,618 - INFO - Epoch 20/50 - Train Loss: 1.164819, Val Loss: 0.955320
2025-06-28 14:43:48,643 - INFO - New best model saved with Val Loss: 0.955320
2025-06-28 14:43:58,388 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:43:58,388 - INFO - total_loss value: 11.66547679901123
2025-06-28 14:43:58,388 - INFO - length of train_dataloader: 10
2025-06-28 14:44:02,054 - INFO - Epoch 21/50 - Train Loss: 1.166548, Val Loss: 0.952791
2025-06-28 14:44:02,088 - INFO - New best model saved with Val Loss: 0.952791
2025-06-28 14:44:08,959 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:44:08,960 - INFO - total_loss value: 11.666450500488281
2025-06-28 14:44:08,960 - INFO - length of train_dataloader: 10
2025-06-28 14:44:12,752 - INFO - Epoch 22/50 - Train Loss: 1.166645, Val Loss: 0.953860
2025-06-28 14:44:19,852 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:44:19,852 - INFO - total_loss value: 11.671009302139282
2025-06-28 14:44:19,852 - INFO - length of train_dataloader: 10
2025-06-28 14:44:23,377 - INFO - Epoch 23/50 - Train Loss: 1.167101, Val Loss: 0.951229
2025-06-28 14:44:23,401 - INFO - New best model saved with Val Loss: 0.951229
2025-06-28 14:44:30,449 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:44:30,449 - INFO - total_loss value: 11.672417163848877
2025-06-28 14:44:30,449 - INFO - length of train_dataloader: 10
2025-06-28 14:44:34,011 - INFO - Epoch 24/50 - Train Loss: 1.167242, Val Loss: 0.957333
2025-06-28 14:44:40,926 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:44:40,926 - INFO - total_loss value: 11.652331113815308
2025-06-28 14:44:40,926 - INFO - length of train_dataloader: 10
2025-06-28 14:44:44,462 - INFO - Epoch 25/50 - Train Loss: 1.165233, Val Loss: 0.958300
2025-06-28 14:44:51,510 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:44:51,510 - INFO - total_loss value: 11.66399097442627
2025-06-28 14:44:51,510 - INFO - length of train_dataloader: 10
2025-06-28 14:44:55,034 - INFO - Epoch 26/50 - Train Loss: 1.166399, Val Loss: 0.944509
2025-06-28 14:44:55,058 - INFO - New best model saved with Val Loss: 0.944509
2025-06-28 14:45:01,907 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:45:01,907 - INFO - total_loss value: 11.5212641954422
2025-06-28 14:45:01,907 - INFO - length of train_dataloader: 10
2025-06-28 14:45:05,431 - INFO - Epoch 27/50 - Train Loss: 1.152126, Val Loss: 0.949081
2025-06-28 14:45:12,353 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:45:12,353 - INFO - total_loss value: 11.659118175506592
2025-06-28 14:45:12,353 - INFO - length of train_dataloader: 10
2025-06-28 14:45:16,062 - INFO - Epoch 28/50 - Train Loss: 1.165912, Val Loss: 0.953573
2025-06-28 14:45:23,171 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:45:23,171 - INFO - total_loss value: 11.656983256340027
2025-06-28 14:45:23,171 - INFO - length of train_dataloader: 10
2025-06-28 14:45:26,851 - INFO - Epoch 29/50 - Train Loss: 1.165698, Val Loss: 0.954406
2025-06-28 14:45:33,679 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:45:33,679 - INFO - total_loss value: 11.692601919174194
2025-06-28 14:45:33,679 - INFO - length of train_dataloader: 10
2025-06-28 14:45:37,192 - INFO - Epoch 30/50 - Train Loss: 1.169260, Val Loss: 0.953179
2025-06-28 14:45:44,244 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:45:44,244 - INFO - total_loss value: 11.533832788467407
2025-06-28 14:45:44,244 - INFO - length of train_dataloader: 10
2025-06-28 14:45:47,943 - INFO - Epoch 31/50 - Train Loss: 1.153383, Val Loss: 0.956231
2025-06-28 14:45:54,821 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:45:54,821 - INFO - total_loss value: 11.666002988815308
2025-06-28 14:45:54,821 - INFO - length of train_dataloader: 10
2025-06-28 14:45:58,474 - INFO - Epoch 32/50 - Train Loss: 1.166600, Val Loss: 0.951611
2025-06-28 14:46:05,287 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:46:05,288 - INFO - total_loss value: 11.666587829589844
2025-06-28 14:46:05,288 - INFO - length of train_dataloader: 10
2025-06-28 14:46:08,847 - INFO - Epoch 33/50 - Train Loss: 1.166659, Val Loss: 0.942014
2025-06-28 14:46:08,873 - INFO - New best model saved with Val Loss: 0.942014
2025-06-28 14:46:15,794 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:46:15,794 - INFO - total_loss value: 11.67379629611969
2025-06-28 14:46:15,795 - INFO - length of train_dataloader: 10
2025-06-28 14:46:19,286 - INFO - Epoch 34/50 - Train Loss: 1.167380, Val Loss: 0.929979
2025-06-28 14:46:19,310 - INFO - New best model saved with Val Loss: 0.929979
2025-06-28 14:46:26,183 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:46:26,184 - INFO - total_loss value: 11.541240930557251
2025-06-28 14:46:26,184 - INFO - length of train_dataloader: 10
2025-06-28 14:46:29,644 - INFO - Epoch 35/50 - Train Loss: 1.154124, Val Loss: 0.935797
2025-06-28 14:46:36,388 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:46:36,388 - INFO - total_loss value: 11.633399605751038
2025-06-28 14:46:36,388 - INFO - length of train_dataloader: 10
2025-06-28 14:46:40,093 - INFO - Epoch 36/50 - Train Loss: 1.163340, Val Loss: 0.937645
2025-06-28 14:46:46,984 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:46:46,984 - INFO - total_loss value: 11.65716278553009
2025-06-28 14:46:46,984 - INFO - length of train_dataloader: 10
2025-06-28 14:46:50,704 - INFO - Epoch 37/50 - Train Loss: 1.165716, Val Loss: 0.934001
2025-06-28 14:46:57,548 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:46:57,548 - INFO - total_loss value: 11.701975703239441
2025-06-28 14:46:57,549 - INFO - length of train_dataloader: 10
2025-06-28 14:47:01,279 - INFO - Epoch 38/50 - Train Loss: 1.170198, Val Loss: 0.939264
2025-06-28 14:47:08,077 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:47:08,077 - INFO - total_loss value: 11.589049220085144
2025-06-28 14:47:08,077 - INFO - length of train_dataloader: 10
2025-06-28 14:47:12,026 - INFO - Epoch 39/50 - Train Loss: 1.158905, Val Loss: 0.932368
2025-06-28 14:47:18,851 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:47:18,851 - INFO - total_loss value: 11.677146792411804
2025-06-28 14:47:18,851 - INFO - length of train_dataloader: 10
2025-06-28 14:47:24,188 - INFO - Epoch 40/50 - Train Loss: 1.167715, Val Loss: 0.936677
2025-06-28 14:47:31,213 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:47:31,213 - INFO - total_loss value: 11.620135068893433
2025-06-28 14:47:31,213 - INFO - length of train_dataloader: 10
2025-06-28 14:47:34,956 - INFO - Epoch 41/50 - Train Loss: 1.162014, Val Loss: 0.933867
2025-06-28 14:47:41,809 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:47:41,809 - INFO - total_loss value: 11.648094654083252
2025-06-28 14:47:41,809 - INFO - length of train_dataloader: 10
2025-06-28 14:47:45,384 - INFO - Epoch 42/50 - Train Loss: 1.164809, Val Loss: 0.930149
2025-06-28 14:47:52,231 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:47:52,232 - INFO - total_loss value: 11.515152335166931
2025-06-28 14:47:52,232 - INFO - length of train_dataloader: 10
2025-06-28 14:47:55,943 - INFO - Epoch 43/50 - Train Loss: 1.151515, Val Loss: 0.921296
2025-06-28 14:47:55,968 - INFO - New best model saved with Val Loss: 0.921296
2025-06-28 14:48:02,956 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:48:02,956 - INFO - total_loss value: 11.655946016311646
2025-06-28 14:48:02,956 - INFO - length of train_dataloader: 10
2025-06-28 14:48:06,420 - INFO - Epoch 44/50 - Train Loss: 1.165595, Val Loss: 0.919199
2025-06-28 14:48:06,445 - INFO - New best model saved with Val Loss: 0.919199
2025-06-28 14:48:13,318 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:48:13,318 - INFO - total_loss value: 11.615602850914001
2025-06-28 14:48:13,318 - INFO - length of train_dataloader: 10
2025-06-28 14:48:16,841 - INFO - Epoch 45/50 - Train Loss: 1.161560, Val Loss: 0.922296
2025-06-28 14:48:23,944 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:48:23,944 - INFO - total_loss value: 11.579261660575867
2025-06-28 14:48:23,944 - INFO - length of train_dataloader: 10
2025-06-28 14:48:27,406 - INFO - Epoch 46/50 - Train Loss: 1.157926, Val Loss: 0.921191
2025-06-28 14:48:34,484 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:48:34,484 - INFO - total_loss value: 11.64852499961853
2025-06-28 14:48:34,484 - INFO - length of train_dataloader: 10
2025-06-28 14:48:38,028 - INFO - Epoch 47/50 - Train Loss: 1.164852, Val Loss: 0.932208
2025-06-28 14:48:45,180 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:48:45,180 - INFO - total_loss value: 11.659417510032654
2025-06-28 14:48:45,180 - INFO - length of train_dataloader: 10
2025-06-28 14:48:48,711 - INFO - Epoch 48/50 - Train Loss: 1.165942, Val Loss: 0.941657
2025-06-28 14:48:55,617 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:48:55,617 - INFO - total_loss value: 11.51139783859253
2025-06-28 14:48:55,617 - INFO - length of train_dataloader: 10
2025-06-28 14:48:59,332 - INFO - Epoch 49/50 - Train Loss: 1.151140, Val Loss: 0.926594
2025-06-28 14:49:06,162 - INFO - type of total_loss: <class 'float'>
2025-06-28 14:49:06,163 - INFO - total_loss value: 11.644763588905334
2025-06-28 14:49:06,163 - INFO - length of train_dataloader: 10
2025-06-28 14:49:09,682 - INFO - Epoch 50/50 - Train Loss: 1.164476, Val Loss: 0.927823
2025-06-28 15:29:34,654 - INFO - args.exp_name : Train_Test
2025-06-28 15:29:34,656 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=8, epochs=10, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-28 15:29:34,656 - INFO - Starting training with 1 GPUs
2025-06-28 15:29:39,467 - INFO - Total trainable parameters: 1437705
2025-06-28 15:29:39,543 - INFO - Data loaded: 10 training batches, 2 validation batches, 3 test batches
2025-06-28 15:29:39,547 - INFO - Staring training for 10 epochs
2025-06-28 15:29:57,103 - INFO - Epoch 1/10 - Train Loss: 1.253324, Val Loss: 1.131323
2025-06-28 15:29:57,140 - INFO - New best model saved with Val Loss: 1.131323
2025-06-28 15:30:14,067 - INFO - Epoch 2/10 - Train Loss: 1.188332, Val Loss: 1.119962
2025-06-28 15:30:14,088 - INFO - New best model saved with Val Loss: 1.119962
2025-06-28 15:53:07,367 - INFO - args.exp_name : Train_Test
2025-06-28 15:53:07,368 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=8, epochs=12, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-28 15:53:07,368 - INFO - Starting training with 1 GPUs
2025-06-28 15:53:13,012 - INFO - Total trainable parameters: 1437705
2025-06-28 15:53:13,074 - INFO - Data loaded: 10 training batches, 2 validation batches, 3 test batches
2025-06-28 15:53:13,079 - INFO - Staring training for 12 epochs
2025-06-28 15:53:31,298 - INFO - Epoch 1/12 - Train Loss: 1.253324, Val Loss: 1.131323
2025-06-28 15:53:31,318 - INFO - New best model saved with Val Loss: 1.131323
2025-06-28 15:53:43,449 - INFO - Epoch 2/12 - Train Loss: 1.188332, Val Loss: 1.119962
2025-06-28 15:53:43,466 - INFO - New best model saved with Val Loss: 1.119962
2025-06-28 15:54:03,278 - INFO - Epoch 3/12 - Train Loss: 1.182359, Val Loss: 1.114902
2025-06-28 15:54:03,300 - INFO - New best model saved with Val Loss: 1.114902
2025-06-28 15:54:15,478 - INFO - Epoch 4/12 - Train Loss: 1.184324, Val Loss: 1.109728
2025-06-28 15:54:15,494 - INFO - New best model saved with Val Loss: 1.109728
2025-06-28 15:54:27,598 - INFO - Epoch 5/12 - Train Loss: 1.177681, Val Loss: 1.104723
2025-06-28 15:54:27,613 - INFO - New best model saved with Val Loss: 1.104723
2025-06-28 15:54:43,449 - INFO - Epoch 6/12 - Train Loss: 1.175024, Val Loss: 1.096504
2025-06-28 15:54:43,481 - INFO - New best model saved with Val Loss: 1.096504
2025-06-28 15:54:55,691 - INFO - Epoch 7/12 - Train Loss: 1.177505, Val Loss: 1.082989
2025-06-28 15:54:55,716 - INFO - New best model saved with Val Loss: 1.082989
2025-06-28 15:55:08,434 - INFO - Epoch 8/12 - Train Loss: 1.175777, Val Loss: 1.058120
2025-06-28 15:55:08,452 - INFO - New best model saved with Val Loss: 1.058120
2025-06-28 15:55:19,027 - INFO - args.exp_name : Train_Test
2025-06-28 15:55:19,030 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=8, epochs=12, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-28 15:55:19,030 - INFO - Starting training with 1 GPUs
2025-06-28 15:55:21,271 - INFO - Total trainable parameters: 1437705
2025-06-28 15:55:21,341 - INFO - Data loaded: 10 training batches, 2 validation batches, 3 test batches
2025-06-28 15:55:21,342 - INFO - Staring training for 12 epochs
2025-06-28 15:55:25,215 - INFO - Epoch 9/12 - Train Loss: 1.170325, Val Loss: 1.028193
2025-06-28 15:55:25,241 - INFO - New best model saved with Val Loss: 1.028193
2025-06-28 15:55:33,807 - INFO - Epoch 1/12 - Train Loss: 1.253324, Val Loss: 1.131323
2025-06-28 15:55:33,839 - INFO - New best model saved with Val Loss: 1.131323
2025-06-28 15:55:44,147 - INFO - Epoch 2/12 - Train Loss: 1.188332, Val Loss: 1.119962
2025-06-28 15:55:44,172 - INFO - New best model saved with Val Loss: 1.119962
2025-06-28 15:55:54,593 - INFO - Epoch 3/12 - Train Loss: 1.182359, Val Loss: 1.114902
2025-06-28 15:55:54,617 - INFO - New best model saved with Val Loss: 1.114902
2025-06-28 15:56:04,812 - INFO - Epoch 4/12 - Train Loss: 1.184324, Val Loss: 1.109728
2025-06-28 15:56:04,836 - INFO - New best model saved with Val Loss: 1.109728
2025-06-28 15:56:15,217 - INFO - Epoch 5/12 - Train Loss: 1.177681, Val Loss: 1.104723
2025-06-28 15:56:15,242 - INFO - New best model saved with Val Loss: 1.104723
2025-06-28 15:56:25,570 - INFO - Epoch 6/12 - Train Loss: 1.175024, Val Loss: 1.096504
2025-06-28 15:56:25,594 - INFO - New best model saved with Val Loss: 1.096504
2025-06-28 15:56:35,848 - INFO - Epoch 7/12 - Train Loss: 1.177505, Val Loss: 1.082989
2025-06-28 15:56:35,873 - INFO - New best model saved with Val Loss: 1.082989
2025-06-28 15:56:46,181 - INFO - Epoch 8/12 - Train Loss: 1.175777, Val Loss: 1.058120
2025-06-28 15:56:46,205 - INFO - New best model saved with Val Loss: 1.058120
2025-06-28 15:56:56,787 - INFO - Epoch 9/12 - Train Loss: 1.170325, Val Loss: 1.028193
2025-06-28 15:56:56,812 - INFO - New best model saved with Val Loss: 1.028193
2025-06-28 15:57:07,466 - INFO - Epoch 10/12 - Train Loss: 1.160947, Val Loss: 1.010467
2025-06-28 15:57:07,490 - INFO - New best model saved with Val Loss: 1.010467
2025-06-28 16:06:12,487 - INFO - args.exp_name : Train_Test
2025-06-28 16:06:12,491 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=8, epochs=12, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-28 16:06:12,491 - INFO - Starting training with 1 GPUs
2025-06-28 16:06:19,858 - INFO - Total trainable parameters: 1437705
2025-06-28 16:06:19,920 - INFO - Data loaded: 10 training batches, 2 validation batches, 3 test batches
2025-06-28 16:06:19,925 - INFO - Staring training for 12 epochs
2025-06-28 16:06:42,263 - INFO - Epoch 1/12 - Train Loss: 1.253324, Val Loss: 1.131323
2025-06-28 16:06:42,332 - INFO - New best model saved with Val Loss: 1.131323
2025-06-28 16:07:03,464 - INFO - Epoch 2/12 - Train Loss: 1.188332, Val Loss: 1.119962
2025-06-28 16:07:03,484 - INFO - New best model saved with Val Loss: 1.119962
2025-06-28 16:07:19,778 - INFO - Epoch 3/12 - Train Loss: 1.182359, Val Loss: 1.114902
2025-06-28 16:07:19,795 - INFO - New best model saved with Val Loss: 1.114902
2025-06-28 16:07:32,749 - INFO - Epoch 4/12 - Train Loss: 1.184324, Val Loss: 1.109728
2025-06-28 16:07:32,765 - INFO - New best model saved with Val Loss: 1.109728
2025-06-28 16:07:45,024 - INFO - Epoch 5/12 - Train Loss: 1.177681, Val Loss: 1.104723
2025-06-28 16:07:45,041 - INFO - New best model saved with Val Loss: 1.104723
2025-06-28 16:07:57,786 - INFO - Epoch 6/12 - Train Loss: 1.175024, Val Loss: 1.096504
2025-06-28 16:07:57,804 - INFO - New best model saved with Val Loss: 1.096504
2025-06-28 16:08:11,182 - INFO - Epoch 7/12 - Train Loss: 1.177505, Val Loss: 1.082989
2025-06-28 16:08:11,203 - INFO - New best model saved with Val Loss: 1.082989
2025-06-28 16:08:23,350 - INFO - Epoch 8/12 - Train Loss: 1.175777, Val Loss: 1.058120
2025-06-28 16:08:23,367 - INFO - New best model saved with Val Loss: 1.058120
2025-06-28 16:08:38,221 - INFO - Epoch 9/12 - Train Loss: 1.170325, Val Loss: 1.028193
2025-06-28 16:08:38,240 - INFO - New best model saved with Val Loss: 1.028193
2025-06-28 16:08:52,473 - INFO - Epoch 10/12 - Train Loss: 1.160947, Val Loss: 1.010467
2025-06-28 16:08:52,492 - INFO - New best model saved with Val Loss: 1.010467
2025-06-28 16:12:47,693 - INFO - args.exp_name : Train_Test
2025-06-28 16:12:47,695 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=8, epochs=12, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-28 16:12:47,695 - INFO - Starting training with 1 GPUs
2025-06-28 16:12:54,493 - INFO - Total trainable parameters: 1437705
2025-06-28 16:12:54,551 - INFO - Data loaded: 10 training batches, 2 validation batches, 3 test batches
2025-06-28 16:12:54,558 - INFO - Staring training for 12 epochs
2025-06-28 16:13:19,223 - INFO - Epoch 1/12 - Train Loss: 1.253324, Val Loss: 1.131323
2025-06-28 16:13:19,252 - INFO - New best model saved with Val Loss: 1.131323
2025-06-28 16:13:34,872 - INFO - Epoch 2/12 - Train Loss: 1.188332, Val Loss: 1.119962
2025-06-28 16:13:34,896 - INFO - New best model saved with Val Loss: 1.119962
2025-06-28 16:13:48,952 - INFO - Epoch 3/12 - Train Loss: 1.182359, Val Loss: 1.114902
2025-06-28 16:13:48,980 - INFO - New best model saved with Val Loss: 1.114902
2025-06-28 16:14:06,875 - INFO - Epoch 4/12 - Train Loss: 1.184324, Val Loss: 1.109728
2025-06-28 16:14:06,898 - INFO - New best model saved with Val Loss: 1.109728
2025-06-28 16:14:22,948 - INFO - Epoch 5/12 - Train Loss: 1.177681, Val Loss: 1.104723
2025-06-28 16:14:22,969 - INFO - New best model saved with Val Loss: 1.104723
2025-06-28 16:14:38,304 - INFO - Epoch 6/12 - Train Loss: 1.175024, Val Loss: 1.096504
2025-06-28 16:14:38,329 - INFO - New best model saved with Val Loss: 1.096504
2025-06-28 16:14:52,969 - INFO - Epoch 7/12 - Train Loss: 1.177505, Val Loss: 1.082989
2025-06-28 16:14:52,993 - INFO - New best model saved with Val Loss: 1.082989
2025-06-28 16:15:08,834 - INFO - Epoch 8/12 - Train Loss: 1.175777, Val Loss: 1.058120
2025-06-28 16:15:08,856 - INFO - New best model saved with Val Loss: 1.058120
2025-06-28 16:15:23,602 - INFO - Epoch 9/12 - Train Loss: 1.170325, Val Loss: 1.028193
2025-06-28 16:15:23,624 - INFO - New best model saved with Val Loss: 1.028193
2025-06-28 16:15:37,812 - INFO - Epoch 10/12 - Train Loss: 1.160947, Val Loss: 1.010467
2025-06-28 16:15:37,830 - INFO - New best model saved with Val Loss: 1.010467
2025-06-28 16:28:22,451 - INFO - args.exp_name : Train_Test
2025-06-28 16:28:22,461 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=8, epochs=12, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-28 16:28:22,461 - INFO - Starting training with 1 GPUs
2025-06-28 16:28:27,748 - INFO - Total trainable parameters: 1437705
2025-06-28 16:28:27,821 - INFO - Data loaded: 10 training batches, 2 validation batches, 3 test batches
2025-06-28 16:28:27,828 - INFO - Staring training for 12 epochs
2025-06-28 16:28:45,439 - INFO - Epoch 1/12 - Train Loss: 1.253324, Val Loss: 1.131323
2025-06-28 16:28:45,459 - INFO - New best model saved with Val Loss: 1.131323
2025-06-28 16:28:57,528 - INFO - Epoch 2/12 - Train Loss: 1.188332, Val Loss: 1.119962
2025-06-28 16:28:57,548 - INFO - New best model saved with Val Loss: 1.119962
2025-06-28 16:29:15,218 - INFO - Epoch 3/12 - Train Loss: 1.182359, Val Loss: 1.114902
2025-06-28 16:29:15,239 - INFO - New best model saved with Val Loss: 1.114902
2025-06-28 16:29:28,435 - INFO - Epoch 4/12 - Train Loss: 1.184324, Val Loss: 1.109728
2025-06-28 16:29:28,454 - INFO - New best model saved with Val Loss: 1.109728
2025-06-28 16:29:53,630 - INFO - Epoch 5/12 - Train Loss: 1.177681, Val Loss: 1.104723
2025-06-28 16:29:53,646 - INFO - New best model saved with Val Loss: 1.104723
2025-06-28 16:30:08,471 - INFO - Epoch 6/12 - Train Loss: 1.175024, Val Loss: 1.096504
2025-06-28 16:30:08,490 - INFO - New best model saved with Val Loss: 1.096504
2025-06-28 16:30:21,706 - INFO - Epoch 7/12 - Train Loss: 1.177505, Val Loss: 1.082989
2025-06-28 16:30:21,725 - INFO - New best model saved with Val Loss: 1.082989
2025-06-28 16:30:53,740 - INFO - Epoch 8/12 - Train Loss: 1.175777, Val Loss: 1.058120
2025-06-28 16:30:53,757 - INFO - New best model saved with Val Loss: 1.058120
2025-06-28 16:31:09,345 - INFO - Epoch 9/12 - Train Loss: 1.170325, Val Loss: 1.028193
2025-06-28 16:31:09,363 - INFO - New best model saved with Val Loss: 1.028193
2025-06-28 16:31:22,986 - INFO - Epoch 10/12 - Train Loss: 1.160947, Val Loss: 1.010467
2025-06-28 16:31:23,006 - INFO - New best model saved with Val Loss: 1.010467
2025-06-28 16:31:36,627 - INFO - Epoch 11/12 - Train Loss: 1.173847, Val Loss: 0.980210
2025-06-28 16:31:36,647 - INFO - New best model saved with Val Loss: 0.980210
2025-06-28 16:31:48,878 - INFO - Epoch 12/12 - Train Loss: 1.172093, Val Loss: 1.007287
2025-06-28 16:31:49,003 - INFO - Final model saved to experiments/Train_Test/final_model_pth
2025-06-28 16:36:21,974 - INFO - args.exp_name : Train_Test
2025-06-28 16:36:21,983 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=8, epochs=12, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-28 16:36:21,984 - INFO - Starting training with 1 GPUs
2025-06-28 16:36:27,948 - INFO - Total trainable parameters: 1437705
2025-06-28 16:36:28,010 - INFO - Data loaded: 10 training batches, 2 validation batches, 3 test batches
2025-06-28 16:36:28,014 - INFO - Staring training for 12 epochs
2025-06-28 16:37:01,024 - INFO - Epoch 1/12 - Train Loss: 1.253324, Val Loss: 1.131323
2025-06-28 16:37:01,086 - INFO - New best model saved with Val Loss: 1.131323
2025-06-28 16:37:16,122 - INFO - Epoch 2/12 - Train Loss: 1.188332, Val Loss: 1.119962
2025-06-28 16:37:16,154 - INFO - New best model saved with Val Loss: 1.119962
2025-06-28 16:37:27,172 - INFO - Epoch 3/12 - Train Loss: 1.182359, Val Loss: 1.114902
2025-06-28 16:37:27,188 - INFO - New best model saved with Val Loss: 1.114902
2025-06-28 16:37:38,405 - INFO - Epoch 4/12 - Train Loss: 1.184324, Val Loss: 1.109728
2025-06-28 16:37:38,421 - INFO - New best model saved with Val Loss: 1.109728
2025-06-28 16:37:49,869 - INFO - Epoch 5/12 - Train Loss: 1.177681, Val Loss: 1.104723
2025-06-28 16:37:49,886 - INFO - New best model saved with Val Loss: 1.104723
2025-06-28 16:38:01,142 - INFO - Epoch 6/12 - Train Loss: 1.175024, Val Loss: 1.096504
2025-06-28 16:38:01,159 - INFO - New best model saved with Val Loss: 1.096504
2025-06-28 16:38:11,445 - INFO - Epoch 7/12 - Train Loss: 1.177505, Val Loss: 1.082989
2025-06-28 16:38:11,462 - INFO - New best model saved with Val Loss: 1.082989
2025-06-28 16:38:23,944 - INFO - Epoch 8/12 - Train Loss: 1.175777, Val Loss: 1.058120
2025-06-28 16:38:23,963 - INFO - New best model saved with Val Loss: 1.058120
2025-06-28 16:38:35,278 - INFO - Epoch 9/12 - Train Loss: 1.170325, Val Loss: 1.028193
2025-06-28 16:38:35,294 - INFO - New best model saved with Val Loss: 1.028193
2025-06-28 16:38:45,989 - INFO - Epoch 10/12 - Train Loss: 1.160947, Val Loss: 1.010467
2025-06-28 16:38:46,003 - INFO - New best model saved with Val Loss: 1.010467
2025-06-28 16:38:56,776 - INFO - Epoch 11/12 - Train Loss: 1.173847, Val Loss: 0.980210
2025-06-28 16:38:56,794 - INFO - New best model saved with Val Loss: 0.980210
2025-06-28 16:39:09,038 - INFO - Epoch 12/12 - Train Loss: 1.172093, Val Loss: 1.007287
2025-06-28 16:39:09,168 - INFO - Final model saved to experiments/Train_Test/final_model_pth
2025-06-28 16:44:58,608 - INFO - args.exp_name : Train_Test
2025-06-28 16:44:58,610 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=8, epochs=12, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-28 16:44:58,610 - INFO - Starting training with 1 GPUs
2025-06-28 16:45:03,908 - INFO - Total trainable parameters: 1437705
2025-06-28 16:45:03,962 - INFO - Data loaded: 10 training batches, 2 validation batches, 3 test batches
2025-06-28 16:45:03,968 - INFO - Staring training for 12 epochs
2025-06-28 16:46:09,320 - INFO - Epoch 1/12 - Train Loss: 1.253324, Val Loss: 1.131323
2025-06-28 16:46:09,362 - INFO - New best model saved with Val Loss: 1.131323
2025-06-28 16:46:24,542 - INFO - Epoch 2/12 - Train Loss: 1.188332, Val Loss: 1.119962
2025-06-28 16:46:24,560 - INFO - New best model saved with Val Loss: 1.119962
2025-06-28 16:46:35,885 - INFO - Epoch 3/12 - Train Loss: 1.182359, Val Loss: 1.114902
2025-06-28 16:46:35,902 - INFO - New best model saved with Val Loss: 1.114902
2025-06-28 16:46:48,232 - INFO - Epoch 4/12 - Train Loss: 1.184324, Val Loss: 1.109728
2025-06-28 16:46:48,262 - INFO - New best model saved with Val Loss: 1.109728
2025-06-28 16:47:01,475 - INFO - Epoch 5/12 - Train Loss: 1.177681, Val Loss: 1.104723
2025-06-28 16:47:01,493 - INFO - New best model saved with Val Loss: 1.104723
2025-06-28 16:47:19,029 - INFO - Epoch 6/12 - Train Loss: 1.175024, Val Loss: 1.096504
2025-06-28 16:47:19,047 - INFO - New best model saved with Val Loss: 1.096504
2025-06-28 16:47:31,678 - INFO - Epoch 7/12 - Train Loss: 1.177505, Val Loss: 1.082989
2025-06-28 16:47:31,696 - INFO - New best model saved with Val Loss: 1.082989
2025-06-28 16:47:44,080 - INFO - Epoch 8/12 - Train Loss: 1.175777, Val Loss: 1.058120
2025-06-28 16:47:44,099 - INFO - New best model saved with Val Loss: 1.058120
2025-06-28 16:47:55,991 - INFO - Epoch 9/12 - Train Loss: 1.170325, Val Loss: 1.028193
2025-06-28 16:47:56,008 - INFO - New best model saved with Val Loss: 1.028193
2025-06-28 16:48:08,047 - INFO - Epoch 10/12 - Train Loss: 1.160947, Val Loss: 1.010467
2025-06-28 16:48:08,065 - INFO - New best model saved with Val Loss: 1.010467
2025-06-28 16:48:21,738 - INFO - Epoch 11/12 - Train Loss: 1.173847, Val Loss: 0.980210
2025-06-28 16:48:21,762 - INFO - New best model saved with Val Loss: 0.980210
2025-06-28 16:48:35,348 - INFO - Epoch 12/12 - Train Loss: 1.172093, Val Loss: 1.007287
2025-06-28 16:48:35,481 - INFO - Final model saved to experiments/Train_Test/final_model_pth
2025-06-28 16:48:35,493 - INFO - Testing the final model
2025-06-28 16:49:38,705 - INFO - args.exp_name : Train_Test
2025-06-28 16:49:38,714 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=8, epochs=12, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-28 16:49:38,714 - INFO - Starting training with 1 GPUs
2025-06-28 16:49:43,284 - INFO - Total trainable parameters: 1437705
2025-06-28 16:49:43,340 - INFO - Data loaded: 10 training batches, 2 validation batches, 3 test batches
2025-06-28 16:49:43,345 - INFO - Staring training for 12 epochs
2025-06-28 16:50:00,842 - INFO - Epoch 1/12 - Train Loss: 1.253324, Val Loss: 1.131323
2025-06-28 16:50:00,887 - INFO - New best model saved with Val Loss: 1.131323
2025-06-28 16:50:13,527 - INFO - Epoch 2/12 - Train Loss: 1.188332, Val Loss: 1.119962
2025-06-28 16:50:13,545 - INFO - New best model saved with Val Loss: 1.119962
2025-06-28 16:50:26,179 - INFO - Epoch 3/12 - Train Loss: 1.182359, Val Loss: 1.114902
2025-06-28 16:50:26,197 - INFO - New best model saved with Val Loss: 1.114902
2025-06-28 16:50:38,916 - INFO - Epoch 4/12 - Train Loss: 1.184324, Val Loss: 1.109728
2025-06-28 16:50:38,935 - INFO - New best model saved with Val Loss: 1.109728
2025-06-28 16:50:51,177 - INFO - Epoch 5/12 - Train Loss: 1.177681, Val Loss: 1.104723
2025-06-28 16:50:51,194 - INFO - New best model saved with Val Loss: 1.104723
2025-06-28 16:51:03,522 - INFO - Epoch 6/12 - Train Loss: 1.175024, Val Loss: 1.096504
2025-06-28 16:51:03,538 - INFO - New best model saved with Val Loss: 1.096504
2025-06-28 16:51:14,828 - INFO - Epoch 7/12 - Train Loss: 1.177505, Val Loss: 1.082989
2025-06-28 16:51:14,844 - INFO - New best model saved with Val Loss: 1.082989
2025-06-28 16:51:26,940 - INFO - Epoch 8/12 - Train Loss: 1.175777, Val Loss: 1.058120
2025-06-28 16:51:26,957 - INFO - New best model saved with Val Loss: 1.058120
2025-06-28 16:51:39,875 - INFO - Epoch 9/12 - Train Loss: 1.170325, Val Loss: 1.028193
2025-06-28 16:51:39,891 - INFO - New best model saved with Val Loss: 1.028193
2025-06-28 16:51:52,764 - INFO - Epoch 10/12 - Train Loss: 1.160947, Val Loss: 1.010467
2025-06-28 16:51:52,783 - INFO - New best model saved with Val Loss: 1.010467
2025-06-28 16:52:04,711 - INFO - Epoch 11/12 - Train Loss: 1.173847, Val Loss: 0.980210
2025-06-28 16:52:04,729 - INFO - New best model saved with Val Loss: 0.980210
2025-06-28 16:52:17,143 - INFO - Epoch 12/12 - Train Loss: 1.172093, Val Loss: 1.007287
2025-06-28 16:52:17,274 - INFO - Final model saved to experiments/Train_Test/final_model_pth
2025-06-28 16:52:17,289 - INFO - Testing the final model
2025-06-28 17:40:57,583 - INFO - args.exp_name : Train_Test
2025-06-28 17:40:57,592 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=8, epochs=12, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-28 17:40:57,593 - INFO - Starting training with 1 GPUs
2025-06-28 17:41:02,288 - INFO - Total trainable parameters: 1437705
2025-06-28 17:41:02,349 - INFO - Data loaded: 10 training batches, 2 validation batches, 3 test batches
2025-06-28 17:41:02,353 - INFO - Staring training for 12 epochs
2025-06-28 17:41:20,569 - INFO - Epoch 1/12 - Train Loss: 1.253324, Val Loss: 1.140946
2025-06-28 17:41:20,597 - INFO - New best model saved with Val Loss: 1.140946
2025-06-28 17:41:33,602 - INFO - Epoch 2/12 - Train Loss: 1.188389, Val Loss: 1.113803
2025-06-28 17:41:33,622 - INFO - New best model saved with Val Loss: 1.113803
2025-06-28 17:41:45,120 - INFO - Epoch 3/12 - Train Loss: 1.182415, Val Loss: 1.121538
2025-06-28 17:41:58,656 - INFO - Epoch 4/12 - Train Loss: 1.184420, Val Loss: 1.125069
2025-06-28 17:42:11,109 - INFO - Epoch 5/12 - Train Loss: 1.177936, Val Loss: 1.114436
2025-06-28 17:42:27,952 - INFO - Epoch 6/12 - Train Loss: 1.174998, Val Loss: 1.103332
2025-06-28 17:42:27,982 - INFO - New best model saved with Val Loss: 1.103332
2025-06-28 17:42:40,462 - INFO - Epoch 7/12 - Train Loss: 1.177706, Val Loss: 1.091069
2025-06-28 17:42:40,485 - INFO - New best model saved with Val Loss: 1.091069
2025-06-28 17:42:52,824 - INFO - Epoch 8/12 - Train Loss: 1.176191, Val Loss: 1.076332
2025-06-28 17:42:52,849 - INFO - New best model saved with Val Loss: 1.076332
2025-06-28 17:43:10,553 - INFO - Epoch 9/12 - Train Loss: 1.170609, Val Loss: 1.064585
2025-06-28 17:43:10,570 - INFO - New best model saved with Val Loss: 1.064585
2025-06-28 17:43:23,868 - INFO - Epoch 10/12 - Train Loss: 1.161243, Val Loss: 1.050977
2025-06-28 17:43:23,898 - INFO - New best model saved with Val Loss: 1.050977
2025-06-28 17:43:35,538 - INFO - Epoch 11/12 - Train Loss: 1.173800, Val Loss: 1.018686
2025-06-28 17:43:35,567 - INFO - New best model saved with Val Loss: 1.018686
2025-06-28 17:43:47,557 - INFO - Epoch 12/12 - Train Loss: 1.172042, Val Loss: 0.995451
2025-06-28 17:43:47,574 - INFO - New best model saved with Val Loss: 0.995451
2025-06-28 17:43:47,722 - INFO - Final model saved to experiments/Train_Test/final_model_pth
2025-06-28 17:43:47,732 - INFO - Testing the final model
2025-06-28 17:43:50,700 - INFO - mse type: <class 'torch.Tensor'>
2025-06-28 18:21:25,619 - INFO - args.exp_name : Train_Test
2025-06-28 18:21:25,622 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=8, epochs=12, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-28 18:21:25,622 - INFO - Starting training with 1 GPUs
2025-06-28 18:21:27,703 - INFO - Total trainable parameters: 1437705
2025-06-28 18:21:27,761 - INFO - Data loaded: 10 training batches, 2 validation batches, 3 test batches
2025-06-28 18:21:27,762 - INFO - Staring training for 12 epochs
2025-06-28 18:21:39,806 - INFO - Epoch 1/12 - Train Loss: 1.253324, Val Loss: 1.140946
2025-06-28 18:21:39,849 - INFO - New best model saved with Val Loss: 1.140946
2025-06-28 18:21:50,336 - INFO - Epoch 2/12 - Train Loss: 1.188389, Val Loss: 1.113803
2025-06-28 18:21:50,361 - INFO - New best model saved with Val Loss: 1.113803
2025-06-28 18:22:01,754 - INFO - Epoch 3/12 - Train Loss: 1.182415, Val Loss: 1.121538
2025-06-28 18:22:13,083 - INFO - Epoch 4/12 - Train Loss: 1.184420, Val Loss: 1.125069
2025-06-28 18:22:23,809 - INFO - Epoch 5/12 - Train Loss: 1.177936, Val Loss: 1.114436
2025-06-28 18:22:34,385 - INFO - Epoch 6/12 - Train Loss: 1.174998, Val Loss: 1.103332
2025-06-28 18:22:34,412 - INFO - New best model saved with Val Loss: 1.103332
2025-06-28 18:22:44,971 - INFO - Epoch 7/12 - Train Loss: 1.177706, Val Loss: 1.091069
2025-06-28 18:22:44,996 - INFO - New best model saved with Val Loss: 1.091069
2025-06-28 18:22:55,323 - INFO - Epoch 8/12 - Train Loss: 1.176191, Val Loss: 1.076332
2025-06-28 18:22:55,348 - INFO - New best model saved with Val Loss: 1.076332
2025-06-28 18:23:05,672 - INFO - Epoch 9/12 - Train Loss: 1.170609, Val Loss: 1.064585
2025-06-28 18:23:05,696 - INFO - New best model saved with Val Loss: 1.064585
2025-06-28 18:23:16,284 - INFO - Epoch 10/12 - Train Loss: 1.161243, Val Loss: 1.050977
2025-06-28 18:23:16,309 - INFO - New best model saved with Val Loss: 1.050977
2025-06-28 18:23:26,649 - INFO - Epoch 11/12 - Train Loss: 1.173800, Val Loss: 1.018686
2025-06-28 18:23:26,675 - INFO - New best model saved with Val Loss: 1.018686
2025-06-28 18:23:37,014 - INFO - Epoch 12/12 - Train Loss: 1.172042, Val Loss: 0.995451
2025-06-28 18:23:37,038 - INFO - New best model saved with Val Loss: 0.995451
2025-06-28 18:23:37,175 - INFO - Final model saved to experiments/Train_Test/final_model_pth
2025-06-28 18:23:37,175 - INFO - Testing the final model
2025-06-28 18:23:40,000 - INFO - mse type: <class 'torch.Tensor'>
2025-06-28 18:23:40,005 - INFO - mse shape: torch.Size([])
2025-06-28 18:23:40,005 - INFO - mae type: <class 'torch.Tensor'>
2025-06-28 18:23:40,005 - INFO - mae shape: torch.Size([])
2025-06-28 18:23:40,041 - INFO - mse type: <class 'torch.Tensor'>
2025-06-28 18:23:40,041 - INFO - mse shape: torch.Size([])
2025-06-28 18:23:40,041 - INFO - mae type: <class 'torch.Tensor'>
2025-06-28 18:23:40,041 - INFO - mae shape: torch.Size([])
2025-06-28 18:23:40,275 - INFO - mse type: <class 'torch.Tensor'>
2025-06-28 18:23:40,279 - INFO - mse shape: torch.Size([])
2025-06-28 18:23:40,279 - INFO - mae type: <class 'torch.Tensor'>
2025-06-28 18:23:40,288 - INFO - mae shape: torch.Size([])
2025-06-28 18:30:15,743 - INFO - args.exp_name : Train_Test
2025-06-28 18:30:15,755 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=8, epochs=12, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-28 18:30:15,755 - INFO - Starting training with 1 GPUs
2025-06-28 18:30:22,593 - INFO - Total trainable parameters: 1437705
2025-06-28 18:30:22,648 - INFO - Data loaded: 10 training batches, 2 validation batches, 3 test batches
2025-06-28 18:30:22,651 - INFO - Staring training for 12 epochs
2025-06-28 18:30:42,202 - INFO - Epoch 1/12 - Train Loss: 1.253324, Val Loss: 1.140946
2025-06-28 18:30:42,231 - INFO - New best model saved with Val Loss: 1.140946
2025-06-28 18:30:58,928 - INFO - Epoch 2/12 - Train Loss: 1.188389, Val Loss: 1.113803
2025-06-28 18:30:58,949 - INFO - New best model saved with Val Loss: 1.113803
2025-06-28 18:31:15,250 - INFO - Epoch 3/12 - Train Loss: 1.182415, Val Loss: 1.121538
2025-06-28 18:31:31,814 - INFO - Epoch 4/12 - Train Loss: 1.184420, Val Loss: 1.125069
2025-06-28 18:31:47,594 - INFO - Epoch 5/12 - Train Loss: 1.177936, Val Loss: 1.114436
2025-06-28 18:32:03,738 - INFO - Epoch 6/12 - Train Loss: 1.174998, Val Loss: 1.103332
2025-06-28 18:32:03,759 - INFO - New best model saved with Val Loss: 1.103332
2025-06-28 18:32:20,505 - INFO - Epoch 7/12 - Train Loss: 1.177706, Val Loss: 1.091069
2025-06-28 18:32:20,525 - INFO - New best model saved with Val Loss: 1.091069
2025-06-28 18:34:09,706 - INFO - args.exp_name : Train_Test
2025-06-28 18:34:09,715 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=8, epochs=12, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-28 18:34:09,715 - INFO - Starting training with 1 GPUs
2025-06-28 18:34:15,351 - INFO - Total trainable parameters: 1437705
2025-06-28 18:34:15,413 - INFO - Data loaded: 10 training batches, 2 validation batches, 3 test batches
2025-06-28 18:34:15,419 - INFO - Staring training for 12 epochs
2025-06-28 18:34:34,140 - INFO - Epoch 1/12 - Train Loss: 1.253324, Val Loss: 1.140946
2025-06-28 18:34:34,190 - INFO - New best model saved with Val Loss: 1.140946
2025-06-28 18:34:48,816 - INFO - Epoch 2/12 - Train Loss: 1.188389, Val Loss: 1.113803
2025-06-28 18:34:48,837 - INFO - New best model saved with Val Loss: 1.113803
2025-06-28 18:35:03,056 - INFO - Epoch 3/12 - Train Loss: 1.182415, Val Loss: 1.121538
2025-06-28 18:35:16,281 - INFO - Epoch 4/12 - Train Loss: 1.184420, Val Loss: 1.125069
2025-06-28 18:35:31,027 - INFO - Epoch 5/12 - Train Loss: 1.177936, Val Loss: 1.114436
2025-06-28 18:35:45,304 - INFO - Epoch 6/12 - Train Loss: 1.174998, Val Loss: 1.103332
2025-06-28 18:35:45,339 - INFO - New best model saved with Val Loss: 1.103332
2025-06-28 18:35:59,806 - INFO - Epoch 7/12 - Train Loss: 1.177706, Val Loss: 1.091069
2025-06-28 18:35:59,823 - INFO - New best model saved with Val Loss: 1.091069
2025-06-28 18:36:15,787 - INFO - Epoch 8/12 - Train Loss: 1.176191, Val Loss: 1.076332
2025-06-28 18:36:15,807 - INFO - New best model saved with Val Loss: 1.076332
2025-06-28 18:36:30,336 - INFO - Epoch 9/12 - Train Loss: 1.170609, Val Loss: 1.064585
2025-06-28 18:36:30,356 - INFO - New best model saved with Val Loss: 1.064585
2025-06-28 18:36:44,411 - INFO - Epoch 10/12 - Train Loss: 1.161243, Val Loss: 1.050977
2025-06-28 18:36:44,430 - INFO - New best model saved with Val Loss: 1.050977
2025-06-28 18:37:00,978 - INFO - Epoch 11/12 - Train Loss: 1.173800, Val Loss: 1.018686
2025-06-28 18:37:01,001 - INFO - New best model saved with Val Loss: 1.018686
2025-06-28 18:37:14,497 - INFO - Epoch 12/12 - Train Loss: 1.172042, Val Loss: 0.995451
2025-06-28 18:37:14,518 - INFO - New best model saved with Val Loss: 0.995451
2025-06-28 18:37:14,668 - INFO - Final model saved to experiments/Train_Test/final_model_pth
2025-06-28 18:37:14,679 - INFO - Testing the final model
2025-06-28 18:37:19,202 - INFO - mse type: <class 'torch.Tensor'>
2025-06-28 18:37:19,208 - INFO - mse value: 1.0333396196365356
2025-06-28 18:37:19,208 - INFO - mse value_with_item: 1.0333396196365356
2025-06-28 18:37:19,208 - INFO - mae type: <class 'torch.Tensor'>
2025-06-28 18:37:19,209 - INFO - mae value: 0.6205043792724609
2025-06-28 18:37:19,209 - INFO - mae value_with_item: 0.6205043792724609
2025-06-28 18:37:19,246 - INFO - rel_l1 value: 0.9312472343444824
2025-06-28 18:37:19,246 - INFO - rel_l1_with_item value: 0.9312472343444824
2025-06-28 18:37:19,246 - INFO - rel_l2 value: 0.9395401477813721
2025-06-28 18:37:19,246 - INFO - rel_l2_with_item value: 0.9395401477813721
2025-06-28 18:37:19,252 - INFO - mse type: <class 'torch.Tensor'>
2025-06-28 18:37:19,478 - INFO - mse value: 1.0370538234710693
2025-06-28 18:37:19,478 - INFO - mse value_with_item: 1.0370538234710693
2025-06-28 18:37:19,478 - INFO - mae type: <class 'torch.Tensor'>
2025-06-28 18:37:19,478 - INFO - mae value: 0.6142085194587708
2025-06-28 18:37:19,478 - INFO - mae value_with_item: 0.6142085194587708
2025-06-28 18:37:19,479 - INFO - rel_l1 value: 0.9384238719940186
2025-06-28 18:37:19,479 - INFO - rel_l1_with_item value: 0.9384238719940186
2025-06-28 18:37:19,479 - INFO - rel_l2 value: 0.9456447958946228
2025-06-28 18:37:19,479 - INFO - rel_l2_with_item value: 0.9456447958946228
2025-06-28 18:37:19,484 - INFO - mse type: <class 'torch.Tensor'>
2025-06-28 18:37:19,710 - INFO - mse value: 0.9745650291442871
2025-06-28 18:37:19,711 - INFO - mse value_with_item: 0.9745650291442871
2025-06-28 18:37:19,711 - INFO - mae type: <class 'torch.Tensor'>
2025-06-28 18:37:19,711 - INFO - mae value: 0.5982407927513123
2025-06-28 18:37:19,711 - INFO - mae value_with_item: 0.5982407927513123
2025-06-28 18:37:19,711 - INFO - rel_l1 value: 0.9408509731292725
2025-06-28 18:37:19,712 - INFO - rel_l1_with_item value: 0.9408509731292725
2025-06-28 18:37:19,712 - INFO - rel_l2 value: 0.9449415802955627
2025-06-28 18:37:19,712 - INFO - rel_l2_with_item value: 0.9449415802955627
2025-06-30 14:25:18,222 - INFO - args.exp_name : Train_Test
2025-06-30 14:25:18,227 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=8, epochs=12, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-30 14:25:18,227 - INFO - Starting training with 1 GPUs
2025-06-30 14:25:45,431 - INFO - Total trainable parameters: 1437705
2025-06-30 14:25:45,731 - INFO - Data loaded: 10 training batches, 2 validation batches, 3 test batches
2025-06-30 14:25:45,772 - INFO - Staring training for 12 epochs
2025-06-30 14:26:41,222 - INFO - Epoch 1/12 - Train Loss: 1.253324, Val Loss: 1.140946
2025-06-30 14:26:41,322 - INFO - New best model saved with Val Loss: 1.140946
2025-06-30 14:27:12,608 - INFO - Epoch 2/12 - Train Loss: 1.188389, Val Loss: 1.113803
2025-06-30 14:27:12,671 - INFO - New best model saved with Val Loss: 1.113803
2025-06-30 14:27:33,990 - INFO - Epoch 3/12 - Train Loss: 1.182415, Val Loss: 1.121538
2025-06-30 14:27:51,809 - INFO - Epoch 4/12 - Train Loss: 1.184420, Val Loss: 1.125069
2025-06-30 14:28:10,981 - INFO - Epoch 5/12 - Train Loss: 1.177936, Val Loss: 1.114436
2025-06-30 14:28:35,485 - INFO - Epoch 6/12 - Train Loss: 1.174998, Val Loss: 1.103332
2025-06-30 14:28:35,537 - INFO - New best model saved with Val Loss: 1.103332
2025-06-30 14:28:54,890 - INFO - Epoch 7/12 - Train Loss: 1.177706, Val Loss: 1.091069
2025-06-30 14:28:54,934 - INFO - New best model saved with Val Loss: 1.091069
2025-06-30 14:29:14,007 - INFO - Epoch 8/12 - Train Loss: 1.176191, Val Loss: 1.076332
2025-06-30 14:29:14,059 - INFO - New best model saved with Val Loss: 1.076332
2025-06-30 14:29:47,099 - INFO - Epoch 9/12 - Train Loss: 1.170609, Val Loss: 1.064585
2025-06-30 14:29:47,152 - INFO - New best model saved with Val Loss: 1.064585
2025-06-30 14:30:13,224 - INFO - Epoch 10/12 - Train Loss: 1.161243, Val Loss: 1.050977
2025-06-30 14:30:13,276 - INFO - New best model saved with Val Loss: 1.050977
2025-06-30 14:30:34,450 - INFO - Epoch 11/12 - Train Loss: 1.173800, Val Loss: 1.018686
2025-06-30 14:30:34,507 - INFO - New best model saved with Val Loss: 1.018686
2025-06-30 14:30:52,670 - INFO - Epoch 12/12 - Train Loss: 1.172042, Val Loss: 0.995451
2025-06-30 14:30:52,716 - INFO - New best model saved with Val Loss: 0.995451
2025-06-30 14:30:53,130 - INFO - Final model saved to experiments/Train_Test/final_model_pth
2025-06-30 14:30:53,131 - INFO - Testing the final model
2025-06-30 14:30:59,473 - INFO - normalized_outputs type: <class 'torch.Tensor'>
2025-06-30 14:30:59,505 - INFO - normalized_outputs shape: torch.Size([8, 10000])
2025-06-30 14:30:59,505 - INFO - normalized_targets type: <class 'torch.Tensor'>
2025-06-30 14:30:59,505 - INFO - normalized_targets shape: torch.Size([8, 10000])
2025-06-30 14:30:59,705 - INFO - mse type: <class 'torch.Tensor'>
2025-06-30 14:30:59,706 - INFO - mse value: 1.0333396196365356
2025-06-30 14:30:59,706 - INFO - mse value_with_item: 1.0333396196365356
2025-06-30 14:30:59,706 - INFO - mae type: <class 'torch.Tensor'>
2025-06-30 14:30:59,706 - INFO - mae value: 0.6205043792724609
2025-06-30 14:30:59,706 - INFO - mae value_with_item: 0.6205043792724609
2025-06-30 14:30:59,744 - INFO - rel_l1 value: 0.9312472343444824
2025-06-30 14:30:59,744 - INFO - rel_l1_with_item value: 0.9312472343444824
2025-06-30 14:30:59,744 - INFO - rel_l2 value: 0.9395401477813721
2025-06-30 14:30:59,744 - INFO - rel_l2_with_item value: 0.9395401477813721
2025-06-30 14:30:59,811 - INFO - normalized_outputs type: <class 'torch.Tensor'>
2025-06-30 14:30:59,812 - INFO - normalized_outputs shape: torch.Size([8, 10000])
2025-06-30 14:30:59,812 - INFO - normalized_targets type: <class 'torch.Tensor'>
2025-06-30 14:30:59,822 - INFO - normalized_targets shape: torch.Size([8, 10000])
2025-06-30 14:30:59,822 - INFO - mse type: <class 'torch.Tensor'>
2025-06-30 14:31:00,037 - INFO - mse value: 1.0370538234710693
2025-06-30 14:31:00,038 - INFO - mse value_with_item: 1.0370538234710693
2025-06-30 14:31:00,038 - INFO - mae type: <class 'torch.Tensor'>
2025-06-30 14:31:00,038 - INFO - mae value: 0.6142085194587708
2025-06-30 14:31:00,038 - INFO - mae value_with_item: 0.6142085194587708
2025-06-30 14:31:00,038 - INFO - rel_l1 value: 0.9384238719940186
2025-06-30 14:31:00,038 - INFO - rel_l1_with_item value: 0.9384238719940186
2025-06-30 14:31:00,038 - INFO - rel_l2 value: 0.9456447958946228
2025-06-30 14:31:00,038 - INFO - rel_l2_with_item value: 0.9456447958946228
2025-06-30 14:31:00,227 - INFO - normalized_outputs type: <class 'torch.Tensor'>
2025-06-30 14:31:00,227 - INFO - normalized_outputs shape: torch.Size([8, 10000])
2025-06-30 14:31:00,227 - INFO - normalized_targets type: <class 'torch.Tensor'>
2025-06-30 14:31:00,227 - INFO - normalized_targets shape: torch.Size([8, 10000])
2025-06-30 14:31:00,227 - INFO - mse type: <class 'torch.Tensor'>
2025-06-30 14:31:00,467 - INFO - mse value: 0.9745650291442871
2025-06-30 14:31:00,497 - INFO - mse value_with_item: 0.9745650291442871
2025-06-30 14:31:00,497 - INFO - mae type: <class 'torch.Tensor'>
2025-06-30 14:31:00,497 - INFO - mae value: 0.5982407927513123
2025-06-30 14:31:00,497 - INFO - mae value_with_item: 0.5982407927513123
2025-06-30 14:31:00,498 - INFO - rel_l1 value: 0.9408509731292725
2025-06-30 14:31:00,498 - INFO - rel_l1_with_item value: 0.9408509731292725
2025-06-30 14:31:00,498 - INFO - rel_l2 value: 0.9449415802955627
2025-06-30 14:31:00,498 - INFO - rel_l2_with_item value: 0.9449415802955627
2025-06-30 14:45:59,768 - INFO - args.exp_name : Train_Test
2025-06-30 14:45:59,773 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=8, epochs=12, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-30 14:45:59,773 - INFO - Starting training with 1 GPUs
2025-06-30 14:46:18,462 - INFO - Total trainable parameters: 1437705
2025-06-30 14:46:18,629 - INFO - Data loaded: 10 training batches, 2 validation batches, 3 test batches
2025-06-30 14:46:18,665 - INFO - Staring training for 12 epochs
2025-06-30 14:48:56,460 - INFO - args.exp_name : Train_Test
2025-06-30 14:48:56,483 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=8, epochs=12, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-30 14:48:56,483 - INFO - Starting training with 1 GPUs
2025-06-30 14:49:13,574 - INFO - Total trainable parameters: 1437705
2025-06-30 14:49:13,861 - INFO - Data loaded: 10 training batches, 2 validation batches, 3 test batches
2025-06-30 14:49:13,876 - INFO - Staring training for 12 epochs
2025-06-30 14:49:13,956 - INFO - Final model saved to experiments/Train_Test/final_model_pth
2025-06-30 14:49:13,959 - INFO - Testing the final model
2025-06-30 14:49:35,414 - INFO - normalized_outputs type: <class 'torch.Tensor'>
2025-06-30 15:15:54,168 - INFO - args.exp_name : Train_Test
2025-06-30 15:15:54,192 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=8, epochs=12, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-30 15:15:54,199 - INFO - Starting training with 1 GPUs
2025-06-30 15:16:04,837 - INFO - Total trainable parameters: 1437705
2025-06-30 15:16:04,900 - INFO - Data loaded: 10 training batches, 2 validation batches, 3 test batches
2025-06-30 15:16:04,909 - INFO - Staring training for 12 epochs
2025-06-30 15:16:04,949 - INFO - Final model saved to experiments/Train_Test/final_model_pth
2025-06-30 15:16:04,959 - INFO - Testing the final model
2025-06-30 15:16:19,803 - INFO - normalized_outputs type: <class 'torch.Tensor'>
2025-06-30 15:16:19,803 - INFO - normalized_outputs length : 1
2025-06-30 15:16:20,056 - INFO - normalized_outputs type: <class 'torch.Tensor'>
2025-06-30 15:16:20,056 - INFO - normalized_outputs length : 2
2025-06-30 15:16:20,288 - INFO - normalized_outputs type: <class 'torch.Tensor'>
2025-06-30 15:16:20,288 - INFO - normalized_outputs length : 3
2025-06-30 15:19:06,968 - INFO - args.exp_name : Train_Test
2025-06-30 15:19:06,985 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=8, epochs=12, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-30 15:19:06,985 - INFO - Starting training with 1 GPUs
2025-06-30 15:19:16,304 - INFO - Total trainable parameters: 1437705
2025-06-30 15:19:16,388 - INFO - Data loaded: 10 training batches, 2 validation batches, 3 test batches
2025-06-30 15:19:16,389 - INFO - Staring training for 12 epochs
2025-06-30 15:19:16,454 - INFO - Final model saved to experiments/Train_Test/final_model_pth
2025-06-30 15:19:16,462 - INFO - Testing the final model
2025-06-30 15:19:29,598 - INFO - normalized_outputs type: <class 'torch.Tensor'>
2025-06-30 15:19:29,640 - INFO - normalized_outputs first 5 value : [tensor([[-0.0004,  0.0395,  0.0787,  ...,  0.0295,  0.0384, -0.0151],
        [ 0.0676,  0.0940, -0.1913,  ...,  0.0342,  0.0119, -0.0270],
        [-0.1073,  0.0153, -0.0993,  ..., -0.0663,  0.0120,  0.0184],
        ...,
        [-0.0584, -0.1467,  0.0653,  ..., -0.0670,  0.0390, -0.0941],
        [-0.1066, -0.1257, -0.0436,  ...,  0.0280, -0.1407, -0.0362],
        [-0.1631, -0.0101,  0.0420,  ..., -0.0108,  0.0685,  0.0153]])]
2025-06-30 15:19:29,872 - INFO - normalized_outputs type: <class 'torch.Tensor'>
2025-06-30 15:19:29,874 - INFO - normalized_outputs first 5 value : [tensor([[-0.0004,  0.0395,  0.0787,  ...,  0.0295,  0.0384, -0.0151],
        [ 0.0676,  0.0940, -0.1913,  ...,  0.0342,  0.0119, -0.0270],
        [-0.1073,  0.0153, -0.0993,  ..., -0.0663,  0.0120,  0.0184],
        ...,
        [-0.0584, -0.1467,  0.0653,  ..., -0.0670,  0.0390, -0.0941],
        [-0.1066, -0.1257, -0.0436,  ...,  0.0280, -0.1407, -0.0362],
        [-0.1631, -0.0101,  0.0420,  ..., -0.0108,  0.0685,  0.0153]]), tensor([[-1.3223e-01,  4.0609e-01, -1.0546e-01,  ...,  8.2760e-02,
         -2.9105e-02, -7.0697e-02],
        [ 2.6392e-02,  2.4208e-03,  7.3777e-02,  ..., -7.4097e-02,
         -7.5070e-02, -1.2867e-01],
        [-8.9194e-02, -1.5162e-01,  9.0782e-03,  ...,  2.4502e-02,
          3.7299e-02,  4.6280e-02],
        ...,
        [-1.6333e-02, -9.1008e-02, -1.0734e-01,  ...,  9.9977e-03,
          4.0366e-02,  1.9166e-02],
        [-3.6702e-02, -8.2186e-02, -9.7411e-02,  ..., -8.2859e-02,
         -9.1823e-02, -1.0160e-02],
        [ 2.6854e-02, -1.2274e-01, -2.8979e-04,  ..., -1.3167e-01,
          1.9786e-02, -1.7892e-02]])]
2025-06-30 15:19:30,106 - INFO - normalized_outputs type: <class 'torch.Tensor'>
2025-06-30 15:19:30,108 - INFO - normalized_outputs first 5 value : [tensor([[-0.0004,  0.0395,  0.0787,  ...,  0.0295,  0.0384, -0.0151],
        [ 0.0676,  0.0940, -0.1913,  ...,  0.0342,  0.0119, -0.0270],
        [-0.1073,  0.0153, -0.0993,  ..., -0.0663,  0.0120,  0.0184],
        ...,
        [-0.0584, -0.1467,  0.0653,  ..., -0.0670,  0.0390, -0.0941],
        [-0.1066, -0.1257, -0.0436,  ...,  0.0280, -0.1407, -0.0362],
        [-0.1631, -0.0101,  0.0420,  ..., -0.0108,  0.0685,  0.0153]]), tensor([[-1.3223e-01,  4.0609e-01, -1.0546e-01,  ...,  8.2760e-02,
         -2.9105e-02, -7.0697e-02],
        [ 2.6392e-02,  2.4208e-03,  7.3777e-02,  ..., -7.4097e-02,
         -7.5070e-02, -1.2867e-01],
        [-8.9194e-02, -1.5162e-01,  9.0782e-03,  ...,  2.4502e-02,
          3.7299e-02,  4.6280e-02],
        ...,
        [-1.6333e-02, -9.1008e-02, -1.0734e-01,  ...,  9.9977e-03,
          4.0366e-02,  1.9166e-02],
        [-3.6702e-02, -8.2186e-02, -9.7411e-02,  ..., -8.2859e-02,
         -9.1823e-02, -1.0160e-02],
        [ 2.6854e-02, -1.2274e-01, -2.8979e-04,  ..., -1.3167e-01,
          1.9786e-02, -1.7892e-02]]), tensor([[ 9.4023e-02, -1.7952e-01, -5.0626e-02,  ...,  8.2223e-02,
         -2.3529e-03, -4.7622e-02],
        [-8.2041e-02, -7.6069e-03,  4.4658e-02,  ..., -4.3549e-02,
         -5.0403e-02,  1.9752e-02],
        [-4.7886e-02, -1.0890e-02, -7.9050e-02,  ..., -1.2168e-01,
         -7.0545e-02,  1.5359e-01],
        ...,
        [-8.7113e-02, -1.1998e-01, -1.0086e-01,  ..., -1.1805e-01,
         -3.3237e-02, -1.0960e-01],
        [ 6.0501e-02,  3.9387e-02, -8.4609e-02,  ...,  8.6239e-03,
         -1.6217e-01,  2.3374e-02],
        [ 5.2814e-02, -8.3480e-02, -7.3634e-05,  ..., -1.2143e-01,
          1.0725e-02, -3.9310e-02]])]
2025-06-30 15:29:57,305 - INFO - args.exp_name : Train_Test
2025-06-30 15:29:57,353 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=8, epochs=12, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-30 15:29:57,353 - INFO - Starting training with 1 GPUs
2025-06-30 15:30:10,243 - INFO - Total trainable parameters: 1437705
2025-06-30 15:30:10,306 - INFO - Data loaded: 10 training batches, 2 validation batches, 3 test batches
2025-06-30 15:30:10,311 - INFO - Staring training for 12 epochs
2025-06-30 15:30:10,330 - INFO - Final model saved to experiments/Train_Test/final_model_pth
2025-06-30 15:30:10,334 - INFO - Testing the final model
2025-06-30 15:30:24,502 - INFO - Total MSE across all processes: 24.359668731689453
2025-06-30 16:19:27,843 - INFO - args.exp_name : Train_Test
2025-06-30 16:19:27,891 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=8, epochs=12, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-30 16:19:27,891 - INFO - Starting training with 1 GPUs
2025-06-30 16:19:47,594 - INFO - Total trainable parameters: 1437705
2025-06-30 16:19:47,668 - INFO - Data loaded: 10 training batches, 2 validation batches, 3 test batches
2025-06-30 16:19:47,701 - INFO - Staring training for 12 epochs
2025-06-30 16:24:15,185 - INFO - Final model saved to experiments/Train_Test/final_model_pth
2025-06-30 16:24:26,595 - INFO - Total MSE across all processes: 24.359668731689453
2025-06-30 16:24:26,597 - INFO - mean value for all_targets: {tmp}
2025-06-30 16:24:26,599 - INFO - Test MSE: 1.014986, Test MAE: 0.610985, Max MAE: 17.060396, Test R2: 0.1095
2025-06-30 16:24:26,599 - INFO - Relative L2 Error: 0.943376, Relative L1 error: 0.936841
2025-06-30 16:24:26,599 - INFO - Total inference time:  0.01s for 24 samples
2025-06-30 16:24:26,600 - INFO - Testing the final model
2025-06-30 16:24:34,020 - INFO - Total MSE across all processes: 24.359668731689453
2025-06-30 16:24:34,021 - INFO - mean value for all_targets: {tmp}
2025-06-30 16:24:34,022 - INFO - Test MSE: 1.014986, Test MAE: 0.610985, Max MAE: 17.060396, Test R2: 0.1095
2025-06-30 16:24:34,022 - INFO - Relative L2 Error: 0.943376, Relative L1 error: 0.936841
2025-06-30 16:24:34,030 - INFO - Total inference time:  0.01s for 24 samples
2025-06-30 16:40:49,296 - INFO - args.exp_name : Train_Test
2025-06-30 16:40:49,336 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=8, epochs=12, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-30 16:40:49,336 - INFO - Starting training with 1 GPUs
2025-06-30 16:41:01,051 - INFO - Total trainable parameters: 1437705
2025-06-30 16:41:01,107 - INFO - Data loaded: 10 training batches, 2 validation batches, 3 test batches
2025-06-30 16:41:01,110 - INFO - Staring training for 12 epochs
2025-06-30 16:41:37,009 - INFO - Epoch 1/12 - Train Loss: 1.253324, Val Loss: 1.140946
2025-06-30 16:41:37,088 - INFO - New best model saved with Val Loss: 1.140946
2025-06-30 16:42:02,680 - INFO - Epoch 2/12 - Train Loss: 1.188389, Val Loss: 1.113803
2025-06-30 16:42:02,725 - INFO - New best model saved with Val Loss: 1.113803
2025-06-30 16:42:27,807 - INFO - Epoch 3/12 - Train Loss: 1.182415, Val Loss: 1.121538
2025-06-30 16:42:52,816 - INFO - Epoch 4/12 - Train Loss: 1.184420, Val Loss: 1.125069
2025-06-30 16:43:10,803 - INFO - Epoch 5/12 - Train Loss: 1.177936, Val Loss: 1.114436
2025-06-30 16:43:32,894 - INFO - Epoch 6/12 - Train Loss: 1.174998, Val Loss: 1.103332
2025-06-30 16:43:32,965 - INFO - New best model saved with Val Loss: 1.103332
2025-06-30 16:43:59,150 - INFO - Epoch 7/12 - Train Loss: 1.177706, Val Loss: 1.091069
2025-06-30 16:43:59,211 - INFO - New best model saved with Val Loss: 1.091069
2025-06-30 16:44:24,872 - INFO - Epoch 8/12 - Train Loss: 1.176191, Val Loss: 1.076332
2025-06-30 16:44:24,936 - INFO - New best model saved with Val Loss: 1.076332
2025-06-30 16:44:50,255 - INFO - Epoch 9/12 - Train Loss: 1.170609, Val Loss: 1.064585
2025-06-30 16:44:50,318 - INFO - New best model saved with Val Loss: 1.064585
2025-06-30 16:45:15,230 - INFO - Epoch 10/12 - Train Loss: 1.161243, Val Loss: 1.050977
2025-06-30 16:45:15,291 - INFO - New best model saved with Val Loss: 1.050977
2025-06-30 16:45:41,679 - INFO - Epoch 11/12 - Train Loss: 1.173800, Val Loss: 1.018686
2025-06-30 16:45:41,729 - INFO - New best model saved with Val Loss: 1.018686
2025-06-30 16:46:07,104 - INFO - Epoch 12/12 - Train Loss: 1.172042, Val Loss: 0.995451
2025-06-30 16:46:07,152 - INFO - New best model saved with Val Loss: 0.995451
2025-06-30 16:46:07,616 - INFO - Final model saved to experiments/Train_Test/final_model_pth
2025-06-30 16:46:07,617 - INFO - Testing the final model
2025-06-30 16:46:19,758 - INFO - Total MSE across all processes: 24.359668731689453
2025-06-30 16:46:19,760 - INFO - mean value for all_targets: {tmp}
2025-06-30 16:46:19,766 - INFO - Test MSE: 1.014986, Test MAE: 0.610985, Max MAE: 17.060396, Test R2: 0.1095
2025-06-30 16:46:19,766 - INFO - Relative L2 Error: 0.943376, Relative L1 error: 0.936841
2025-06-30 16:46:19,766 - INFO - Total inference time:  0.01s for 24 samples
2025-06-30 16:46:19,768 - INFO - Testing the best model
2025-06-30 16:46:31,723 - INFO - Total MSE across all processes: 24.359668731689453
2025-06-30 16:46:31,724 - INFO - mean value for all_targets: {tmp}
2025-06-30 16:46:31,725 - INFO - Test MSE: 1.014986, Test MAE: 0.610985, Max MAE: 17.060396, Test R2: 0.1095
2025-06-30 16:46:31,725 - INFO - Relative L2 Error: 0.943376, Relative L1 error: 0.936841
2025-06-30 16:46:31,725 - INFO - Total inference time:  0.01s for 24 samples
2025-06-30 16:51:48,631 - INFO - args.exp_name : Train_Test
2025-06-30 16:51:48,649 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data', num_points=10000, batch_size=12, epochs=150, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-06-30 16:51:48,650 - INFO - Starting training with 1 GPUs
2025-06-30 16:52:05,381 - INFO - Total trainable parameters: 1437705
2025-06-30 16:52:05,694 - INFO - Data loaded: 19 training batches, 4 validation batches, 4 test batches
2025-06-30 16:52:05,701 - INFO - Staring training for 150 epochs
2025-06-30 16:52:52,236 - INFO - Epoch 1/150 - Train Loss: 1.214562, Val Loss: 1.139650
2025-06-30 16:52:52,311 - INFO - New best model saved with Val Loss: 1.139650
2025-06-30 16:53:20,199 - INFO - Epoch 2/150 - Train Loss: 1.159891, Val Loss: 1.142322
2025-06-30 16:53:47,984 - INFO - Epoch 3/150 - Train Loss: 1.159527, Val Loss: 1.136151
2025-06-30 16:53:48,043 - INFO - New best model saved with Val Loss: 1.136151
2025-06-30 16:54:16,527 - INFO - Epoch 4/150 - Train Loss: 1.158275, Val Loss: 1.134893
2025-06-30 16:54:16,579 - INFO - New best model saved with Val Loss: 1.134893
2025-06-30 16:54:47,309 - INFO - Epoch 5/150 - Train Loss: 1.158841, Val Loss: 1.130716
2025-06-30 16:54:47,349 - INFO - New best model saved with Val Loss: 1.130716
2025-06-30 16:55:14,837 - INFO - Epoch 6/150 - Train Loss: 1.157435, Val Loss: 1.128637
2025-06-30 16:55:14,851 - INFO - New best model saved with Val Loss: 1.128637
2025-06-30 16:55:41,294 - INFO - Epoch 7/150 - Train Loss: 1.158527, Val Loss: 1.126826
2025-06-30 16:55:41,337 - INFO - New best model saved with Val Loss: 1.126826
2025-06-30 16:56:15,374 - INFO - Epoch 8/150 - Train Loss: 1.159670, Val Loss: 1.127982
2025-06-30 16:56:48,989 - INFO - Epoch 9/150 - Train Loss: 1.157885, Val Loss: 1.108465
2025-06-30 16:56:49,056 - INFO - New best model saved with Val Loss: 1.108465
2025-06-30 16:57:22,691 - INFO - Epoch 10/150 - Train Loss: 1.152975, Val Loss: 1.099538
2025-06-30 16:57:22,745 - INFO - New best model saved with Val Loss: 1.099538
2025-06-30 16:57:57,392 - INFO - Epoch 11/150 - Train Loss: 1.154798, Val Loss: 1.097098
2025-06-30 16:57:57,436 - INFO - New best model saved with Val Loss: 1.097098
2025-06-30 16:58:31,957 - INFO - Epoch 12/150 - Train Loss: 1.151280, Val Loss: 1.071959
2025-06-30 16:58:32,013 - INFO - New best model saved with Val Loss: 1.071959
2025-06-30 16:59:06,841 - INFO - Epoch 13/150 - Train Loss: 1.154427, Val Loss: 1.022585
2025-06-30 16:59:06,871 - INFO - New best model saved with Val Loss: 1.022585
2025-06-30 16:59:36,631 - INFO - Epoch 14/150 - Train Loss: 1.149373, Val Loss: 1.066904
2025-06-30 17:00:06,794 - INFO - Epoch 15/150 - Train Loss: 1.153083, Val Loss: 1.044195
2025-06-30 17:00:39,968 - INFO - Epoch 16/150 - Train Loss: 1.149388, Val Loss: 1.047594
2025-06-30 17:01:08,692 - INFO - Epoch 17/150 - Train Loss: 1.152448, Val Loss: 1.034870
2025-06-30 17:01:34,550 - INFO - Epoch 18/150 - Train Loss: 1.151513, Val Loss: 1.050777
2025-06-30 17:02:04,571 - INFO - Epoch 19/150 - Train Loss: 1.146651, Val Loss: 1.016412
2025-06-30 17:02:04,625 - INFO - New best model saved with Val Loss: 1.016412
2025-06-30 17:02:51,972 - INFO - Epoch 20/150 - Train Loss: 1.149560, Val Loss: 1.036892
2025-06-30 17:03:25,857 - INFO - Epoch 21/150 - Train Loss: 1.152120, Val Loss: 1.037410
2025-06-30 17:03:58,755 - INFO - Epoch 22/150 - Train Loss: 1.150785, Val Loss: 1.030477
2025-06-30 17:04:32,711 - INFO - Epoch 23/150 - Train Loss: 1.150990, Val Loss: 1.043045
2025-06-30 17:05:07,070 - INFO - Epoch 24/150 - Train Loss: 1.151737, Val Loss: 1.018163
2025-06-30 17:05:41,494 - INFO - Epoch 25/150 - Train Loss: 1.151702, Val Loss: 1.033189
2025-06-30 17:06:15,997 - INFO - Epoch 26/150 - Train Loss: 1.152441, Val Loss: 1.031626
2025-06-30 17:06:51,002 - INFO - Epoch 27/150 - Train Loss: 1.151930, Val Loss: 1.030635
2025-06-30 17:07:25,442 - INFO - Epoch 28/150 - Train Loss: 1.149480, Val Loss: 1.032951
2025-06-30 17:08:00,199 - INFO - Epoch 29/150 - Train Loss: 1.149540, Val Loss: 1.027915
2025-06-30 17:08:34,494 - INFO - Epoch 30/150 - Train Loss: 1.150046, Val Loss: 1.025701
2025-06-30 17:09:22,222 - INFO - Epoch 31/150 - Train Loss: 1.150857, Val Loss: 1.018049
2025-06-30 17:09:50,295 - INFO - Epoch 32/150 - Train Loss: 1.148125, Val Loss: 1.013000
2025-06-30 17:09:50,316 - INFO - New best model saved with Val Loss: 1.013000
2025-06-30 17:10:18,637 - INFO - Epoch 33/150 - Train Loss: 1.153354, Val Loss: 1.019805
2025-06-30 17:10:45,338 - INFO - Epoch 34/150 - Train Loss: 1.149081, Val Loss: 1.014312
2025-06-30 17:11:16,784 - INFO - Epoch 35/150 - Train Loss: 1.151963, Val Loss: 1.019807
2025-06-30 17:11:43,524 - INFO - Epoch 36/150 - Train Loss: 1.151386, Val Loss: 1.016370
2025-06-30 17:12:10,975 - INFO - Epoch 37/150 - Train Loss: 1.152770, Val Loss: 1.015124
2025-06-30 17:12:45,883 - INFO - Epoch 38/150 - Train Loss: 1.145815, Val Loss: 1.010870
2025-06-30 17:12:45,945 - INFO - New best model saved with Val Loss: 1.010870
2025-06-30 17:13:20,627 - INFO - Epoch 39/150 - Train Loss: 1.151062, Val Loss: 1.022470
2025-06-30 17:13:54,343 - INFO - Epoch 40/150 - Train Loss: 1.149539, Val Loss: 1.015680
2025-06-30 17:14:27,643 - INFO - Epoch 41/150 - Train Loss: 1.150300, Val Loss: 1.021166
2025-06-30 17:14:59,917 - INFO - Epoch 42/150 - Train Loss: 1.151812, Val Loss: 1.011826
2025-06-30 17:15:26,756 - INFO - Epoch 43/150 - Train Loss: 1.150189, Val Loss: 1.023766
2025-06-30 17:15:57,687 - INFO - Epoch 44/150 - Train Loss: 1.151446, Val Loss: 1.012347
2025-06-30 17:16:30,431 - INFO - Epoch 45/150 - Train Loss: 1.149226, Val Loss: 1.014126
2025-06-30 17:17:00,758 - INFO - Epoch 46/150 - Train Loss: 1.150818, Val Loss: 1.016673
2025-06-30 17:17:27,129 - INFO - Epoch 47/150 - Train Loss: 1.152273, Val Loss: 1.016973
2025-06-30 17:17:53,563 - INFO - Epoch 48/150 - Train Loss: 1.152706, Val Loss: 1.013585
2025-06-30 17:18:20,011 - INFO - Epoch 49/150 - Train Loss: 1.152967, Val Loss: 1.012885
2025-06-30 17:18:47,411 - INFO - Epoch 50/150 - Train Loss: 1.149793, Val Loss: 1.014034
2025-06-30 17:19:14,329 - INFO - Epoch 51/150 - Train Loss: 1.151599, Val Loss: 1.014963
2025-06-30 17:19:40,739 - INFO - Epoch 52/150 - Train Loss: 1.149825, Val Loss: 1.015483
2025-06-30 17:20:07,043 - INFO - Epoch 53/150 - Train Loss: 1.148759, Val Loss: 1.014243
2025-06-30 17:20:37,431 - INFO - Epoch 54/150 - Train Loss: 1.149218, Val Loss: 1.014622
2025-06-30 17:21:06,583 - INFO - Epoch 55/150 - Train Loss: 1.152413, Val Loss: 1.013234
2025-06-30 17:21:32,561 - INFO - Epoch 56/150 - Train Loss: 1.149147, Val Loss: 1.014769
2025-06-30 17:21:58,929 - INFO - Epoch 57/150 - Train Loss: 1.151125, Val Loss: 1.014339
2025-06-30 17:22:25,086 - INFO - Epoch 58/150 - Train Loss: 1.149256, Val Loss: 1.013369
2025-06-30 17:22:52,282 - INFO - Epoch 59/150 - Train Loss: 1.151146, Val Loss: 1.014887
2025-06-30 17:23:20,401 - INFO - Epoch 60/150 - Train Loss: 1.151584, Val Loss: 1.014976
2025-06-30 17:23:47,937 - INFO - Epoch 61/150 - Train Loss: 1.151559, Val Loss: 1.015210
2025-06-30 17:24:15,019 - INFO - Epoch 62/150 - Train Loss: 1.145339, Val Loss: 1.014917
2025-06-30 17:24:45,767 - INFO - Epoch 63/150 - Train Loss: 1.152052, Val Loss: 1.014691
2025-06-30 17:25:16,289 - INFO - Epoch 64/150 - Train Loss: 1.149146, Val Loss: 1.014958
2025-06-30 17:25:54,057 - INFO - Epoch 65/150 - Train Loss: 1.151268, Val Loss: 1.014413
2025-06-30 17:26:20,327 - INFO - Epoch 66/150 - Train Loss: 1.152615, Val Loss: 1.014783
2025-06-30 17:26:52,441 - INFO - Epoch 67/150 - Train Loss: 1.150394, Val Loss: 1.015154
2025-06-30 17:27:26,489 - INFO - Epoch 68/150 - Train Loss: 1.150520, Val Loss: 1.014982
2025-06-30 17:27:53,309 - INFO - Epoch 69/150 - Train Loss: 1.149891, Val Loss: 1.015464
2025-06-30 17:28:21,430 - INFO - Epoch 70/150 - Train Loss: 1.151592, Val Loss: 1.015131
2025-06-30 17:28:48,656 - INFO - Epoch 71/150 - Train Loss: 1.150308, Val Loss: 1.014803
2025-06-30 17:29:14,651 - INFO - Epoch 72/150 - Train Loss: 1.151882, Val Loss: 1.014853
2025-06-30 17:29:44,110 - INFO - Epoch 73/150 - Train Loss: 1.152950, Val Loss: 1.015332
2025-06-30 17:30:11,674 - INFO - Epoch 74/150 - Train Loss: 1.148542, Val Loss: 1.014488
2025-06-30 17:30:40,635 - INFO - Epoch 75/150 - Train Loss: 1.152436, Val Loss: 1.015019
2025-06-30 17:31:15,162 - INFO - Epoch 76/150 - Train Loss: 1.148143, Val Loss: 1.015147
2025-06-30 17:31:49,116 - INFO - Epoch 77/150 - Train Loss: 1.153455, Val Loss: 1.014535
2025-06-30 17:32:18,531 - INFO - Epoch 78/150 - Train Loss: 1.148739, Val Loss: 1.014750
2025-06-30 17:32:45,246 - INFO - Epoch 79/150 - Train Loss: 1.152679, Val Loss: 1.015313
2025-06-30 17:33:12,101 - INFO - Epoch 80/150 - Train Loss: 1.151642, Val Loss: 1.015295
2025-06-30 17:33:38,231 - INFO - Epoch 81/150 - Train Loss: 1.150476, Val Loss: 1.014581
2025-06-30 17:34:04,738 - INFO - Epoch 82/150 - Train Loss: 1.150879, Val Loss: 1.015313
2025-06-30 17:34:35,558 - INFO - Epoch 83/150 - Train Loss: 1.146307, Val Loss: 1.014597
2025-06-30 17:35:09,497 - INFO - Epoch 84/150 - Train Loss: 1.147950, Val Loss: 1.014687
2025-06-30 17:35:42,730 - INFO - Epoch 85/150 - Train Loss: 1.151794, Val Loss: 1.015187
2025-06-30 17:36:16,502 - INFO - Epoch 86/150 - Train Loss: 1.148333, Val Loss: 1.015448
2025-06-30 17:36:49,471 - INFO - Epoch 87/150 - Train Loss: 1.150854, Val Loss: 1.014578
2025-06-30 17:37:23,156 - INFO - Epoch 88/150 - Train Loss: 1.151282, Val Loss: 1.014658
2025-06-30 17:37:57,641 - INFO - Epoch 89/150 - Train Loss: 1.147973, Val Loss: 1.015706
2025-06-30 17:38:31,691 - INFO - Epoch 90/150 - Train Loss: 1.151156, Val Loss: 1.014912
2025-06-30 17:39:04,718 - INFO - Epoch 91/150 - Train Loss: 1.152580, Val Loss: 1.014372
2025-06-30 17:39:30,070 - INFO - Epoch 92/150 - Train Loss: 1.150741, Val Loss: 1.014595
2025-06-30 17:39:57,261 - INFO - Epoch 93/150 - Train Loss: 1.148515, Val Loss: 1.014537
2025-06-30 17:40:23,429 - INFO - Epoch 94/150 - Train Loss: 1.151005, Val Loss: 1.015277
2025-06-30 17:40:50,227 - INFO - Epoch 95/150 - Train Loss: 1.153723, Val Loss: 1.015026
2025-06-30 17:41:20,621 - INFO - Epoch 96/150 - Train Loss: 1.149982, Val Loss: 1.015000
2025-06-30 17:42:00,621 - INFO - Epoch 97/150 - Train Loss: 1.153451, Val Loss: 1.014857
2025-06-30 17:42:31,195 - INFO - Epoch 98/150 - Train Loss: 1.151845, Val Loss: 1.014428
2025-06-30 17:43:01,146 - INFO - Epoch 99/150 - Train Loss: 1.146699, Val Loss: 1.015603
2025-06-30 17:43:33,414 - INFO - Epoch 100/150 - Train Loss: 1.149745, Val Loss: 1.015130
2025-06-30 17:44:07,836 - INFO - Epoch 101/150 - Train Loss: 1.151851, Val Loss: 1.015183
2025-06-30 17:44:48,766 - INFO - Epoch 102/150 - Train Loss: 1.151895, Val Loss: 1.015093
2025-06-30 17:45:22,267 - INFO - Epoch 103/150 - Train Loss: 1.152467, Val Loss: 1.015152
2025-06-30 17:45:51,202 - INFO - Epoch 104/150 - Train Loss: 1.153332, Val Loss: 1.015086
2025-06-30 17:46:18,307 - INFO - Epoch 105/150 - Train Loss: 1.153229, Val Loss: 1.014584
2025-06-30 17:46:46,023 - INFO - Epoch 106/150 - Train Loss: 1.150959, Val Loss: 1.015254
2025-06-30 17:47:15,066 - INFO - Epoch 107/150 - Train Loss: 1.150141, Val Loss: 1.014739
2025-06-30 17:47:47,948 - INFO - Epoch 108/150 - Train Loss: 1.149630, Val Loss: 1.013919
2025-06-30 17:48:22,245 - INFO - Epoch 109/150 - Train Loss: 1.151386, Val Loss: 1.015281
2025-06-30 17:48:57,208 - INFO - Epoch 110/150 - Train Loss: 1.152757, Val Loss: 1.015360
2025-06-30 17:49:32,081 - INFO - Epoch 111/150 - Train Loss: 1.152244, Val Loss: 1.014822
2025-06-30 17:50:06,866 - INFO - Epoch 112/150 - Train Loss: 1.149596, Val Loss: 1.014999
2025-06-30 17:50:41,306 - INFO - Epoch 113/150 - Train Loss: 1.151858, Val Loss: 1.015705
2025-06-30 17:51:14,828 - INFO - Epoch 114/150 - Train Loss: 1.151614, Val Loss: 1.014928
2025-06-30 17:51:48,589 - INFO - Epoch 115/150 - Train Loss: 1.152609, Val Loss: 1.014629
2025-06-30 17:52:22,241 - INFO - Epoch 116/150 - Train Loss: 1.151527, Val Loss: 1.014652
2025-06-30 17:52:56,074 - INFO - Epoch 117/150 - Train Loss: 1.149109, Val Loss: 1.014678
2025-06-30 17:53:29,399 - INFO - Epoch 118/150 - Train Loss: 1.152869, Val Loss: 1.014989
2025-06-30 17:54:02,238 - INFO - Epoch 119/150 - Train Loss: 1.150167, Val Loss: 1.014000
2025-06-30 17:54:35,937 - INFO - Epoch 120/150 - Train Loss: 1.151869, Val Loss: 1.014707
2025-06-30 17:55:09,869 - INFO - Epoch 121/150 - Train Loss: 1.152079, Val Loss: 1.015041
2025-06-30 17:55:37,894 - INFO - Epoch 122/150 - Train Loss: 1.151798, Val Loss: 1.014780
2025-06-30 17:56:11,460 - INFO - Epoch 123/150 - Train Loss: 1.150301, Val Loss: 1.014770
2025-06-30 17:56:45,017 - INFO - Epoch 124/150 - Train Loss: 1.154219, Val Loss: 1.015151
2025-06-30 17:57:18,827 - INFO - Epoch 125/150 - Train Loss: 1.148334, Val Loss: 1.014790
2025-06-30 17:57:52,234 - INFO - Epoch 126/150 - Train Loss: 1.151422, Val Loss: 1.015385
2025-06-30 17:58:25,448 - INFO - Epoch 127/150 - Train Loss: 1.151254, Val Loss: 1.015309
2025-06-30 17:59:02,047 - INFO - Epoch 128/150 - Train Loss: 1.153110, Val Loss: 1.014931
2025-06-30 17:59:36,800 - INFO - Epoch 129/150 - Train Loss: 1.150866, Val Loss: 1.014606
2025-06-30 18:00:28,487 - INFO - Epoch 130/150 - Train Loss: 1.150708, Val Loss: 1.015156
2025-06-30 18:00:55,497 - INFO - Epoch 131/150 - Train Loss: 1.151088, Val Loss: 1.015073
2025-06-30 18:01:22,240 - INFO - Epoch 132/150 - Train Loss: 1.150347, Val Loss: 1.015175
2025-06-30 18:01:49,458 - INFO - Epoch 133/150 - Train Loss: 1.151725, Val Loss: 1.014874
2025-06-30 18:02:16,363 - INFO - Epoch 134/150 - Train Loss: 1.150342, Val Loss: 1.014693
2025-06-30 18:02:41,978 - INFO - Epoch 135/150 - Train Loss: 1.147962, Val Loss: 1.015001
2025-06-30 18:03:08,055 - INFO - Epoch 136/150 - Train Loss: 1.148906, Val Loss: 1.014719
2025-06-30 18:03:35,334 - INFO - Epoch 137/150 - Train Loss: 1.150771, Val Loss: 1.014664
2025-06-30 18:04:06,016 - INFO - Epoch 138/150 - Train Loss: 1.149895, Val Loss: 1.014495
2025-06-30 18:04:39,633 - INFO - Epoch 139/150 - Train Loss: 1.149676, Val Loss: 1.015222
2025-06-30 18:05:11,462 - INFO - Epoch 140/150 - Train Loss: 1.149190, Val Loss: 1.015104
2025-06-30 18:05:38,234 - INFO - Epoch 141/150 - Train Loss: 1.149869, Val Loss: 1.015008
2025-06-30 18:06:09,043 - INFO - Epoch 142/150 - Train Loss: 1.149840, Val Loss: 1.014385
2025-06-30 18:06:42,399 - INFO - Epoch 143/150 - Train Loss: 1.151804, Val Loss: 1.014938
2025-06-30 18:07:15,754 - INFO - Epoch 144/150 - Train Loss: 1.148924, Val Loss: 1.015386
2025-06-30 18:07:48,489 - INFO - Epoch 145/150 - Train Loss: 1.150310, Val Loss: 1.015137
2025-06-30 18:08:19,089 - INFO - Epoch 146/150 - Train Loss: 1.150626, Val Loss: 1.015166
2025-06-30 18:08:45,484 - INFO - Epoch 147/150 - Train Loss: 1.151395, Val Loss: 1.014767
2025-06-30 18:09:16,880 - INFO - Epoch 148/150 - Train Loss: 1.151253, Val Loss: 1.014992
2025-06-30 18:09:50,882 - INFO - Epoch 149/150 - Train Loss: 1.151055, Val Loss: 1.015121
2025-06-30 18:10:19,950 - INFO - Epoch 150/150 - Train Loss: 1.147844, Val Loss: 1.014008
2025-06-30 18:10:20,318 - INFO - Final model saved to experiments/Train_Test/final_model_pth
2025-06-30 18:10:20,357 - INFO - Testing the final model
2025-06-30 18:10:29,521 - INFO - Total MSE across all processes: 47.99393844604492
2025-06-30 18:10:29,524 - INFO - mean value for all_targets: {tmp}
2025-06-30 18:10:29,527 - INFO - Test MSE: 0.999874, Test MAE: 0.609285, Max MAE: 20.959023, Test R2: 0.1096
2025-06-30 18:10:29,527 - INFO - Relative L2 Error: 0.943193, Relative L1 error: 0.939679
2025-06-30 18:10:29,527 - INFO - Total inference time:  0.02s for 48 samples
2025-06-30 18:10:29,529 - INFO - Testing the best model
2025-06-30 18:10:38,699 - INFO - Total MSE across all processes: 47.9373664855957
2025-06-30 18:10:38,700 - INFO - mean value for all_targets: {tmp}
2025-06-30 18:10:38,702 - INFO - Test MSE: 0.998695, Test MAE: 0.608575, Max MAE: 20.926542, Test R2: 0.1107
2025-06-30 18:10:38,702 - INFO - Relative L2 Error: 0.942515, Relative L1 error: 0.938526
2025-06-30 18:10:38,702 - INFO - Total inference time:  0.02s for 48 samples
2025-07-01 13:07:17,378 - INFO - args.exp_name : Train_Test
2025-07-01 13:07:17,379 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data', num_points=10000, batch_size=12, epochs=150, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-07-01 13:07:17,383 - INFO - Starting training with 1 GPUs
2025-07-02 11:01:52,608 - INFO - args.exp_name : Train_Test
2025-07-02 11:01:52,610 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data', num_points=10000, batch_size=6, epochs=20, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-07-02 11:01:52,611 - INFO - Starting training with 1 GPUs
2025-07-02 11:01:54,881 - INFO - Total trainable parameters: 1437705
2025-07-02 11:01:55,052 - INFO - Data loaded: 39 training batches, 8 validation batches, 9 test batches
2025-07-02 11:01:55,054 - INFO - Staring training for 20 epochs
2025-07-02 11:02:41,337 - INFO - Epoch 1/20 - Train Loss: 1.189811, Val Loss: 1.150744
2025-07-02 11:02:41,358 - INFO - New best model saved with Val Loss: 1.150744
2025-07-02 11:03:26,357 - INFO - Epoch 2/20 - Train Loss: 1.155146, Val Loss: 1.089376
2025-07-02 11:03:26,376 - INFO - New best model saved with Val Loss: 1.089376
2025-07-02 11:04:11,435 - INFO - Epoch 3/20 - Train Loss: 1.150646, Val Loss: 1.079947
2025-07-02 11:04:11,454 - INFO - New best model saved with Val Loss: 1.079947
2025-07-02 11:04:56,385 - INFO - Epoch 4/20 - Train Loss: 1.142872, Val Loss: 0.970974
2025-07-02 11:04:56,403 - INFO - New best model saved with Val Loss: 0.970974
2025-07-02 11:05:42,052 - INFO - Epoch 5/20 - Train Loss: 1.139206, Val Loss: 0.975353
2025-07-02 11:06:26,939 - INFO - Epoch 6/20 - Train Loss: 1.135798, Val Loss: 0.916148
2025-07-02 11:06:26,958 - INFO - New best model saved with Val Loss: 0.916148
2025-07-02 11:07:11,961 - INFO - Epoch 7/20 - Train Loss: 1.137600, Val Loss: 0.967226
2025-07-02 11:07:56,974 - INFO - Epoch 8/20 - Train Loss: 1.136670, Val Loss: 0.933321
2025-07-02 11:08:41,797 - INFO - Epoch 9/20 - Train Loss: 1.135825, Val Loss: 0.914879
2025-07-02 11:08:41,815 - INFO - New best model saved with Val Loss: 0.914879
2025-07-02 11:09:26,590 - INFO - Epoch 10/20 - Train Loss: 1.135171, Val Loss: 0.883284
2025-07-02 11:09:26,608 - INFO - New best model saved with Val Loss: 0.883284
2025-07-02 11:10:11,535 - INFO - Epoch 11/20 - Train Loss: 1.133573, Val Loss: 0.897518
2025-07-02 11:10:56,213 - INFO - Epoch 12/20 - Train Loss: 1.129549, Val Loss: 0.906144
2025-07-02 11:11:40,861 - INFO - Epoch 13/20 - Train Loss: 1.133971, Val Loss: 0.902175
2025-07-02 11:12:25,518 - INFO - Epoch 14/20 - Train Loss: 1.132658, Val Loss: 0.885658
2025-07-02 11:13:10,196 - INFO - Epoch 15/20 - Train Loss: 1.132081, Val Loss: 0.859638
2025-07-02 11:13:10,214 - INFO - New best model saved with Val Loss: 0.859638
2025-07-02 11:13:54,945 - INFO - Epoch 16/20 - Train Loss: 1.132230, Val Loss: 0.887372
2025-07-02 11:14:39,641 - INFO - Epoch 17/20 - Train Loss: 1.130843, Val Loss: 0.868037
2025-07-02 11:15:24,444 - INFO - Epoch 18/20 - Train Loss: 1.130759, Val Loss: 0.848050
2025-07-02 11:15:24,461 - INFO - New best model saved with Val Loss: 0.848050
2025-07-02 11:16:09,136 - INFO - Epoch 19/20 - Train Loss: 1.131286, Val Loss: 0.849644
2025-07-02 11:16:53,846 - INFO - Epoch 20/20 - Train Loss: 1.131221, Val Loss: 0.863135
2025-07-02 11:16:54,013 - INFO - Final model saved to experiments/Train_Test/final_model_pth
2025-07-02 11:16:54,014 - INFO - Testing the final model
2025-07-02 11:17:00,139 - INFO - Total MSE across all processes: 45.7446174621582
2025-07-02 11:17:00,142 - INFO - mean value for all_targets: {tmp}
2025-07-02 20:11:12,558 - INFO - args.exp_name : Train_Test
2025-07-02 20:11:12,559 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=6, epochs=150, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-07-02 20:11:12,560 - INFO - Starting training with 1 GPUs
2025-07-02 20:11:18,258 - INFO - Total trainable parameters: 1437705
2025-07-02 20:11:18,408 - INFO - Data loaded: 14 training batches, 3 validation batches, 4 test batches
2025-07-02 20:11:18,411 - INFO - Staring training for 150 epochs
2025-07-04 08:52:20,030 - INFO - args.exp_name : Train_Test
2025-07-04 08:52:20,036 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=6, epochs=150, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-07-04 08:52:20,036 - INFO - Starting training with 1 GPUs
2025-07-04 08:52:28,425 - INFO - Total trainable parameters: 1437705
2025-07-04 08:52:28,524 - INFO - Data loaded: 14 training batches, 3 validation batches, 4 test batches
2025-07-04 08:52:28,526 - INFO - Staring training for 150 epochs
2025-07-04 08:52:41,547 - INFO - Epoch 1/150 - Train Loss: 1.241446, Val Loss: 1.177541
2025-07-04 08:52:41,567 - INFO - New best model saved with Val Loss: 1.177541
2025-07-04 08:52:51,204 - INFO - Epoch 2/150 - Train Loss: 1.186031, Val Loss: 1.122562
2025-07-04 08:52:51,219 - INFO - New best model saved with Val Loss: 1.122562
2025-07-04 08:53:00,904 - INFO - Epoch 3/150 - Train Loss: 1.179019, Val Loss: 1.108872
2025-07-04 08:53:00,919 - INFO - New best model saved with Val Loss: 1.108872
2025-07-04 08:53:10,568 - INFO - Epoch 4/150 - Train Loss: 1.178043, Val Loss: 1.094974
2025-07-04 08:53:10,583 - INFO - New best model saved with Val Loss: 1.094974
2025-07-04 08:53:20,216 - INFO - Epoch 5/150 - Train Loss: 1.174424, Val Loss: 1.076401
2025-07-04 08:53:20,231 - INFO - New best model saved with Val Loss: 1.076401
2025-07-04 08:53:29,865 - INFO - Epoch 6/150 - Train Loss: 1.172814, Val Loss: 1.058396
2025-07-04 08:53:29,880 - INFO - New best model saved with Val Loss: 1.058396
2025-07-04 08:53:39,495 - INFO - Epoch 7/150 - Train Loss: 1.173182, Val Loss: 1.028594
2025-07-04 08:53:39,510 - INFO - New best model saved with Val Loss: 1.028594
2025-07-04 08:53:49,153 - INFO - Epoch 8/150 - Train Loss: 1.170327, Val Loss: 1.008587
2025-07-04 08:53:49,168 - INFO - New best model saved with Val Loss: 1.008587
2025-07-04 08:53:58,792 - INFO - Epoch 9/150 - Train Loss: 1.165756, Val Loss: 1.012987
2025-07-04 08:54:08,437 - INFO - Epoch 10/150 - Train Loss: 1.163875, Val Loss: 0.976703
2025-07-04 08:54:08,452 - INFO - New best model saved with Val Loss: 0.976703
2025-07-04 08:54:18,326 - INFO - Epoch 11/150 - Train Loss: 1.162383, Val Loss: 0.957697
2025-07-04 08:54:18,341 - INFO - New best model saved with Val Loss: 0.957697
2025-07-04 08:54:27,965 - INFO - Epoch 12/150 - Train Loss: 1.160220, Val Loss: 0.902563
2025-07-04 08:54:27,979 - INFO - New best model saved with Val Loss: 0.902563
2025-07-04 08:54:37,617 - INFO - Epoch 13/150 - Train Loss: 1.156775, Val Loss: 0.870499
2025-07-04 08:54:37,632 - INFO - New best model saved with Val Loss: 0.870499
2025-07-04 08:54:47,264 - INFO - Epoch 14/150 - Train Loss: 1.155465, Val Loss: 0.899167
2025-07-04 08:54:56,908 - INFO - Epoch 15/150 - Train Loss: 1.157795, Val Loss: 0.917017
2025-07-04 08:55:06,538 - INFO - Epoch 16/150 - Train Loss: 1.157543, Val Loss: 0.873709
2025-07-04 08:55:16,192 - INFO - Epoch 17/150 - Train Loss: 1.156704, Val Loss: 0.897988
2025-07-04 08:55:25,840 - INFO - Epoch 18/150 - Train Loss: 1.157150, Val Loss: 0.910194
2025-07-04 08:55:35,489 - INFO - Epoch 19/150 - Train Loss: 1.155878, Val Loss: 0.874251
2025-07-04 08:55:45,111 - INFO - Epoch 20/150 - Train Loss: 1.155908, Val Loss: 0.879709
2025-07-04 08:55:54,845 - INFO - Epoch 21/150 - Train Loss: 1.155028, Val Loss: 0.908767
2025-07-04 08:56:04,469 - INFO - Epoch 22/150 - Train Loss: 1.154765, Val Loss: 0.880731
2025-07-04 08:56:14,100 - INFO - Epoch 23/150 - Train Loss: 1.155112, Val Loss: 0.878649
2025-07-04 08:56:23,703 - INFO - Epoch 24/150 - Train Loss: 1.153464, Val Loss: 0.924204
2025-07-04 08:56:33,328 - INFO - Epoch 25/150 - Train Loss: 1.152233, Val Loss: 0.866455
2025-07-04 08:56:33,343 - INFO - New best model saved with Val Loss: 0.866455
2025-07-04 08:56:42,961 - INFO - Epoch 26/150 - Train Loss: 1.153581, Val Loss: 0.881249
2025-07-04 08:56:52,576 - INFO - Epoch 27/150 - Train Loss: 1.152243, Val Loss: 0.880733
2025-07-04 08:57:02,192 - INFO - Epoch 28/150 - Train Loss: 1.152568, Val Loss: 0.878158
2025-07-04 08:57:11,796 - INFO - Epoch 29/150 - Train Loss: 1.152290, Val Loss: 0.874380
2025-07-04 08:57:21,424 - INFO - Epoch 30/150 - Train Loss: 1.152829, Val Loss: 0.875143
2025-07-04 08:57:31,164 - INFO - Epoch 31/150 - Train Loss: 1.140987, Val Loss: 0.875324
2025-07-04 08:57:40,777 - INFO - Epoch 32/150 - Train Loss: 1.152547, Val Loss: 0.878501
2025-07-04 08:57:50,394 - INFO - Epoch 33/150 - Train Loss: 1.153246, Val Loss: 0.878727
2025-07-04 08:57:59,994 - INFO - Epoch 34/150 - Train Loss: 1.154446, Val Loss: 0.871191
2025-07-04 08:58:09,611 - INFO - Epoch 35/150 - Train Loss: 1.154074, Val Loss: 0.874708
2025-07-04 08:58:19,222 - INFO - Epoch 36/150 - Train Loss: 1.151375, Val Loss: 0.872105
2025-07-04 08:58:28,828 - INFO - Epoch 37/150 - Train Loss: 1.154260, Val Loss: 0.873454
2025-07-04 08:58:38,443 - INFO - Epoch 38/150 - Train Loss: 1.153229, Val Loss: 0.875780
2025-07-04 08:58:48,062 - INFO - Epoch 39/150 - Train Loss: 1.150356, Val Loss: 0.875329
2025-07-04 08:58:57,699 - INFO - Epoch 40/150 - Train Loss: 1.153559, Val Loss: 0.875707
2025-07-04 08:59:07,426 - INFO - Epoch 41/150 - Train Loss: 1.153825, Val Loss: 0.876817
2025-07-04 08:59:17,053 - INFO - Epoch 42/150 - Train Loss: 1.152899, Val Loss: 0.875426
2025-07-04 08:59:26,665 - INFO - Epoch 43/150 - Train Loss: 1.154966, Val Loss: 0.875305
2025-07-04 08:59:36,320 - INFO - Epoch 44/150 - Train Loss: 1.152189, Val Loss: 0.874278
2025-07-04 08:59:45,942 - INFO - Epoch 45/150 - Train Loss: 1.153907, Val Loss: 0.874331
2025-07-04 08:59:55,604 - INFO - Epoch 46/150 - Train Loss: 1.153043, Val Loss: 0.875236
2025-07-04 09:00:05,247 - INFO - Epoch 47/150 - Train Loss: 1.154773, Val Loss: 0.873472
2025-07-04 09:00:14,904 - INFO - Epoch 48/150 - Train Loss: 1.153229, Val Loss: 0.872523
2025-07-04 09:00:24,538 - INFO - Epoch 49/150 - Train Loss: 1.153976, Val Loss: 0.873105
2025-07-04 09:00:34,170 - INFO - Epoch 50/150 - Train Loss: 1.152770, Val Loss: 0.873154
2025-07-04 09:00:43,893 - INFO - Epoch 51/150 - Train Loss: 1.152427, Val Loss: 0.873966
2025-07-04 09:00:53,532 - INFO - Epoch 52/150 - Train Loss: 1.152633, Val Loss: 0.872660
2025-07-04 09:01:03,172 - INFO - Epoch 53/150 - Train Loss: 1.153153, Val Loss: 0.873497
2025-07-04 09:01:12,807 - INFO - Epoch 54/150 - Train Loss: 1.152727, Val Loss: 0.873510
2025-07-04 09:01:22,434 - INFO - Epoch 55/150 - Train Loss: 1.150634, Val Loss: 0.873938
2025-07-04 09:01:32,068 - INFO - Epoch 56/150 - Train Loss: 1.152500, Val Loss: 0.874070
2025-07-04 09:01:41,675 - INFO - Epoch 57/150 - Train Loss: 1.151416, Val Loss: 0.873577
2025-07-04 09:01:51,238 - INFO - Epoch 58/150 - Train Loss: 1.153988, Val Loss: 0.873091
2025-07-04 09:02:00,845 - INFO - Epoch 59/150 - Train Loss: 1.152799, Val Loss: 0.873124
2025-07-04 09:02:10,479 - INFO - Epoch 60/150 - Train Loss: 1.153275, Val Loss: 0.873418
2025-07-04 09:02:20,217 - INFO - Epoch 61/150 - Train Loss: 1.154078, Val Loss: 0.873387
2025-07-04 09:02:29,835 - INFO - Epoch 62/150 - Train Loss: 1.152570, Val Loss: 0.872664
2025-07-04 09:02:39,458 - INFO - Epoch 63/150 - Train Loss: 1.152630, Val Loss: 0.873286
2025-07-04 09:02:49,085 - INFO - Epoch 64/150 - Train Loss: 1.151116, Val Loss: 0.873913
2025-07-04 09:02:58,687 - INFO - Epoch 65/150 - Train Loss: 1.152723, Val Loss: 0.873274
2025-07-04 09:03:08,300 - INFO - Epoch 66/150 - Train Loss: 1.151570, Val Loss: 0.872757
2025-07-04 09:03:17,924 - INFO - Epoch 67/150 - Train Loss: 1.152477, Val Loss: 0.873092
2025-07-04 09:03:27,548 - INFO - Epoch 68/150 - Train Loss: 1.150931, Val Loss: 0.873222
2025-07-04 09:03:37,172 - INFO - Epoch 69/150 - Train Loss: 1.151670, Val Loss: 0.873713
2025-07-04 09:03:46,815 - INFO - Epoch 70/150 - Train Loss: 1.153419, Val Loss: 0.873722
2025-07-04 09:03:56,546 - INFO - Epoch 71/150 - Train Loss: 1.154862, Val Loss: 0.874301
2025-07-04 09:04:06,136 - INFO - Epoch 72/150 - Train Loss: 1.152769, Val Loss: 0.873145
2025-07-04 09:04:15,748 - INFO - Epoch 73/150 - Train Loss: 1.153697, Val Loss: 0.873199
2025-07-04 09:04:25,355 - INFO - Epoch 74/150 - Train Loss: 1.151516, Val Loss: 0.874258
2025-07-04 09:04:34,995 - INFO - Epoch 75/150 - Train Loss: 1.152371, Val Loss: 0.873783
2025-07-04 09:04:44,652 - INFO - Epoch 76/150 - Train Loss: 1.152795, Val Loss: 0.873676
2025-07-04 09:04:54,304 - INFO - Epoch 77/150 - Train Loss: 1.152586, Val Loss: 0.873685
2025-07-04 09:05:03,930 - INFO - Epoch 78/150 - Train Loss: 1.154487, Val Loss: 0.873479
2025-07-04 09:05:13,524 - INFO - Epoch 79/150 - Train Loss: 1.152081, Val Loss: 0.873248
2025-07-04 09:05:23,144 - INFO - Epoch 80/150 - Train Loss: 1.153493, Val Loss: 0.873805
2025-07-04 09:05:32,899 - INFO - Epoch 81/150 - Train Loss: 1.152695, Val Loss: 0.873204
2025-07-04 09:05:42,528 - INFO - Epoch 82/150 - Train Loss: 1.152202, Val Loss: 0.873357
2025-07-04 09:05:52,177 - INFO - Epoch 83/150 - Train Loss: 1.154032, Val Loss: 0.874270
2025-07-04 09:06:01,780 - INFO - Epoch 84/150 - Train Loss: 1.152854, Val Loss: 0.873772
2025-07-04 09:06:11,403 - INFO - Epoch 85/150 - Train Loss: 1.152796, Val Loss: 0.873991
2025-07-04 09:06:21,006 - INFO - Epoch 86/150 - Train Loss: 1.152520, Val Loss: 0.873427
2025-07-04 09:06:30,615 - INFO - Epoch 87/150 - Train Loss: 1.151348, Val Loss: 0.874311
2025-07-04 09:06:40,243 - INFO - Epoch 88/150 - Train Loss: 1.153036, Val Loss: 0.873612
2025-07-04 09:06:49,878 - INFO - Epoch 89/150 - Train Loss: 1.152249, Val Loss: 0.873483
2025-07-04 09:06:59,520 - INFO - Epoch 90/150 - Train Loss: 1.152378, Val Loss: 0.873306
2025-07-04 09:07:09,282 - INFO - Epoch 91/150 - Train Loss: 1.154740, Val Loss: 0.873980
2025-07-04 09:07:18,914 - INFO - Epoch 92/150 - Train Loss: 1.153242, Val Loss: 0.873601
2025-07-04 09:07:28,541 - INFO - Epoch 93/150 - Train Loss: 1.152556, Val Loss: 0.873785
2025-07-04 09:07:38,185 - INFO - Epoch 94/150 - Train Loss: 1.152815, Val Loss: 0.873088
2025-07-04 09:07:47,836 - INFO - Epoch 95/150 - Train Loss: 1.154911, Val Loss: 0.873480
2025-07-04 09:07:57,489 - INFO - Epoch 96/150 - Train Loss: 1.151365, Val Loss: 0.873631
2025-07-04 09:08:07,149 - INFO - Epoch 97/150 - Train Loss: 1.154766, Val Loss: 0.874919
2025-07-04 09:08:16,771 - INFO - Epoch 98/150 - Train Loss: 1.152729, Val Loss: 0.874305
2025-07-04 09:08:26,397 - INFO - Epoch 99/150 - Train Loss: 1.153715, Val Loss: 0.873401
2025-07-04 09:08:36,032 - INFO - Epoch 100/150 - Train Loss: 1.152547, Val Loss: 0.873287
2025-07-04 09:08:45,767 - INFO - Epoch 101/150 - Train Loss: 1.152440, Val Loss: 0.872898
2025-07-04 09:08:55,373 - INFO - Epoch 102/150 - Train Loss: 1.152278, Val Loss: 0.872688
2025-07-04 09:09:04,998 - INFO - Epoch 103/150 - Train Loss: 1.152758, Val Loss: 0.872871
2025-07-04 09:09:14,622 - INFO - Epoch 104/150 - Train Loss: 1.152842, Val Loss: 0.873401
2025-07-04 09:09:24,264 - INFO - Epoch 105/150 - Train Loss: 1.153891, Val Loss: 0.873807
2025-07-04 09:09:33,897 - INFO - Epoch 106/150 - Train Loss: 1.153532, Val Loss: 0.874173
2025-07-04 09:09:43,523 - INFO - Epoch 107/150 - Train Loss: 1.152759, Val Loss: 0.873700
2025-07-04 09:09:53,144 - INFO - Epoch 108/150 - Train Loss: 1.153455, Val Loss: 0.872497
2025-07-04 09:10:02,716 - INFO - Epoch 109/150 - Train Loss: 1.153009, Val Loss: 0.873867
2025-07-04 09:10:12,336 - INFO - Epoch 110/150 - Train Loss: 1.154003, Val Loss: 0.873587
2025-07-04 09:10:22,051 - INFO - Epoch 111/150 - Train Loss: 1.153342, Val Loss: 0.873033
2025-07-04 09:10:31,692 - INFO - Epoch 112/150 - Train Loss: 1.154682, Val Loss: 0.874066
2025-07-04 09:10:41,304 - INFO - Epoch 113/150 - Train Loss: 1.154469, Val Loss: 0.874227
2025-07-04 09:10:50,916 - INFO - Epoch 114/150 - Train Loss: 1.152259, Val Loss: 0.873901
2025-07-04 09:11:00,545 - INFO - Epoch 115/150 - Train Loss: 1.154351, Val Loss: 0.873536
2025-07-04 09:11:10,150 - INFO - Epoch 116/150 - Train Loss: 1.151255, Val Loss: 0.873927
2025-07-04 09:11:19,770 - INFO - Epoch 117/150 - Train Loss: 1.153796, Val Loss: 0.874327
2025-07-04 09:11:29,393 - INFO - Epoch 118/150 - Train Loss: 1.151567, Val Loss: 0.873807
2025-07-04 09:11:39,037 - INFO - Epoch 119/150 - Train Loss: 1.150924, Val Loss: 0.873749
2025-07-04 09:11:48,649 - INFO - Epoch 120/150 - Train Loss: 1.152751, Val Loss: 0.873765
2025-07-04 09:11:58,385 - INFO - Epoch 121/150 - Train Loss: 1.152423, Val Loss: 0.872958
2025-07-04 09:12:08,003 - INFO - Epoch 122/150 - Train Loss: 1.152789, Val Loss: 0.873576
2025-07-04 09:12:17,592 - INFO - Epoch 123/150 - Train Loss: 1.154129, Val Loss: 0.873808
2025-07-04 09:12:27,202 - INFO - Epoch 124/150 - Train Loss: 1.151936, Val Loss: 0.873762
2025-07-04 09:12:36,834 - INFO - Epoch 125/150 - Train Loss: 1.152352, Val Loss: 0.873750
2025-07-04 09:12:46,484 - INFO - Epoch 126/150 - Train Loss: 1.155440, Val Loss: 0.873888
2025-07-04 09:12:56,138 - INFO - Epoch 127/150 - Train Loss: 1.153147, Val Loss: 0.873769
2025-07-04 09:13:05,770 - INFO - Epoch 128/150 - Train Loss: 1.151241, Val Loss: 0.874397
2025-07-04 09:13:15,391 - INFO - Epoch 129/150 - Train Loss: 1.153389, Val Loss: 0.873702
2025-07-04 09:13:25,023 - INFO - Epoch 130/150 - Train Loss: 1.154868, Val Loss: 0.873116
2025-07-04 09:13:34,778 - INFO - Epoch 131/150 - Train Loss: 1.152740, Val Loss: 0.873281
2025-07-04 09:13:44,427 - INFO - Epoch 132/150 - Train Loss: 1.152790, Val Loss: 0.873503
2025-07-04 09:13:54,049 - INFO - Epoch 133/150 - Train Loss: 1.153289, Val Loss: 0.873433
2025-07-04 09:14:03,687 - INFO - Epoch 134/150 - Train Loss: 1.152448, Val Loss: 0.873979
2025-07-04 09:14:13,339 - INFO - Epoch 135/150 - Train Loss: 1.153034, Val Loss: 0.874439
2025-07-04 09:14:22,965 - INFO - Epoch 136/150 - Train Loss: 1.152523, Val Loss: 0.873218
2025-07-04 09:14:32,595 - INFO - Epoch 137/150 - Train Loss: 1.152435, Val Loss: 0.874103
2025-07-04 09:14:42,199 - INFO - Epoch 138/150 - Train Loss: 1.152524, Val Loss: 0.874153
2025-07-04 09:14:51,824 - INFO - Epoch 139/150 - Train Loss: 1.152752, Val Loss: 0.874754
2025-07-04 09:15:01,444 - INFO - Epoch 140/150 - Train Loss: 1.152819, Val Loss: 0.874353
2025-07-04 09:15:11,212 - INFO - Epoch 141/150 - Train Loss: 1.149516, Val Loss: 0.873920
2025-07-04 09:15:20,859 - INFO - Epoch 142/150 - Train Loss: 1.151008, Val Loss: 0.872659
2025-07-04 09:15:30,492 - INFO - Epoch 143/150 - Train Loss: 1.140574, Val Loss: 0.873182
2025-07-04 09:15:40,157 - INFO - Epoch 144/150 - Train Loss: 1.140706, Val Loss: 0.873095
2025-07-04 09:15:49,799 - INFO - Epoch 145/150 - Train Loss: 1.153340, Val Loss: 0.873945
2025-07-04 09:15:59,441 - INFO - Epoch 146/150 - Train Loss: 1.151823, Val Loss: 0.873226
2025-07-04 09:16:09,108 - INFO - Epoch 147/150 - Train Loss: 1.153316, Val Loss: 0.873210
2025-07-04 09:16:18,725 - INFO - Epoch 148/150 - Train Loss: 1.151713, Val Loss: 0.873454
2025-07-04 09:16:29,039 - INFO - Epoch 149/150 - Train Loss: 1.152790, Val Loss: 0.873946
2025-07-04 09:16:38,662 - INFO - Epoch 150/150 - Train Loss: 1.152922, Val Loss: 0.873481
2025-07-04 09:16:38,811 - INFO - Final model saved to experiments/Train_Test/final_model_pth
2025-07-04 09:16:38,820 - INFO - Testing the final model
2025-07-04 09:16:42,320 - INFO - Total MSE across all processes: 21.41421890258789
2025-07-04 09:16:42,321 - INFO - mean value for all_targets: {tmp}
2025-07-04 09:16:42,323 - INFO - Test MSE: 0.892259, Test MAE: 0.572756, Max AE: 16.443457, Test R2: 0.2171
2025-07-04 09:16:42,323 - INFO - Relative L2 Error: 0.884298, Relative L1 error: 0.878014
2025-07-04 09:16:42,323 - INFO - Total inference time:  0.01s for 24 samples
2025-07-04 09:59:21,112 - INFO - args.exp_name : Train_Test
2025-07-04 09:59:21,114 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=6, epochs=50, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-07-04 09:59:21,114 - INFO - Starting training with 1 GPUs
2025-07-04 09:59:25,975 - INFO - Total trainable parameters: 1437705
2025-07-04 09:59:26,039 - INFO - Data loaded: 2 training batches, 0 validation batches, 1 test batches
2025-07-04 09:59:26,042 - INFO - Staring training for 50 epochs
2025-07-04 10:26:58,897 - INFO - args.exp_name : Train_Test
2025-07-04 10:26:58,903 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=6, epochs=50, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-07-04 10:26:58,903 - INFO - Starting training with 1 GPUs
2025-07-04 10:27:03,799 - INFO - Total trainable parameters: 1437705
2025-07-04 10:27:03,857 - INFO - Data loaded: 2 training batches, 0 validation batches, 1 test batches
2025-07-04 10:27:03,860 - INFO - Staring training for 50 epochs
2025-07-04 10:31:47,052 - INFO - args.exp_name : Train_Test
2025-07-04 10:31:47,056 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=6, epochs=50, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-07-04 10:31:47,057 - INFO - Starting training with 1 GPUs
2025-07-04 10:31:50,475 - INFO - Total trainable parameters: 1437705
2025-07-04 10:31:50,539 - INFO - Data loaded: 3 training batches, 1 validation batches, 1 test batches
2025-07-04 10:31:50,539 - INFO - Staring training for 50 epochs
2025-07-04 10:31:59,013 - INFO - Epoch 1/50 - Train Loss: 1.283437, Val Loss: 1.146866
2025-07-04 10:31:59,031 - INFO - New best model saved with Val Loss: 1.146866
2025-07-04 10:32:05,120 - INFO - Epoch 2/50 - Train Loss: 1.159811, Val Loss: 1.148012
2025-07-04 10:32:11,178 - INFO - Epoch 3/50 - Train Loss: 1.015355, Val Loss: 1.148288
2025-07-04 10:32:17,249 - INFO - Epoch 4/50 - Train Loss: 0.916734, Val Loss: 1.249089
2025-07-04 10:32:23,285 - INFO - Epoch 5/50 - Train Loss: 0.839702, Val Loss: 1.442995
2025-07-04 10:32:29,338 - INFO - Epoch 6/50 - Train Loss: 0.757819, Val Loss: 1.361055
2025-07-04 10:32:35,401 - INFO - Epoch 7/50 - Train Loss: 0.661384, Val Loss: 1.379884
2025-07-04 10:32:41,459 - INFO - Epoch 8/50 - Train Loss: 0.608690, Val Loss: 1.595568
2025-07-04 10:32:47,524 - INFO - Epoch 9/50 - Train Loss: 0.560139, Val Loss: 1.838627
2025-07-04 10:32:53,574 - INFO - Epoch 10/50 - Train Loss: 0.526667, Val Loss: 1.521763
2025-07-04 10:32:59,809 - INFO - Epoch 11/50 - Train Loss: 0.494009, Val Loss: 1.437564
2025-07-04 10:33:05,869 - INFO - Epoch 12/50 - Train Loss: 0.474216, Val Loss: 1.348367
2025-07-04 10:33:11,941 - INFO - Epoch 13/50 - Train Loss: 0.457834, Val Loss: 1.089559
2025-07-04 10:33:11,957 - INFO - New best model saved with Val Loss: 1.089559
2025-07-04 10:33:18,018 - INFO - Epoch 14/50 - Train Loss: 0.455360, Val Loss: 0.832426
2025-07-04 10:33:18,031 - INFO - New best model saved with Val Loss: 0.832426
2025-07-04 10:33:24,074 - INFO - Epoch 15/50 - Train Loss: 0.447783, Val Loss: 0.654857
2025-07-04 10:33:24,097 - INFO - New best model saved with Val Loss: 0.654857
2025-07-04 10:33:30,177 - INFO - Epoch 16/50 - Train Loss: 0.446389, Val Loss: 0.548675
2025-07-04 10:33:30,191 - INFO - New best model saved with Val Loss: 0.548675
2025-07-04 10:33:36,251 - INFO - Epoch 17/50 - Train Loss: 0.440610, Val Loss: 0.495317
2025-07-04 10:33:36,265 - INFO - New best model saved with Val Loss: 0.495317
2025-07-04 10:33:42,334 - INFO - Epoch 18/50 - Train Loss: 0.438833, Val Loss: 0.464275
2025-07-04 10:33:42,347 - INFO - New best model saved with Val Loss: 0.464275
2025-07-04 10:33:48,433 - INFO - Epoch 19/50 - Train Loss: 0.439969, Val Loss: 0.443737
2025-07-04 10:33:48,447 - INFO - New best model saved with Val Loss: 0.443737
2025-07-04 10:33:54,533 - INFO - Epoch 20/50 - Train Loss: 0.431883, Val Loss: 0.428062
2025-07-04 10:33:54,547 - INFO - New best model saved with Val Loss: 0.428062
2025-07-04 10:34:00,781 - INFO - Epoch 21/50 - Train Loss: 0.431155, Val Loss: 0.423547
2025-07-04 10:34:00,796 - INFO - New best model saved with Val Loss: 0.423547
2025-07-04 10:34:06,859 - INFO - Epoch 22/50 - Train Loss: 0.428144, Val Loss: 0.426146
2025-07-04 10:34:12,893 - INFO - Epoch 23/50 - Train Loss: 0.425435, Val Loss: 0.427524
2025-07-04 10:34:18,948 - INFO - Epoch 24/50 - Train Loss: 0.422210, Val Loss: 0.422279
2025-07-04 10:34:18,962 - INFO - New best model saved with Val Loss: 0.422279
2025-07-04 10:34:25,023 - INFO - Epoch 25/50 - Train Loss: 0.423424, Val Loss: 0.427988
2025-07-04 10:34:31,079 - INFO - Epoch 26/50 - Train Loss: 0.416589, Val Loss: 0.438708
2025-07-04 10:34:37,114 - INFO - Epoch 27/50 - Train Loss: 0.415543, Val Loss: 0.429039
2025-07-04 10:34:43,202 - INFO - Epoch 28/50 - Train Loss: 0.413719, Val Loss: 0.420002
2025-07-04 10:34:43,218 - INFO - New best model saved with Val Loss: 0.420002
2025-07-04 10:34:49,247 - INFO - Epoch 29/50 - Train Loss: 0.410406, Val Loss: 0.413966
2025-07-04 10:34:49,260 - INFO - New best model saved with Val Loss: 0.413966
2025-07-04 10:34:55,327 - INFO - Epoch 30/50 - Train Loss: 0.409573, Val Loss: 0.411146
2025-07-04 10:34:55,341 - INFO - New best model saved with Val Loss: 0.411146
2025-07-04 10:35:01,513 - INFO - Epoch 31/50 - Train Loss: 0.407763, Val Loss: 0.405612
2025-07-04 10:35:01,527 - INFO - New best model saved with Val Loss: 0.405612
2025-07-04 10:35:07,573 - INFO - Epoch 32/50 - Train Loss: 0.407623, Val Loss: 0.406176
2025-07-04 10:35:13,616 - INFO - Epoch 33/50 - Train Loss: 0.403604, Val Loss: 0.407962
2025-07-04 10:35:19,690 - INFO - Epoch 34/50 - Train Loss: 0.399802, Val Loss: 0.401497
2025-07-04 10:35:19,714 - INFO - New best model saved with Val Loss: 0.401497
2025-07-04 10:35:25,778 - INFO - Epoch 35/50 - Train Loss: 0.400421, Val Loss: 0.400646
2025-07-04 10:35:25,792 - INFO - New best model saved with Val Loss: 0.400646
2025-07-04 10:35:31,848 - INFO - Epoch 36/50 - Train Loss: 0.395775, Val Loss: 0.403946
2025-07-04 10:35:37,907 - INFO - Epoch 37/50 - Train Loss: 0.395949, Val Loss: 0.401222
2025-07-04 10:35:43,955 - INFO - Epoch 38/50 - Train Loss: 0.393724, Val Loss: 0.398120
2025-07-04 10:35:43,969 - INFO - New best model saved with Val Loss: 0.398120
2025-07-04 10:35:50,023 - INFO - Epoch 39/50 - Train Loss: 0.390039, Val Loss: 0.399025
2025-07-04 10:35:56,058 - INFO - Epoch 40/50 - Train Loss: 0.391684, Val Loss: 0.390313
2025-07-04 10:35:56,072 - INFO - New best model saved with Val Loss: 0.390313
2025-07-04 10:36:02,256 - INFO - Epoch 41/50 - Train Loss: 0.386746, Val Loss: 0.386531
2025-07-04 10:36:02,269 - INFO - New best model saved with Val Loss: 0.386531
2025-07-04 10:36:08,328 - INFO - Epoch 42/50 - Train Loss: 0.386503, Val Loss: 0.384749
2025-07-04 10:36:08,341 - INFO - New best model saved with Val Loss: 0.384749
2025-07-04 10:36:14,404 - INFO - Epoch 43/50 - Train Loss: 0.385221, Val Loss: 0.382403
2025-07-04 10:36:14,419 - INFO - New best model saved with Val Loss: 0.382403
2025-07-04 10:36:20,488 - INFO - Epoch 44/50 - Train Loss: 0.379563, Val Loss: 0.379401
2025-07-04 10:36:20,502 - INFO - New best model saved with Val Loss: 0.379401
2025-07-04 10:36:26,565 - INFO - Epoch 45/50 - Train Loss: 0.381152, Val Loss: 0.383046
2025-07-04 10:36:32,639 - INFO - Epoch 46/50 - Train Loss: 0.377841, Val Loss: 0.374077
2025-07-04 10:36:32,654 - INFO - New best model saved with Val Loss: 0.374077
2025-07-04 10:36:38,710 - INFO - Epoch 47/50 - Train Loss: 0.376989, Val Loss: 0.374267
2025-07-04 10:36:44,771 - INFO - Epoch 48/50 - Train Loss: 0.372625, Val Loss: 0.375827
2025-07-04 10:36:50,824 - INFO - Epoch 49/50 - Train Loss: 0.373013, Val Loss: 0.377917
2025-07-04 10:36:56,862 - INFO - Epoch 50/50 - Train Loss: 0.370192, Val Loss: 0.374004
2025-07-04 10:36:56,876 - INFO - New best model saved with Val Loss: 0.374004
2025-07-04 10:36:57,017 - INFO - Final model saved to experiments/Train_Test/final_model_pth
2025-07-04 10:36:57,023 - INFO - Testing the final model
2025-07-04 10:36:59,752 - INFO - Total MSE across all processes: 2.023336172103882
2025-07-04 10:36:59,753 - INFO - mean value for all_targets: {tmp}
2025-07-04 10:36:59,753 - INFO - Test MSE: 0.337223, Test MAE: 0.317886, Max AE: 7.466796, Test R2: 0.7012
2025-07-04 10:36:59,753 - INFO - Relative L2 Error: 0.546824, Relative L1 error: 0.485240
2025-07-04 10:36:59,753 - INFO - Total inference time:  0.00s for 6 samples
2025-07-04 10:36:59,755 - INFO - Testing the best model
2025-07-04 10:37:02,454 - INFO - Total MSE across all processes: 2.023336172103882
2025-07-04 10:37:02,454 - INFO - mean value for all_targets: {tmp}
2025-07-04 10:37:02,454 - INFO - Test MSE: 0.337223, Test MAE: 0.317886, Max AE: 7.466796, Test R2: 0.7012
2025-07-04 10:37:02,455 - INFO - Relative L2 Error: 0.546824, Relative L1 error: 0.485240
2025-07-04 10:37:02,455 - INFO - Total inference time:  0.00s for 6 samples
2025-07-04 10:57:13,577 - INFO - args.exp_name : Train_Test
2025-07-04 10:57:13,578 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data', num_points=10000, batch_size=6, epochs=150, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-07-04 10:57:13,578 - INFO - Starting training with 1 GPUs
2025-07-04 10:57:16,876 - INFO - Total trainable parameters: 1437705
2025-07-04 10:57:17,065 - INFO - Data loaded: 39 training batches, 8 validation batches, 9 test batches
2025-07-04 10:57:17,068 - INFO - Staring training for 150 epochs
2025-07-04 10:57:37,225 - INFO - Epoch 1/150 - Train Loss: 0.765392, Val Loss: 1.117532
2025-07-04 10:57:37,258 - INFO - New best model saved with Val Loss: 1.117532
2025-07-04 10:57:54,967 - INFO - Epoch 2/150 - Train Loss: 0.425968, Val Loss: 0.480214
2025-07-04 10:57:54,982 - INFO - New best model saved with Val Loss: 0.480214
2025-07-04 10:58:12,671 - INFO - Epoch 3/150 - Train Loss: 0.359811, Val Loss: 0.444877
2025-07-04 10:58:12,686 - INFO - New best model saved with Val Loss: 0.444877
2025-07-04 10:58:30,381 - INFO - Epoch 4/150 - Train Loss: 0.312085, Val Loss: 0.590544
2025-07-04 10:58:48,122 - INFO - Epoch 5/150 - Train Loss: 0.284683, Val Loss: 0.833210
2025-07-04 10:59:05,840 - INFO - Epoch 6/150 - Train Loss: 0.266364, Val Loss: 1.044873
2025-07-04 10:59:23,565 - INFO - Epoch 7/150 - Train Loss: 0.244517, Val Loss: 0.458772
2025-07-04 10:59:41,802 - INFO - Epoch 8/150 - Train Loss: 0.227804, Val Loss: 1.118219
2025-07-04 10:59:59,532 - INFO - Epoch 9/150 - Train Loss: 0.222722, Val Loss: 0.292218
2025-07-04 10:59:59,547 - INFO - New best model saved with Val Loss: 0.292218
2025-07-04 11:00:17,280 - INFO - Epoch 10/150 - Train Loss: 0.213346, Val Loss: 0.264306
2025-07-04 11:00:17,295 - INFO - New best model saved with Val Loss: 0.264306
2025-07-04 11:00:35,156 - INFO - Epoch 11/150 - Train Loss: 0.198541, Val Loss: 1.010461
2025-07-04 11:00:52,876 - INFO - Epoch 12/150 - Train Loss: 0.188102, Val Loss: 0.402349
2025-07-04 11:01:10,606 - INFO - Epoch 13/150 - Train Loss: 0.190205, Val Loss: 0.351225
2025-07-04 11:01:28,360 - INFO - Epoch 14/150 - Train Loss: 0.188799, Val Loss: 0.817092
2025-07-04 11:01:46,206 - INFO - Epoch 15/150 - Train Loss: 0.181614, Val Loss: 0.227752
2025-07-04 11:01:46,221 - INFO - New best model saved with Val Loss: 0.227752
2025-07-04 11:02:05,107 - INFO - Epoch 16/150 - Train Loss: 0.177835, Val Loss: 0.312880
2025-07-04 11:02:23,725 - INFO - Epoch 17/150 - Train Loss: 0.174542, Val Loss: 0.204217
2025-07-04 11:02:23,740 - INFO - New best model saved with Val Loss: 0.204217
2025-07-04 11:02:41,459 - INFO - Epoch 18/150 - Train Loss: 0.171377, Val Loss: 0.178336
2025-07-04 11:02:41,473 - INFO - New best model saved with Val Loss: 0.178336
2025-07-04 11:02:59,214 - INFO - Epoch 19/150 - Train Loss: 0.167564, Val Loss: 0.218340
2025-07-04 11:03:16,955 - INFO - Epoch 20/150 - Train Loss: 0.167842, Val Loss: 0.332284
2025-07-04 11:03:34,826 - INFO - Epoch 21/150 - Train Loss: 0.163059, Val Loss: 0.209619
2025-07-04 11:03:52,539 - INFO - Epoch 22/150 - Train Loss: 0.160918, Val Loss: 0.248925
2025-07-04 11:04:10,271 - INFO - Epoch 23/150 - Train Loss: 0.157175, Val Loss: 0.624631
2025-07-04 11:04:28,006 - INFO - Epoch 24/150 - Train Loss: 0.156025, Val Loss: 0.170956
2025-07-04 11:04:28,021 - INFO - New best model saved with Val Loss: 0.170956
2025-07-04 11:04:45,800 - INFO - Epoch 25/150 - Train Loss: 0.153771, Val Loss: 0.321865
2025-07-04 11:05:03,538 - INFO - Epoch 26/150 - Train Loss: 0.148996, Val Loss: 0.149375
2025-07-04 11:05:03,553 - INFO - New best model saved with Val Loss: 0.149375
2025-07-04 11:05:21,299 - INFO - Epoch 27/150 - Train Loss: 0.149616, Val Loss: 0.178216
2025-07-04 11:05:39,054 - INFO - Epoch 28/150 - Train Loss: 0.154057, Val Loss: 0.161862
2025-07-04 11:05:56,757 - INFO - Epoch 29/150 - Train Loss: 0.146227, Val Loss: 0.175928
2025-07-04 11:06:14,447 - INFO - Epoch 30/150 - Train Loss: 0.146135, Val Loss: 0.377274
2025-07-04 11:06:32,248 - INFO - Epoch 31/150 - Train Loss: 0.145402, Val Loss: 0.213034
2025-07-04 11:06:49,915 - INFO - Epoch 32/150 - Train Loss: 0.142771, Val Loss: 0.151741
2025-07-04 11:07:07,605 - INFO - Epoch 33/150 - Train Loss: 0.145088, Val Loss: 0.146101
2025-07-04 11:07:07,772 - INFO - New best model saved with Val Loss: 0.146101
2025-07-04 11:07:25,485 - INFO - Epoch 34/150 - Train Loss: 0.139568, Val Loss: 0.273251
2025-07-04 11:07:43,166 - INFO - Epoch 35/150 - Train Loss: 0.140397, Val Loss: 0.148392
2025-07-04 11:08:00,841 - INFO - Epoch 36/150 - Train Loss: 0.136741, Val Loss: 0.150139
2025-07-04 11:08:18,529 - INFO - Epoch 37/150 - Train Loss: 0.135322, Val Loss: 0.148857
2025-07-04 11:08:36,229 - INFO - Epoch 38/150 - Train Loss: 0.132527, Val Loss: 0.130883
2025-07-04 11:08:36,244 - INFO - New best model saved with Val Loss: 0.130883
2025-07-04 11:08:53,921 - INFO - Epoch 39/150 - Train Loss: 0.135555, Val Loss: 0.149993
2025-07-04 11:09:11,628 - INFO - Epoch 40/150 - Train Loss: 0.135385, Val Loss: 0.164116
2025-07-04 11:09:29,416 - INFO - Epoch 41/150 - Train Loss: 0.132284, Val Loss: 0.146587
2025-07-04 11:09:47,072 - INFO - Epoch 42/150 - Train Loss: 0.133476, Val Loss: 0.166374
2025-07-04 11:10:04,740 - INFO - Epoch 43/150 - Train Loss: 0.132089, Val Loss: 0.138480
2025-07-04 11:10:22,422 - INFO - Epoch 44/150 - Train Loss: 0.131016, Val Loss: 0.134061
2025-07-04 11:10:40,137 - INFO - Epoch 45/150 - Train Loss: 0.131406, Val Loss: 0.128516
2025-07-04 11:10:40,153 - INFO - New best model saved with Val Loss: 0.128516
2025-07-04 11:10:57,844 - INFO - Epoch 46/150 - Train Loss: 0.127681, Val Loss: 0.202615
2025-07-04 11:11:15,682 - INFO - Epoch 47/150 - Train Loss: 0.126269, Val Loss: 0.136413
2025-07-04 11:11:33,387 - INFO - Epoch 48/150 - Train Loss: 0.128555, Val Loss: 0.211257
2025-07-04 11:11:51,064 - INFO - Epoch 49/150 - Train Loss: 0.128324, Val Loss: 0.134678
2025-07-04 11:12:09,127 - INFO - Epoch 50/150 - Train Loss: 0.125648, Val Loss: 0.164913
2025-07-04 11:12:12,302 - INFO - args.exp_name : Train_Test
2025-07-04 11:12:12,305 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data', num_points=10000, batch_size=6, epochs=150, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-07-04 11:12:12,305 - INFO - Starting training with 1 GPUs
2025-07-04 11:12:15,606 - INFO - Total trainable parameters: 1437705
2025-07-04 11:12:15,739 - INFO - Data loaded: 39 training batches, 8 validation batches, 9 test batches
2025-07-04 11:12:15,740 - INFO - Staring training for 150 epochs
2025-07-04 11:12:19,921 - INFO - before .to(local_rank)***************************************
2025-07-04 11:12:19,921 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:12:27,217 - INFO - Epoch 51/150 - Train Loss: 0.124183, Val Loss: 0.121055
2025-07-04 11:12:27,249 - INFO - New best model saved with Val Loss: 0.121055
2025-07-04 11:12:44,946 - INFO - Epoch 52/150 - Train Loss: 0.125603, Val Loss: 0.207307
2025-07-04 11:13:02,677 - INFO - Epoch 53/150 - Train Loss: 0.122962, Val Loss: 0.134787
2025-07-04 11:13:20,428 - INFO - Epoch 54/150 - Train Loss: 0.122586, Val Loss: 0.152079
2025-07-04 11:13:38,151 - INFO - Epoch 55/150 - Train Loss: 0.122021, Val Loss: 0.123622
2025-07-04 11:13:55,889 - INFO - Epoch 56/150 - Train Loss: 0.121857, Val Loss: 0.212121
2025-07-04 11:14:13,639 - INFO - Epoch 57/150 - Train Loss: 0.123328, Val Loss: 0.150480
2025-07-04 11:14:37,412 - INFO - Epoch 58/150 - Train Loss: 0.122286, Val Loss: 0.167857
2025-07-04 11:14:55,379 - INFO - Epoch 59/150 - Train Loss: 0.121922, Val Loss: 0.140145
2025-07-04 11:15:13,186 - INFO - Epoch 60/150 - Train Loss: 0.117993, Val Loss: 0.169449
2025-07-04 11:15:31,080 - INFO - Epoch 61/150 - Train Loss: 0.120024, Val Loss: 0.118396
2025-07-04 11:15:31,111 - INFO - New best model saved with Val Loss: 0.118396
2025-07-04 11:15:48,911 - INFO - Epoch 62/150 - Train Loss: 0.120212, Val Loss: 0.193534
2025-07-04 11:16:06,679 - INFO - Epoch 63/150 - Train Loss: 0.121789, Val Loss: 0.137048
2025-07-04 11:16:24,498 - INFO - Epoch 64/150 - Train Loss: 0.119106, Val Loss: 0.115732
2025-07-04 11:16:24,513 - INFO - New best model saved with Val Loss: 0.115732
2025-07-04 11:16:42,283 - INFO - Epoch 65/150 - Train Loss: 0.116286, Val Loss: 0.150539
2025-07-04 11:17:00,073 - INFO - Epoch 66/150 - Train Loss: 0.116608, Val Loss: 0.204416
2025-07-04 11:17:17,859 - INFO - Epoch 67/150 - Train Loss: 0.116302, Val Loss: 0.160922
2025-07-04 11:17:35,638 - INFO - Epoch 68/150 - Train Loss: 0.120537, Val Loss: 0.140712
2025-07-04 11:17:53,397 - INFO - Epoch 69/150 - Train Loss: 0.116008, Val Loss: 0.133827
2025-07-04 11:18:11,186 - INFO - Epoch 70/150 - Train Loss: 0.117500, Val Loss: 0.125367
2025-07-04 11:18:29,100 - INFO - Epoch 71/150 - Train Loss: 0.115497, Val Loss: 0.111867
2025-07-04 11:18:29,117 - INFO - New best model saved with Val Loss: 0.111867
2025-07-04 11:18:46,862 - INFO - Epoch 72/150 - Train Loss: 0.113848, Val Loss: 0.149078
2025-07-04 11:19:04,584 - INFO - Epoch 73/150 - Train Loss: 0.115463, Val Loss: 0.112712
2025-07-04 11:19:22,329 - INFO - Epoch 74/150 - Train Loss: 0.112697, Val Loss: 0.117975
2025-07-04 11:19:39,642 - INFO - args.exp_name : Train_Test
2025-07-04 11:19:39,642 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data', num_points=10000, batch_size=6, epochs=150, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-07-04 11:19:39,643 - INFO - Starting training with 1 GPUs
2025-07-04 11:19:40,162 - INFO - Epoch 75/150 - Train Loss: 0.116695, Val Loss: 0.156708
2025-07-04 11:19:43,809 - INFO - Total trainable parameters: 1437705
2025-07-04 11:19:43,945 - INFO - Data loaded: 39 training batches, 8 validation batches, 9 test batches
2025-07-04 11:19:43,948 - INFO - Staring training for 150 epochs
2025-07-04 11:19:58,452 - INFO - Epoch 76/150 - Train Loss: 0.115100, Val Loss: 0.130494
2025-07-04 11:20:16,182 - INFO - Epoch 77/150 - Train Loss: 0.112540, Val Loss: 0.115179
2025-07-04 11:20:33,917 - INFO - Epoch 78/150 - Train Loss: 0.111732, Val Loss: 0.116926
2025-07-04 11:20:52,823 - INFO - Epoch 79/150 - Train Loss: 0.110727, Val Loss: 0.126542
2025-07-04 11:20:54,270 - INFO - args.exp_name : Train_Test
2025-07-04 11:20:54,271 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=6, epochs=150, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-07-04 11:20:54,271 - INFO - Starting training with 1 GPUs
2025-07-04 11:20:58,251 - INFO - Total trainable parameters: 1437705
2025-07-04 11:20:58,314 - INFO - Data loaded: 3 training batches, 1 validation batches, 1 test batches
2025-07-04 11:20:58,314 - INFO - Staring training for 150 epochs
2025-07-04 11:21:10,629 - INFO - Epoch 80/150 - Train Loss: 0.111588, Val Loss: 0.117037
2025-07-04 11:21:28,458 - INFO - Epoch 81/150 - Train Loss: 0.111193, Val Loss: 0.166504
2025-07-04 11:21:46,188 - INFO - Epoch 82/150 - Train Loss: 0.111560, Val Loss: 0.212419
2025-07-04 11:22:03,922 - INFO - Epoch 83/150 - Train Loss: 0.103109, Val Loss: 0.092613
2025-07-04 11:22:03,939 - INFO - New best model saved with Val Loss: 0.092613
2025-07-04 11:22:13,605 - INFO - args.exp_name : Train_Test
2025-07-04 11:22:13,605 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=6, epochs=150, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-07-04 11:22:13,605 - INFO - Starting training with 1 GPUs
2025-07-04 11:22:17,612 - INFO - Total trainable parameters: 1437705
2025-07-04 11:22:17,640 - INFO - Data loaded: 3 training batches, 1 validation batches, 1 test batches
2025-07-04 11:22:17,643 - INFO - Staring training for 150 epochs
2025-07-04 11:22:21,988 - INFO - before .to(local_rank)***************************************
2025-07-04 11:22:21,989 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:22:23,643 - INFO - Epoch 84/150 - Train Loss: 0.098936, Val Loss: 0.090915
2025-07-04 11:22:23,660 - INFO - New best model saved with Val Loss: 0.090915
2025-07-04 11:22:41,391 - INFO - Epoch 85/150 - Train Loss: 0.097921, Val Loss: 0.090856
2025-07-04 11:22:41,407 - INFO - New best model saved with Val Loss: 0.090856
2025-07-04 11:22:59,119 - INFO - Epoch 86/150 - Train Loss: 0.097712, Val Loss: 0.091261
2025-07-04 11:23:16,809 - INFO - Epoch 87/150 - Train Loss: 0.097985, Val Loss: 0.089322
2025-07-04 11:23:16,824 - INFO - New best model saved with Val Loss: 0.089322
2025-07-04 11:23:34,524 - INFO - Epoch 88/150 - Train Loss: 0.097777, Val Loss: 0.090429
2025-07-04 11:23:52,215 - INFO - Epoch 89/150 - Train Loss: 0.097160, Val Loss: 0.090603
2025-07-04 11:24:09,894 - INFO - Epoch 90/150 - Train Loss: 0.097306, Val Loss: 0.090642
2025-07-04 11:24:27,724 - INFO - Epoch 91/150 - Train Loss: 0.096543, Val Loss: 0.092955
2025-07-04 11:24:45,444 - INFO - Epoch 92/150 - Train Loss: 0.097235, Val Loss: 0.090075
2025-07-04 11:25:03,135 - INFO - Epoch 93/150 - Train Loss: 0.096742, Val Loss: 0.090382
2025-07-04 11:25:20,910 - INFO - Epoch 94/150 - Train Loss: 0.095817, Val Loss: 0.090097
2025-07-04 11:25:26,480 - INFO - args.exp_name : Train_Test
2025-07-04 11:25:26,484 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=6, epochs=150, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-07-04 11:25:26,485 - INFO - Starting training with 1 GPUs
2025-07-04 11:25:30,407 - INFO - Total trainable parameters: 1437705
2025-07-04 11:25:30,433 - INFO - Data loaded: 3 training batches, 1 validation batches, 1 test batches
2025-07-04 11:25:30,437 - INFO - Staring training for 150 epochs
2025-07-04 11:25:34,711 - INFO - before .to(local_rank)***************************************
2025-07-04 11:25:34,717 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:25:34,718 - INFO - After .to(local_rank)***************************************
2025-07-04 11:25:34,718 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:34,718 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:34,742 - INFO - After Normalization***************************************
2025-07-04 11:25:34,742 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:34,742 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:35,580 - INFO - before .to(local_rank)***************************************
2025-07-04 11:25:35,580 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:25:35,580 - INFO - After .to(local_rank)***************************************
2025-07-04 11:25:35,580 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:35,580 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:35,580 - INFO - After Normalization***************************************
2025-07-04 11:25:35,580 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:35,581 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:35,875 - INFO - before .to(local_rank)***************************************
2025-07-04 11:25:35,875 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:25:35,876 - INFO - After .to(local_rank)***************************************
2025-07-04 11:25:35,876 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:35,876 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:35,876 - INFO - After Normalization***************************************
2025-07-04 11:25:35,876 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:35,876 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:39,114 - INFO - Epoch 1/150 - Train Loss: 1.280600, Val Loss: 1.146895
2025-07-04 11:25:39,132 - INFO - New best model saved with Val Loss: 1.146895
2025-07-04 11:25:39,458 - INFO - Epoch 95/150 - Train Loss: 0.096246, Val Loss: 0.089551
2025-07-04 11:25:41,416 - INFO - before .to(local_rank)***************************************
2025-07-04 11:25:41,429 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:25:41,429 - INFO - After .to(local_rank)***************************************
2025-07-04 11:25:41,429 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:41,429 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:41,429 - INFO - After Normalization***************************************
2025-07-04 11:25:41,429 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:41,429 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:41,742 - INFO - before .to(local_rank)***************************************
2025-07-04 11:25:41,742 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:25:41,742 - INFO - After .to(local_rank)***************************************
2025-07-04 11:25:41,742 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:41,742 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:41,742 - INFO - After Normalization***************************************
2025-07-04 11:25:41,743 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:41,743 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:42,032 - INFO - before .to(local_rank)***************************************
2025-07-04 11:25:42,032 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:25:42,032 - INFO - After .to(local_rank)***************************************
2025-07-04 11:25:42,032 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:42,032 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:42,032 - INFO - After Normalization***************************************
2025-07-04 11:25:42,032 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:42,032 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:45,246 - INFO - Epoch 2/150 - Train Loss: 1.144802, Val Loss: 1.149067
2025-07-04 11:25:47,510 - INFO - before .to(local_rank)***************************************
2025-07-04 11:25:47,523 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:25:47,523 - INFO - After .to(local_rank)***************************************
2025-07-04 11:25:47,523 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:47,523 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:47,523 - INFO - After Normalization***************************************
2025-07-04 11:25:47,523 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:47,523 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:47,828 - INFO - before .to(local_rank)***************************************
2025-07-04 11:25:47,828 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:25:47,829 - INFO - After .to(local_rank)***************************************
2025-07-04 11:25:47,829 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:47,829 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:47,829 - INFO - After Normalization***************************************
2025-07-04 11:25:47,829 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:47,829 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:48,117 - INFO - before .to(local_rank)***************************************
2025-07-04 11:25:48,118 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:25:48,118 - INFO - After .to(local_rank)***************************************
2025-07-04 11:25:48,118 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:48,118 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:48,118 - INFO - After Normalization***************************************
2025-07-04 11:25:48,118 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:48,118 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:51,309 - INFO - Epoch 3/150 - Train Loss: 0.975273, Val Loss: 1.146720
2025-07-04 11:25:51,324 - INFO - New best model saved with Val Loss: 1.146720
2025-07-04 11:25:53,575 - INFO - before .to(local_rank)***************************************
2025-07-04 11:25:53,588 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:25:53,589 - INFO - After .to(local_rank)***************************************
2025-07-04 11:25:53,589 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:53,589 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:53,589 - INFO - After Normalization***************************************
2025-07-04 11:25:53,589 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:53,589 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:53,900 - INFO - before .to(local_rank)***************************************
2025-07-04 11:25:53,900 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:25:53,901 - INFO - After .to(local_rank)***************************************
2025-07-04 11:25:53,901 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:53,901 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:53,901 - INFO - After Normalization***************************************
2025-07-04 11:25:53,901 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:53,901 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:54,190 - INFO - before .to(local_rank)***************************************
2025-07-04 11:25:54,190 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:25:54,190 - INFO - After .to(local_rank)***************************************
2025-07-04 11:25:54,190 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:54,190 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:54,190 - INFO - After Normalization***************************************
2025-07-04 11:25:54,191 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:54,191 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:57,221 - INFO - Epoch 96/150 - Train Loss: 0.095710, Val Loss: 0.088552
2025-07-04 11:25:57,240 - INFO - New best model saved with Val Loss: 0.088552
2025-07-04 11:25:57,415 - INFO - Epoch 4/150 - Train Loss: 0.867832, Val Loss: 1.204947
2025-07-04 11:25:59,659 - INFO - before .to(local_rank)***************************************
2025-07-04 11:25:59,672 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:25:59,672 - INFO - After .to(local_rank)***************************************
2025-07-04 11:25:59,673 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:59,673 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:59,673 - INFO - After Normalization***************************************
2025-07-04 11:25:59,673 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:59,673 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:59,990 - INFO - before .to(local_rank)***************************************
2025-07-04 11:25:59,990 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:25:59,990 - INFO - After .to(local_rank)***************************************
2025-07-04 11:25:59,990 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:59,990 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:59,990 - INFO - After Normalization***************************************
2025-07-04 11:25:59,990 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:25:59,990 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:00,279 - INFO - before .to(local_rank)***************************************
2025-07-04 11:26:00,279 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:26:00,279 - INFO - After .to(local_rank)***************************************
2025-07-04 11:26:00,279 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:00,279 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:00,279 - INFO - After Normalization***************************************
2025-07-04 11:26:00,279 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:00,279 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:03,503 - INFO - Epoch 5/150 - Train Loss: 0.776425, Val Loss: 1.353248
2025-07-04 11:26:05,751 - INFO - before .to(local_rank)***************************************
2025-07-04 11:26:05,764 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:26:05,765 - INFO - After .to(local_rank)***************************************
2025-07-04 11:26:05,765 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:05,765 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:05,765 - INFO - After Normalization***************************************
2025-07-04 11:26:05,765 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:05,765 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:06,075 - INFO - before .to(local_rank)***************************************
2025-07-04 11:26:06,075 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:26:06,075 - INFO - After .to(local_rank)***************************************
2025-07-04 11:26:06,075 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:06,076 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:06,076 - INFO - After Normalization***************************************
2025-07-04 11:26:06,076 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:06,076 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:06,364 - INFO - before .to(local_rank)***************************************
2025-07-04 11:26:06,364 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:26:06,364 - INFO - After .to(local_rank)***************************************
2025-07-04 11:26:06,364 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:06,364 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:06,364 - INFO - After Normalization***************************************
2025-07-04 11:26:06,365 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:06,365 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:09,552 - INFO - Epoch 6/150 - Train Loss: 0.683154, Val Loss: 1.512758
2025-07-04 11:26:11,793 - INFO - before .to(local_rank)***************************************
2025-07-04 11:26:11,806 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:26:11,807 - INFO - After .to(local_rank)***************************************
2025-07-04 11:26:11,807 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:11,807 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:11,807 - INFO - After Normalization***************************************
2025-07-04 11:26:11,807 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:11,807 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:12,116 - INFO - before .to(local_rank)***************************************
2025-07-04 11:26:12,116 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:26:12,116 - INFO - After .to(local_rank)***************************************
2025-07-04 11:26:12,116 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:12,116 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:12,117 - INFO - After Normalization***************************************
2025-07-04 11:26:12,117 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:12,117 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:12,406 - INFO - before .to(local_rank)***************************************
2025-07-04 11:26:12,406 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:26:12,406 - INFO - After .to(local_rank)***************************************
2025-07-04 11:26:12,406 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:12,406 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:12,407 - INFO - After Normalization***************************************
2025-07-04 11:26:12,407 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:12,407 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:15,027 - INFO - Epoch 97/150 - Train Loss: 0.096374, Val Loss: 0.089566
2025-07-04 11:26:15,599 - INFO - Epoch 7/150 - Train Loss: 0.610629, Val Loss: 1.877720
2025-07-04 11:26:17,852 - INFO - before .to(local_rank)***************************************
2025-07-04 11:26:17,865 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:26:17,865 - INFO - After .to(local_rank)***************************************
2025-07-04 11:26:17,865 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:17,865 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:17,866 - INFO - After Normalization***************************************
2025-07-04 11:26:17,866 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:17,866 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:18,171 - INFO - before .to(local_rank)***************************************
2025-07-04 11:26:18,171 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:26:18,171 - INFO - After .to(local_rank)***************************************
2025-07-04 11:26:18,171 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:18,171 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:18,171 - INFO - After Normalization***************************************
2025-07-04 11:26:18,172 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:18,172 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:18,461 - INFO - before .to(local_rank)***************************************
2025-07-04 11:26:18,461 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:26:18,461 - INFO - After .to(local_rank)***************************************
2025-07-04 11:26:18,461 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:18,461 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:18,461 - INFO - After Normalization***************************************
2025-07-04 11:26:18,461 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:18,461 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:21,682 - INFO - Epoch 8/150 - Train Loss: 0.574927, Val Loss: 2.574531
2025-07-04 11:26:23,956 - INFO - before .to(local_rank)***************************************
2025-07-04 11:26:23,969 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:26:23,969 - INFO - After .to(local_rank)***************************************
2025-07-04 11:26:23,970 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:23,970 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:23,970 - INFO - After Normalization***************************************
2025-07-04 11:26:23,970 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:23,970 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:24,290 - INFO - before .to(local_rank)***************************************
2025-07-04 11:26:24,290 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:26:24,290 - INFO - After .to(local_rank)***************************************
2025-07-04 11:26:24,290 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:24,290 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:24,290 - INFO - After Normalization***************************************
2025-07-04 11:26:24,291 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:24,291 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:24,580 - INFO - before .to(local_rank)***************************************
2025-07-04 11:26:24,580 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:26:24,580 - INFO - After .to(local_rank)***************************************
2025-07-04 11:26:24,580 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:24,580 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:24,581 - INFO - After Normalization***************************************
2025-07-04 11:26:24,581 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:24,581 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:27,811 - INFO - Epoch 9/150 - Train Loss: 0.542028, Val Loss: 1.789927
2025-07-04 11:26:30,083 - INFO - before .to(local_rank)***************************************
2025-07-04 11:26:30,097 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:26:30,097 - INFO - After .to(local_rank)***************************************
2025-07-04 11:26:30,097 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:30,097 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:30,097 - INFO - After Normalization***************************************
2025-07-04 11:26:30,097 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:30,097 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:30,407 - INFO - before .to(local_rank)***************************************
2025-07-04 11:26:30,407 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:26:30,407 - INFO - After .to(local_rank)***************************************
2025-07-04 11:26:30,407 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:30,408 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:30,408 - INFO - After Normalization***************************************
2025-07-04 11:26:30,408 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:30,408 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:30,696 - INFO - before .to(local_rank)***************************************
2025-07-04 11:26:30,696 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:26:30,697 - INFO - After .to(local_rank)***************************************
2025-07-04 11:26:30,697 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:30,697 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:30,697 - INFO - After Normalization***************************************
2025-07-04 11:26:30,697 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:30,697 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:32,834 - INFO - Epoch 98/150 - Train Loss: 0.096752, Val Loss: 0.088469
2025-07-04 11:26:32,849 - INFO - New best model saved with Val Loss: 0.088469
2025-07-04 11:26:33,915 - INFO - Epoch 10/150 - Train Loss: 0.521374, Val Loss: 1.558796
2025-07-04 11:26:36,326 - INFO - before .to(local_rank)***************************************
2025-07-04 11:26:36,339 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:26:36,339 - INFO - After .to(local_rank)***************************************
2025-07-04 11:26:36,339 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:36,339 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:36,339 - INFO - After Normalization***************************************
2025-07-04 11:26:36,339 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:36,339 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:36,645 - INFO - before .to(local_rank)***************************************
2025-07-04 11:26:36,645 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:26:36,645 - INFO - After .to(local_rank)***************************************
2025-07-04 11:26:36,645 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:36,645 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:36,645 - INFO - After Normalization***************************************
2025-07-04 11:26:36,645 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:36,645 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:36,934 - INFO - before .to(local_rank)***************************************
2025-07-04 11:26:36,934 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:26:36,934 - INFO - After .to(local_rank)***************************************
2025-07-04 11:26:36,934 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:36,934 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:36,934 - INFO - After Normalization***************************************
2025-07-04 11:26:36,934 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:36,934 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:40,117 - INFO - Epoch 11/150 - Train Loss: 0.496060, Val Loss: 1.854632
2025-07-04 11:26:42,376 - INFO - before .to(local_rank)***************************************
2025-07-04 11:26:42,389 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:26:42,389 - INFO - After .to(local_rank)***************************************
2025-07-04 11:26:42,390 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:42,390 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:42,390 - INFO - After Normalization***************************************
2025-07-04 11:26:42,390 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:42,390 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:42,691 - INFO - before .to(local_rank)***************************************
2025-07-04 11:26:42,691 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:26:42,692 - INFO - After .to(local_rank)***************************************
2025-07-04 11:26:42,692 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:42,692 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:42,692 - INFO - After Normalization***************************************
2025-07-04 11:26:42,692 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:42,692 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:42,980 - INFO - before .to(local_rank)***************************************
2025-07-04 11:26:42,980 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:26:42,981 - INFO - After .to(local_rank)***************************************
2025-07-04 11:26:42,981 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:42,981 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:42,981 - INFO - After Normalization***************************************
2025-07-04 11:26:42,981 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:42,981 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:46,176 - INFO - Epoch 12/150 - Train Loss: 0.475875, Val Loss: 1.684819
2025-07-04 11:26:48,436 - INFO - before .to(local_rank)***************************************
2025-07-04 11:26:48,449 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:26:48,450 - INFO - After .to(local_rank)***************************************
2025-07-04 11:26:48,451 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:48,451 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:48,451 - INFO - After Normalization***************************************
2025-07-04 11:26:48,451 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:48,451 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:48,755 - INFO - before .to(local_rank)***************************************
2025-07-04 11:26:48,755 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:26:48,755 - INFO - After .to(local_rank)***************************************
2025-07-04 11:26:48,755 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:48,755 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:48,755 - INFO - After Normalization***************************************
2025-07-04 11:26:48,756 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:48,756 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:49,044 - INFO - before .to(local_rank)***************************************
2025-07-04 11:26:49,045 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:26:49,045 - INFO - After .to(local_rank)***************************************
2025-07-04 11:26:49,045 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:49,045 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:49,045 - INFO - After Normalization***************************************
2025-07-04 11:26:49,045 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:49,045 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:50,565 - INFO - Epoch 99/150 - Train Loss: 0.093261, Val Loss: 0.089550
2025-07-04 11:26:52,248 - INFO - Epoch 13/150 - Train Loss: 0.461486, Val Loss: 0.891453
2025-07-04 11:26:52,270 - INFO - New best model saved with Val Loss: 0.891453
2025-07-04 11:26:54,525 - INFO - before .to(local_rank)***************************************
2025-07-04 11:26:54,540 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:26:54,540 - INFO - After .to(local_rank)***************************************
2025-07-04 11:26:54,541 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:54,541 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:54,541 - INFO - After Normalization***************************************
2025-07-04 11:26:54,541 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:54,541 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:54,853 - INFO - before .to(local_rank)***************************************
2025-07-04 11:26:54,854 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:26:54,854 - INFO - After .to(local_rank)***************************************
2025-07-04 11:26:54,854 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:54,854 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:54,854 - INFO - After Normalization***************************************
2025-07-04 11:26:54,854 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:54,854 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:55,142 - INFO - before .to(local_rank)***************************************
2025-07-04 11:26:55,143 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:26:55,143 - INFO - After .to(local_rank)***************************************
2025-07-04 11:26:55,143 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:55,143 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:55,144 - INFO - After Normalization***************************************
2025-07-04 11:26:55,144 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:55,144 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:26:58,351 - INFO - Epoch 14/150 - Train Loss: 0.446934, Val Loss: 0.620117
2025-07-04 11:26:58,365 - INFO - New best model saved with Val Loss: 0.620117
2025-07-04 11:27:00,593 - INFO - before .to(local_rank)***************************************
2025-07-04 11:27:00,605 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:27:00,606 - INFO - After .to(local_rank)***************************************
2025-07-04 11:27:00,606 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:00,606 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:00,606 - INFO - After Normalization***************************************
2025-07-04 11:27:00,606 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:00,606 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:00,914 - INFO - before .to(local_rank)***************************************
2025-07-04 11:27:00,914 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:27:00,915 - INFO - After .to(local_rank)***************************************
2025-07-04 11:27:00,915 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:00,915 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:00,915 - INFO - After Normalization***************************************
2025-07-04 11:27:00,915 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:00,915 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:01,203 - INFO - before .to(local_rank)***************************************
2025-07-04 11:27:01,203 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:27:01,203 - INFO - After .to(local_rank)***************************************
2025-07-04 11:27:01,203 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:01,204 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:01,204 - INFO - After Normalization***************************************
2025-07-04 11:27:01,204 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:01,204 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:04,429 - INFO - Epoch 15/150 - Train Loss: 0.428600, Val Loss: 0.572159
2025-07-04 11:27:04,443 - INFO - New best model saved with Val Loss: 0.572159
2025-07-04 11:27:06,681 - INFO - before .to(local_rank)***************************************
2025-07-04 11:27:06,694 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:27:06,694 - INFO - After .to(local_rank)***************************************
2025-07-04 11:27:06,695 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:06,695 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:06,695 - INFO - After Normalization***************************************
2025-07-04 11:27:06,695 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:06,695 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:06,997 - INFO - before .to(local_rank)***************************************
2025-07-04 11:27:06,997 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:27:06,997 - INFO - After .to(local_rank)***************************************
2025-07-04 11:27:06,997 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:06,997 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:06,997 - INFO - After Normalization***************************************
2025-07-04 11:27:06,998 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:06,998 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:07,286 - INFO - before .to(local_rank)***************************************
2025-07-04 11:27:07,286 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:27:07,286 - INFO - After .to(local_rank)***************************************
2025-07-04 11:27:07,287 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:07,287 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:07,287 - INFO - After Normalization***************************************
2025-07-04 11:27:07,287 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:07,287 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:08,336 - INFO - Epoch 100/150 - Train Loss: 0.095612, Val Loss: 0.096346
2025-07-04 11:27:10,489 - INFO - Epoch 16/150 - Train Loss: 0.421643, Val Loss: 0.504932
2025-07-04 11:27:10,503 - INFO - New best model saved with Val Loss: 0.504932
2025-07-04 11:27:12,757 - INFO - before .to(local_rank)***************************************
2025-07-04 11:27:12,770 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:27:12,770 - INFO - After .to(local_rank)***************************************
2025-07-04 11:27:12,770 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:12,770 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:12,771 - INFO - After Normalization***************************************
2025-07-04 11:27:12,771 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:12,771 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:13,085 - INFO - before .to(local_rank)***************************************
2025-07-04 11:27:13,085 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:27:13,085 - INFO - After .to(local_rank)***************************************
2025-07-04 11:27:13,086 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:13,086 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:13,086 - INFO - After Normalization***************************************
2025-07-04 11:27:13,086 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:13,086 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:13,376 - INFO - before .to(local_rank)***************************************
2025-07-04 11:27:13,377 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:27:13,377 - INFO - After .to(local_rank)***************************************
2025-07-04 11:27:13,377 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:13,377 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:13,377 - INFO - After Normalization***************************************
2025-07-04 11:27:13,377 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:13,377 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:16,564 - INFO - Epoch 17/150 - Train Loss: 0.403576, Val Loss: 0.716280
2025-07-04 11:27:18,826 - INFO - before .to(local_rank)***************************************
2025-07-04 11:27:18,838 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:27:18,839 - INFO - After .to(local_rank)***************************************
2025-07-04 11:27:18,839 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:18,839 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:18,839 - INFO - After Normalization***************************************
2025-07-04 11:27:18,839 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:18,840 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:19,154 - INFO - before .to(local_rank)***************************************
2025-07-04 11:27:19,154 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:27:19,155 - INFO - After .to(local_rank)***************************************
2025-07-04 11:27:19,155 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:19,155 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:19,155 - INFO - After Normalization***************************************
2025-07-04 11:27:19,155 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:19,155 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:19,446 - INFO - before .to(local_rank)***************************************
2025-07-04 11:27:19,446 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:27:19,446 - INFO - After .to(local_rank)***************************************
2025-07-04 11:27:19,446 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:19,446 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:19,447 - INFO - After Normalization***************************************
2025-07-04 11:27:19,447 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:19,447 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:22,660 - INFO - Epoch 18/150 - Train Loss: 0.402675, Val Loss: 0.490075
2025-07-04 11:27:22,674 - INFO - New best model saved with Val Loss: 0.490075
2025-07-04 11:27:24,924 - INFO - before .to(local_rank)***************************************
2025-07-04 11:27:24,937 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:27:24,937 - INFO - After .to(local_rank)***************************************
2025-07-04 11:27:24,937 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:24,937 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:24,937 - INFO - After Normalization***************************************
2025-07-04 11:27:24,937 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:24,937 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:25,244 - INFO - before .to(local_rank)***************************************
2025-07-04 11:27:25,244 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:27:25,244 - INFO - After .to(local_rank)***************************************
2025-07-04 11:27:25,244 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:25,244 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:25,245 - INFO - After Normalization***************************************
2025-07-04 11:27:25,245 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:25,245 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:25,536 - INFO - before .to(local_rank)***************************************
2025-07-04 11:27:25,536 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:27:25,536 - INFO - After .to(local_rank)***************************************
2025-07-04 11:27:25,536 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:25,536 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:25,536 - INFO - After Normalization***************************************
2025-07-04 11:27:25,536 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:25,536 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:26,197 - INFO - Epoch 101/150 - Train Loss: 0.096476, Val Loss: 0.128738
2025-07-04 11:27:28,753 - INFO - Epoch 19/150 - Train Loss: 0.398048, Val Loss: 0.483450
2025-07-04 11:27:28,768 - INFO - New best model saved with Val Loss: 0.483450
2025-07-04 11:27:31,017 - INFO - before .to(local_rank)***************************************
2025-07-04 11:27:31,030 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:27:31,030 - INFO - After .to(local_rank)***************************************
2025-07-04 11:27:31,030 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:31,030 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:31,030 - INFO - After Normalization***************************************
2025-07-04 11:27:31,031 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:31,031 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:31,331 - INFO - before .to(local_rank)***************************************
2025-07-04 11:27:31,331 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:27:31,331 - INFO - After .to(local_rank)***************************************
2025-07-04 11:27:31,331 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:31,331 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:31,331 - INFO - After Normalization***************************************
2025-07-04 11:27:31,331 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:31,331 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:31,622 - INFO - before .to(local_rank)***************************************
2025-07-04 11:27:31,622 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:27:31,623 - INFO - After .to(local_rank)***************************************
2025-07-04 11:27:31,623 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:31,623 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:31,623 - INFO - After Normalization***************************************
2025-07-04 11:27:31,623 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:31,623 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:34,821 - INFO - Epoch 20/150 - Train Loss: 0.380748, Val Loss: 0.511743
2025-07-04 11:27:37,191 - INFO - before .to(local_rank)***************************************
2025-07-04 11:27:37,203 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:27:37,204 - INFO - After .to(local_rank)***************************************
2025-07-04 11:27:37,204 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:37,204 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:37,204 - INFO - After Normalization***************************************
2025-07-04 11:27:37,204 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:37,204 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:37,512 - INFO - before .to(local_rank)***************************************
2025-07-04 11:27:37,512 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:27:37,512 - INFO - After .to(local_rank)***************************************
2025-07-04 11:27:37,513 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:37,513 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:37,513 - INFO - After Normalization***************************************
2025-07-04 11:27:37,513 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:37,513 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:37,801 - INFO - before .to(local_rank)***************************************
2025-07-04 11:27:37,801 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:27:37,801 - INFO - After .to(local_rank)***************************************
2025-07-04 11:27:37,802 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:37,802 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:37,802 - INFO - After Normalization***************************************
2025-07-04 11:27:37,802 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:37,802 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:41,009 - INFO - Epoch 21/150 - Train Loss: 0.374902, Val Loss: 1.120439
2025-07-04 11:27:43,240 - INFO - before .to(local_rank)***************************************
2025-07-04 11:27:43,253 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:27:43,254 - INFO - After .to(local_rank)***************************************
2025-07-04 11:27:43,254 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:43,254 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:43,254 - INFO - After Normalization***************************************
2025-07-04 11:27:43,254 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:43,254 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:43,560 - INFO - before .to(local_rank)***************************************
2025-07-04 11:27:43,560 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:27:43,560 - INFO - After .to(local_rank)***************************************
2025-07-04 11:27:43,560 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:43,560 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:43,560 - INFO - After Normalization***************************************
2025-07-04 11:27:43,561 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:43,561 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:43,850 - INFO - before .to(local_rank)***************************************
2025-07-04 11:27:43,850 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:27:43,850 - INFO - After .to(local_rank)***************************************
2025-07-04 11:27:43,850 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:43,850 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:43,850 - INFO - After Normalization***************************************
2025-07-04 11:27:43,850 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:43,850 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:43,960 - INFO - Epoch 102/150 - Train Loss: 0.096039, Val Loss: 0.090330
2025-07-04 11:27:47,040 - INFO - Epoch 22/150 - Train Loss: 0.366255, Val Loss: 2.700198
2025-07-04 11:27:49,303 - INFO - before .to(local_rank)***************************************
2025-07-04 11:27:49,315 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:27:49,316 - INFO - After .to(local_rank)***************************************
2025-07-04 11:27:49,316 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:49,316 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:49,316 - INFO - After Normalization***************************************
2025-07-04 11:27:49,316 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:49,316 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:49,619 - INFO - before .to(local_rank)***************************************
2025-07-04 11:27:49,619 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:27:49,620 - INFO - After .to(local_rank)***************************************
2025-07-04 11:27:49,620 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:49,620 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:49,621 - INFO - After Normalization***************************************
2025-07-04 11:27:49,621 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:49,621 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:49,909 - INFO - before .to(local_rank)***************************************
2025-07-04 11:27:49,909 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:27:49,909 - INFO - After .to(local_rank)***************************************
2025-07-04 11:27:49,909 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:49,909 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:49,910 - INFO - After Normalization***************************************
2025-07-04 11:27:49,910 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:49,910 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:53,105 - INFO - Epoch 23/150 - Train Loss: 0.356884, Val Loss: 1.268673
2025-07-04 11:27:55,363 - INFO - before .to(local_rank)***************************************
2025-07-04 11:27:55,376 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:27:55,377 - INFO - After .to(local_rank)***************************************
2025-07-04 11:27:55,377 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:55,377 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:55,377 - INFO - After Normalization***************************************
2025-07-04 11:27:55,377 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:55,377 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:55,699 - INFO - before .to(local_rank)***************************************
2025-07-04 11:27:55,700 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:27:55,700 - INFO - After .to(local_rank)***************************************
2025-07-04 11:27:55,700 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:55,700 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:55,700 - INFO - After Normalization***************************************
2025-07-04 11:27:55,700 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:55,700 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:55,988 - INFO - before .to(local_rank)***************************************
2025-07-04 11:27:55,988 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:27:55,989 - INFO - After .to(local_rank)***************************************
2025-07-04 11:27:55,989 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:55,989 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:55,989 - INFO - After Normalization***************************************
2025-07-04 11:27:55,989 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:55,989 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:27:59,210 - INFO - Epoch 24/150 - Train Loss: 0.356916, Val Loss: 0.439105
2025-07-04 11:27:59,225 - INFO - New best model saved with Val Loss: 0.439105
2025-07-04 11:28:01,462 - INFO - before .to(local_rank)***************************************
2025-07-04 11:28:01,476 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:28:01,477 - INFO - After .to(local_rank)***************************************
2025-07-04 11:28:01,477 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:01,477 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:01,477 - INFO - After Normalization***************************************
2025-07-04 11:28:01,477 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:01,478 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:01,744 - INFO - Epoch 103/150 - Train Loss: 0.094943, Val Loss: 0.120177
2025-07-04 11:28:01,791 - INFO - before .to(local_rank)***************************************
2025-07-04 11:28:01,791 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:28:01,791 - INFO - After .to(local_rank)***************************************
2025-07-04 11:28:01,791 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:01,791 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:01,791 - INFO - After Normalization***************************************
2025-07-04 11:28:01,791 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:01,791 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:02,081 - INFO - before .to(local_rank)***************************************
2025-07-04 11:28:02,081 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:28:02,081 - INFO - After .to(local_rank)***************************************
2025-07-04 11:28:02,081 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:02,081 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:02,081 - INFO - After Normalization***************************************
2025-07-04 11:28:02,081 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:02,081 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:05,287 - INFO - Epoch 25/150 - Train Loss: 0.348590, Val Loss: 0.820585
2025-07-04 11:28:07,530 - INFO - before .to(local_rank)***************************************
2025-07-04 11:28:07,543 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:28:07,543 - INFO - After .to(local_rank)***************************************
2025-07-04 11:28:07,544 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:07,544 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:07,544 - INFO - After Normalization***************************************
2025-07-04 11:28:07,544 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:07,544 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:07,853 - INFO - before .to(local_rank)***************************************
2025-07-04 11:28:07,853 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:28:07,854 - INFO - After .to(local_rank)***************************************
2025-07-04 11:28:07,854 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:07,854 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:07,854 - INFO - After Normalization***************************************
2025-07-04 11:28:07,854 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:07,854 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:08,142 - INFO - before .to(local_rank)***************************************
2025-07-04 11:28:08,142 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:28:08,142 - INFO - After .to(local_rank)***************************************
2025-07-04 11:28:08,143 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:08,143 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:08,143 - INFO - After Normalization***************************************
2025-07-04 11:28:08,143 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:08,143 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:11,343 - INFO - Epoch 26/150 - Train Loss: 0.344870, Val Loss: 0.852622
2025-07-04 11:28:13,581 - INFO - before .to(local_rank)***************************************
2025-07-04 11:28:13,595 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:28:13,595 - INFO - After .to(local_rank)***************************************
2025-07-04 11:28:13,595 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:13,595 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:13,596 - INFO - After Normalization***************************************
2025-07-04 11:28:13,596 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:13,596 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:13,904 - INFO - before .to(local_rank)***************************************
2025-07-04 11:28:13,904 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:28:13,904 - INFO - After .to(local_rank)***************************************
2025-07-04 11:28:13,904 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:13,904 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:13,904 - INFO - After Normalization***************************************
2025-07-04 11:28:13,904 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:13,904 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:14,192 - INFO - before .to(local_rank)***************************************
2025-07-04 11:28:14,192 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:28:14,193 - INFO - After .to(local_rank)***************************************
2025-07-04 11:28:14,193 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:14,193 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:14,193 - INFO - After Normalization***************************************
2025-07-04 11:28:14,193 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:14,193 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:17,391 - INFO - Epoch 27/150 - Train Loss: 0.341391, Val Loss: 0.770657
2025-07-04 11:28:19,522 - INFO - Epoch 104/150 - Train Loss: 0.095132, Val Loss: 0.088605
2025-07-04 11:28:19,650 - INFO - before .to(local_rank)***************************************
2025-07-04 11:28:19,664 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:28:19,664 - INFO - After .to(local_rank)***************************************
2025-07-04 11:28:19,664 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:19,664 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:19,664 - INFO - After Normalization***************************************
2025-07-04 11:28:19,664 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:19,664 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:19,969 - INFO - before .to(local_rank)***************************************
2025-07-04 11:28:19,969 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:28:19,969 - INFO - After .to(local_rank)***************************************
2025-07-04 11:28:19,969 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:19,969 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:19,969 - INFO - After Normalization***************************************
2025-07-04 11:28:19,969 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:19,969 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:20,258 - INFO - before .to(local_rank)***************************************
2025-07-04 11:28:20,258 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:28:20,259 - INFO - After .to(local_rank)***************************************
2025-07-04 11:28:20,259 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:20,260 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:20,260 - INFO - After Normalization***************************************
2025-07-04 11:28:20,260 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:20,260 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:23,466 - INFO - Epoch 28/150 - Train Loss: 0.332293, Val Loss: 0.407206
2025-07-04 11:28:23,481 - INFO - New best model saved with Val Loss: 0.407206
2025-07-04 11:28:25,744 - INFO - before .to(local_rank)***************************************
2025-07-04 11:28:25,757 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:28:25,757 - INFO - After .to(local_rank)***************************************
2025-07-04 11:28:25,757 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:25,757 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:25,757 - INFO - After Normalization***************************************
2025-07-04 11:28:25,757 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:25,758 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:26,072 - INFO - before .to(local_rank)***************************************
2025-07-04 11:28:26,072 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:28:26,072 - INFO - After .to(local_rank)***************************************
2025-07-04 11:28:26,072 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:26,072 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:26,073 - INFO - After Normalization***************************************
2025-07-04 11:28:26,073 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:26,073 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:26,361 - INFO - before .to(local_rank)***************************************
2025-07-04 11:28:26,361 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:28:26,361 - INFO - After .to(local_rank)***************************************
2025-07-04 11:28:26,361 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:26,361 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:26,361 - INFO - After Normalization***************************************
2025-07-04 11:28:26,361 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:26,362 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:29,574 - INFO - Epoch 29/150 - Train Loss: 0.325987, Val Loss: 2.452645
2025-07-04 11:28:31,836 - INFO - before .to(local_rank)***************************************
2025-07-04 11:28:31,850 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:28:31,850 - INFO - After .to(local_rank)***************************************
2025-07-04 11:28:31,850 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:31,850 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:31,850 - INFO - After Normalization***************************************
2025-07-04 11:28:31,850 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:31,851 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:32,158 - INFO - before .to(local_rank)***************************************
2025-07-04 11:28:32,158 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:28:32,158 - INFO - After .to(local_rank)***************************************
2025-07-04 11:28:32,159 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:32,159 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:32,159 - INFO - After Normalization***************************************
2025-07-04 11:28:32,159 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:32,159 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:32,448 - INFO - before .to(local_rank)***************************************
2025-07-04 11:28:32,448 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:28:32,449 - INFO - After .to(local_rank)***************************************
2025-07-04 11:28:32,449 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:32,449 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:32,449 - INFO - After Normalization***************************************
2025-07-04 11:28:32,449 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:32,449 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:35,695 - INFO - Epoch 30/150 - Train Loss: 0.319199, Val Loss: 7.066501
2025-07-04 11:28:37,289 - INFO - Epoch 105/150 - Train Loss: 0.095240, Val Loss: 0.088804
2025-07-04 11:28:38,069 - INFO - before .to(local_rank)***************************************
2025-07-04 11:28:38,082 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:28:38,083 - INFO - After .to(local_rank)***************************************
2025-07-04 11:28:38,083 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:38,083 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:38,083 - INFO - After Normalization***************************************
2025-07-04 11:28:38,083 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:38,083 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:38,390 - INFO - before .to(local_rank)***************************************
2025-07-04 11:28:38,391 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:28:38,391 - INFO - After .to(local_rank)***************************************
2025-07-04 11:28:38,391 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:38,391 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:38,391 - INFO - After Normalization***************************************
2025-07-04 11:28:38,391 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:38,391 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:38,680 - INFO - before .to(local_rank)***************************************
2025-07-04 11:28:38,680 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:28:38,681 - INFO - After .to(local_rank)***************************************
2025-07-04 11:28:38,681 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:38,681 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:38,681 - INFO - After Normalization***************************************
2025-07-04 11:28:38,681 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:38,681 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:41,915 - INFO - Epoch 31/150 - Train Loss: 0.321032, Val Loss: 1.561920
2025-07-04 11:28:44,186 - INFO - before .to(local_rank)***************************************
2025-07-04 11:28:44,200 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:28:44,200 - INFO - After .to(local_rank)***************************************
2025-07-04 11:28:44,200 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:44,200 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:44,200 - INFO - After Normalization***************************************
2025-07-04 11:28:44,200 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:44,201 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:44,512 - INFO - before .to(local_rank)***************************************
2025-07-04 11:28:44,512 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:28:44,512 - INFO - After .to(local_rank)***************************************
2025-07-04 11:28:44,512 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:44,512 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:44,512 - INFO - After Normalization***************************************
2025-07-04 11:28:44,513 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:44,513 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:44,801 - INFO - before .to(local_rank)***************************************
2025-07-04 11:28:44,801 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:28:44,801 - INFO - After .to(local_rank)***************************************
2025-07-04 11:28:44,801 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:44,801 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:44,801 - INFO - After Normalization***************************************
2025-07-04 11:28:44,801 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:44,801 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:48,009 - INFO - Epoch 32/150 - Train Loss: 0.321487, Val Loss: 0.346940
2025-07-04 11:28:48,025 - INFO - New best model saved with Val Loss: 0.346940
2025-07-04 11:28:50,294 - INFO - before .to(local_rank)***************************************
2025-07-04 11:28:50,307 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:28:50,308 - INFO - After .to(local_rank)***************************************
2025-07-04 11:28:50,308 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:50,308 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:50,308 - INFO - After Normalization***************************************
2025-07-04 11:28:50,308 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:50,308 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:50,618 - INFO - before .to(local_rank)***************************************
2025-07-04 11:28:50,618 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:28:50,618 - INFO - After .to(local_rank)***************************************
2025-07-04 11:28:50,618 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:50,618 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:50,618 - INFO - After Normalization***************************************
2025-07-04 11:28:50,618 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:50,618 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:50,911 - INFO - before .to(local_rank)***************************************
2025-07-04 11:28:50,911 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:28:50,912 - INFO - After .to(local_rank)***************************************
2025-07-04 11:28:50,912 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:50,912 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:50,912 - INFO - After Normalization***************************************
2025-07-04 11:28:50,912 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:50,912 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:54,125 - INFO - Epoch 33/150 - Train Loss: 0.315683, Val Loss: 0.400630
2025-07-04 11:28:55,027 - INFO - Epoch 106/150 - Train Loss: 0.095847, Val Loss: 0.092196
2025-07-04 11:28:56,396 - INFO - before .to(local_rank)***************************************
2025-07-04 11:28:56,411 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:28:56,411 - INFO - After .to(local_rank)***************************************
2025-07-04 11:28:56,411 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:56,411 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:56,411 - INFO - After Normalization***************************************
2025-07-04 11:28:56,412 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:56,412 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:56,714 - INFO - before .to(local_rank)***************************************
2025-07-04 11:28:56,714 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:28:56,714 - INFO - After .to(local_rank)***************************************
2025-07-04 11:28:56,714 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:56,715 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:56,715 - INFO - After Normalization***************************************
2025-07-04 11:28:56,715 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:56,715 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:57,008 - INFO - before .to(local_rank)***************************************
2025-07-04 11:28:57,008 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:28:57,008 - INFO - After .to(local_rank)***************************************
2025-07-04 11:28:57,008 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:57,008 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:57,008 - INFO - After Normalization***************************************
2025-07-04 11:28:57,009 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:28:57,009 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:00,220 - INFO - Epoch 34/150 - Train Loss: 0.309488, Val Loss: 0.348718
2025-07-04 11:29:02,480 - INFO - before .to(local_rank)***************************************
2025-07-04 11:29:02,509 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:29:02,510 - INFO - After .to(local_rank)***************************************
2025-07-04 11:29:02,510 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:02,510 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:02,510 - INFO - After Normalization***************************************
2025-07-04 11:29:02,510 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:02,510 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:02,828 - INFO - before .to(local_rank)***************************************
2025-07-04 11:29:02,828 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:29:02,828 - INFO - After .to(local_rank)***************************************
2025-07-04 11:29:02,828 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:02,828 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:02,828 - INFO - After Normalization***************************************
2025-07-04 11:29:02,828 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:02,828 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:03,121 - INFO - before .to(local_rank)***************************************
2025-07-04 11:29:03,121 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:29:03,121 - INFO - After .to(local_rank)***************************************
2025-07-04 11:29:03,121 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:03,121 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:03,122 - INFO - After Normalization***************************************
2025-07-04 11:29:03,122 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:03,122 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:06,308 - INFO - Epoch 35/150 - Train Loss: 0.303473, Val Loss: 0.380616
2025-07-04 11:29:08,549 - INFO - before .to(local_rank)***************************************
2025-07-04 11:29:08,563 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:29:08,563 - INFO - After .to(local_rank)***************************************
2025-07-04 11:29:08,563 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:08,563 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:08,564 - INFO - After Normalization***************************************
2025-07-04 11:29:08,564 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:08,564 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:08,878 - INFO - before .to(local_rank)***************************************
2025-07-04 11:29:08,878 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:29:08,879 - INFO - After .to(local_rank)***************************************
2025-07-04 11:29:08,879 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:08,879 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:08,879 - INFO - After Normalization***************************************
2025-07-04 11:29:08,879 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:08,879 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:09,172 - INFO - before .to(local_rank)***************************************
2025-07-04 11:29:09,172 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:29:09,173 - INFO - After .to(local_rank)***************************************
2025-07-04 11:29:09,173 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:09,173 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:09,173 - INFO - After Normalization***************************************
2025-07-04 11:29:09,173 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:09,173 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:12,356 - INFO - Epoch 36/150 - Train Loss: 0.301787, Val Loss: 0.787710
2025-07-04 11:29:12,759 - INFO - Epoch 107/150 - Train Loss: 0.095251, Val Loss: 0.097188
2025-07-04 11:29:14,615 - INFO - before .to(local_rank)***************************************
2025-07-04 11:29:14,629 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:29:14,630 - INFO - After .to(local_rank)***************************************
2025-07-04 11:29:14,630 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:14,630 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:14,630 - INFO - After Normalization***************************************
2025-07-04 11:29:14,630 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:14,630 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:14,939 - INFO - before .to(local_rank)***************************************
2025-07-04 11:29:14,939 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:29:14,939 - INFO - After .to(local_rank)***************************************
2025-07-04 11:29:14,939 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:14,939 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:14,940 - INFO - After Normalization***************************************
2025-07-04 11:29:14,940 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:14,942 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:15,236 - INFO - before .to(local_rank)***************************************
2025-07-04 11:29:15,236 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:29:15,236 - INFO - After .to(local_rank)***************************************
2025-07-04 11:29:15,236 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:15,236 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:15,236 - INFO - After Normalization***************************************
2025-07-04 11:29:15,236 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:15,236 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:18,421 - INFO - Epoch 37/150 - Train Loss: 0.298016, Val Loss: 2.206627
2025-07-04 11:29:20,688 - INFO - before .to(local_rank)***************************************
2025-07-04 11:29:20,702 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:29:20,702 - INFO - After .to(local_rank)***************************************
2025-07-04 11:29:20,702 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:20,702 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:20,702 - INFO - After Normalization***************************************
2025-07-04 11:29:20,702 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:20,702 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:21,012 - INFO - before .to(local_rank)***************************************
2025-07-04 11:29:21,012 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:29:21,012 - INFO - After .to(local_rank)***************************************
2025-07-04 11:29:21,013 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:21,013 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:21,013 - INFO - After Normalization***************************************
2025-07-04 11:29:21,013 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:21,013 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:21,301 - INFO - before .to(local_rank)***************************************
2025-07-04 11:29:21,301 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:29:21,301 - INFO - After .to(local_rank)***************************************
2025-07-04 11:29:21,301 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:21,301 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:21,302 - INFO - After Normalization***************************************
2025-07-04 11:29:21,302 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:21,302 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:24,498 - INFO - Epoch 38/150 - Train Loss: 0.286918, Val Loss: 2.745399
2025-07-04 11:29:26,751 - INFO - before .to(local_rank)***************************************
2025-07-04 11:29:26,766 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:29:26,766 - INFO - After .to(local_rank)***************************************
2025-07-04 11:29:26,766 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:26,767 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:26,767 - INFO - After Normalization***************************************
2025-07-04 11:29:26,767 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:26,767 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:27,073 - INFO - before .to(local_rank)***************************************
2025-07-04 11:29:27,073 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:29:27,074 - INFO - After .to(local_rank)***************************************
2025-07-04 11:29:27,074 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:27,074 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:27,074 - INFO - After Normalization***************************************
2025-07-04 11:29:27,074 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:27,074 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:27,363 - INFO - before .to(local_rank)***************************************
2025-07-04 11:29:27,363 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:29:27,363 - INFO - After .to(local_rank)***************************************
2025-07-04 11:29:27,364 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:27,364 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:27,364 - INFO - After Normalization***************************************
2025-07-04 11:29:27,364 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:27,364 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:30,521 - INFO - Epoch 108/150 - Train Loss: 0.096115, Val Loss: 0.095816
2025-07-04 11:29:30,587 - INFO - Epoch 39/150 - Train Loss: 0.283908, Val Loss: 1.141375
2025-07-04 11:29:32,817 - INFO - before .to(local_rank)***************************************
2025-07-04 11:29:32,831 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:29:32,832 - INFO - After .to(local_rank)***************************************
2025-07-04 11:29:32,832 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:32,832 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:32,832 - INFO - After Normalization***************************************
2025-07-04 11:29:32,832 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:32,832 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:33,145 - INFO - before .to(local_rank)***************************************
2025-07-04 11:29:33,145 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:29:33,145 - INFO - After .to(local_rank)***************************************
2025-07-04 11:29:33,145 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:33,145 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:33,145 - INFO - After Normalization***************************************
2025-07-04 11:29:33,145 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:33,145 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:33,433 - INFO - before .to(local_rank)***************************************
2025-07-04 11:29:33,434 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:29:33,434 - INFO - After .to(local_rank)***************************************
2025-07-04 11:29:33,434 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:33,434 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:33,434 - INFO - After Normalization***************************************
2025-07-04 11:29:33,434 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:33,434 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:36,629 - INFO - Epoch 40/150 - Train Loss: 0.286190, Val Loss: 0.318154
2025-07-04 11:29:36,643 - INFO - New best model saved with Val Loss: 0.318154
2025-07-04 11:29:39,001 - INFO - before .to(local_rank)***************************************
2025-07-04 11:29:39,014 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:29:39,015 - INFO - After .to(local_rank)***************************************
2025-07-04 11:29:39,015 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:39,015 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:39,015 - INFO - After Normalization***************************************
2025-07-04 11:29:39,015 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:39,015 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:39,321 - INFO - before .to(local_rank)***************************************
2025-07-04 11:29:39,321 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:29:39,321 - INFO - After .to(local_rank)***************************************
2025-07-04 11:29:39,321 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:39,321 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:39,322 - INFO - After Normalization***************************************
2025-07-04 11:29:39,322 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:39,322 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:39,610 - INFO - before .to(local_rank)***************************************
2025-07-04 11:29:39,610 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:29:39,610 - INFO - After .to(local_rank)***************************************
2025-07-04 11:29:39,610 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:39,610 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:39,610 - INFO - After Normalization***************************************
2025-07-04 11:29:39,611 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:39,611 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:42,804 - INFO - Epoch 41/150 - Train Loss: 0.286844, Val Loss: 0.326355
2025-07-04 11:29:45,033 - INFO - before .to(local_rank)***************************************
2025-07-04 11:29:45,047 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:29:45,047 - INFO - After .to(local_rank)***************************************
2025-07-04 11:29:45,047 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:45,047 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:45,047 - INFO - After Normalization***************************************
2025-07-04 11:29:45,047 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:45,047 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:45,353 - INFO - before .to(local_rank)***************************************
2025-07-04 11:29:45,354 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:29:45,354 - INFO - After .to(local_rank)***************************************
2025-07-04 11:29:45,354 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:45,354 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:45,354 - INFO - After Normalization***************************************
2025-07-04 11:29:45,354 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:45,354 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:45,643 - INFO - before .to(local_rank)***************************************
2025-07-04 11:29:45,643 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:29:45,644 - INFO - After .to(local_rank)***************************************
2025-07-04 11:29:45,644 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:45,644 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:45,644 - INFO - After Normalization***************************************
2025-07-04 11:29:45,644 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:45,644 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:48,290 - INFO - Epoch 109/150 - Train Loss: 0.095379, Val Loss: 0.088785
2025-07-04 11:29:48,869 - INFO - Epoch 42/150 - Train Loss: 0.284038, Val Loss: 0.437666
2025-07-04 11:29:51,115 - INFO - before .to(local_rank)***************************************
2025-07-04 11:29:51,128 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:29:51,129 - INFO - After .to(local_rank)***************************************
2025-07-04 11:29:51,129 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:51,129 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:51,129 - INFO - After Normalization***************************************
2025-07-04 11:29:51,129 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:51,129 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:51,451 - INFO - before .to(local_rank)***************************************
2025-07-04 11:29:51,451 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:29:51,451 - INFO - After .to(local_rank)***************************************
2025-07-04 11:29:51,452 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:51,452 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:51,452 - INFO - After Normalization***************************************
2025-07-04 11:29:51,452 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:51,452 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:51,740 - INFO - before .to(local_rank)***************************************
2025-07-04 11:29:51,740 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:29:51,740 - INFO - After .to(local_rank)***************************************
2025-07-04 11:29:51,740 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:51,741 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:51,741 - INFO - After Normalization***************************************
2025-07-04 11:29:51,741 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:51,741 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:54,922 - INFO - Epoch 43/150 - Train Loss: 0.287417, Val Loss: 0.862749
2025-07-04 11:29:57,190 - INFO - before .to(local_rank)***************************************
2025-07-04 11:29:57,203 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:29:57,204 - INFO - After .to(local_rank)***************************************
2025-07-04 11:29:57,204 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:57,204 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:57,204 - INFO - After Normalization***************************************
2025-07-04 11:29:57,204 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:57,204 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:57,520 - INFO - before .to(local_rank)***************************************
2025-07-04 11:29:57,520 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:29:57,520 - INFO - After .to(local_rank)***************************************
2025-07-04 11:29:57,520 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:57,520 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:57,520 - INFO - After Normalization***************************************
2025-07-04 11:29:57,520 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:57,520 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:57,809 - INFO - before .to(local_rank)***************************************
2025-07-04 11:29:57,809 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:29:57,809 - INFO - After .to(local_rank)***************************************
2025-07-04 11:29:57,809 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:57,810 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:57,810 - INFO - After Normalization***************************************
2025-07-04 11:29:57,810 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:29:57,810 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:00,966 - INFO - Epoch 44/150 - Train Loss: 0.282725, Val Loss: 0.694332
2025-07-04 11:30:03,229 - INFO - before .to(local_rank)***************************************
2025-07-04 11:30:03,242 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:30:03,243 - INFO - After .to(local_rank)***************************************
2025-07-04 11:30:03,243 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:03,243 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:03,243 - INFO - After Normalization***************************************
2025-07-04 11:30:03,243 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:03,243 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:03,557 - INFO - before .to(local_rank)***************************************
2025-07-04 11:30:03,557 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:30:03,558 - INFO - After .to(local_rank)***************************************
2025-07-04 11:30:03,558 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:03,558 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:03,558 - INFO - After Normalization***************************************
2025-07-04 11:30:03,558 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:03,558 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:03,847 - INFO - before .to(local_rank)***************************************
2025-07-04 11:30:03,847 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:30:03,847 - INFO - After .to(local_rank)***************************************
2025-07-04 11:30:03,847 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:03,847 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:03,847 - INFO - After Normalization***************************************
2025-07-04 11:30:03,847 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:03,847 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:06,033 - INFO - Epoch 110/150 - Train Loss: 0.094124, Val Loss: 0.086502
2025-07-04 11:30:06,049 - INFO - New best model saved with Val Loss: 0.086502
2025-07-04 11:30:07,056 - INFO - Epoch 45/150 - Train Loss: 0.293271, Val Loss: 0.363853
2025-07-04 11:30:09,299 - INFO - before .to(local_rank)***************************************
2025-07-04 11:30:09,312 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:30:09,312 - INFO - After .to(local_rank)***************************************
2025-07-04 11:30:09,312 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:09,312 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:09,312 - INFO - After Normalization***************************************
2025-07-04 11:30:09,312 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:09,312 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:09,620 - INFO - before .to(local_rank)***************************************
2025-07-04 11:30:09,620 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:30:09,620 - INFO - After .to(local_rank)***************************************
2025-07-04 11:30:09,620 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:09,620 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:09,620 - INFO - After Normalization***************************************
2025-07-04 11:30:09,620 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:09,620 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:09,909 - INFO - before .to(local_rank)***************************************
2025-07-04 11:30:09,909 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:30:09,909 - INFO - After .to(local_rank)***************************************
2025-07-04 11:30:09,909 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:09,909 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:09,909 - INFO - After Normalization***************************************
2025-07-04 11:30:09,909 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:09,909 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:13,102 - INFO - Epoch 46/150 - Train Loss: 0.283596, Val Loss: 0.348534
2025-07-04 11:30:15,342 - INFO - before .to(local_rank)***************************************
2025-07-04 11:30:15,355 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:30:15,356 - INFO - After .to(local_rank)***************************************
2025-07-04 11:30:15,356 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:15,356 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:15,356 - INFO - After Normalization***************************************
2025-07-04 11:30:15,356 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:15,356 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:15,663 - INFO - before .to(local_rank)***************************************
2025-07-04 11:30:15,663 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:30:15,663 - INFO - After .to(local_rank)***************************************
2025-07-04 11:30:15,663 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:15,663 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:15,663 - INFO - After Normalization***************************************
2025-07-04 11:30:15,663 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:15,663 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:15,952 - INFO - before .to(local_rank)***************************************
2025-07-04 11:30:15,952 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:30:15,952 - INFO - After .to(local_rank)***************************************
2025-07-04 11:30:15,952 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:15,952 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:15,952 - INFO - After Normalization***************************************
2025-07-04 11:30:15,952 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:15,953 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:19,146 - INFO - Epoch 47/150 - Train Loss: 0.268562, Val Loss: 0.536266
2025-07-04 11:30:21,394 - INFO - before .to(local_rank)***************************************
2025-07-04 11:30:21,406 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:30:21,407 - INFO - After .to(local_rank)***************************************
2025-07-04 11:30:21,407 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:21,407 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:21,407 - INFO - After Normalization***************************************
2025-07-04 11:30:21,407 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:21,407 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:21,711 - INFO - before .to(local_rank)***************************************
2025-07-04 11:30:21,711 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:30:21,711 - INFO - After .to(local_rank)***************************************
2025-07-04 11:30:21,711 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:21,711 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:21,712 - INFO - After Normalization***************************************
2025-07-04 11:30:21,712 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:21,712 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:22,000 - INFO - before .to(local_rank)***************************************
2025-07-04 11:30:22,000 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:30:22,001 - INFO - After .to(local_rank)***************************************
2025-07-04 11:30:22,001 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:22,001 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:22,001 - INFO - After Normalization***************************************
2025-07-04 11:30:22,001 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:22,001 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:23,870 - INFO - Epoch 111/150 - Train Loss: 0.093858, Val Loss: 0.087059
2025-07-04 11:30:25,252 - INFO - Epoch 48/150 - Train Loss: 0.268272, Val Loss: 1.022365
2025-07-04 11:30:27,510 - INFO - before .to(local_rank)***************************************
2025-07-04 11:30:27,523 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:30:27,523 - INFO - After .to(local_rank)***************************************
2025-07-04 11:30:27,524 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:27,524 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:27,524 - INFO - After Normalization***************************************
2025-07-04 11:30:27,524 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:27,524 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:27,840 - INFO - before .to(local_rank)***************************************
2025-07-04 11:30:27,840 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:30:27,840 - INFO - After .to(local_rank)***************************************
2025-07-04 11:30:27,841 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:27,841 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:27,841 - INFO - After Normalization***************************************
2025-07-04 11:30:27,841 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:27,841 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:28,129 - INFO - before .to(local_rank)***************************************
2025-07-04 11:30:28,129 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:30:28,129 - INFO - After .to(local_rank)***************************************
2025-07-04 11:30:28,129 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:28,129 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:28,130 - INFO - After Normalization***************************************
2025-07-04 11:30:28,130 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:28,130 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:31,329 - INFO - Epoch 49/150 - Train Loss: 0.265477, Val Loss: 1.328436
2025-07-04 11:30:33,581 - INFO - before .to(local_rank)***************************************
2025-07-04 11:30:33,595 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:30:33,596 - INFO - After .to(local_rank)***************************************
2025-07-04 11:30:33,596 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:33,596 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:33,596 - INFO - After Normalization***************************************
2025-07-04 11:30:33,596 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:33,596 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:33,906 - INFO - before .to(local_rank)***************************************
2025-07-04 11:30:33,906 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:30:33,906 - INFO - After .to(local_rank)***************************************
2025-07-04 11:30:33,906 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:33,907 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:33,907 - INFO - After Normalization***************************************
2025-07-04 11:30:33,907 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:33,907 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:34,195 - INFO - before .to(local_rank)***************************************
2025-07-04 11:30:34,195 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:30:34,195 - INFO - After .to(local_rank)***************************************
2025-07-04 11:30:34,195 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:34,196 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:34,196 - INFO - After Normalization***************************************
2025-07-04 11:30:34,196 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:34,196 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:37,383 - INFO - Epoch 50/150 - Train Loss: 0.256372, Val Loss: 0.734287
2025-07-04 11:30:39,772 - INFO - before .to(local_rank)***************************************
2025-07-04 11:30:39,785 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:30:39,786 - INFO - After .to(local_rank)***************************************
2025-07-04 11:30:39,786 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:39,786 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:39,786 - INFO - After Normalization***************************************
2025-07-04 11:30:39,786 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:39,786 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:40,102 - INFO - before .to(local_rank)***************************************
2025-07-04 11:30:40,102 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:30:40,102 - INFO - After .to(local_rank)***************************************
2025-07-04 11:30:40,102 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:40,102 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:40,102 - INFO - After Normalization***************************************
2025-07-04 11:30:40,102 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:40,102 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:40,391 - INFO - before .to(local_rank)***************************************
2025-07-04 11:30:40,391 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:30:40,391 - INFO - After .to(local_rank)***************************************
2025-07-04 11:30:40,391 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:40,391 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:40,392 - INFO - After Normalization***************************************
2025-07-04 11:30:40,392 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:40,392 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:41,594 - INFO - Epoch 112/150 - Train Loss: 0.094762, Val Loss: 0.086803
2025-07-04 11:30:43,611 - INFO - Epoch 51/150 - Train Loss: 0.254741, Val Loss: 1.214569
2025-07-04 11:30:45,854 - INFO - before .to(local_rank)***************************************
2025-07-04 11:30:45,870 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:30:45,870 - INFO - After .to(local_rank)***************************************
2025-07-04 11:30:45,870 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:45,870 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:45,871 - INFO - After Normalization***************************************
2025-07-04 11:30:45,871 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:45,871 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:46,178 - INFO - before .to(local_rank)***************************************
2025-07-04 11:30:46,178 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:30:46,179 - INFO - After .to(local_rank)***************************************
2025-07-04 11:30:46,179 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:46,179 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:46,179 - INFO - After Normalization***************************************
2025-07-04 11:30:46,179 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:46,179 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:46,467 - INFO - before .to(local_rank)***************************************
2025-07-04 11:30:46,467 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:30:46,468 - INFO - After .to(local_rank)***************************************
2025-07-04 11:30:46,468 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:46,468 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:46,468 - INFO - After Normalization***************************************
2025-07-04 11:30:46,468 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:46,468 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:49,663 - INFO - Epoch 52/150 - Train Loss: 0.251523, Val Loss: 0.768222
2025-07-04 11:30:51,904 - INFO - before .to(local_rank)***************************************
2025-07-04 11:30:51,919 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:30:51,919 - INFO - After .to(local_rank)***************************************
2025-07-04 11:30:51,919 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:51,919 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:51,919 - INFO - After Normalization***************************************
2025-07-04 11:30:51,919 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:51,919 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:52,226 - INFO - before .to(local_rank)***************************************
2025-07-04 11:30:52,226 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:30:52,227 - INFO - After .to(local_rank)***************************************
2025-07-04 11:30:52,227 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:52,227 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:52,227 - INFO - After Normalization***************************************
2025-07-04 11:30:52,227 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:52,227 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:52,515 - INFO - before .to(local_rank)***************************************
2025-07-04 11:30:52,515 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:30:52,515 - INFO - After .to(local_rank)***************************************
2025-07-04 11:30:52,516 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:52,516 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:52,516 - INFO - After Normalization***************************************
2025-07-04 11:30:52,516 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:52,516 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:55,757 - INFO - Epoch 53/150 - Train Loss: 0.239440, Val Loss: 0.476771
2025-07-04 11:30:58,004 - INFO - before .to(local_rank)***************************************
2025-07-04 11:30:58,018 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:30:58,019 - INFO - After .to(local_rank)***************************************
2025-07-04 11:30:58,019 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:58,019 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:58,019 - INFO - After Normalization***************************************
2025-07-04 11:30:58,019 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:58,019 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:58,319 - INFO - before .to(local_rank)***************************************
2025-07-04 11:30:58,319 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:30:58,320 - INFO - After .to(local_rank)***************************************
2025-07-04 11:30:58,320 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:58,320 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:58,320 - INFO - After Normalization***************************************
2025-07-04 11:30:58,320 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:58,320 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:58,613 - INFO - before .to(local_rank)***************************************
2025-07-04 11:30:58,613 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:30:58,613 - INFO - After .to(local_rank)***************************************
2025-07-04 11:30:58,614 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:58,614 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:58,614 - INFO - After Normalization***************************************
2025-07-04 11:30:58,614 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:58,614 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:30:59,352 - INFO - Epoch 113/150 - Train Loss: 0.094220, Val Loss: 0.086305
2025-07-04 11:30:59,367 - INFO - New best model saved with Val Loss: 0.086305
2025-07-04 11:31:01,837 - INFO - Epoch 54/150 - Train Loss: 0.240818, Val Loss: 0.354884
2025-07-04 11:31:04,099 - INFO - before .to(local_rank)***************************************
2025-07-04 11:31:04,113 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:31:04,113 - INFO - After .to(local_rank)***************************************
2025-07-04 11:31:04,113 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:04,113 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:04,113 - INFO - After Normalization***************************************
2025-07-04 11:31:04,114 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:04,114 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:04,427 - INFO - before .to(local_rank)***************************************
2025-07-04 11:31:04,427 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:31:04,427 - INFO - After .to(local_rank)***************************************
2025-07-04 11:31:04,427 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:04,427 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:04,427 - INFO - After Normalization***************************************
2025-07-04 11:31:04,427 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:04,427 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:04,720 - INFO - before .to(local_rank)***************************************
2025-07-04 11:31:04,720 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:31:04,721 - INFO - After .to(local_rank)***************************************
2025-07-04 11:31:04,721 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:04,721 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:04,721 - INFO - After Normalization***************************************
2025-07-04 11:31:04,721 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:04,721 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:07,910 - INFO - Epoch 55/150 - Train Loss: 0.240019, Val Loss: 0.299964
2025-07-04 11:31:07,926 - INFO - New best model saved with Val Loss: 0.299964
2025-07-04 11:31:10,191 - INFO - before .to(local_rank)***************************************
2025-07-04 11:31:10,206 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:31:10,206 - INFO - After .to(local_rank)***************************************
2025-07-04 11:31:10,206 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:10,206 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:10,206 - INFO - After Normalization***************************************
2025-07-04 11:31:10,206 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:10,206 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:10,512 - INFO - before .to(local_rank)***************************************
2025-07-04 11:31:10,512 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:31:10,513 - INFO - After .to(local_rank)***************************************
2025-07-04 11:31:10,513 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:10,513 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:10,513 - INFO - After Normalization***************************************
2025-07-04 11:31:10,513 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:10,513 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:10,807 - INFO - before .to(local_rank)***************************************
2025-07-04 11:31:10,807 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:31:10,807 - INFO - After .to(local_rank)***************************************
2025-07-04 11:31:10,807 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:10,807 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:10,807 - INFO - After Normalization***************************************
2025-07-04 11:31:10,807 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:10,807 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:14,014 - INFO - Epoch 56/150 - Train Loss: 0.238060, Val Loss: 0.274806
2025-07-04 11:31:14,030 - INFO - New best model saved with Val Loss: 0.274806
2025-07-04 11:31:16,268 - INFO - before .to(local_rank)***************************************
2025-07-04 11:31:16,282 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:31:16,283 - INFO - After .to(local_rank)***************************************
2025-07-04 11:31:16,283 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:16,283 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:16,283 - INFO - After Normalization***************************************
2025-07-04 11:31:16,283 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:16,283 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:16,585 - INFO - before .to(local_rank)***************************************
2025-07-04 11:31:16,585 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:31:16,585 - INFO - After .to(local_rank)***************************************
2025-07-04 11:31:16,585 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:16,585 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:16,585 - INFO - After Normalization***************************************
2025-07-04 11:31:16,585 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:16,585 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:16,879 - INFO - before .to(local_rank)***************************************
2025-07-04 11:31:16,879 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:31:16,879 - INFO - After .to(local_rank)***************************************
2025-07-04 11:31:16,879 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:16,879 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:16,879 - INFO - After Normalization***************************************
2025-07-04 11:31:16,879 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:16,879 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:17,098 - INFO - Epoch 114/150 - Train Loss: 0.093979, Val Loss: 0.086554
2025-07-04 11:31:20,072 - INFO - Epoch 57/150 - Train Loss: 0.236272, Val Loss: 0.257384
2025-07-04 11:31:20,087 - INFO - New best model saved with Val Loss: 0.257384
2025-07-04 11:31:22,348 - INFO - before .to(local_rank)***************************************
2025-07-04 11:31:22,361 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:31:22,362 - INFO - After .to(local_rank)***************************************
2025-07-04 11:31:22,362 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:22,362 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:22,362 - INFO - After Normalization***************************************
2025-07-04 11:31:22,362 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:22,362 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:22,680 - INFO - before .to(local_rank)***************************************
2025-07-04 11:31:22,681 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:31:22,681 - INFO - After .to(local_rank)***************************************
2025-07-04 11:31:22,681 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:22,681 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:22,681 - INFO - After Normalization***************************************
2025-07-04 11:31:22,681 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:22,681 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:22,974 - INFO - before .to(local_rank)***************************************
2025-07-04 11:31:22,974 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:31:22,974 - INFO - After .to(local_rank)***************************************
2025-07-04 11:31:22,974 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:22,974 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:22,974 - INFO - After Normalization***************************************
2025-07-04 11:31:22,974 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:22,974 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:26,155 - INFO - Epoch 58/150 - Train Loss: 0.239714, Val Loss: 0.249452
2025-07-04 11:31:26,169 - INFO - New best model saved with Val Loss: 0.249452
2025-07-04 11:31:28,419 - INFO - before .to(local_rank)***************************************
2025-07-04 11:31:28,433 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:31:28,434 - INFO - After .to(local_rank)***************************************
2025-07-04 11:31:28,434 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:28,434 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:28,434 - INFO - After Normalization***************************************
2025-07-04 11:31:28,434 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:28,434 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:28,747 - INFO - before .to(local_rank)***************************************
2025-07-04 11:31:28,747 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:31:28,747 - INFO - After .to(local_rank)***************************************
2025-07-04 11:31:28,748 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:28,748 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:28,748 - INFO - After Normalization***************************************
2025-07-04 11:31:28,748 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:28,748 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:29,041 - INFO - before .to(local_rank)***************************************
2025-07-04 11:31:29,041 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:31:29,041 - INFO - After .to(local_rank)***************************************
2025-07-04 11:31:29,041 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:29,041 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:29,041 - INFO - After Normalization***************************************
2025-07-04 11:31:29,041 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:29,041 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:32,280 - INFO - Epoch 59/150 - Train Loss: 0.234231, Val Loss: 0.246667
2025-07-04 11:31:32,295 - INFO - New best model saved with Val Loss: 0.246667
2025-07-04 11:31:34,548 - INFO - before .to(local_rank)***************************************
2025-07-04 11:31:34,562 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:31:34,562 - INFO - After .to(local_rank)***************************************
2025-07-04 11:31:34,562 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:34,562 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:34,562 - INFO - After Normalization***************************************
2025-07-04 11:31:34,562 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:34,562 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:34,810 - INFO - Epoch 115/150 - Train Loss: 0.093502, Val Loss: 0.086534
2025-07-04 11:31:34,869 - INFO - before .to(local_rank)***************************************
2025-07-04 11:31:34,869 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:31:34,870 - INFO - After .to(local_rank)***************************************
2025-07-04 11:31:34,870 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:34,870 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:34,870 - INFO - After Normalization***************************************
2025-07-04 11:31:34,870 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:34,870 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:35,159 - INFO - before .to(local_rank)***************************************
2025-07-04 11:31:35,159 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:31:35,160 - INFO - After .to(local_rank)***************************************
2025-07-04 11:31:35,160 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:35,160 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:35,160 - INFO - After Normalization***************************************
2025-07-04 11:31:35,160 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:35,160 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:38,340 - INFO - Epoch 60/150 - Train Loss: 0.234758, Val Loss: 0.247478
2025-07-04 11:31:40,717 - INFO - before .to(local_rank)***************************************
2025-07-04 11:31:40,731 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:31:40,731 - INFO - After .to(local_rank)***************************************
2025-07-04 11:31:40,731 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:40,731 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:40,731 - INFO - After Normalization***************************************
2025-07-04 11:31:40,731 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:40,731 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:41,042 - INFO - before .to(local_rank)***************************************
2025-07-04 11:31:41,042 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:31:41,042 - INFO - After .to(local_rank)***************************************
2025-07-04 11:31:41,042 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:41,042 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:41,042 - INFO - After Normalization***************************************
2025-07-04 11:31:41,042 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:41,043 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:41,331 - INFO - before .to(local_rank)***************************************
2025-07-04 11:31:41,331 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:31:41,331 - INFO - After .to(local_rank)***************************************
2025-07-04 11:31:41,331 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:41,331 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:41,331 - INFO - After Normalization***************************************
2025-07-04 11:31:41,331 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:41,331 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:44,539 - INFO - Epoch 61/150 - Train Loss: 0.233135, Val Loss: 0.252457
2025-07-04 11:31:46,795 - INFO - before .to(local_rank)***************************************
2025-07-04 11:31:46,809 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:31:46,809 - INFO - After .to(local_rank)***************************************
2025-07-04 11:31:46,809 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:46,809 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:46,809 - INFO - After Normalization***************************************
2025-07-04 11:31:46,809 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:46,809 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:47,116 - INFO - before .to(local_rank)***************************************
2025-07-04 11:31:47,116 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:31:47,117 - INFO - After .to(local_rank)***************************************
2025-07-04 11:31:47,117 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:47,117 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:47,117 - INFO - After Normalization***************************************
2025-07-04 11:31:47,117 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:47,117 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:47,405 - INFO - before .to(local_rank)***************************************
2025-07-04 11:31:47,405 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:31:47,406 - INFO - After .to(local_rank)***************************************
2025-07-04 11:31:47,406 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:47,406 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:47,406 - INFO - After Normalization***************************************
2025-07-04 11:31:47,406 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:47,406 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:50,593 - INFO - Epoch 62/150 - Train Loss: 0.232894, Val Loss: 0.257394
2025-07-04 11:31:52,554 - INFO - Epoch 116/150 - Train Loss: 0.093854, Val Loss: 0.086689
2025-07-04 11:31:52,833 - INFO - before .to(local_rank)***************************************
2025-07-04 11:31:52,847 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:31:52,847 - INFO - After .to(local_rank)***************************************
2025-07-04 11:31:52,847 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:52,847 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:52,848 - INFO - After Normalization***************************************
2025-07-04 11:31:52,848 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:52,848 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:53,153 - INFO - before .to(local_rank)***************************************
2025-07-04 11:31:53,153 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:31:53,154 - INFO - After .to(local_rank)***************************************
2025-07-04 11:31:53,154 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:53,154 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:53,154 - INFO - After Normalization***************************************
2025-07-04 11:31:53,154 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:53,154 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:53,443 - INFO - before .to(local_rank)***************************************
2025-07-04 11:31:53,443 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:31:53,443 - INFO - After .to(local_rank)***************************************
2025-07-04 11:31:53,444 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:53,444 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:53,444 - INFO - After Normalization***************************************
2025-07-04 11:31:53,444 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:53,444 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:56,647 - INFO - Epoch 63/150 - Train Loss: 0.233125, Val Loss: 0.255208
2025-07-04 11:31:58,899 - INFO - before .to(local_rank)***************************************
2025-07-04 11:31:58,912 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:31:58,912 - INFO - After .to(local_rank)***************************************
2025-07-04 11:31:58,912 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:58,912 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:58,912 - INFO - After Normalization***************************************
2025-07-04 11:31:58,912 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:58,912 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:59,221 - INFO - before .to(local_rank)***************************************
2025-07-04 11:31:59,221 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:31:59,222 - INFO - After .to(local_rank)***************************************
2025-07-04 11:31:59,222 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:59,222 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:59,222 - INFO - After Normalization***************************************
2025-07-04 11:31:59,222 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:59,222 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:59,510 - INFO - before .to(local_rank)***************************************
2025-07-04 11:31:59,510 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:31:59,511 - INFO - After .to(local_rank)***************************************
2025-07-04 11:31:59,511 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:59,511 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:59,511 - INFO - After Normalization***************************************
2025-07-04 11:31:59,511 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:31:59,511 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:02,706 - INFO - Epoch 64/150 - Train Loss: 0.234421, Val Loss: 0.255270
2025-07-04 11:32:04,950 - INFO - before .to(local_rank)***************************************
2025-07-04 11:32:04,963 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:32:04,964 - INFO - After .to(local_rank)***************************************
2025-07-04 11:32:04,964 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:04,964 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:04,964 - INFO - After Normalization***************************************
2025-07-04 11:32:04,964 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:04,964 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:05,282 - INFO - before .to(local_rank)***************************************
2025-07-04 11:32:05,282 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:32:05,282 - INFO - After .to(local_rank)***************************************
2025-07-04 11:32:05,282 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:05,282 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:05,283 - INFO - After Normalization***************************************
2025-07-04 11:32:05,283 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:05,283 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:05,571 - INFO - before .to(local_rank)***************************************
2025-07-04 11:32:05,571 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:32:05,571 - INFO - After .to(local_rank)***************************************
2025-07-04 11:32:05,571 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:05,571 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:05,572 - INFO - After Normalization***************************************
2025-07-04 11:32:05,572 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:05,572 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:08,788 - INFO - Epoch 65/150 - Train Loss: 0.234516, Val Loss: 0.252954
2025-07-04 11:32:10,308 - INFO - Epoch 117/150 - Train Loss: 0.093443, Val Loss: 0.086520
2025-07-04 11:32:11,032 - INFO - before .to(local_rank)***************************************
2025-07-04 11:32:11,046 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:32:11,046 - INFO - After .to(local_rank)***************************************
2025-07-04 11:32:11,046 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:11,046 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:11,046 - INFO - After Normalization***************************************
2025-07-04 11:32:11,047 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:11,047 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:11,357 - INFO - before .to(local_rank)***************************************
2025-07-04 11:32:11,357 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:32:11,358 - INFO - After .to(local_rank)***************************************
2025-07-04 11:32:11,358 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:11,358 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:11,358 - INFO - After Normalization***************************************
2025-07-04 11:32:11,358 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:11,358 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:11,647 - INFO - before .to(local_rank)***************************************
2025-07-04 11:32:11,647 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:32:11,648 - INFO - After .to(local_rank)***************************************
2025-07-04 11:32:11,648 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:11,648 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:11,648 - INFO - After Normalization***************************************
2025-07-04 11:32:11,648 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:11,648 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:14,826 - INFO - Epoch 66/150 - Train Loss: 0.231194, Val Loss: 0.250868
2025-07-04 11:32:17,087 - INFO - before .to(local_rank)***************************************
2025-07-04 11:32:17,101 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:32:17,101 - INFO - After .to(local_rank)***************************************
2025-07-04 11:32:17,101 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:17,101 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:17,101 - INFO - After Normalization***************************************
2025-07-04 11:32:17,101 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:17,102 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:17,409 - INFO - before .to(local_rank)***************************************
2025-07-04 11:32:17,409 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:32:17,410 - INFO - After .to(local_rank)***************************************
2025-07-04 11:32:17,410 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:17,410 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:17,410 - INFO - After Normalization***************************************
2025-07-04 11:32:17,410 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:17,410 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:17,698 - INFO - before .to(local_rank)***************************************
2025-07-04 11:32:17,698 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:32:17,699 - INFO - After .to(local_rank)***************************************
2025-07-04 11:32:17,699 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:17,699 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:17,699 - INFO - After Normalization***************************************
2025-07-04 11:32:17,699 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:17,699 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:20,899 - INFO - Epoch 67/150 - Train Loss: 0.230656, Val Loss: 0.250073
2025-07-04 11:32:23,161 - INFO - before .to(local_rank)***************************************
2025-07-04 11:32:23,174 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:32:23,175 - INFO - After .to(local_rank)***************************************
2025-07-04 11:32:23,175 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:23,175 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:23,175 - INFO - After Normalization***************************************
2025-07-04 11:32:23,175 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:23,175 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:23,479 - INFO - before .to(local_rank)***************************************
2025-07-04 11:32:23,479 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:32:23,479 - INFO - After .to(local_rank)***************************************
2025-07-04 11:32:23,479 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:23,479 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:23,479 - INFO - After Normalization***************************************
2025-07-04 11:32:23,479 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:23,479 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:23,768 - INFO - before .to(local_rank)***************************************
2025-07-04 11:32:23,768 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:32:23,768 - INFO - After .to(local_rank)***************************************
2025-07-04 11:32:23,768 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:23,768 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:23,768 - INFO - After Normalization***************************************
2025-07-04 11:32:23,768 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:23,768 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:26,967 - INFO - Epoch 68/150 - Train Loss: 0.229500, Val Loss: 0.250125
2025-07-04 11:32:28,042 - INFO - Epoch 118/150 - Train Loss: 0.093456, Val Loss: 0.086879
2025-07-04 11:32:29,246 - INFO - before .to(local_rank)***************************************
2025-07-04 11:32:29,259 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:32:29,260 - INFO - After .to(local_rank)***************************************
2025-07-04 11:32:29,260 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:29,260 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:29,260 - INFO - After Normalization***************************************
2025-07-04 11:32:29,260 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:29,260 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:29,565 - INFO - before .to(local_rank)***************************************
2025-07-04 11:32:29,565 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:32:29,566 - INFO - After .to(local_rank)***************************************
2025-07-04 11:32:29,566 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:29,566 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:29,566 - INFO - After Normalization***************************************
2025-07-04 11:32:29,566 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:29,566 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:29,854 - INFO - before .to(local_rank)***************************************
2025-07-04 11:32:29,854 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:32:29,855 - INFO - After .to(local_rank)***************************************
2025-07-04 11:32:29,855 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:29,855 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:29,855 - INFO - After Normalization***************************************
2025-07-04 11:32:29,855 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:29,855 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:33,066 - INFO - Epoch 69/150 - Train Loss: 0.230819, Val Loss: 0.247301
2025-07-04 11:32:35,298 - INFO - before .to(local_rank)***************************************
2025-07-04 11:32:35,311 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:32:35,312 - INFO - After .to(local_rank)***************************************
2025-07-04 11:32:35,312 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:35,312 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:35,312 - INFO - After Normalization***************************************
2025-07-04 11:32:35,312 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:35,312 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:35,630 - INFO - before .to(local_rank)***************************************
2025-07-04 11:32:35,630 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:32:35,630 - INFO - After .to(local_rank)***************************************
2025-07-04 11:32:35,630 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:35,630 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:35,630 - INFO - After Normalization***************************************
2025-07-04 11:32:35,630 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:35,630 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:35,919 - INFO - before .to(local_rank)***************************************
2025-07-04 11:32:35,919 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:32:35,919 - INFO - After .to(local_rank)***************************************
2025-07-04 11:32:35,919 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:35,919 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:35,919 - INFO - After Normalization***************************************
2025-07-04 11:32:35,919 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:35,919 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:39,114 - INFO - Epoch 70/150 - Train Loss: 0.228859, Val Loss: 0.245401
2025-07-04 11:32:39,127 - INFO - New best model saved with Val Loss: 0.245401
2025-07-04 11:32:41,486 - INFO - before .to(local_rank)***************************************
2025-07-04 11:32:41,499 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:32:41,500 - INFO - After .to(local_rank)***************************************
2025-07-04 11:32:41,500 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:41,500 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:41,500 - INFO - After Normalization***************************************
2025-07-04 11:32:41,500 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:41,500 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:41,801 - INFO - before .to(local_rank)***************************************
2025-07-04 11:32:41,801 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:32:41,801 - INFO - After .to(local_rank)***************************************
2025-07-04 11:32:41,801 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:41,801 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:41,802 - INFO - After Normalization***************************************
2025-07-04 11:32:41,802 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:41,802 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:42,091 - INFO - before .to(local_rank)***************************************
2025-07-04 11:32:42,091 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:32:42,091 - INFO - After .to(local_rank)***************************************
2025-07-04 11:32:42,091 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:42,091 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:42,092 - INFO - After Normalization***************************************
2025-07-04 11:32:42,092 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:42,092 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:45,302 - INFO - Epoch 71/150 - Train Loss: 0.228805, Val Loss: 0.245921
2025-07-04 11:32:45,800 - INFO - Epoch 119/150 - Train Loss: 0.093429, Val Loss: 0.086754
2025-07-04 11:32:47,558 - INFO - before .to(local_rank)***************************************
2025-07-04 11:32:47,572 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:32:47,572 - INFO - After .to(local_rank)***************************************
2025-07-04 11:32:47,572 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:47,572 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:47,572 - INFO - After Normalization***************************************
2025-07-04 11:32:47,572 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:47,572 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:47,890 - INFO - before .to(local_rank)***************************************
2025-07-04 11:32:47,890 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:32:47,890 - INFO - After .to(local_rank)***************************************
2025-07-04 11:32:47,890 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:47,890 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:47,890 - INFO - After Normalization***************************************
2025-07-04 11:32:47,890 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:47,890 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:48,182 - INFO - before .to(local_rank)***************************************
2025-07-04 11:32:48,183 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:32:48,183 - INFO - After .to(local_rank)***************************************
2025-07-04 11:32:48,183 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:48,183 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:48,183 - INFO - After Normalization***************************************
2025-07-04 11:32:48,183 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:48,183 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:51,373 - INFO - Epoch 72/150 - Train Loss: 0.229246, Val Loss: 0.244591
2025-07-04 11:32:51,388 - INFO - New best model saved with Val Loss: 0.244591
2025-07-04 11:32:53,625 - INFO - before .to(local_rank)***************************************
2025-07-04 11:32:53,638 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:32:53,639 - INFO - After .to(local_rank)***************************************
2025-07-04 11:32:53,639 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:53,639 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:53,639 - INFO - After Normalization***************************************
2025-07-04 11:32:53,639 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:53,639 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:53,952 - INFO - before .to(local_rank)***************************************
2025-07-04 11:32:53,952 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:32:53,952 - INFO - After .to(local_rank)***************************************
2025-07-04 11:32:53,952 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:53,952 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:53,952 - INFO - After Normalization***************************************
2025-07-04 11:32:53,952 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:53,952 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:54,244 - INFO - before .to(local_rank)***************************************
2025-07-04 11:32:54,244 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:32:54,244 - INFO - After .to(local_rank)***************************************
2025-07-04 11:32:54,244 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:54,244 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:54,244 - INFO - After Normalization***************************************
2025-07-04 11:32:54,244 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:54,244 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:57,452 - INFO - Epoch 73/150 - Train Loss: 0.228147, Val Loss: 0.242999
2025-07-04 11:32:57,466 - INFO - New best model saved with Val Loss: 0.242999
2025-07-04 11:32:59,726 - INFO - before .to(local_rank)***************************************
2025-07-04 11:32:59,740 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:32:59,740 - INFO - After .to(local_rank)***************************************
2025-07-04 11:32:59,740 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:59,740 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:59,740 - INFO - After Normalization***************************************
2025-07-04 11:32:59,740 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:32:59,740 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:00,045 - INFO - before .to(local_rank)***************************************
2025-07-04 11:33:00,046 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:33:00,046 - INFO - After .to(local_rank)***************************************
2025-07-04 11:33:00,046 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:00,046 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:00,046 - INFO - After Normalization***************************************
2025-07-04 11:33:00,046 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:00,046 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:00,338 - INFO - before .to(local_rank)***************************************
2025-07-04 11:33:00,338 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:33:00,339 - INFO - After .to(local_rank)***************************************
2025-07-04 11:33:00,339 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:00,339 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:00,339 - INFO - After Normalization***************************************
2025-07-04 11:33:00,339 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:00,339 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:03,541 - INFO - Epoch 120/150 - Train Loss: 0.093038, Val Loss: 0.086636
2025-07-04 11:33:03,573 - INFO - Epoch 74/150 - Train Loss: 0.227171, Val Loss: 0.242266
2025-07-04 11:33:03,588 - INFO - New best model saved with Val Loss: 0.242266
2025-07-04 11:33:05,845 - INFO - before .to(local_rank)***************************************
2025-07-04 11:33:05,859 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:33:05,859 - INFO - After .to(local_rank)***************************************
2025-07-04 11:33:05,859 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:05,859 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:05,859 - INFO - After Normalization***************************************
2025-07-04 11:33:05,859 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:05,859 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:06,178 - INFO - before .to(local_rank)***************************************
2025-07-04 11:33:06,178 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:33:06,178 - INFO - After .to(local_rank)***************************************
2025-07-04 11:33:06,178 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:06,178 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:06,179 - INFO - After Normalization***************************************
2025-07-04 11:33:06,179 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:06,179 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:06,471 - INFO - before .to(local_rank)***************************************
2025-07-04 11:33:06,471 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:33:06,471 - INFO - After .to(local_rank)***************************************
2025-07-04 11:33:06,471 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:06,471 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:06,471 - INFO - After Normalization***************************************
2025-07-04 11:33:06,471 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:06,471 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:09,689 - INFO - Epoch 75/150 - Train Loss: 0.227594, Val Loss: 0.240315
2025-07-04 11:33:09,703 - INFO - New best model saved with Val Loss: 0.240315
2025-07-04 11:33:11,955 - INFO - before .to(local_rank)***************************************
2025-07-04 11:33:11,968 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:33:11,969 - INFO - After .to(local_rank)***************************************
2025-07-04 11:33:11,969 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:11,969 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:11,969 - INFO - After Normalization***************************************
2025-07-04 11:33:11,969 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:11,969 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:12,277 - INFO - before .to(local_rank)***************************************
2025-07-04 11:33:12,277 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:33:12,277 - INFO - After .to(local_rank)***************************************
2025-07-04 11:33:12,277 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:12,277 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:12,277 - INFO - After Normalization***************************************
2025-07-04 11:33:12,277 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:12,277 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:12,569 - INFO - before .to(local_rank)***************************************
2025-07-04 11:33:12,569 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:33:12,569 - INFO - After .to(local_rank)***************************************
2025-07-04 11:33:12,569 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:12,569 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:12,569 - INFO - After Normalization***************************************
2025-07-04 11:33:12,569 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:12,570 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:15,769 - INFO - Epoch 76/150 - Train Loss: 0.226053, Val Loss: 0.238202
2025-07-04 11:33:15,783 - INFO - New best model saved with Val Loss: 0.238202
2025-07-04 11:33:18,039 - INFO - before .to(local_rank)***************************************
2025-07-04 11:33:18,053 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:33:18,053 - INFO - After .to(local_rank)***************************************
2025-07-04 11:33:18,053 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:18,053 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:18,053 - INFO - After Normalization***************************************
2025-07-04 11:33:18,053 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:18,053 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:18,359 - INFO - before .to(local_rank)***************************************
2025-07-04 11:33:18,359 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:33:18,359 - INFO - After .to(local_rank)***************************************
2025-07-04 11:33:18,359 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:18,359 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:18,359 - INFO - After Normalization***************************************
2025-07-04 11:33:18,359 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:18,359 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:18,648 - INFO - before .to(local_rank)***************************************
2025-07-04 11:33:18,648 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:33:18,649 - INFO - After .to(local_rank)***************************************
2025-07-04 11:33:18,649 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:18,649 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:18,649 - INFO - After Normalization***************************************
2025-07-04 11:33:18,649 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:18,649 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:21,376 - INFO - Epoch 121/150 - Train Loss: 0.093188, Val Loss: 0.086384
2025-07-04 11:33:21,848 - INFO - Epoch 77/150 - Train Loss: 0.225167, Val Loss: 0.238969
2025-07-04 11:33:24,091 - INFO - before .to(local_rank)***************************************
2025-07-04 11:33:24,104 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:33:24,105 - INFO - After .to(local_rank)***************************************
2025-07-04 11:33:24,105 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:24,105 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:24,105 - INFO - After Normalization***************************************
2025-07-04 11:33:24,105 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:24,105 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:24,410 - INFO - before .to(local_rank)***************************************
2025-07-04 11:33:24,410 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:33:24,410 - INFO - After .to(local_rank)***************************************
2025-07-04 11:33:24,410 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:24,410 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:24,411 - INFO - After Normalization***************************************
2025-07-04 11:33:24,411 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:24,411 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:24,699 - INFO - before .to(local_rank)***************************************
2025-07-04 11:33:24,699 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:33:24,699 - INFO - After .to(local_rank)***************************************
2025-07-04 11:33:24,699 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:24,699 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:24,699 - INFO - After Normalization***************************************
2025-07-04 11:33:24,699 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:24,700 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:27,884 - INFO - Epoch 78/150 - Train Loss: 0.231253, Val Loss: 0.240782
2025-07-04 11:33:30,132 - INFO - before .to(local_rank)***************************************
2025-07-04 11:33:30,146 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:33:30,146 - INFO - After .to(local_rank)***************************************
2025-07-04 11:33:30,147 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:30,147 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:30,147 - INFO - After Normalization***************************************
2025-07-04 11:33:30,147 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:30,147 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:30,467 - INFO - before .to(local_rank)***************************************
2025-07-04 11:33:30,467 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:33:30,467 - INFO - After .to(local_rank)***************************************
2025-07-04 11:33:30,467 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:30,467 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:30,467 - INFO - After Normalization***************************************
2025-07-04 11:33:30,467 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:30,467 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:30,756 - INFO - before .to(local_rank)***************************************
2025-07-04 11:33:30,756 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:33:30,756 - INFO - After .to(local_rank)***************************************
2025-07-04 11:33:30,756 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:30,756 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:30,756 - INFO - After Normalization***************************************
2025-07-04 11:33:30,756 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:30,756 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:33,938 - INFO - Epoch 79/150 - Train Loss: 0.223478, Val Loss: 0.243409
2025-07-04 11:33:36,198 - INFO - before .to(local_rank)***************************************
2025-07-04 11:33:36,213 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:33:36,213 - INFO - After .to(local_rank)***************************************
2025-07-04 11:33:36,213 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:36,213 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:36,213 - INFO - After Normalization***************************************
2025-07-04 11:33:36,213 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:36,213 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:36,533 - INFO - before .to(local_rank)***************************************
2025-07-04 11:33:36,533 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:33:36,533 - INFO - After .to(local_rank)***************************************
2025-07-04 11:33:36,533 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:36,533 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:36,533 - INFO - After Normalization***************************************
2025-07-04 11:33:36,533 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:36,533 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:36,822 - INFO - before .to(local_rank)***************************************
2025-07-04 11:33:36,822 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:33:36,823 - INFO - After .to(local_rank)***************************************
2025-07-04 11:33:36,823 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:36,823 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:36,823 - INFO - After Normalization***************************************
2025-07-04 11:33:36,823 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:36,823 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:39,097 - INFO - Epoch 122/150 - Train Loss: 0.093174, Val Loss: 0.086662
2025-07-04 11:33:40,045 - INFO - Epoch 80/150 - Train Loss: 0.224525, Val Loss: 0.241048
2025-07-04 11:33:42,411 - INFO - before .to(local_rank)***************************************
2025-07-04 11:33:42,425 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:33:42,426 - INFO - After .to(local_rank)***************************************
2025-07-04 11:33:42,426 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:42,426 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:42,426 - INFO - After Normalization***************************************
2025-07-04 11:33:42,426 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:42,426 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:42,747 - INFO - before .to(local_rank)***************************************
2025-07-04 11:33:42,747 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:33:42,747 - INFO - After .to(local_rank)***************************************
2025-07-04 11:33:42,747 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:42,748 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:42,748 - INFO - After Normalization***************************************
2025-07-04 11:33:42,748 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:42,748 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:43,036 - INFO - before .to(local_rank)***************************************
2025-07-04 11:33:43,036 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:33:43,036 - INFO - After .to(local_rank)***************************************
2025-07-04 11:33:43,036 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:43,036 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:43,036 - INFO - After Normalization***************************************
2025-07-04 11:33:43,037 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:43,037 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:46,226 - INFO - Epoch 81/150 - Train Loss: 0.224605, Val Loss: 0.241788
2025-07-04 11:33:48,470 - INFO - before .to(local_rank)***************************************
2025-07-04 11:33:48,486 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:33:48,487 - INFO - After .to(local_rank)***************************************
2025-07-04 11:33:48,487 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:48,487 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:48,487 - INFO - After Normalization***************************************
2025-07-04 11:33:48,487 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:48,487 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:48,799 - INFO - before .to(local_rank)***************************************
2025-07-04 11:33:48,800 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:33:48,800 - INFO - After .to(local_rank)***************************************
2025-07-04 11:33:48,800 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:48,800 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:48,800 - INFO - After Normalization***************************************
2025-07-04 11:33:48,800 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:48,800 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:49,088 - INFO - before .to(local_rank)***************************************
2025-07-04 11:33:49,088 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:33:49,089 - INFO - After .to(local_rank)***************************************
2025-07-04 11:33:49,089 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:49,089 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:49,089 - INFO - After Normalization***************************************
2025-07-04 11:33:49,089 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:49,089 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:52,291 - INFO - Epoch 82/150 - Train Loss: 0.224534, Val Loss: 0.241378
2025-07-04 11:33:54,558 - INFO - before .to(local_rank)***************************************
2025-07-04 11:33:54,572 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:33:54,572 - INFO - After .to(local_rank)***************************************
2025-07-04 11:33:54,572 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:54,572 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:54,572 - INFO - After Normalization***************************************
2025-07-04 11:33:54,572 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:54,572 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:54,879 - INFO - before .to(local_rank)***************************************
2025-07-04 11:33:54,879 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:33:54,880 - INFO - After .to(local_rank)***************************************
2025-07-04 11:33:54,880 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:54,880 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:54,880 - INFO - After Normalization***************************************
2025-07-04 11:33:54,880 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:54,880 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:55,169 - INFO - before .to(local_rank)***************************************
2025-07-04 11:33:55,169 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:33:55,169 - INFO - After .to(local_rank)***************************************
2025-07-04 11:33:55,169 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:55,169 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:55,169 - INFO - After Normalization***************************************
2025-07-04 11:33:55,169 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:55,170 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:33:56,840 - INFO - Epoch 123/150 - Train Loss: 0.093458, Val Loss: 0.086432
2025-07-04 11:33:58,391 - INFO - Epoch 83/150 - Train Loss: 0.225927, Val Loss: 0.239900
2025-07-04 11:34:00,645 - INFO - before .to(local_rank)***************************************
2025-07-04 11:34:00,660 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:34:00,660 - INFO - After .to(local_rank)***************************************
2025-07-04 11:34:00,660 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:00,660 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:00,660 - INFO - After Normalization***************************************
2025-07-04 11:34:00,660 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:00,660 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:00,962 - INFO - before .to(local_rank)***************************************
2025-07-04 11:34:00,962 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:34:00,962 - INFO - After .to(local_rank)***************************************
2025-07-04 11:34:00,962 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:00,962 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:00,962 - INFO - After Normalization***************************************
2025-07-04 11:34:00,963 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:00,963 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:01,251 - INFO - before .to(local_rank)***************************************
2025-07-04 11:34:01,251 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:34:01,251 - INFO - After .to(local_rank)***************************************
2025-07-04 11:34:01,251 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:01,251 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:01,251 - INFO - After Normalization***************************************
2025-07-04 11:34:01,251 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:01,251 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:04,444 - INFO - Epoch 84/150 - Train Loss: 0.222113, Val Loss: 0.241609
2025-07-04 11:34:06,680 - INFO - before .to(local_rank)***************************************
2025-07-04 11:34:06,694 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:34:06,694 - INFO - After .to(local_rank)***************************************
2025-07-04 11:34:06,694 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:06,694 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:06,694 - INFO - After Normalization***************************************
2025-07-04 11:34:06,694 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:06,694 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:06,994 - INFO - before .to(local_rank)***************************************
2025-07-04 11:34:06,994 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:34:06,994 - INFO - After .to(local_rank)***************************************
2025-07-04 11:34:06,995 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:06,995 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:06,995 - INFO - After Normalization***************************************
2025-07-04 11:34:06,995 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:06,995 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:07,283 - INFO - before .to(local_rank)***************************************
2025-07-04 11:34:07,283 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:34:07,284 - INFO - After .to(local_rank)***************************************
2025-07-04 11:34:07,284 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:07,284 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:07,284 - INFO - After Normalization***************************************
2025-07-04 11:34:07,284 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:07,284 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:10,482 - INFO - Epoch 85/150 - Train Loss: 0.222664, Val Loss: 0.241702
2025-07-04 11:34:12,750 - INFO - before .to(local_rank)***************************************
2025-07-04 11:34:12,764 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:34:12,764 - INFO - After .to(local_rank)***************************************
2025-07-04 11:34:12,764 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:12,764 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:12,764 - INFO - After Normalization***************************************
2025-07-04 11:34:12,764 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:12,764 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:13,082 - INFO - before .to(local_rank)***************************************
2025-07-04 11:34:13,082 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:34:13,082 - INFO - After .to(local_rank)***************************************
2025-07-04 11:34:13,082 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:13,083 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:13,083 - INFO - After Normalization***************************************
2025-07-04 11:34:13,083 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:13,083 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:13,371 - INFO - before .to(local_rank)***************************************
2025-07-04 11:34:13,371 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:34:13,372 - INFO - After .to(local_rank)***************************************
2025-07-04 11:34:13,372 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:13,372 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:13,372 - INFO - After Normalization***************************************
2025-07-04 11:34:13,372 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:13,372 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:14,607 - INFO - Epoch 124/150 - Train Loss: 0.093784, Val Loss: 0.086574
2025-07-04 11:34:16,587 - INFO - Epoch 86/150 - Train Loss: 0.222005, Val Loss: 0.240705
2025-07-04 11:34:18,806 - INFO - before .to(local_rank)***************************************
2025-07-04 11:34:18,820 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:34:18,820 - INFO - After .to(local_rank)***************************************
2025-07-04 11:34:18,821 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:18,821 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:18,821 - INFO - After Normalization***************************************
2025-07-04 11:34:18,821 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:18,821 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:19,133 - INFO - before .to(local_rank)***************************************
2025-07-04 11:34:19,133 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:34:19,134 - INFO - After .to(local_rank)***************************************
2025-07-04 11:34:19,134 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:19,134 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:19,134 - INFO - After Normalization***************************************
2025-07-04 11:34:19,134 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:19,134 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:19,422 - INFO - before .to(local_rank)***************************************
2025-07-04 11:34:19,422 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:34:19,423 - INFO - After .to(local_rank)***************************************
2025-07-04 11:34:19,423 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:19,423 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:19,423 - INFO - After Normalization***************************************
2025-07-04 11:34:19,423 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:19,423 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:22,632 - INFO - Epoch 87/150 - Train Loss: 0.221814, Val Loss: 0.236728
2025-07-04 11:34:22,648 - INFO - New best model saved with Val Loss: 0.236728
2025-07-04 11:34:24,913 - INFO - before .to(local_rank)***************************************
2025-07-04 11:34:24,927 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:34:24,928 - INFO - After .to(local_rank)***************************************
2025-07-04 11:34:24,928 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:24,928 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:24,928 - INFO - After Normalization***************************************
2025-07-04 11:34:24,928 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:24,928 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:25,232 - INFO - before .to(local_rank)***************************************
2025-07-04 11:34:25,232 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:34:25,232 - INFO - After .to(local_rank)***************************************
2025-07-04 11:34:25,233 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:25,233 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:25,233 - INFO - After Normalization***************************************
2025-07-04 11:34:25,233 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:25,233 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:25,521 - INFO - before .to(local_rank)***************************************
2025-07-04 11:34:25,521 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:34:25,521 - INFO - After .to(local_rank)***************************************
2025-07-04 11:34:25,521 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:25,521 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:25,522 - INFO - After Normalization***************************************
2025-07-04 11:34:25,522 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:25,522 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:28,745 - INFO - Epoch 88/150 - Train Loss: 0.222914, Val Loss: 0.237586
2025-07-04 11:34:30,986 - INFO - before .to(local_rank)***************************************
2025-07-04 11:34:31,000 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:34:31,001 - INFO - After .to(local_rank)***************************************
2025-07-04 11:34:31,001 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:31,001 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:31,001 - INFO - After Normalization***************************************
2025-07-04 11:34:31,001 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:31,001 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:31,301 - INFO - before .to(local_rank)***************************************
2025-07-04 11:34:31,301 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:34:31,301 - INFO - After .to(local_rank)***************************************
2025-07-04 11:34:31,301 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:31,301 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:31,301 - INFO - After Normalization***************************************
2025-07-04 11:34:31,301 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:31,302 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:31,590 - INFO - before .to(local_rank)***************************************
2025-07-04 11:34:31,590 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:34:31,590 - INFO - After .to(local_rank)***************************************
2025-07-04 11:34:31,590 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:31,590 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:31,590 - INFO - After Normalization***************************************
2025-07-04 11:34:31,591 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:31,591 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:32,343 - INFO - Epoch 125/150 - Train Loss: 0.093038, Val Loss: 0.086059
2025-07-04 11:34:32,358 - INFO - New best model saved with Val Loss: 0.086059
2025-07-04 11:34:34,826 - INFO - Epoch 89/150 - Train Loss: 0.223983, Val Loss: 0.233450
2025-07-04 11:34:34,839 - INFO - New best model saved with Val Loss: 0.233450
2025-07-04 11:34:37,089 - INFO - before .to(local_rank)***************************************
2025-07-04 11:34:37,103 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:34:37,103 - INFO - After .to(local_rank)***************************************
2025-07-04 11:34:37,103 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:37,103 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:37,103 - INFO - After Normalization***************************************
2025-07-04 11:34:37,103 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:37,103 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:37,416 - INFO - before .to(local_rank)***************************************
2025-07-04 11:34:37,416 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:34:37,416 - INFO - After .to(local_rank)***************************************
2025-07-04 11:34:37,416 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:37,416 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:37,416 - INFO - After Normalization***************************************
2025-07-04 11:34:37,416 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:37,416 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:37,705 - INFO - before .to(local_rank)***************************************
2025-07-04 11:34:37,705 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:34:37,705 - INFO - After .to(local_rank)***************************************
2025-07-04 11:34:37,705 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:37,705 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:37,705 - INFO - After Normalization***************************************
2025-07-04 11:34:37,705 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:37,705 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:40,884 - INFO - Epoch 90/150 - Train Loss: 0.224280, Val Loss: 0.233574
2025-07-04 11:34:43,248 - INFO - before .to(local_rank)***************************************
2025-07-04 11:34:43,261 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:34:43,262 - INFO - After .to(local_rank)***************************************
2025-07-04 11:34:43,262 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:43,262 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:43,262 - INFO - After Normalization***************************************
2025-07-04 11:34:43,262 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:43,262 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:43,562 - INFO - before .to(local_rank)***************************************
2025-07-04 11:34:43,562 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:34:43,562 - INFO - After .to(local_rank)***************************************
2025-07-04 11:34:43,563 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:43,563 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:43,563 - INFO - After Normalization***************************************
2025-07-04 11:34:43,563 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:43,563 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:43,854 - INFO - before .to(local_rank)***************************************
2025-07-04 11:34:43,854 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:34:43,855 - INFO - After .to(local_rank)***************************************
2025-07-04 11:34:43,855 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:43,855 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:43,855 - INFO - After Normalization***************************************
2025-07-04 11:34:43,855 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:43,855 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:47,065 - INFO - Epoch 91/150 - Train Loss: 0.221463, Val Loss: 0.233713
2025-07-04 11:34:49,305 - INFO - before .to(local_rank)***************************************
2025-07-04 11:34:49,318 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:34:49,318 - INFO - After .to(local_rank)***************************************
2025-07-04 11:34:49,318 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:49,318 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:49,318 - INFO - After Normalization***************************************
2025-07-04 11:34:49,318 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:49,319 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:49,637 - INFO - before .to(local_rank)***************************************
2025-07-04 11:34:49,638 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:34:49,638 - INFO - After .to(local_rank)***************************************
2025-07-04 11:34:49,638 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:49,638 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:49,638 - INFO - After Normalization***************************************
2025-07-04 11:34:49,638 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:49,638 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:49,931 - INFO - before .to(local_rank)***************************************
2025-07-04 11:34:49,931 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:34:49,931 - INFO - After .to(local_rank)***************************************
2025-07-04 11:34:49,932 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:49,932 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:49,932 - INFO - After Normalization***************************************
2025-07-04 11:34:49,932 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:49,932 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:50,092 - INFO - Epoch 126/150 - Train Loss: 0.091458, Val Loss: 0.086364
2025-07-04 11:34:53,127 - INFO - Epoch 92/150 - Train Loss: 0.224099, Val Loss: 0.235924
2025-07-04 11:34:55,378 - INFO - before .to(local_rank)***************************************
2025-07-04 11:34:55,391 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:34:55,392 - INFO - After .to(local_rank)***************************************
2025-07-04 11:34:55,392 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:55,392 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:55,392 - INFO - After Normalization***************************************
2025-07-04 11:34:55,392 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:55,392 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:55,705 - INFO - before .to(local_rank)***************************************
2025-07-04 11:34:55,705 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:34:55,705 - INFO - After .to(local_rank)***************************************
2025-07-04 11:34:55,705 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:55,705 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:55,705 - INFO - After Normalization***************************************
2025-07-04 11:34:55,705 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:55,705 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:55,998 - INFO - before .to(local_rank)***************************************
2025-07-04 11:34:55,998 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:34:55,998 - INFO - After .to(local_rank)***************************************
2025-07-04 11:34:55,998 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:55,998 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:55,998 - INFO - After Normalization***************************************
2025-07-04 11:34:55,998 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:55,998 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:34:59,197 - INFO - Epoch 93/150 - Train Loss: 0.224064, Val Loss: 0.235446
2025-07-04 11:35:01,437 - INFO - before .to(local_rank)***************************************
2025-07-04 11:35:01,451 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:35:01,451 - INFO - After .to(local_rank)***************************************
2025-07-04 11:35:01,451 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:01,451 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:01,451 - INFO - After Normalization***************************************
2025-07-04 11:35:01,452 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:01,452 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:01,760 - INFO - before .to(local_rank)***************************************
2025-07-04 11:35:01,760 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:35:01,761 - INFO - After .to(local_rank)***************************************
2025-07-04 11:35:01,761 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:01,761 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:01,761 - INFO - After Normalization***************************************
2025-07-04 11:35:01,761 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:01,761 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:02,053 - INFO - before .to(local_rank)***************************************
2025-07-04 11:35:02,053 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:35:02,053 - INFO - After .to(local_rank)***************************************
2025-07-04 11:35:02,053 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:02,053 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:02,053 - INFO - After Normalization***************************************
2025-07-04 11:35:02,054 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:02,054 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:05,287 - INFO - Epoch 94/150 - Train Loss: 0.218898, Val Loss: 0.233914
2025-07-04 11:35:07,544 - INFO - before .to(local_rank)***************************************
2025-07-04 11:35:07,558 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:35:07,558 - INFO - After .to(local_rank)***************************************
2025-07-04 11:35:07,559 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:07,559 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:07,559 - INFO - After Normalization***************************************
2025-07-04 11:35:07,559 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:07,559 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:07,856 - INFO - Epoch 127/150 - Train Loss: 0.092800, Val Loss: 0.086594
2025-07-04 11:35:07,861 - INFO - before .to(local_rank)***************************************
2025-07-04 11:35:07,861 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:35:07,861 - INFO - After .to(local_rank)***************************************
2025-07-04 11:35:07,861 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:07,862 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:07,862 - INFO - After Normalization***************************************
2025-07-04 11:35:07,862 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:07,862 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:08,155 - INFO - before .to(local_rank)***************************************
2025-07-04 11:35:08,155 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:35:08,155 - INFO - After .to(local_rank)***************************************
2025-07-04 11:35:08,155 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:08,155 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:08,155 - INFO - After Normalization***************************************
2025-07-04 11:35:08,155 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:08,156 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:11,347 - INFO - Epoch 95/150 - Train Loss: 0.219660, Val Loss: 0.235059
2025-07-04 11:35:13,605 - INFO - before .to(local_rank)***************************************
2025-07-04 11:35:13,618 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:35:13,618 - INFO - After .to(local_rank)***************************************
2025-07-04 11:35:13,618 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:13,618 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:13,618 - INFO - After Normalization***************************************
2025-07-04 11:35:13,618 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:13,618 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:13,936 - INFO - before .to(local_rank)***************************************
2025-07-04 11:35:13,949 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:35:13,966 - INFO - After .to(local_rank)***************************************
2025-07-04 11:35:13,975 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:13,987 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:13,996 - INFO - After Normalization***************************************
2025-07-04 11:35:14,006 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:14,015 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:14,316 - INFO - before .to(local_rank)***************************************
2025-07-04 11:35:14,316 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:35:14,316 - INFO - After .to(local_rank)***************************************
2025-07-04 11:35:14,316 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:14,317 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:14,317 - INFO - After Normalization***************************************
2025-07-04 11:35:14,317 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:14,317 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:17,489 - INFO - Epoch 96/150 - Train Loss: 0.219717, Val Loss: 0.233484
2025-07-04 11:35:19,749 - INFO - before .to(local_rank)***************************************
2025-07-04 11:35:19,763 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:35:19,763 - INFO - After .to(local_rank)***************************************
2025-07-04 11:35:19,763 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:19,763 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:19,763 - INFO - After Normalization***************************************
2025-07-04 11:35:19,763 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:19,763 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:20,075 - INFO - before .to(local_rank)***************************************
2025-07-04 11:35:20,075 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:35:20,075 - INFO - After .to(local_rank)***************************************
2025-07-04 11:35:20,075 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:20,075 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:20,075 - INFO - After Normalization***************************************
2025-07-04 11:35:20,075 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:20,075 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:20,364 - INFO - before .to(local_rank)***************************************
2025-07-04 11:35:20,364 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:35:20,364 - INFO - After .to(local_rank)***************************************
2025-07-04 11:35:20,364 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:20,364 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:20,364 - INFO - After Normalization***************************************
2025-07-04 11:35:20,364 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:20,364 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:23,569 - INFO - Epoch 97/150 - Train Loss: 0.220275, Val Loss: 0.234563
2025-07-04 11:35:25,590 - INFO - Epoch 128/150 - Train Loss: 0.093453, Val Loss: 0.086473
2025-07-04 11:35:25,813 - INFO - before .to(local_rank)***************************************
2025-07-04 11:35:25,827 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:35:25,827 - INFO - After .to(local_rank)***************************************
2025-07-04 11:35:25,827 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:25,827 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:25,828 - INFO - After Normalization***************************************
2025-07-04 11:35:25,828 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:25,828 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:26,136 - INFO - before .to(local_rank)***************************************
2025-07-04 11:35:26,136 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:35:26,136 - INFO - After .to(local_rank)***************************************
2025-07-04 11:35:26,136 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:26,136 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:26,137 - INFO - After Normalization***************************************
2025-07-04 11:35:26,137 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:26,137 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:26,425 - INFO - before .to(local_rank)***************************************
2025-07-04 11:35:26,426 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:35:26,426 - INFO - After .to(local_rank)***************************************
2025-07-04 11:35:26,426 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:26,426 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:26,426 - INFO - After Normalization***************************************
2025-07-04 11:35:26,426 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:26,426 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:29,637 - INFO - Epoch 98/150 - Train Loss: 0.218811, Val Loss: 0.234070
2025-07-04 11:35:31,893 - INFO - before .to(local_rank)***************************************
2025-07-04 11:35:31,906 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:35:31,906 - INFO - After .to(local_rank)***************************************
2025-07-04 11:35:31,907 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:31,907 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:31,907 - INFO - After Normalization***************************************
2025-07-04 11:35:31,907 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:31,907 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:32,211 - INFO - before .to(local_rank)***************************************
2025-07-04 11:35:32,211 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:35:32,212 - INFO - After .to(local_rank)***************************************
2025-07-04 11:35:32,212 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:32,212 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:32,212 - INFO - After Normalization***************************************
2025-07-04 11:35:32,212 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:32,212 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:32,500 - INFO - before .to(local_rank)***************************************
2025-07-04 11:35:32,500 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:35:32,501 - INFO - After .to(local_rank)***************************************
2025-07-04 11:35:32,501 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:32,501 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:32,501 - INFO - After Normalization***************************************
2025-07-04 11:35:32,501 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:32,501 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:35,697 - INFO - Epoch 99/150 - Train Loss: 0.216731, Val Loss: 0.233418
2025-07-04 11:35:35,712 - INFO - New best model saved with Val Loss: 0.233418
2025-07-04 11:35:37,957 - INFO - before .to(local_rank)***************************************
2025-07-04 11:35:37,970 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:35:37,971 - INFO - After .to(local_rank)***************************************
2025-07-04 11:35:37,971 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:37,971 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:37,971 - INFO - After Normalization***************************************
2025-07-04 11:35:37,971 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:37,971 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:38,291 - INFO - before .to(local_rank)***************************************
2025-07-04 11:35:38,291 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:35:38,291 - INFO - After .to(local_rank)***************************************
2025-07-04 11:35:38,291 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:38,291 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:38,291 - INFO - After Normalization***************************************
2025-07-04 11:35:38,291 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:38,291 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:38,580 - INFO - before .to(local_rank)***************************************
2025-07-04 11:35:38,580 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:35:38,580 - INFO - After .to(local_rank)***************************************
2025-07-04 11:35:38,580 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:38,580 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:38,580 - INFO - After Normalization***************************************
2025-07-04 11:35:38,580 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:38,580 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:41,807 - INFO - Epoch 100/150 - Train Loss: 0.215245, Val Loss: 0.231929
2025-07-04 11:35:41,821 - INFO - New best model saved with Val Loss: 0.231929
2025-07-04 11:35:43,346 - INFO - Epoch 129/150 - Train Loss: 0.092883, Val Loss: 0.086414
2025-07-04 11:35:44,195 - INFO - before .to(local_rank)***************************************
2025-07-04 11:35:44,209 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:35:44,209 - INFO - After .to(local_rank)***************************************
2025-07-04 11:35:44,209 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:44,209 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:44,209 - INFO - After Normalization***************************************
2025-07-04 11:35:44,209 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:44,210 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:44,526 - INFO - before .to(local_rank)***************************************
2025-07-04 11:35:44,526 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:35:44,527 - INFO - After .to(local_rank)***************************************
2025-07-04 11:35:44,527 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:44,527 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:44,527 - INFO - After Normalization***************************************
2025-07-04 11:35:44,527 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:44,527 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:44,816 - INFO - before .to(local_rank)***************************************
2025-07-04 11:35:44,816 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:35:44,817 - INFO - After .to(local_rank)***************************************
2025-07-04 11:35:44,817 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:44,817 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:44,817 - INFO - After Normalization***************************************
2025-07-04 11:35:44,817 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:44,817 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:47,997 - INFO - Epoch 101/150 - Train Loss: 0.220793, Val Loss: 0.232915
2025-07-04 11:35:50,264 - INFO - before .to(local_rank)***************************************
2025-07-04 11:35:50,277 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:35:50,277 - INFO - After .to(local_rank)***************************************
2025-07-04 11:35:50,278 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:50,278 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:50,278 - INFO - After Normalization***************************************
2025-07-04 11:35:50,278 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:50,278 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:50,588 - INFO - before .to(local_rank)***************************************
2025-07-04 11:35:50,588 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:35:50,589 - INFO - After .to(local_rank)***************************************
2025-07-04 11:35:50,589 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:50,589 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:50,589 - INFO - After Normalization***************************************
2025-07-04 11:35:50,589 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:50,589 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:50,877 - INFO - before .to(local_rank)***************************************
2025-07-04 11:35:50,877 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:35:50,877 - INFO - After .to(local_rank)***************************************
2025-07-04 11:35:50,878 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:50,878 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:50,878 - INFO - After Normalization***************************************
2025-07-04 11:35:50,878 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:50,878 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:54,067 - INFO - Epoch 102/150 - Train Loss: 0.215615, Val Loss: 0.231711
2025-07-04 11:35:54,082 - INFO - New best model saved with Val Loss: 0.231711
2025-07-04 11:35:56,342 - INFO - before .to(local_rank)***************************************
2025-07-04 11:35:56,356 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:35:56,356 - INFO - After .to(local_rank)***************************************
2025-07-04 11:35:56,356 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:56,356 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:56,356 - INFO - After Normalization***************************************
2025-07-04 11:35:56,356 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:56,356 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:56,662 - INFO - before .to(local_rank)***************************************
2025-07-04 11:35:56,662 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:35:56,662 - INFO - After .to(local_rank)***************************************
2025-07-04 11:35:56,662 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:56,662 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:56,663 - INFO - After Normalization***************************************
2025-07-04 11:35:56,663 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:56,663 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:56,952 - INFO - before .to(local_rank)***************************************
2025-07-04 11:35:56,952 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:35:56,952 - INFO - After .to(local_rank)***************************************
2025-07-04 11:35:56,952 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:56,952 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:56,952 - INFO - After Normalization***************************************
2025-07-04 11:35:56,952 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:35:56,952 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:00,154 - INFO - Epoch 103/150 - Train Loss: 0.215830, Val Loss: 0.233838
2025-07-04 11:36:01,069 - INFO - Epoch 130/150 - Train Loss: 0.093339, Val Loss: 0.086173
2025-07-04 11:36:02,403 - INFO - before .to(local_rank)***************************************
2025-07-04 11:36:02,417 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:36:02,417 - INFO - After .to(local_rank)***************************************
2025-07-04 11:36:02,418 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:02,418 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:02,418 - INFO - After Normalization***************************************
2025-07-04 11:36:02,418 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:02,418 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:02,720 - INFO - before .to(local_rank)***************************************
2025-07-04 11:36:02,720 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:36:02,721 - INFO - After .to(local_rank)***************************************
2025-07-04 11:36:02,721 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:02,721 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:02,721 - INFO - After Normalization***************************************
2025-07-04 11:36:02,721 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:02,721 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:03,009 - INFO - before .to(local_rank)***************************************
2025-07-04 11:36:03,009 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:36:03,010 - INFO - After .to(local_rank)***************************************
2025-07-04 11:36:03,010 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:03,010 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:03,010 - INFO - After Normalization***************************************
2025-07-04 11:36:03,010 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:03,010 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:06,229 - INFO - Epoch 104/150 - Train Loss: 0.219100, Val Loss: 0.238959
2025-07-04 11:36:08,479 - INFO - before .to(local_rank)***************************************
2025-07-04 11:36:08,492 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:36:08,493 - INFO - After .to(local_rank)***************************************
2025-07-04 11:36:08,493 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:08,493 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:08,493 - INFO - After Normalization***************************************
2025-07-04 11:36:08,493 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:08,493 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:08,803 - INFO - before .to(local_rank)***************************************
2025-07-04 11:36:08,803 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:36:08,803 - INFO - After .to(local_rank)***************************************
2025-07-04 11:36:08,803 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:08,803 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:08,803 - INFO - After Normalization***************************************
2025-07-04 11:36:08,803 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:08,803 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:09,092 - INFO - before .to(local_rank)***************************************
2025-07-04 11:36:09,092 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:36:09,092 - INFO - After .to(local_rank)***************************************
2025-07-04 11:36:09,092 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:09,092 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:09,093 - INFO - After Normalization***************************************
2025-07-04 11:36:09,093 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:09,093 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:12,290 - INFO - Epoch 105/150 - Train Loss: 0.217095, Val Loss: 0.235791
2025-07-04 11:36:14,555 - INFO - before .to(local_rank)***************************************
2025-07-04 11:36:14,568 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:36:14,569 - INFO - After .to(local_rank)***************************************
2025-07-04 11:36:14,569 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:14,569 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:14,569 - INFO - After Normalization***************************************
2025-07-04 11:36:14,569 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:14,569 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:14,884 - INFO - before .to(local_rank)***************************************
2025-07-04 11:36:14,884 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:36:14,885 - INFO - After .to(local_rank)***************************************
2025-07-04 11:36:14,885 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:14,885 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:14,885 - INFO - After Normalization***************************************
2025-07-04 11:36:14,885 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:14,885 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:15,174 - INFO - before .to(local_rank)***************************************
2025-07-04 11:36:15,174 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:36:15,174 - INFO - After .to(local_rank)***************************************
2025-07-04 11:36:15,174 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:15,175 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:15,175 - INFO - After Normalization***************************************
2025-07-04 11:36:15,175 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:15,175 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:18,382 - INFO - Epoch 106/150 - Train Loss: 0.219045, Val Loss: 0.238134
2025-07-04 11:36:18,921 - INFO - Epoch 131/150 - Train Loss: 0.093019, Val Loss: 0.086383
2025-07-04 11:36:20,668 - INFO - before .to(local_rank)***************************************
2025-07-04 11:36:20,681 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:36:20,682 - INFO - After .to(local_rank)***************************************
2025-07-04 11:36:20,682 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:20,682 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:20,682 - INFO - After Normalization***************************************
2025-07-04 11:36:20,682 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:20,682 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:20,987 - INFO - before .to(local_rank)***************************************
2025-07-04 11:36:20,987 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:36:20,987 - INFO - After .to(local_rank)***************************************
2025-07-04 11:36:20,987 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:20,987 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:20,987 - INFO - After Normalization***************************************
2025-07-04 11:36:20,987 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:20,987 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:21,276 - INFO - before .to(local_rank)***************************************
2025-07-04 11:36:21,276 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:36:21,277 - INFO - After .to(local_rank)***************************************
2025-07-04 11:36:21,277 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:21,277 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:21,277 - INFO - After Normalization***************************************
2025-07-04 11:36:21,277 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:21,277 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:24,485 - INFO - Epoch 107/150 - Train Loss: 0.217866, Val Loss: 0.237858
2025-07-04 11:36:26,757 - INFO - before .to(local_rank)***************************************
2025-07-04 11:36:26,770 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:36:26,771 - INFO - After .to(local_rank)***************************************
2025-07-04 11:36:26,771 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:26,771 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:26,771 - INFO - After Normalization***************************************
2025-07-04 11:36:26,771 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:26,771 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:27,073 - INFO - before .to(local_rank)***************************************
2025-07-04 11:36:27,073 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:36:27,074 - INFO - After .to(local_rank)***************************************
2025-07-04 11:36:27,074 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:27,074 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:27,074 - INFO - After Normalization***************************************
2025-07-04 11:36:27,074 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:27,074 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:27,362 - INFO - before .to(local_rank)***************************************
2025-07-04 11:36:27,362 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:36:27,362 - INFO - After .to(local_rank)***************************************
2025-07-04 11:36:27,362 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:27,362 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:27,363 - INFO - After Normalization***************************************
2025-07-04 11:36:27,363 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:27,363 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:30,595 - INFO - Epoch 108/150 - Train Loss: 0.213142, Val Loss: 0.232590
2025-07-04 11:36:32,851 - INFO - before .to(local_rank)***************************************
2025-07-04 11:36:32,864 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:36:32,865 - INFO - After .to(local_rank)***************************************
2025-07-04 11:36:32,865 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:32,865 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:32,865 - INFO - After Normalization***************************************
2025-07-04 11:36:32,865 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:32,865 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:33,178 - INFO - before .to(local_rank)***************************************
2025-07-04 11:36:33,178 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:36:33,179 - INFO - After .to(local_rank)***************************************
2025-07-04 11:36:33,179 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:33,179 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:33,179 - INFO - After Normalization***************************************
2025-07-04 11:36:33,179 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:33,179 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:33,468 - INFO - before .to(local_rank)***************************************
2025-07-04 11:36:33,468 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:36:33,468 - INFO - After .to(local_rank)***************************************
2025-07-04 11:36:33,468 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:33,468 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:33,468 - INFO - After Normalization***************************************
2025-07-04 11:36:33,468 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:33,468 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:36,675 - INFO - Epoch 132/150 - Train Loss: 0.093502, Val Loss: 0.086444
2025-07-04 11:36:36,725 - INFO - Epoch 109/150 - Train Loss: 0.215017, Val Loss: 0.234218
2025-07-04 11:36:38,983 - INFO - before .to(local_rank)***************************************
2025-07-04 11:36:38,996 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:36:38,997 - INFO - After .to(local_rank)***************************************
2025-07-04 11:36:38,997 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:38,997 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:38,997 - INFO - After Normalization***************************************
2025-07-04 11:36:38,997 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:38,997 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:39,299 - INFO - before .to(local_rank)***************************************
2025-07-04 11:36:39,299 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:36:39,299 - INFO - After .to(local_rank)***************************************
2025-07-04 11:36:39,299 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:39,299 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:39,300 - INFO - After Normalization***************************************
2025-07-04 11:36:39,300 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:39,300 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:39,592 - INFO - before .to(local_rank)***************************************
2025-07-04 11:36:39,592 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:36:39,592 - INFO - After .to(local_rank)***************************************
2025-07-04 11:36:39,592 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:39,592 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:39,592 - INFO - After Normalization***************************************
2025-07-04 11:36:39,592 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:39,592 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:42,789 - INFO - Epoch 110/150 - Train Loss: 0.216315, Val Loss: 0.234832
2025-07-04 11:36:46,653 - INFO - before .to(local_rank)***************************************
2025-07-04 11:36:46,667 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:36:46,667 - INFO - After .to(local_rank)***************************************
2025-07-04 11:36:46,667 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:46,667 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:46,667 - INFO - After Normalization***************************************
2025-07-04 11:36:46,667 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:46,667 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:46,974 - INFO - before .to(local_rank)***************************************
2025-07-04 11:36:46,974 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:36:46,974 - INFO - After .to(local_rank)***************************************
2025-07-04 11:36:46,974 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:46,974 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:46,974 - INFO - After Normalization***************************************
2025-07-04 11:36:46,974 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:46,974 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:47,263 - INFO - before .to(local_rank)***************************************
2025-07-04 11:36:47,263 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:36:47,263 - INFO - After .to(local_rank)***************************************
2025-07-04 11:36:47,263 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:47,263 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:47,263 - INFO - After Normalization***************************************
2025-07-04 11:36:47,264 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:47,264 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:50,487 - INFO - Epoch 111/150 - Train Loss: 0.212657, Val Loss: 0.228432
2025-07-04 11:36:50,502 - INFO - New best model saved with Val Loss: 0.228432
2025-07-04 11:36:52,785 - INFO - before .to(local_rank)***************************************
2025-07-04 11:36:52,798 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:36:52,799 - INFO - After .to(local_rank)***************************************
2025-07-04 11:36:52,799 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:52,799 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:52,799 - INFO - After Normalization***************************************
2025-07-04 11:36:52,799 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:52,799 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:53,107 - INFO - before .to(local_rank)***************************************
2025-07-04 11:36:53,107 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:36:53,107 - INFO - After .to(local_rank)***************************************
2025-07-04 11:36:53,107 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:53,107 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:53,107 - INFO - After Normalization***************************************
2025-07-04 11:36:53,107 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:53,107 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:53,396 - INFO - before .to(local_rank)***************************************
2025-07-04 11:36:53,396 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:36:53,396 - INFO - After .to(local_rank)***************************************
2025-07-04 11:36:53,396 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:53,396 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:53,397 - INFO - After Normalization***************************************
2025-07-04 11:36:53,397 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:53,397 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:54,482 - INFO - Epoch 133/150 - Train Loss: 0.093330, Val Loss: 0.086222
2025-07-04 11:36:56,599 - INFO - Epoch 112/150 - Train Loss: 0.213089, Val Loss: 0.229737
2025-07-04 11:36:58,853 - INFO - before .to(local_rank)***************************************
2025-07-04 11:36:58,867 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:36:58,867 - INFO - After .to(local_rank)***************************************
2025-07-04 11:36:58,867 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:58,867 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:58,867 - INFO - After Normalization***************************************
2025-07-04 11:36:58,868 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:58,868 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:59,173 - INFO - before .to(local_rank)***************************************
2025-07-04 11:36:59,173 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:36:59,173 - INFO - After .to(local_rank)***************************************
2025-07-04 11:36:59,173 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:59,173 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:59,173 - INFO - After Normalization***************************************
2025-07-04 11:36:59,173 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:59,173 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:59,462 - INFO - before .to(local_rank)***************************************
2025-07-04 11:36:59,462 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:36:59,462 - INFO - After .to(local_rank)***************************************
2025-07-04 11:36:59,462 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:59,462 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:59,462 - INFO - After Normalization***************************************
2025-07-04 11:36:59,462 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:36:59,462 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:02,671 - INFO - Epoch 113/150 - Train Loss: 0.216253, Val Loss: 0.234988
2025-07-04 11:37:04,924 - INFO - before .to(local_rank)***************************************
2025-07-04 11:37:04,937 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:37:04,937 - INFO - After .to(local_rank)***************************************
2025-07-04 11:37:04,937 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:04,937 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:04,937 - INFO - After Normalization***************************************
2025-07-04 11:37:04,937 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:04,937 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:05,238 - INFO - before .to(local_rank)***************************************
2025-07-04 11:37:05,238 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:37:05,239 - INFO - After .to(local_rank)***************************************
2025-07-04 11:37:05,239 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:05,239 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:05,239 - INFO - After Normalization***************************************
2025-07-04 11:37:05,239 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:05,239 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:05,527 - INFO - before .to(local_rank)***************************************
2025-07-04 11:37:05,527 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:37:05,528 - INFO - After .to(local_rank)***************************************
2025-07-04 11:37:05,528 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:05,528 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:05,528 - INFO - After Normalization***************************************
2025-07-04 11:37:05,528 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:05,528 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:08,753 - INFO - Epoch 114/150 - Train Loss: 0.210370, Val Loss: 0.231040
2025-07-04 11:37:11,020 - INFO - before .to(local_rank)***************************************
2025-07-04 11:37:11,034 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:37:11,034 - INFO - After .to(local_rank)***************************************
2025-07-04 11:37:11,034 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:11,035 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:11,035 - INFO - After Normalization***************************************
2025-07-04 11:37:11,035 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:11,035 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:11,349 - INFO - before .to(local_rank)***************************************
2025-07-04 11:37:11,349 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:37:11,349 - INFO - After .to(local_rank)***************************************
2025-07-04 11:37:11,349 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:11,350 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:11,350 - INFO - After Normalization***************************************
2025-07-04 11:37:11,350 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:11,350 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:11,638 - INFO - before .to(local_rank)***************************************
2025-07-04 11:37:11,638 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:37:11,639 - INFO - After .to(local_rank)***************************************
2025-07-04 11:37:11,639 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:11,639 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:11,639 - INFO - After Normalization***************************************
2025-07-04 11:37:11,639 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:11,639 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:12,236 - INFO - Epoch 134/150 - Train Loss: 0.093427, Val Loss: 0.086623
2025-07-04 11:37:14,950 - INFO - Epoch 115/150 - Train Loss: 0.215257, Val Loss: 0.229911
2025-07-04 11:37:17,186 - INFO - before .to(local_rank)***************************************
2025-07-04 11:37:17,200 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:37:17,200 - INFO - After .to(local_rank)***************************************
2025-07-04 11:37:17,200 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:17,200 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:17,200 - INFO - After Normalization***************************************
2025-07-04 11:37:17,200 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:17,200 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:17,500 - INFO - before .to(local_rank)***************************************
2025-07-04 11:37:17,500 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:37:17,500 - INFO - After .to(local_rank)***************************************
2025-07-04 11:37:17,500 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:17,500 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:17,501 - INFO - After Normalization***************************************
2025-07-04 11:37:17,501 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:17,501 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:17,800 - INFO - before .to(local_rank)***************************************
2025-07-04 11:37:17,800 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:37:17,801 - INFO - After .to(local_rank)***************************************
2025-07-04 11:37:17,801 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:17,801 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:17,801 - INFO - After Normalization***************************************
2025-07-04 11:37:17,801 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:17,801 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:20,991 - INFO - Epoch 116/150 - Train Loss: 0.210573, Val Loss: 0.230565
2025-07-04 11:37:23,260 - INFO - before .to(local_rank)***************************************
2025-07-04 11:37:23,273 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:37:23,274 - INFO - After .to(local_rank)***************************************
2025-07-04 11:37:23,274 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:23,274 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:23,274 - INFO - After Normalization***************************************
2025-07-04 11:37:23,274 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:23,274 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:23,589 - INFO - before .to(local_rank)***************************************
2025-07-04 11:37:23,589 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:37:23,590 - INFO - After .to(local_rank)***************************************
2025-07-04 11:37:23,590 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:23,590 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:23,590 - INFO - After Normalization***************************************
2025-07-04 11:37:23,590 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:23,590 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:23,881 - INFO - before .to(local_rank)***************************************
2025-07-04 11:37:23,881 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:37:23,882 - INFO - After .to(local_rank)***************************************
2025-07-04 11:37:23,882 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:23,882 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:23,882 - INFO - After Normalization***************************************
2025-07-04 11:37:23,882 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:23,882 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:27,088 - INFO - Epoch 117/150 - Train Loss: 0.214040, Val Loss: 0.228656
2025-07-04 11:37:29,335 - INFO - before .to(local_rank)***************************************
2025-07-04 11:37:29,358 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:37:29,358 - INFO - After .to(local_rank)***************************************
2025-07-04 11:37:29,358 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:29,358 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:29,358 - INFO - After Normalization***************************************
2025-07-04 11:37:29,358 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:29,358 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:29,667 - INFO - before .to(local_rank)***************************************
2025-07-04 11:37:29,667 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:37:29,667 - INFO - After .to(local_rank)***************************************
2025-07-04 11:37:29,667 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:29,667 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:29,667 - INFO - After Normalization***************************************
2025-07-04 11:37:29,667 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:29,667 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:29,960 - INFO - before .to(local_rank)***************************************
2025-07-04 11:37:29,960 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:37:29,961 - INFO - After .to(local_rank)***************************************
2025-07-04 11:37:29,961 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:29,961 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:29,961 - INFO - After Normalization***************************************
2025-07-04 11:37:29,961 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:29,961 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:29,974 - INFO - Epoch 135/150 - Train Loss: 0.093817, Val Loss: 0.086278
2025-07-04 11:37:33,163 - INFO - Epoch 118/150 - Train Loss: 0.211064, Val Loss: 0.229791
2025-07-04 11:37:35,403 - INFO - before .to(local_rank)***************************************
2025-07-04 11:37:35,425 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:37:35,425 - INFO - After .to(local_rank)***************************************
2025-07-04 11:37:35,425 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:35,425 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:35,426 - INFO - After Normalization***************************************
2025-07-04 11:37:35,426 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:35,426 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:35,731 - INFO - before .to(local_rank)***************************************
2025-07-04 11:37:35,731 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:37:35,731 - INFO - After .to(local_rank)***************************************
2025-07-04 11:37:35,731 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:35,731 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:35,731 - INFO - After Normalization***************************************
2025-07-04 11:37:35,731 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:35,732 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:36,023 - INFO - before .to(local_rank)***************************************
2025-07-04 11:37:36,023 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:37:36,024 - INFO - After .to(local_rank)***************************************
2025-07-04 11:37:36,024 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:36,024 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:36,024 - INFO - After Normalization***************************************
2025-07-04 11:37:36,024 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:36,024 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:39,223 - INFO - Epoch 119/150 - Train Loss: 0.218802, Val Loss: 0.228340
2025-07-04 11:37:39,237 - INFO - New best model saved with Val Loss: 0.228340
2025-07-04 11:37:41,474 - INFO - before .to(local_rank)***************************************
2025-07-04 11:37:41,487 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:37:41,487 - INFO - After .to(local_rank)***************************************
2025-07-04 11:37:41,488 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:41,488 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:41,488 - INFO - After Normalization***************************************
2025-07-04 11:37:41,488 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:41,488 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:41,790 - INFO - before .to(local_rank)***************************************
2025-07-04 11:37:41,790 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:37:41,790 - INFO - After .to(local_rank)***************************************
2025-07-04 11:37:41,790 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:41,790 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:41,790 - INFO - After Normalization***************************************
2025-07-04 11:37:41,790 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:41,790 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:42,082 - INFO - before .to(local_rank)***************************************
2025-07-04 11:37:42,082 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:37:42,082 - INFO - After .to(local_rank)***************************************
2025-07-04 11:37:42,082 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:42,082 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:42,082 - INFO - After Normalization***************************************
2025-07-04 11:37:42,082 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:42,082 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:45,301 - INFO - Epoch 120/150 - Train Loss: 0.211176, Val Loss: 0.227035
2025-07-04 11:37:45,315 - INFO - New best model saved with Val Loss: 0.227035
2025-07-04 11:37:47,671 - INFO - before .to(local_rank)***************************************
2025-07-04 11:37:47,685 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:37:47,685 - INFO - After .to(local_rank)***************************************
2025-07-04 11:37:47,686 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:47,686 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:47,686 - INFO - After Normalization***************************************
2025-07-04 11:37:47,686 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:47,686 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:47,735 - INFO - Epoch 136/150 - Train Loss: 0.093156, Val Loss: 0.086409
2025-07-04 11:37:47,995 - INFO - before .to(local_rank)***************************************
2025-07-04 11:37:47,995 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:37:47,995 - INFO - After .to(local_rank)***************************************
2025-07-04 11:37:47,995 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:47,995 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:47,996 - INFO - After Normalization***************************************
2025-07-04 11:37:47,996 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:47,996 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:48,285 - INFO - before .to(local_rank)***************************************
2025-07-04 11:37:48,285 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:37:48,285 - INFO - After .to(local_rank)***************************************
2025-07-04 11:37:48,285 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:48,285 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:48,285 - INFO - After Normalization***************************************
2025-07-04 11:37:48,285 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:48,286 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:51,490 - INFO - Epoch 121/150 - Train Loss: 0.209712, Val Loss: 0.227454
2025-07-04 11:37:53,752 - INFO - before .to(local_rank)***************************************
2025-07-04 11:37:53,766 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:37:53,766 - INFO - After .to(local_rank)***************************************
2025-07-04 11:37:53,766 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:53,766 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:53,767 - INFO - After Normalization***************************************
2025-07-04 11:37:53,767 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:53,767 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:54,069 - INFO - before .to(local_rank)***************************************
2025-07-04 11:37:54,069 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:37:54,070 - INFO - After .to(local_rank)***************************************
2025-07-04 11:37:54,070 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:54,070 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:54,070 - INFO - After Normalization***************************************
2025-07-04 11:37:54,070 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:54,070 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:54,358 - INFO - before .to(local_rank)***************************************
2025-07-04 11:37:54,358 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:37:54,358 - INFO - After .to(local_rank)***************************************
2025-07-04 11:37:54,358 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:54,359 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:54,359 - INFO - After Normalization***************************************
2025-07-04 11:37:54,359 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:54,359 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:57,532 - INFO - Epoch 122/150 - Train Loss: 0.210517, Val Loss: 0.229289
2025-07-04 11:37:59,789 - INFO - before .to(local_rank)***************************************
2025-07-04 11:37:59,803 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:37:59,803 - INFO - After .to(local_rank)***************************************
2025-07-04 11:37:59,803 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:59,804 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:59,804 - INFO - After Normalization***************************************
2025-07-04 11:37:59,804 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:37:59,804 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:00,111 - INFO - before .to(local_rank)***************************************
2025-07-04 11:38:00,111 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:38:00,112 - INFO - After .to(local_rank)***************************************
2025-07-04 11:38:00,112 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:00,112 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:00,112 - INFO - After Normalization***************************************
2025-07-04 11:38:00,112 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:00,112 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:00,400 - INFO - before .to(local_rank)***************************************
2025-07-04 11:38:00,400 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:38:00,401 - INFO - After .to(local_rank)***************************************
2025-07-04 11:38:00,401 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:00,401 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:00,401 - INFO - After Normalization***************************************
2025-07-04 11:38:00,401 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:00,401 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:03,582 - INFO - Epoch 123/150 - Train Loss: 0.206994, Val Loss: 0.232915
2025-07-04 11:38:05,487 - INFO - Epoch 137/150 - Train Loss: 0.092966, Val Loss: 0.086330
2025-07-04 11:38:05,834 - INFO - before .to(local_rank)***************************************
2025-07-04 11:38:05,847 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:38:05,848 - INFO - After .to(local_rank)***************************************
2025-07-04 11:38:05,848 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:05,848 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:05,848 - INFO - After Normalization***************************************
2025-07-04 11:38:05,848 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:05,848 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:06,191 - INFO - before .to(local_rank)***************************************
2025-07-04 11:38:06,191 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:38:06,191 - INFO - After .to(local_rank)***************************************
2025-07-04 11:38:06,191 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:06,192 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:06,192 - INFO - After Normalization***************************************
2025-07-04 11:38:06,192 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:06,192 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:06,481 - INFO - before .to(local_rank)***************************************
2025-07-04 11:38:06,481 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:38:06,481 - INFO - After .to(local_rank)***************************************
2025-07-04 11:38:06,482 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:06,482 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:06,482 - INFO - After Normalization***************************************
2025-07-04 11:38:06,482 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:06,482 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:09,683 - INFO - Epoch 124/150 - Train Loss: 0.210682, Val Loss: 0.232058
2025-07-04 11:38:11,920 - INFO - before .to(local_rank)***************************************
2025-07-04 11:38:11,934 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:38:11,935 - INFO - After .to(local_rank)***************************************
2025-07-04 11:38:11,935 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:11,935 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:11,935 - INFO - After Normalization***************************************
2025-07-04 11:38:11,935 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:11,935 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:12,250 - INFO - before .to(local_rank)***************************************
2025-07-04 11:38:12,251 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:38:12,251 - INFO - After .to(local_rank)***************************************
2025-07-04 11:38:12,251 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:12,251 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:12,251 - INFO - After Normalization***************************************
2025-07-04 11:38:12,251 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:12,251 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:12,540 - INFO - before .to(local_rank)***************************************
2025-07-04 11:38:12,540 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:38:12,540 - INFO - After .to(local_rank)***************************************
2025-07-04 11:38:12,540 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:12,540 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:12,540 - INFO - After Normalization***************************************
2025-07-04 11:38:12,540 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:12,540 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:18,806 - INFO - Epoch 125/150 - Train Loss: 0.210332, Val Loss: 0.235467
2025-07-04 11:38:21,072 - INFO - before .to(local_rank)***************************************
2025-07-04 11:38:21,086 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:38:21,086 - INFO - After .to(local_rank)***************************************
2025-07-04 11:38:21,086 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:21,086 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:21,086 - INFO - After Normalization***************************************
2025-07-04 11:38:21,086 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:21,086 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:21,387 - INFO - before .to(local_rank)***************************************
2025-07-04 11:38:21,387 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:38:21,388 - INFO - After .to(local_rank)***************************************
2025-07-04 11:38:21,388 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:21,388 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:21,388 - INFO - After Normalization***************************************
2025-07-04 11:38:21,388 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:21,388 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:21,677 - INFO - before .to(local_rank)***************************************
2025-07-04 11:38:21,677 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:38:21,677 - INFO - After .to(local_rank)***************************************
2025-07-04 11:38:21,677 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:21,677 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:21,677 - INFO - After Normalization***************************************
2025-07-04 11:38:21,678 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:21,678 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:23,315 - INFO - Epoch 138/150 - Train Loss: 0.093484, Val Loss: 0.086202
2025-07-04 11:38:24,920 - INFO - Epoch 126/150 - Train Loss: 0.208929, Val Loss: 0.232208
2025-07-04 11:38:27,157 - INFO - before .to(local_rank)***************************************
2025-07-04 11:38:27,170 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:38:27,171 - INFO - After .to(local_rank)***************************************
2025-07-04 11:38:27,171 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:27,171 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:27,171 - INFO - After Normalization***************************************
2025-07-04 11:38:27,171 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:27,171 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:27,488 - INFO - before .to(local_rank)***************************************
2025-07-04 11:38:27,488 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:38:27,489 - INFO - After .to(local_rank)***************************************
2025-07-04 11:38:27,489 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:27,489 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:27,489 - INFO - After Normalization***************************************
2025-07-04 11:38:27,489 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:27,489 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:27,777 - INFO - before .to(local_rank)***************************************
2025-07-04 11:38:27,777 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:38:27,778 - INFO - After .to(local_rank)***************************************
2025-07-04 11:38:27,778 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:27,778 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:27,778 - INFO - After Normalization***************************************
2025-07-04 11:38:27,778 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:27,778 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:30,973 - INFO - Epoch 127/150 - Train Loss: 0.206713, Val Loss: 0.226560
2025-07-04 11:38:30,989 - INFO - New best model saved with Val Loss: 0.226560
2025-07-04 11:38:33,240 - INFO - before .to(local_rank)***************************************
2025-07-04 11:38:33,253 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:38:33,254 - INFO - After .to(local_rank)***************************************
2025-07-04 11:38:33,254 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:33,254 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:33,254 - INFO - After Normalization***************************************
2025-07-04 11:38:33,254 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:33,254 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:33,563 - INFO - before .to(local_rank)***************************************
2025-07-04 11:38:33,563 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:38:33,564 - INFO - After .to(local_rank)***************************************
2025-07-04 11:38:33,564 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:33,564 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:33,564 - INFO - After Normalization***************************************
2025-07-04 11:38:33,564 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:33,564 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:33,852 - INFO - before .to(local_rank)***************************************
2025-07-04 11:38:33,852 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:38:33,853 - INFO - After .to(local_rank)***************************************
2025-07-04 11:38:33,853 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:33,853 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:33,853 - INFO - After Normalization***************************************
2025-07-04 11:38:33,853 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:33,853 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:37,071 - INFO - Epoch 128/150 - Train Loss: 0.209242, Val Loss: 0.223407
2025-07-04 11:38:37,085 - INFO - New best model saved with Val Loss: 0.223407
2025-07-04 11:38:39,353 - INFO - before .to(local_rank)***************************************
2025-07-04 11:38:39,367 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:38:39,367 - INFO - After .to(local_rank)***************************************
2025-07-04 11:38:39,367 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:39,367 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:39,367 - INFO - After Normalization***************************************
2025-07-04 11:38:39,367 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:39,367 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:39,669 - INFO - before .to(local_rank)***************************************
2025-07-04 11:38:39,670 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:38:39,670 - INFO - After .to(local_rank)***************************************
2025-07-04 11:38:39,670 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:39,670 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:39,670 - INFO - After Normalization***************************************
2025-07-04 11:38:39,670 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:39,670 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:39,959 - INFO - before .to(local_rank)***************************************
2025-07-04 11:38:39,959 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:38:39,959 - INFO - After .to(local_rank)***************************************
2025-07-04 11:38:39,959 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:39,959 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:39,959 - INFO - After Normalization***************************************
2025-07-04 11:38:39,959 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:39,959 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:41,090 - INFO - Epoch 139/150 - Train Loss: 0.092633, Val Loss: 0.086555
2025-07-04 11:38:43,171 - INFO - Epoch 129/150 - Train Loss: 0.207208, Val Loss: 0.222295
2025-07-04 11:38:43,185 - INFO - New best model saved with Val Loss: 0.222295
2025-07-04 11:38:45,438 - INFO - before .to(local_rank)***************************************
2025-07-04 11:38:45,452 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:38:45,452 - INFO - After .to(local_rank)***************************************
2025-07-04 11:38:45,452 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:45,452 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:45,452 - INFO - After Normalization***************************************
2025-07-04 11:38:45,452 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:45,452 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:45,769 - INFO - before .to(local_rank)***************************************
2025-07-04 11:38:45,769 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:38:45,770 - INFO - After .to(local_rank)***************************************
2025-07-04 11:38:45,770 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:45,770 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:45,770 - INFO - After Normalization***************************************
2025-07-04 11:38:45,770 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:45,770 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:46,058 - INFO - before .to(local_rank)***************************************
2025-07-04 11:38:46,058 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:38:46,059 - INFO - After .to(local_rank)***************************************
2025-07-04 11:38:46,059 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:46,059 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:46,059 - INFO - After Normalization***************************************
2025-07-04 11:38:46,059 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:46,059 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:49,253 - INFO - Epoch 130/150 - Train Loss: 0.206944, Val Loss: 0.225768
2025-07-04 11:38:51,623 - INFO - before .to(local_rank)***************************************
2025-07-04 11:38:51,639 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:38:51,639 - INFO - After .to(local_rank)***************************************
2025-07-04 11:38:51,639 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:51,639 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:51,639 - INFO - After Normalization***************************************
2025-07-04 11:38:51,639 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:51,639 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:51,939 - INFO - before .to(local_rank)***************************************
2025-07-04 11:38:51,939 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:38:51,940 - INFO - After .to(local_rank)***************************************
2025-07-04 11:38:51,940 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:51,940 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:51,940 - INFO - After Normalization***************************************
2025-07-04 11:38:51,940 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:51,940 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:52,231 - INFO - before .to(local_rank)***************************************
2025-07-04 11:38:52,231 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:38:52,232 - INFO - After .to(local_rank)***************************************
2025-07-04 11:38:52,232 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:52,232 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:52,232 - INFO - After Normalization***************************************
2025-07-04 11:38:52,232 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:52,232 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:55,448 - INFO - Epoch 131/150 - Train Loss: 0.205182, Val Loss: 0.224567
2025-07-04 11:38:57,670 - INFO - before .to(local_rank)***************************************
2025-07-04 11:38:57,683 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:38:57,684 - INFO - After .to(local_rank)***************************************
2025-07-04 11:38:57,684 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:57,684 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:57,684 - INFO - After Normalization***************************************
2025-07-04 11:38:57,684 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:57,684 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:57,995 - INFO - before .to(local_rank)***************************************
2025-07-04 11:38:57,995 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:38:57,995 - INFO - After .to(local_rank)***************************************
2025-07-04 11:38:57,995 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:57,995 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:57,995 - INFO - After Normalization***************************************
2025-07-04 11:38:57,995 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:57,995 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:58,288 - INFO - before .to(local_rank)***************************************
2025-07-04 11:38:58,288 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:38:58,288 - INFO - After .to(local_rank)***************************************
2025-07-04 11:38:58,288 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:58,288 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:58,288 - INFO - After Normalization***************************************
2025-07-04 11:38:58,288 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:58,288 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:38:58,900 - INFO - Epoch 140/150 - Train Loss: 0.092953, Val Loss: 0.086549
2025-07-04 11:39:01,522 - INFO - Epoch 132/150 - Train Loss: 0.207266, Val Loss: 0.224274
2025-07-04 11:39:03,780 - INFO - before .to(local_rank)***************************************
2025-07-04 11:39:03,793 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:39:03,794 - INFO - After .to(local_rank)***************************************
2025-07-04 11:39:03,794 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:03,794 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:03,794 - INFO - After Normalization***************************************
2025-07-04 11:39:03,794 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:03,794 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:04,103 - INFO - before .to(local_rank)***************************************
2025-07-04 11:39:04,103 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:39:04,104 - INFO - After .to(local_rank)***************************************
2025-07-04 11:39:04,104 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:04,104 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:04,104 - INFO - After Normalization***************************************
2025-07-04 11:39:04,104 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:04,104 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:04,397 - INFO - before .to(local_rank)***************************************
2025-07-04 11:39:04,397 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:39:04,397 - INFO - After .to(local_rank)***************************************
2025-07-04 11:39:04,397 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:04,397 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:04,398 - INFO - After Normalization***************************************
2025-07-04 11:39:04,398 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:04,398 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:07,594 - INFO - Epoch 133/150 - Train Loss: 0.204924, Val Loss: 0.225970
2025-07-04 11:39:09,840 - INFO - before .to(local_rank)***************************************
2025-07-04 11:39:09,854 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:39:09,855 - INFO - After .to(local_rank)***************************************
2025-07-04 11:39:09,855 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:09,855 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:09,855 - INFO - After Normalization***************************************
2025-07-04 11:39:09,855 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:09,855 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:10,162 - INFO - before .to(local_rank)***************************************
2025-07-04 11:39:10,163 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:39:10,163 - INFO - After .to(local_rank)***************************************
2025-07-04 11:39:10,163 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:10,163 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:10,163 - INFO - After Normalization***************************************
2025-07-04 11:39:10,163 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:10,163 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:10,455 - INFO - before .to(local_rank)***************************************
2025-07-04 11:39:10,455 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:39:10,455 - INFO - After .to(local_rank)***************************************
2025-07-04 11:39:10,455 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:10,455 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:10,455 - INFO - After Normalization***************************************
2025-07-04 11:39:10,455 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:10,455 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:13,668 - INFO - Epoch 134/150 - Train Loss: 0.204168, Val Loss: 0.226186
2025-07-04 11:39:15,897 - INFO - before .to(local_rank)***************************************
2025-07-04 11:39:15,910 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:39:15,911 - INFO - After .to(local_rank)***************************************
2025-07-04 11:39:15,911 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:15,911 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:15,911 - INFO - After Normalization***************************************
2025-07-04 11:39:15,911 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:15,911 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:16,216 - INFO - before .to(local_rank)***************************************
2025-07-04 11:39:16,216 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:39:16,216 - INFO - After .to(local_rank)***************************************
2025-07-04 11:39:16,216 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:16,216 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:16,217 - INFO - After Normalization***************************************
2025-07-04 11:39:16,217 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:16,217 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:16,509 - INFO - before .to(local_rank)***************************************
2025-07-04 11:39:16,509 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:39:16,509 - INFO - After .to(local_rank)***************************************
2025-07-04 11:39:16,509 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:16,509 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:16,509 - INFO - After Normalization***************************************
2025-07-04 11:39:16,510 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:16,510 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:16,744 - INFO - Epoch 141/150 - Train Loss: 0.092855, Val Loss: 0.086349
2025-07-04 11:39:19,728 - INFO - Epoch 135/150 - Train Loss: 0.205579, Val Loss: 0.229163
2025-07-04 11:39:21,978 - INFO - before .to(local_rank)***************************************
2025-07-04 11:39:21,991 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:39:21,992 - INFO - After .to(local_rank)***************************************
2025-07-04 11:39:21,992 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:21,992 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:21,992 - INFO - After Normalization***************************************
2025-07-04 11:39:21,992 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:21,992 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:22,292 - INFO - before .to(local_rank)***************************************
2025-07-04 11:39:22,292 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:39:22,292 - INFO - After .to(local_rank)***************************************
2025-07-04 11:39:22,292 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:22,292 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:22,292 - INFO - After Normalization***************************************
2025-07-04 11:39:22,292 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:22,292 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:22,584 - INFO - before .to(local_rank)***************************************
2025-07-04 11:39:22,585 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:39:22,585 - INFO - After .to(local_rank)***************************************
2025-07-04 11:39:22,585 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:22,585 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:22,585 - INFO - After Normalization***************************************
2025-07-04 11:39:22,585 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:22,585 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:25,771 - INFO - Epoch 136/150 - Train Loss: 0.206300, Val Loss: 0.230606
2025-07-04 11:39:28,012 - INFO - before .to(local_rank)***************************************
2025-07-04 11:39:28,026 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:39:28,026 - INFO - After .to(local_rank)***************************************
2025-07-04 11:39:28,026 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:28,026 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:28,026 - INFO - After Normalization***************************************
2025-07-04 11:39:28,026 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:28,026 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:28,328 - INFO - before .to(local_rank)***************************************
2025-07-04 11:39:28,328 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:39:28,328 - INFO - After .to(local_rank)***************************************
2025-07-04 11:39:28,328 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:28,328 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:28,328 - INFO - After Normalization***************************************
2025-07-04 11:39:28,328 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:28,328 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:28,620 - INFO - before .to(local_rank)***************************************
2025-07-04 11:39:28,620 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:39:28,621 - INFO - After .to(local_rank)***************************************
2025-07-04 11:39:28,621 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:28,621 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:28,621 - INFO - After Normalization***************************************
2025-07-04 11:39:28,621 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:28,621 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:31,845 - INFO - Epoch 137/150 - Train Loss: 0.204792, Val Loss: 0.228642
2025-07-04 11:39:34,065 - INFO - before .to(local_rank)***************************************
2025-07-04 11:39:34,079 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:39:34,079 - INFO - After .to(local_rank)***************************************
2025-07-04 11:39:34,080 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:34,080 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:34,080 - INFO - After Normalization***************************************
2025-07-04 11:39:34,080 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:34,080 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:34,402 - INFO - before .to(local_rank)***************************************
2025-07-04 11:39:34,402 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:39:34,402 - INFO - After .to(local_rank)***************************************
2025-07-04 11:39:34,402 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:34,402 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:34,402 - INFO - After Normalization***************************************
2025-07-04 11:39:34,402 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:34,402 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:34,495 - INFO - Epoch 142/150 - Train Loss: 0.093116, Val Loss: 0.086281
2025-07-04 11:39:34,692 - INFO - before .to(local_rank)***************************************
2025-07-04 11:39:34,692 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:39:34,692 - INFO - After .to(local_rank)***************************************
2025-07-04 11:39:34,692 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:34,692 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:34,692 - INFO - After Normalization***************************************
2025-07-04 11:39:34,692 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:34,692 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:37,883 - INFO - Epoch 138/150 - Train Loss: 0.204796, Val Loss: 0.232180
2025-07-04 11:39:40,129 - INFO - before .to(local_rank)***************************************
2025-07-04 11:39:40,141 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:39:40,142 - INFO - After .to(local_rank)***************************************
2025-07-04 11:39:40,142 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:40,142 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:40,142 - INFO - After Normalization***************************************
2025-07-04 11:39:40,142 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:40,142 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:40,459 - INFO - before .to(local_rank)***************************************
2025-07-04 11:39:40,459 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:39:40,459 - INFO - After .to(local_rank)***************************************
2025-07-04 11:39:40,459 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:40,459 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:40,459 - INFO - After Normalization***************************************
2025-07-04 11:39:40,459 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:40,459 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:40,748 - INFO - before .to(local_rank)***************************************
2025-07-04 11:39:40,748 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:39:40,748 - INFO - After .to(local_rank)***************************************
2025-07-04 11:39:40,748 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:40,748 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:40,748 - INFO - After Normalization***************************************
2025-07-04 11:39:40,748 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:40,748 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:43,944 - INFO - Epoch 139/150 - Train Loss: 0.205599, Val Loss: 0.224674
2025-07-04 11:39:46,177 - INFO - before .to(local_rank)***************************************
2025-07-04 11:39:46,190 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:39:46,190 - INFO - After .to(local_rank)***************************************
2025-07-04 11:39:46,190 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:46,190 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:46,191 - INFO - After Normalization***************************************
2025-07-04 11:39:46,191 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:46,191 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:46,504 - INFO - before .to(local_rank)***************************************
2025-07-04 11:39:46,504 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:39:46,504 - INFO - After .to(local_rank)***************************************
2025-07-04 11:39:46,505 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:46,505 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:46,505 - INFO - After Normalization***************************************
2025-07-04 11:39:46,505 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:46,505 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:46,793 - INFO - before .to(local_rank)***************************************
2025-07-04 11:39:46,793 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:39:46,793 - INFO - After .to(local_rank)***************************************
2025-07-04 11:39:46,793 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:46,793 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:46,794 - INFO - After Normalization***************************************
2025-07-04 11:39:46,794 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:46,794 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:50,000 - INFO - Epoch 140/150 - Train Loss: 0.204527, Val Loss: 0.222321
2025-07-04 11:39:52,236 - INFO - Epoch 143/150 - Train Loss: 0.093006, Val Loss: 0.086377
2025-07-04 11:39:52,356 - INFO - before .to(local_rank)***************************************
2025-07-04 11:39:52,370 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:39:52,370 - INFO - After .to(local_rank)***************************************
2025-07-04 11:39:52,370 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:52,370 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:52,370 - INFO - After Normalization***************************************
2025-07-04 11:39:52,370 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:52,370 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:52,692 - INFO - before .to(local_rank)***************************************
2025-07-04 11:39:52,692 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:39:52,692 - INFO - After .to(local_rank)***************************************
2025-07-04 11:39:52,692 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:52,692 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:52,692 - INFO - After Normalization***************************************
2025-07-04 11:39:52,692 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:52,692 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:52,982 - INFO - before .to(local_rank)***************************************
2025-07-04 11:39:52,982 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:39:52,982 - INFO - After .to(local_rank)***************************************
2025-07-04 11:39:52,982 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:52,982 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:52,982 - INFO - After Normalization***************************************
2025-07-04 11:39:52,982 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:52,982 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:56,191 - INFO - Epoch 141/150 - Train Loss: 0.204573, Val Loss: 0.222382
2025-07-04 11:39:58,429 - INFO - before .to(local_rank)***************************************
2025-07-04 11:39:58,443 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:39:58,443 - INFO - After .to(local_rank)***************************************
2025-07-04 11:39:58,443 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:58,443 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:58,444 - INFO - After Normalization***************************************
2025-07-04 11:39:58,444 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:58,444 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:58,759 - INFO - before .to(local_rank)***************************************
2025-07-04 11:39:58,759 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:39:58,759 - INFO - After .to(local_rank)***************************************
2025-07-04 11:39:58,759 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:58,759 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:58,760 - INFO - After Normalization***************************************
2025-07-04 11:39:58,760 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:58,760 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:59,048 - INFO - before .to(local_rank)***************************************
2025-07-04 11:39:59,048 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:39:59,048 - INFO - After .to(local_rank)***************************************
2025-07-04 11:39:59,048 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:59,048 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:59,049 - INFO - After Normalization***************************************
2025-07-04 11:39:59,049 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:39:59,049 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:02,244 - INFO - Epoch 142/150 - Train Loss: 0.202772, Val Loss: 0.222352
2025-07-04 11:40:04,506 - INFO - before .to(local_rank)***************************************
2025-07-04 11:40:04,519 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:40:04,520 - INFO - After .to(local_rank)***************************************
2025-07-04 11:40:04,520 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:04,520 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:04,520 - INFO - After Normalization***************************************
2025-07-04 11:40:04,520 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:04,520 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:04,830 - INFO - before .to(local_rank)***************************************
2025-07-04 11:40:04,830 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:40:04,831 - INFO - After .to(local_rank)***************************************
2025-07-04 11:40:04,831 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:04,831 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:04,831 - INFO - After Normalization***************************************
2025-07-04 11:40:04,831 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:04,831 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:05,119 - INFO - before .to(local_rank)***************************************
2025-07-04 11:40:05,119 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:40:05,120 - INFO - After .to(local_rank)***************************************
2025-07-04 11:40:05,120 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:05,120 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:05,120 - INFO - After Normalization***************************************
2025-07-04 11:40:05,120 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:05,120 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:08,337 - INFO - Epoch 143/150 - Train Loss: 0.201713, Val Loss: 0.222547
2025-07-04 11:40:09,976 - INFO - Epoch 144/150 - Train Loss: 0.092932, Val Loss: 0.086349
2025-07-04 11:40:10,595 - INFO - before .to(local_rank)***************************************
2025-07-04 11:40:10,607 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:40:10,608 - INFO - After .to(local_rank)***************************************
2025-07-04 11:40:10,608 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:10,608 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:10,608 - INFO - After Normalization***************************************
2025-07-04 11:40:10,608 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:10,608 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:10,909 - INFO - before .to(local_rank)***************************************
2025-07-04 11:40:10,909 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:40:10,910 - INFO - After .to(local_rank)***************************************
2025-07-04 11:40:10,910 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:10,910 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:10,910 - INFO - After Normalization***************************************
2025-07-04 11:40:10,910 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:10,910 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:11,199 - INFO - before .to(local_rank)***************************************
2025-07-04 11:40:11,199 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:40:11,200 - INFO - After .to(local_rank)***************************************
2025-07-04 11:40:11,200 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:11,200 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:11,200 - INFO - After Normalization***************************************
2025-07-04 11:40:11,200 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:11,200 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:14,403 - INFO - Epoch 144/150 - Train Loss: 0.205784, Val Loss: 0.221948
2025-07-04 11:40:14,419 - INFO - New best model saved with Val Loss: 0.221948
2025-07-04 11:40:16,663 - INFO - before .to(local_rank)***************************************
2025-07-04 11:40:16,677 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:40:16,677 - INFO - After .to(local_rank)***************************************
2025-07-04 11:40:16,677 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:16,677 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:16,677 - INFO - After Normalization***************************************
2025-07-04 11:40:16,677 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:16,677 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:16,996 - INFO - before .to(local_rank)***************************************
2025-07-04 11:40:16,996 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:40:16,996 - INFO - After .to(local_rank)***************************************
2025-07-04 11:40:16,996 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:16,997 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:16,997 - INFO - After Normalization***************************************
2025-07-04 11:40:16,997 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:16,997 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:17,285 - INFO - before .to(local_rank)***************************************
2025-07-04 11:40:17,285 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:40:17,286 - INFO - After .to(local_rank)***************************************
2025-07-04 11:40:17,286 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:17,286 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:17,286 - INFO - After Normalization***************************************
2025-07-04 11:40:17,286 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:17,286 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:20,484 - INFO - Epoch 145/150 - Train Loss: 0.204412, Val Loss: 0.221852
2025-07-04 11:40:20,497 - INFO - New best model saved with Val Loss: 0.221852
2025-07-04 11:40:22,746 - INFO - before .to(local_rank)***************************************
2025-07-04 11:40:22,759 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:40:22,760 - INFO - After .to(local_rank)***************************************
2025-07-04 11:40:22,760 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:22,760 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:22,760 - INFO - After Normalization***************************************
2025-07-04 11:40:22,760 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:22,760 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:23,071 - INFO - before .to(local_rank)***************************************
2025-07-04 11:40:23,071 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:40:23,071 - INFO - After .to(local_rank)***************************************
2025-07-04 11:40:23,071 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:23,071 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:23,072 - INFO - After Normalization***************************************
2025-07-04 11:40:23,072 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:23,072 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:23,360 - INFO - before .to(local_rank)***************************************
2025-07-04 11:40:23,360 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:40:23,360 - INFO - After .to(local_rank)***************************************
2025-07-04 11:40:23,360 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:23,360 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:23,360 - INFO - After Normalization***************************************
2025-07-04 11:40:23,360 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:23,361 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:26,573 - INFO - Epoch 146/150 - Train Loss: 0.205469, Val Loss: 0.220326
2025-07-04 11:40:26,586 - INFO - New best model saved with Val Loss: 0.220326
2025-07-04 11:40:27,726 - INFO - Epoch 145/150 - Train Loss: 0.092390, Val Loss: 0.086420
2025-07-04 11:40:28,868 - INFO - before .to(local_rank)***************************************
2025-07-04 11:40:28,883 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:40:28,883 - INFO - After .to(local_rank)***************************************
2025-07-04 11:40:28,883 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:28,883 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:28,883 - INFO - After Normalization***************************************
2025-07-04 11:40:28,883 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:28,883 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:29,185 - INFO - before .to(local_rank)***************************************
2025-07-04 11:40:29,186 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:40:29,186 - INFO - After .to(local_rank)***************************************
2025-07-04 11:40:29,186 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:29,186 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:29,186 - INFO - After Normalization***************************************
2025-07-04 11:40:29,186 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:29,186 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:29,475 - INFO - before .to(local_rank)***************************************
2025-07-04 11:40:29,475 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:40:29,475 - INFO - After .to(local_rank)***************************************
2025-07-04 11:40:29,475 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:29,475 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:29,475 - INFO - After Normalization***************************************
2025-07-04 11:40:29,475 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:29,476 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:32,703 - INFO - Epoch 147/150 - Train Loss: 0.204432, Val Loss: 0.220514
2025-07-04 11:40:34,967 - INFO - before .to(local_rank)***************************************
2025-07-04 11:40:34,980 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:40:34,980 - INFO - After .to(local_rank)***************************************
2025-07-04 11:40:34,981 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:34,981 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:34,981 - INFO - After Normalization***************************************
2025-07-04 11:40:34,981 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:34,981 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:35,297 - INFO - before .to(local_rank)***************************************
2025-07-04 11:40:35,297 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:40:35,297 - INFO - After .to(local_rank)***************************************
2025-07-04 11:40:35,297 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:35,297 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:35,297 - INFO - After Normalization***************************************
2025-07-04 11:40:35,297 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:35,297 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:35,586 - INFO - before .to(local_rank)***************************************
2025-07-04 11:40:35,586 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:40:35,586 - INFO - After .to(local_rank)***************************************
2025-07-04 11:40:35,586 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:35,586 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:35,586 - INFO - After Normalization***************************************
2025-07-04 11:40:35,586 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:35,586 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:38,792 - INFO - Epoch 148/150 - Train Loss: 0.203702, Val Loss: 0.220369
2025-07-04 11:40:41,039 - INFO - before .to(local_rank)***************************************
2025-07-04 11:40:41,052 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:40:41,053 - INFO - After .to(local_rank)***************************************
2025-07-04 11:40:41,053 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:41,053 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:41,053 - INFO - After Normalization***************************************
2025-07-04 11:40:41,053 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:41,053 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:41,364 - INFO - before .to(local_rank)***************************************
2025-07-04 11:40:41,364 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:40:41,364 - INFO - After .to(local_rank)***************************************
2025-07-04 11:40:41,364 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:41,364 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:41,364 - INFO - After Normalization***************************************
2025-07-04 11:40:41,364 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:41,365 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:41,654 - INFO - before .to(local_rank)***************************************
2025-07-04 11:40:41,654 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:40:41,654 - INFO - After .to(local_rank)***************************************
2025-07-04 11:40:41,654 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:41,654 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:41,654 - INFO - After Normalization***************************************
2025-07-04 11:40:41,654 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:41,654 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:44,860 - INFO - Epoch 149/150 - Train Loss: 0.202560, Val Loss: 0.220369
2025-07-04 11:40:45,482 - INFO - Epoch 146/150 - Train Loss: 0.093185, Val Loss: 0.086400
2025-07-04 11:40:47,128 - INFO - before .to(local_rank)***************************************
2025-07-04 11:40:47,142 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:40:47,142 - INFO - After .to(local_rank)***************************************
2025-07-04 11:40:47,142 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:47,142 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:47,143 - INFO - After Normalization***************************************
2025-07-04 11:40:47,143 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:47,143 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:47,447 - INFO - before .to(local_rank)***************************************
2025-07-04 11:40:47,447 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:40:47,447 - INFO - After .to(local_rank)***************************************
2025-07-04 11:40:47,447 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:47,447 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:47,448 - INFO - After Normalization***************************************
2025-07-04 11:40:47,448 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:47,448 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:47,737 - INFO - before .to(local_rank)***************************************
2025-07-04 11:40:47,737 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 11:40:47,737 - INFO - After .to(local_rank)***************************************
2025-07-04 11:40:47,737 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:47,737 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:47,737 - INFO - After Normalization***************************************
2025-07-04 11:40:47,737 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:47,737 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 11:40:50,986 - INFO - Epoch 150/150 - Train Loss: 0.202702, Val Loss: 0.220655
2025-07-04 11:40:51,109 - INFO - Final model saved to experiments/Train_Test/final_model_tmp
2025-07-04 11:40:51,119 - INFO - Testing the final model
2025-07-04 11:40:51,119 - INFO - Testing the best model
2025-07-04 11:41:03,182 - INFO - Epoch 147/150 - Train Loss: 0.093196, Val Loss: 0.086339
2025-07-04 11:41:20,884 - INFO - Epoch 148/150 - Train Loss: 0.092870, Val Loss: 0.086243
2025-07-04 11:41:38,560 - INFO - Epoch 149/150 - Train Loss: 0.092973, Val Loss: 0.086341
2025-07-04 11:41:56,249 - INFO - Epoch 150/150 - Train Loss: 0.093295, Val Loss: 0.086364
2025-07-04 11:41:56,375 - INFO - Final model saved to experiments/Train_Test/final_model_pth
2025-07-04 11:41:56,375 - INFO - Testing the final model
2025-07-04 11:42:00,622 - INFO - Total MSE across all processes: 4.534732341766357
2025-07-04 11:42:00,624 - INFO - mean value for all_targets: {tmp}
2025-07-04 11:42:00,628 - INFO - Test MSE: 0.083977, Test MAE: 0.163705, Max AE: 14.103622, Test R2: 0.9250
2025-07-04 11:42:00,628 - INFO - Relative L2 Error: 0.273197, Relative L1 error: 0.252804
2025-07-04 11:42:00,628 - INFO - Total inference time:  0.03s for 54 samples
2025-07-04 11:42:00,630 - INFO - Testing the best model
2025-07-04 11:42:04,732 - INFO - Total MSE across all processes: 4.533969402313232
2025-07-04 11:42:04,733 - INFO - mean value for all_targets: {tmp}
2025-07-04 11:42:04,735 - INFO - Test MSE: 0.083962, Test MAE: 0.163290, Max AE: 14.126799, Test R2: 0.9250
2025-07-04 11:42:04,735 - INFO - Relative L2 Error: 0.273214, Relative L1 error: 0.252141
2025-07-04 11:42:04,736 - INFO - Total inference time:  0.03s for 54 samples
2025-07-04 12:23:22,879 - INFO - args.exp_name : Train_Test
2025-07-04 12:23:22,887 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=6, epochs=150, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-07-04 12:23:22,887 - INFO - Starting training with 1 GPUs
2025-07-04 12:23:26,511 - INFO - Total trainable parameters: 1437705
2025-07-04 12:23:26,553 - INFO - Data loaded: 3 training batches, 1 validation batches, 1 test batches
2025-07-04 12:23:26,556 - INFO - Staring training for 150 epochs
2025-07-04 12:23:30,606 - INFO - before .to(local_rank)***************************************
2025-07-04 12:23:30,611 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:23:30,611 - INFO - After .to(local_rank)***************************************
2025-07-04 12:23:30,611 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:23:30,631 - INFO - After Normalization***************************************
2025-07-04 12:23:30,632 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:23:31,532 - INFO - before .to(local_rank)***************************************
2025-07-04 12:23:31,532 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:23:31,532 - INFO - After .to(local_rank)***************************************
2025-07-04 12:23:31,532 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:23:31,532 - INFO - After Normalization***************************************
2025-07-04 12:23:31,533 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:23:31,827 - INFO - before .to(local_rank)***************************************
2025-07-04 12:23:31,827 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:23:31,828 - INFO - After .to(local_rank)***************************************
2025-07-04 12:23:31,828 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:23:31,828 - INFO - After Normalization***************************************
2025-07-04 12:23:31,828 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:23:36,031 - INFO - Epoch 1/150 - Train Loss: 1.283437, Val Loss: 1.146866
2025-07-04 12:23:36,049 - INFO - New best model saved with Val Loss: 1.146866
2025-07-04 12:23:38,300 - INFO - before .to(local_rank)***************************************
2025-07-04 12:23:38,314 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:23:38,315 - INFO - After .to(local_rank)***************************************
2025-07-04 12:23:38,315 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:23:38,315 - INFO - After Normalization***************************************
2025-07-04 12:23:38,315 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:23:38,621 - INFO - before .to(local_rank)***************************************
2025-07-04 12:23:38,621 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:23:38,621 - INFO - After .to(local_rank)***************************************
2025-07-04 12:23:38,621 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:23:38,622 - INFO - After Normalization***************************************
2025-07-04 12:23:38,622 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:23:38,911 - INFO - before .to(local_rank)***************************************
2025-07-04 12:23:38,911 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:23:38,911 - INFO - After .to(local_rank)***************************************
2025-07-04 12:23:38,911 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:23:38,911 - INFO - After Normalization***************************************
2025-07-04 12:23:38,912 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:23:42,151 - INFO - Epoch 2/150 - Train Loss: 1.159811, Val Loss: 1.148012
2025-07-04 12:23:44,523 - INFO - before .to(local_rank)***************************************
2025-07-04 12:23:44,536 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:23:44,536 - INFO - After .to(local_rank)***************************************
2025-07-04 12:23:44,536 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:23:44,536 - INFO - After Normalization***************************************
2025-07-04 12:23:44,537 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:23:44,841 - INFO - before .to(local_rank)***************************************
2025-07-04 12:23:44,841 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:23:44,842 - INFO - After .to(local_rank)***************************************
2025-07-04 12:23:44,842 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:23:44,842 - INFO - After Normalization***************************************
2025-07-04 12:23:44,842 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:23:45,131 - INFO - before .to(local_rank)***************************************
2025-07-04 12:23:45,131 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:23:45,131 - INFO - After .to(local_rank)***************************************
2025-07-04 12:23:45,132 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:23:45,132 - INFO - After Normalization***************************************
2025-07-04 12:23:45,132 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:23:49,923 - INFO - Epoch 3/150 - Train Loss: 1.015355, Val Loss: 1.148288
2025-07-04 12:23:52,855 - INFO - before .to(local_rank)***************************************
2025-07-04 12:23:52,861 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:23:52,861 - INFO - After .to(local_rank)***************************************
2025-07-04 12:23:52,861 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:23:52,861 - INFO - After Normalization***************************************
2025-07-04 12:23:52,861 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:23:53,183 - INFO - before .to(local_rank)***************************************
2025-07-04 12:23:53,183 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:23:53,183 - INFO - After .to(local_rank)***************************************
2025-07-04 12:23:53,183 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:23:53,183 - INFO - After Normalization***************************************
2025-07-04 12:23:53,183 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:23:53,472 - INFO - before .to(local_rank)***************************************
2025-07-04 12:23:53,472 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:23:53,472 - INFO - After .to(local_rank)***************************************
2025-07-04 12:23:53,472 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:23:53,473 - INFO - After Normalization***************************************
2025-07-04 12:23:53,473 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:23:57,118 - INFO - Epoch 4/150 - Train Loss: 0.916734, Val Loss: 1.249089
2025-07-04 12:23:59,453 - INFO - before .to(local_rank)***************************************
2025-07-04 12:23:59,468 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:23:59,468 - INFO - After .to(local_rank)***************************************
2025-07-04 12:23:59,468 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:23:59,469 - INFO - After Normalization***************************************
2025-07-04 12:23:59,471 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:23:59,790 - INFO - before .to(local_rank)***************************************
2025-07-04 12:23:59,790 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:23:59,790 - INFO - After .to(local_rank)***************************************
2025-07-04 12:23:59,790 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:23:59,790 - INFO - After Normalization***************************************
2025-07-04 12:23:59,790 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:00,079 - INFO - before .to(local_rank)***************************************
2025-07-04 12:24:00,079 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:24:00,080 - INFO - After .to(local_rank)***************************************
2025-07-04 12:24:00,080 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:00,080 - INFO - After Normalization***************************************
2025-07-04 12:24:00,080 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:03,706 - INFO - Epoch 5/150 - Train Loss: 0.839702, Val Loss: 1.442995
2025-07-04 12:24:08,749 - INFO - before .to(local_rank)***************************************
2025-07-04 12:24:08,754 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:24:08,755 - INFO - After .to(local_rank)***************************************
2025-07-04 12:24:08,755 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:08,755 - INFO - After Normalization***************************************
2025-07-04 12:24:08,755 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:09,070 - INFO - before .to(local_rank)***************************************
2025-07-04 12:24:09,070 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:24:09,070 - INFO - After .to(local_rank)***************************************
2025-07-04 12:24:09,070 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:09,070 - INFO - After Normalization***************************************
2025-07-04 12:24:09,071 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:09,360 - INFO - before .to(local_rank)***************************************
2025-07-04 12:24:09,360 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:24:09,360 - INFO - After .to(local_rank)***************************************
2025-07-04 12:24:09,360 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:09,360 - INFO - After Normalization***************************************
2025-07-04 12:24:09,360 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:17,006 - INFO - Epoch 6/150 - Train Loss: 0.757819, Val Loss: 1.361055
2025-07-04 12:24:21,841 - INFO - before .to(local_rank)***************************************
2025-07-04 12:24:21,847 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:24:21,848 - INFO - After .to(local_rank)***************************************
2025-07-04 12:24:21,848 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:21,848 - INFO - After Normalization***************************************
2025-07-04 12:24:21,848 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:22,159 - INFO - before .to(local_rank)***************************************
2025-07-04 12:24:22,159 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:24:22,160 - INFO - After .to(local_rank)***************************************
2025-07-04 12:24:22,160 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:22,160 - INFO - After Normalization***************************************
2025-07-04 12:24:22,160 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:22,450 - INFO - before .to(local_rank)***************************************
2025-07-04 12:24:22,450 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:24:22,450 - INFO - After .to(local_rank)***************************************
2025-07-04 12:24:22,450 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:22,450 - INFO - After Normalization***************************************
2025-07-04 12:24:22,451 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:26,617 - INFO - Epoch 7/150 - Train Loss: 0.661384, Val Loss: 1.379884
2025-07-04 12:24:28,913 - INFO - before .to(local_rank)***************************************
2025-07-04 12:24:28,928 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:24:28,928 - INFO - After .to(local_rank)***************************************
2025-07-04 12:24:28,929 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:28,929 - INFO - After Normalization***************************************
2025-07-04 12:24:28,929 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:29,235 - INFO - before .to(local_rank)***************************************
2025-07-04 12:24:29,235 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:24:29,235 - INFO - After .to(local_rank)***************************************
2025-07-04 12:24:29,235 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:29,235 - INFO - After Normalization***************************************
2025-07-04 12:24:29,235 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:29,524 - INFO - before .to(local_rank)***************************************
2025-07-04 12:24:29,524 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:24:29,525 - INFO - After .to(local_rank)***************************************
2025-07-04 12:24:29,525 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:29,525 - INFO - After Normalization***************************************
2025-07-04 12:24:29,525 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:32,911 - INFO - Epoch 8/150 - Train Loss: 0.608690, Val Loss: 1.595568
2025-07-04 12:24:35,196 - INFO - before .to(local_rank)***************************************
2025-07-04 12:24:35,212 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:24:35,212 - INFO - After .to(local_rank)***************************************
2025-07-04 12:24:35,212 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:35,212 - INFO - After Normalization***************************************
2025-07-04 12:24:35,212 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:35,514 - INFO - before .to(local_rank)***************************************
2025-07-04 12:24:35,514 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:24:35,514 - INFO - After .to(local_rank)***************************************
2025-07-04 12:24:35,514 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:35,514 - INFO - After Normalization***************************************
2025-07-04 12:24:35,514 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:35,809 - INFO - before .to(local_rank)***************************************
2025-07-04 12:24:35,809 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:24:35,809 - INFO - After .to(local_rank)***************************************
2025-07-04 12:24:35,809 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:35,809 - INFO - After Normalization***************************************
2025-07-04 12:24:35,809 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:39,175 - INFO - Epoch 9/150 - Train Loss: 0.560139, Val Loss: 1.838627
2025-07-04 12:24:41,477 - INFO - before .to(local_rank)***************************************
2025-07-04 12:24:41,494 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:24:41,494 - INFO - After .to(local_rank)***************************************
2025-07-04 12:24:41,494 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:41,495 - INFO - After Normalization***************************************
2025-07-04 12:24:41,495 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:41,817 - INFO - before .to(local_rank)***************************************
2025-07-04 12:24:41,817 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:24:41,817 - INFO - After .to(local_rank)***************************************
2025-07-04 12:24:41,817 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:41,818 - INFO - After Normalization***************************************
2025-07-04 12:24:41,818 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:42,106 - INFO - before .to(local_rank)***************************************
2025-07-04 12:24:42,106 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:24:42,107 - INFO - After .to(local_rank)***************************************
2025-07-04 12:24:42,107 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:42,107 - INFO - After Normalization***************************************
2025-07-04 12:24:42,107 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:45,429 - INFO - Epoch 10/150 - Train Loss: 0.526667, Val Loss: 1.521763
2025-07-04 12:24:47,868 - INFO - before .to(local_rank)***************************************
2025-07-04 12:24:47,883 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:24:47,883 - INFO - After .to(local_rank)***************************************
2025-07-04 12:24:47,883 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:47,883 - INFO - After Normalization***************************************
2025-07-04 12:24:47,883 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:48,183 - INFO - before .to(local_rank)***************************************
2025-07-04 12:24:48,183 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:24:48,184 - INFO - After .to(local_rank)***************************************
2025-07-04 12:24:48,184 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:48,184 - INFO - After Normalization***************************************
2025-07-04 12:24:48,184 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:48,473 - INFO - before .to(local_rank)***************************************
2025-07-04 12:24:48,473 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:24:48,474 - INFO - After .to(local_rank)***************************************
2025-07-04 12:24:48,474 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:48,474 - INFO - After Normalization***************************************
2025-07-04 12:24:48,474 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:51,759 - INFO - Epoch 11/150 - Train Loss: 0.494009, Val Loss: 1.437564
2025-07-04 12:24:54,060 - INFO - before .to(local_rank)***************************************
2025-07-04 12:24:54,076 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:24:54,076 - INFO - After .to(local_rank)***************************************
2025-07-04 12:24:54,076 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:54,076 - INFO - After Normalization***************************************
2025-07-04 12:24:54,076 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:54,379 - INFO - before .to(local_rank)***************************************
2025-07-04 12:24:54,379 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:24:54,381 - INFO - After .to(local_rank)***************************************
2025-07-04 12:24:54,381 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:54,381 - INFO - After Normalization***************************************
2025-07-04 12:24:54,381 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:54,670 - INFO - before .to(local_rank)***************************************
2025-07-04 12:24:54,670 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:24:54,670 - INFO - After .to(local_rank)***************************************
2025-07-04 12:24:54,671 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:54,671 - INFO - After Normalization***************************************
2025-07-04 12:24:54,671 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:24:58,014 - INFO - Epoch 12/150 - Train Loss: 0.474216, Val Loss: 1.348367
2025-07-04 12:25:00,324 - INFO - before .to(local_rank)***************************************
2025-07-04 12:25:00,339 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:25:00,340 - INFO - After .to(local_rank)***************************************
2025-07-04 12:25:00,340 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:00,340 - INFO - After Normalization***************************************
2025-07-04 12:25:00,340 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:00,641 - INFO - before .to(local_rank)***************************************
2025-07-04 12:25:00,641 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:25:00,641 - INFO - After .to(local_rank)***************************************
2025-07-04 12:25:00,641 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:00,641 - INFO - After Normalization***************************************
2025-07-04 12:25:00,641 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:00,936 - INFO - before .to(local_rank)***************************************
2025-07-04 12:25:00,937 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:25:00,937 - INFO - After .to(local_rank)***************************************
2025-07-04 12:25:00,937 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:00,937 - INFO - After Normalization***************************************
2025-07-04 12:25:00,937 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:04,242 - INFO - Epoch 13/150 - Train Loss: 0.457834, Val Loss: 1.089559
2025-07-04 12:25:04,271 - INFO - New best model saved with Val Loss: 1.089559
2025-07-04 12:25:06,578 - INFO - before .to(local_rank)***************************************
2025-07-04 12:25:06,592 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:25:06,592 - INFO - After .to(local_rank)***************************************
2025-07-04 12:25:06,592 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:06,592 - INFO - After Normalization***************************************
2025-07-04 12:25:06,592 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:06,911 - INFO - before .to(local_rank)***************************************
2025-07-04 12:25:06,911 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:25:06,912 - INFO - After .to(local_rank)***************************************
2025-07-04 12:25:06,912 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:06,912 - INFO - After Normalization***************************************
2025-07-04 12:25:06,912 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:07,206 - INFO - before .to(local_rank)***************************************
2025-07-04 12:25:07,206 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:25:07,208 - INFO - After .to(local_rank)***************************************
2025-07-04 12:25:07,208 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:07,208 - INFO - After Normalization***************************************
2025-07-04 12:25:07,208 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:10,508 - INFO - Epoch 14/150 - Train Loss: 0.455360, Val Loss: 0.832426
2025-07-04 12:25:10,524 - INFO - New best model saved with Val Loss: 0.832426
2025-07-04 12:25:12,811 - INFO - before .to(local_rank)***************************************
2025-07-04 12:25:12,825 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:25:12,826 - INFO - After .to(local_rank)***************************************
2025-07-04 12:25:12,826 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:12,826 - INFO - After Normalization***************************************
2025-07-04 12:25:12,826 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:13,150 - INFO - before .to(local_rank)***************************************
2025-07-04 12:25:13,150 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:25:13,150 - INFO - After .to(local_rank)***************************************
2025-07-04 12:25:13,150 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:13,150 - INFO - After Normalization***************************************
2025-07-04 12:25:13,151 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:13,440 - INFO - before .to(local_rank)***************************************
2025-07-04 12:25:13,440 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:25:13,441 - INFO - After .to(local_rank)***************************************
2025-07-04 12:25:13,441 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:13,441 - INFO - After Normalization***************************************
2025-07-04 12:25:13,441 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:16,773 - INFO - Epoch 15/150 - Train Loss: 0.447783, Val Loss: 0.654857
2025-07-04 12:25:16,787 - INFO - New best model saved with Val Loss: 0.654857
2025-07-04 12:25:19,070 - INFO - before .to(local_rank)***************************************
2025-07-04 12:25:19,085 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:25:19,085 - INFO - After .to(local_rank)***************************************
2025-07-04 12:25:19,085 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:19,085 - INFO - After Normalization***************************************
2025-07-04 12:25:19,085 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:19,400 - INFO - before .to(local_rank)***************************************
2025-07-04 12:25:19,401 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:25:19,401 - INFO - After .to(local_rank)***************************************
2025-07-04 12:25:19,401 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:19,401 - INFO - After Normalization***************************************
2025-07-04 12:25:19,401 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:19,690 - INFO - before .to(local_rank)***************************************
2025-07-04 12:25:19,691 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:25:19,691 - INFO - After .to(local_rank)***************************************
2025-07-04 12:25:19,691 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:19,691 - INFO - After Normalization***************************************
2025-07-04 12:25:19,691 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:23,022 - INFO - Epoch 16/150 - Train Loss: 0.446389, Val Loss: 0.548675
2025-07-04 12:25:23,037 - INFO - New best model saved with Val Loss: 0.548675
2025-07-04 12:25:25,329 - INFO - before .to(local_rank)***************************************
2025-07-04 12:25:25,342 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:25:25,342 - INFO - After .to(local_rank)***************************************
2025-07-04 12:25:25,342 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:25,342 - INFO - After Normalization***************************************
2025-07-04 12:25:25,342 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:25,653 - INFO - before .to(local_rank)***************************************
2025-07-04 12:25:25,653 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:25:25,654 - INFO - After .to(local_rank)***************************************
2025-07-04 12:25:25,654 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:25,654 - INFO - After Normalization***************************************
2025-07-04 12:25:25,654 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:25,943 - INFO - before .to(local_rank)***************************************
2025-07-04 12:25:25,943 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:25:25,944 - INFO - After .to(local_rank)***************************************
2025-07-04 12:25:25,944 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:25,944 - INFO - After Normalization***************************************
2025-07-04 12:25:25,944 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:29,296 - INFO - Epoch 17/150 - Train Loss: 0.440610, Val Loss: 0.495317
2025-07-04 12:25:29,311 - INFO - New best model saved with Val Loss: 0.495317
2025-07-04 12:25:31,600 - INFO - before .to(local_rank)***************************************
2025-07-04 12:25:31,614 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:25:31,615 - INFO - After .to(local_rank)***************************************
2025-07-04 12:25:31,615 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:31,615 - INFO - After Normalization***************************************
2025-07-04 12:25:31,615 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:31,922 - INFO - before .to(local_rank)***************************************
2025-07-04 12:25:31,922 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:25:31,922 - INFO - After .to(local_rank)***************************************
2025-07-04 12:25:31,922 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:31,922 - INFO - After Normalization***************************************
2025-07-04 12:25:31,922 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:32,216 - INFO - before .to(local_rank)***************************************
2025-07-04 12:25:32,217 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:25:32,217 - INFO - After .to(local_rank)***************************************
2025-07-04 12:25:32,217 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:32,217 - INFO - After Normalization***************************************
2025-07-04 12:25:32,217 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:35,527 - INFO - Epoch 18/150 - Train Loss: 0.438833, Val Loss: 0.464275
2025-07-04 12:25:35,543 - INFO - New best model saved with Val Loss: 0.464275
2025-07-04 12:25:37,839 - INFO - before .to(local_rank)***************************************
2025-07-04 12:25:37,854 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:25:37,854 - INFO - After .to(local_rank)***************************************
2025-07-04 12:25:37,854 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:37,854 - INFO - After Normalization***************************************
2025-07-04 12:25:37,854 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:38,165 - INFO - before .to(local_rank)***************************************
2025-07-04 12:25:38,165 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:25:38,166 - INFO - After .to(local_rank)***************************************
2025-07-04 12:25:38,166 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:38,166 - INFO - After Normalization***************************************
2025-07-04 12:25:38,166 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:38,455 - INFO - before .to(local_rank)***************************************
2025-07-04 12:25:38,455 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:25:38,456 - INFO - After .to(local_rank)***************************************
2025-07-04 12:25:38,456 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:38,456 - INFO - After Normalization***************************************
2025-07-04 12:25:38,456 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:41,751 - INFO - Epoch 19/150 - Train Loss: 0.439969, Val Loss: 0.443737
2025-07-04 12:25:41,765 - INFO - New best model saved with Val Loss: 0.443737
2025-07-04 12:25:44,065 - INFO - before .to(local_rank)***************************************
2025-07-04 12:25:44,078 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:25:44,079 - INFO - After .to(local_rank)***************************************
2025-07-04 12:25:44,079 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:44,079 - INFO - After Normalization***************************************
2025-07-04 12:25:44,079 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:44,389 - INFO - before .to(local_rank)***************************************
2025-07-04 12:25:44,390 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:25:44,390 - INFO - After .to(local_rank)***************************************
2025-07-04 12:25:44,390 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:44,390 - INFO - After Normalization***************************************
2025-07-04 12:25:44,390 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:44,679 - INFO - before .to(local_rank)***************************************
2025-07-04 12:25:44,679 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:25:44,680 - INFO - After .to(local_rank)***************************************
2025-07-04 12:25:44,680 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:44,680 - INFO - After Normalization***************************************
2025-07-04 12:25:44,680 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:47,993 - INFO - Epoch 20/150 - Train Loss: 0.431883, Val Loss: 0.428062
2025-07-04 12:25:48,008 - INFO - New best model saved with Val Loss: 0.428062
2025-07-04 12:25:50,430 - INFO - before .to(local_rank)***************************************
2025-07-04 12:25:50,445 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:25:50,445 - INFO - After .to(local_rank)***************************************
2025-07-04 12:25:50,445 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:50,445 - INFO - After Normalization***************************************
2025-07-04 12:25:50,445 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:50,758 - INFO - before .to(local_rank)***************************************
2025-07-04 12:25:50,759 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:25:50,759 - INFO - After .to(local_rank)***************************************
2025-07-04 12:25:50,759 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:50,759 - INFO - After Normalization***************************************
2025-07-04 12:25:50,760 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:51,049 - INFO - before .to(local_rank)***************************************
2025-07-04 12:25:51,049 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:25:51,049 - INFO - After .to(local_rank)***************************************
2025-07-04 12:25:51,050 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:51,050 - INFO - After Normalization***************************************
2025-07-04 12:25:51,050 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:55,007 - INFO - Epoch 21/150 - Train Loss: 0.431155, Val Loss: 0.423547
2025-07-04 12:25:55,104 - INFO - New best model saved with Val Loss: 0.423547
2025-07-04 12:25:57,408 - INFO - before .to(local_rank)***************************************
2025-07-04 12:25:57,423 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:25:57,423 - INFO - After .to(local_rank)***************************************
2025-07-04 12:25:57,424 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:57,424 - INFO - After Normalization***************************************
2025-07-04 12:25:57,424 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:57,736 - INFO - before .to(local_rank)***************************************
2025-07-04 12:25:57,736 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:25:57,736 - INFO - After .to(local_rank)***************************************
2025-07-04 12:25:57,737 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:57,737 - INFO - After Normalization***************************************
2025-07-04 12:25:57,737 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:58,026 - INFO - before .to(local_rank)***************************************
2025-07-04 12:25:58,026 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:25:58,026 - INFO - After .to(local_rank)***************************************
2025-07-04 12:25:58,026 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:25:58,026 - INFO - After Normalization***************************************
2025-07-04 12:25:58,026 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:01,347 - INFO - Epoch 22/150 - Train Loss: 0.428144, Val Loss: 0.426146
2025-07-04 12:26:03,674 - INFO - before .to(local_rank)***************************************
2025-07-04 12:26:03,690 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:26:03,690 - INFO - After .to(local_rank)***************************************
2025-07-04 12:26:03,690 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:03,690 - INFO - After Normalization***************************************
2025-07-04 12:26:03,691 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:04,006 - INFO - before .to(local_rank)***************************************
2025-07-04 12:26:04,006 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:26:04,007 - INFO - After .to(local_rank)***************************************
2025-07-04 12:26:04,007 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:04,007 - INFO - After Normalization***************************************
2025-07-04 12:26:04,007 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:04,296 - INFO - before .to(local_rank)***************************************
2025-07-04 12:26:04,296 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:26:04,296 - INFO - After .to(local_rank)***************************************
2025-07-04 12:26:04,296 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:04,296 - INFO - After Normalization***************************************
2025-07-04 12:26:04,296 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:07,654 - INFO - Epoch 23/150 - Train Loss: 0.425435, Val Loss: 0.427524
2025-07-04 12:26:09,952 - INFO - before .to(local_rank)***************************************
2025-07-04 12:26:09,967 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:26:09,967 - INFO - After .to(local_rank)***************************************
2025-07-04 12:26:09,967 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:09,967 - INFO - After Normalization***************************************
2025-07-04 12:26:09,967 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:10,277 - INFO - before .to(local_rank)***************************************
2025-07-04 12:26:10,277 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:26:10,277 - INFO - After .to(local_rank)***************************************
2025-07-04 12:26:10,277 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:10,278 - INFO - After Normalization***************************************
2025-07-04 12:26:10,278 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:10,572 - INFO - before .to(local_rank)***************************************
2025-07-04 12:26:10,572 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:26:10,572 - INFO - After .to(local_rank)***************************************
2025-07-04 12:26:10,572 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:10,573 - INFO - After Normalization***************************************
2025-07-04 12:26:10,573 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:13,899 - INFO - Epoch 24/150 - Train Loss: 0.422210, Val Loss: 0.422279
2025-07-04 12:26:13,916 - INFO - New best model saved with Val Loss: 0.422279
2025-07-04 12:26:16,185 - INFO - before .to(local_rank)***************************************
2025-07-04 12:26:16,200 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:26:16,200 - INFO - After .to(local_rank)***************************************
2025-07-04 12:26:16,200 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:16,200 - INFO - After Normalization***************************************
2025-07-04 12:26:16,200 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:16,515 - INFO - before .to(local_rank)***************************************
2025-07-04 12:26:16,515 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:26:16,516 - INFO - After .to(local_rank)***************************************
2025-07-04 12:26:16,516 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:16,516 - INFO - After Normalization***************************************
2025-07-04 12:26:16,516 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:16,805 - INFO - before .to(local_rank)***************************************
2025-07-04 12:26:16,805 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:26:16,806 - INFO - After .to(local_rank)***************************************
2025-07-04 12:26:16,806 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:16,806 - INFO - After Normalization***************************************
2025-07-04 12:26:16,806 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:20,149 - INFO - Epoch 25/150 - Train Loss: 0.423424, Val Loss: 0.427988
2025-07-04 12:26:22,459 - INFO - before .to(local_rank)***************************************
2025-07-04 12:26:22,474 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:26:22,474 - INFO - After .to(local_rank)***************************************
2025-07-04 12:26:22,474 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:22,474 - INFO - After Normalization***************************************
2025-07-04 12:26:22,475 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:22,780 - INFO - before .to(local_rank)***************************************
2025-07-04 12:26:22,781 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:26:22,781 - INFO - After .to(local_rank)***************************************
2025-07-04 12:26:22,781 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:22,781 - INFO - After Normalization***************************************
2025-07-04 12:26:22,781 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:23,070 - INFO - before .to(local_rank)***************************************
2025-07-04 12:26:23,070 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:26:23,070 - INFO - After .to(local_rank)***************************************
2025-07-04 12:26:23,070 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:23,070 - INFO - After Normalization***************************************
2025-07-04 12:26:23,070 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:26,430 - INFO - Epoch 26/150 - Train Loss: 0.416589, Val Loss: 0.438708
2025-07-04 12:26:28,742 - INFO - before .to(local_rank)***************************************
2025-07-04 12:26:28,757 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:26:28,757 - INFO - After .to(local_rank)***************************************
2025-07-04 12:26:28,758 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:28,758 - INFO - After Normalization***************************************
2025-07-04 12:26:28,758 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:29,058 - INFO - before .to(local_rank)***************************************
2025-07-04 12:26:29,058 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:26:29,058 - INFO - After .to(local_rank)***************************************
2025-07-04 12:26:29,058 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:29,058 - INFO - After Normalization***************************************
2025-07-04 12:26:29,058 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:29,347 - INFO - before .to(local_rank)***************************************
2025-07-04 12:26:29,347 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:26:29,348 - INFO - After .to(local_rank)***************************************
2025-07-04 12:26:29,348 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:29,348 - INFO - After Normalization***************************************
2025-07-04 12:26:29,348 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:32,705 - INFO - Epoch 27/150 - Train Loss: 0.415543, Val Loss: 0.429039
2025-07-04 12:26:35,019 - INFO - before .to(local_rank)***************************************
2025-07-04 12:26:35,035 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:26:35,035 - INFO - After .to(local_rank)***************************************
2025-07-04 12:26:35,035 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:35,035 - INFO - After Normalization***************************************
2025-07-04 12:26:35,035 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:35,351 - INFO - before .to(local_rank)***************************************
2025-07-04 12:26:35,351 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:26:35,351 - INFO - After .to(local_rank)***************************************
2025-07-04 12:26:35,351 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:35,352 - INFO - After Normalization***************************************
2025-07-04 12:26:35,352 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:35,647 - INFO - before .to(local_rank)***************************************
2025-07-04 12:26:35,647 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:26:35,648 - INFO - After .to(local_rank)***************************************
2025-07-04 12:26:35,648 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:35,648 - INFO - After Normalization***************************************
2025-07-04 12:26:35,648 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:38,991 - INFO - Epoch 28/150 - Train Loss: 0.413719, Val Loss: 0.420002
2025-07-04 12:26:39,008 - INFO - New best model saved with Val Loss: 0.420002
2025-07-04 12:26:41,309 - INFO - before .to(local_rank)***************************************
2025-07-04 12:26:41,324 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:26:41,325 - INFO - After .to(local_rank)***************************************
2025-07-04 12:26:41,325 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:41,325 - INFO - After Normalization***************************************
2025-07-04 12:26:41,325 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:41,639 - INFO - before .to(local_rank)***************************************
2025-07-04 12:26:41,639 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:26:41,639 - INFO - After .to(local_rank)***************************************
2025-07-04 12:26:41,639 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:41,639 - INFO - After Normalization***************************************
2025-07-04 12:26:41,639 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:41,928 - INFO - before .to(local_rank)***************************************
2025-07-04 12:26:41,928 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:26:41,929 - INFO - After .to(local_rank)***************************************
2025-07-04 12:26:41,929 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:41,929 - INFO - After Normalization***************************************
2025-07-04 12:26:41,929 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:45,231 - INFO - Epoch 29/150 - Train Loss: 0.410406, Val Loss: 0.413966
2025-07-04 12:26:45,246 - INFO - New best model saved with Val Loss: 0.413966
2025-07-04 12:26:47,566 - INFO - before .to(local_rank)***************************************
2025-07-04 12:26:47,582 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:26:47,582 - INFO - After .to(local_rank)***************************************
2025-07-04 12:26:47,582 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:47,582 - INFO - After Normalization***************************************
2025-07-04 12:26:47,582 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:47,889 - INFO - before .to(local_rank)***************************************
2025-07-04 12:26:47,889 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:26:47,889 - INFO - After .to(local_rank)***************************************
2025-07-04 12:26:47,889 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:47,889 - INFO - After Normalization***************************************
2025-07-04 12:26:47,889 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:48,179 - INFO - before .to(local_rank)***************************************
2025-07-04 12:26:48,179 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:26:48,179 - INFO - After .to(local_rank)***************************************
2025-07-04 12:26:48,179 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:48,179 - INFO - After Normalization***************************************
2025-07-04 12:26:48,179 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:51,512 - INFO - Epoch 30/150 - Train Loss: 0.409573, Val Loss: 0.411146
2025-07-04 12:26:51,525 - INFO - New best model saved with Val Loss: 0.411146
2025-07-04 12:26:54,233 - INFO - before .to(local_rank)***************************************
2025-07-04 12:26:54,249 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:26:54,249 - INFO - After .to(local_rank)***************************************
2025-07-04 12:26:54,250 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:54,250 - INFO - After Normalization***************************************
2025-07-04 12:26:54,250 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:54,552 - INFO - before .to(local_rank)***************************************
2025-07-04 12:26:54,553 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:26:54,553 - INFO - After .to(local_rank)***************************************
2025-07-04 12:26:54,553 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:54,553 - INFO - After Normalization***************************************
2025-07-04 12:26:54,553 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:54,848 - INFO - before .to(local_rank)***************************************
2025-07-04 12:26:54,848 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:26:54,849 - INFO - After .to(local_rank)***************************************
2025-07-04 12:26:54,849 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:54,849 - INFO - After Normalization***************************************
2025-07-04 12:26:54,849 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:26:58,232 - INFO - Epoch 31/150 - Train Loss: 0.407763, Val Loss: 0.405612
2025-07-04 12:26:58,248 - INFO - New best model saved with Val Loss: 0.405612
2025-07-04 12:27:00,547 - INFO - before .to(local_rank)***************************************
2025-07-04 12:27:00,562 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:27:00,562 - INFO - After .to(local_rank)***************************************
2025-07-04 12:27:00,562 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:00,562 - INFO - After Normalization***************************************
2025-07-04 12:27:00,562 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:00,883 - INFO - before .to(local_rank)***************************************
2025-07-04 12:27:00,883 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:27:00,884 - INFO - After .to(local_rank)***************************************
2025-07-04 12:27:00,884 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:00,884 - INFO - After Normalization***************************************
2025-07-04 12:27:00,884 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:01,173 - INFO - before .to(local_rank)***************************************
2025-07-04 12:27:01,173 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:27:01,174 - INFO - After .to(local_rank)***************************************
2025-07-04 12:27:01,174 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:01,174 - INFO - After Normalization***************************************
2025-07-04 12:27:01,174 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:04,528 - INFO - Epoch 32/150 - Train Loss: 0.407623, Val Loss: 0.406176
2025-07-04 12:27:06,843 - INFO - before .to(local_rank)***************************************
2025-07-04 12:27:06,859 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:27:06,859 - INFO - After .to(local_rank)***************************************
2025-07-04 12:27:06,859 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:06,859 - INFO - After Normalization***************************************
2025-07-04 12:27:06,861 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:07,168 - INFO - before .to(local_rank)***************************************
2025-07-04 12:27:07,168 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:27:07,168 - INFO - After .to(local_rank)***************************************
2025-07-04 12:27:07,168 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:07,169 - INFO - After Normalization***************************************
2025-07-04 12:27:07,169 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:07,457 - INFO - before .to(local_rank)***************************************
2025-07-04 12:27:07,458 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:27:07,458 - INFO - After .to(local_rank)***************************************
2025-07-04 12:27:07,458 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:07,458 - INFO - After Normalization***************************************
2025-07-04 12:27:07,458 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:10,813 - INFO - Epoch 33/150 - Train Loss: 0.403604, Val Loss: 0.407962
2025-07-04 12:27:13,102 - INFO - before .to(local_rank)***************************************
2025-07-04 12:27:13,117 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:27:13,117 - INFO - After .to(local_rank)***************************************
2025-07-04 12:27:13,117 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:13,117 - INFO - After Normalization***************************************
2025-07-04 12:27:13,117 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:13,422 - INFO - before .to(local_rank)***************************************
2025-07-04 12:27:13,422 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:27:13,423 - INFO - After .to(local_rank)***************************************
2025-07-04 12:27:13,423 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:13,423 - INFO - After Normalization***************************************
2025-07-04 12:27:13,423 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:13,712 - INFO - before .to(local_rank)***************************************
2025-07-04 12:27:13,712 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:27:13,712 - INFO - After .to(local_rank)***************************************
2025-07-04 12:27:13,713 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:13,713 - INFO - After Normalization***************************************
2025-07-04 12:27:13,713 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:17,051 - INFO - Epoch 34/150 - Train Loss: 0.399802, Val Loss: 0.401497
2025-07-04 12:27:17,068 - INFO - New best model saved with Val Loss: 0.401497
2025-07-04 12:27:19,388 - INFO - before .to(local_rank)***************************************
2025-07-04 12:27:19,403 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:27:19,403 - INFO - After .to(local_rank)***************************************
2025-07-04 12:27:19,404 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:19,404 - INFO - After Normalization***************************************
2025-07-04 12:27:19,404 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:19,706 - INFO - before .to(local_rank)***************************************
2025-07-04 12:27:19,706 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:27:19,707 - INFO - After .to(local_rank)***************************************
2025-07-04 12:27:19,707 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:19,707 - INFO - After Normalization***************************************
2025-07-04 12:27:19,708 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:20,003 - INFO - before .to(local_rank)***************************************
2025-07-04 12:27:20,003 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:27:20,004 - INFO - After .to(local_rank)***************************************
2025-07-04 12:27:20,004 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:20,004 - INFO - After Normalization***************************************
2025-07-04 12:27:20,004 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:23,332 - INFO - Epoch 35/150 - Train Loss: 0.400421, Val Loss: 0.400646
2025-07-04 12:27:23,345 - INFO - New best model saved with Val Loss: 0.400646
2025-07-04 12:27:25,652 - INFO - before .to(local_rank)***************************************
2025-07-04 12:27:25,667 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:27:25,667 - INFO - After .to(local_rank)***************************************
2025-07-04 12:27:25,667 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:25,667 - INFO - After Normalization***************************************
2025-07-04 12:27:25,667 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:25,989 - INFO - before .to(local_rank)***************************************
2025-07-04 12:27:25,989 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:27:25,990 - INFO - After .to(local_rank)***************************************
2025-07-04 12:27:25,990 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:25,990 - INFO - After Normalization***************************************
2025-07-04 12:27:25,990 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:26,279 - INFO - before .to(local_rank)***************************************
2025-07-04 12:27:26,279 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:27:26,279 - INFO - After .to(local_rank)***************************************
2025-07-04 12:27:26,279 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:26,279 - INFO - After Normalization***************************************
2025-07-04 12:27:26,279 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:29,585 - INFO - Epoch 36/150 - Train Loss: 0.395775, Val Loss: 0.403946
2025-07-04 12:27:31,864 - INFO - before .to(local_rank)***************************************
2025-07-04 12:27:31,879 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:27:31,879 - INFO - After .to(local_rank)***************************************
2025-07-04 12:27:31,879 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:31,880 - INFO - After Normalization***************************************
2025-07-04 12:27:31,880 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:32,200 - INFO - before .to(local_rank)***************************************
2025-07-04 12:27:32,200 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:27:32,200 - INFO - After .to(local_rank)***************************************
2025-07-04 12:27:32,200 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:32,200 - INFO - After Normalization***************************************
2025-07-04 12:27:32,200 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:32,490 - INFO - before .to(local_rank)***************************************
2025-07-04 12:27:32,490 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:27:32,490 - INFO - After .to(local_rank)***************************************
2025-07-04 12:27:32,490 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:32,490 - INFO - After Normalization***************************************
2025-07-04 12:27:32,491 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:35,809 - INFO - Epoch 37/150 - Train Loss: 0.395949, Val Loss: 0.401222
2025-07-04 12:27:38,099 - INFO - before .to(local_rank)***************************************
2025-07-04 12:27:38,113 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:27:38,114 - INFO - After .to(local_rank)***************************************
2025-07-04 12:27:38,114 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:38,114 - INFO - After Normalization***************************************
2025-07-04 12:27:38,114 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:38,433 - INFO - before .to(local_rank)***************************************
2025-07-04 12:27:38,433 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:27:38,434 - INFO - After .to(local_rank)***************************************
2025-07-04 12:27:38,434 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:38,434 - INFO - After Normalization***************************************
2025-07-04 12:27:38,434 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:38,723 - INFO - before .to(local_rank)***************************************
2025-07-04 12:27:38,723 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:27:38,724 - INFO - After .to(local_rank)***************************************
2025-07-04 12:27:38,724 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:38,724 - INFO - After Normalization***************************************
2025-07-04 12:27:38,724 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:42,100 - INFO - Epoch 38/150 - Train Loss: 0.393724, Val Loss: 0.398120
2025-07-04 12:27:42,116 - INFO - New best model saved with Val Loss: 0.398120
2025-07-04 12:27:44,389 - INFO - before .to(local_rank)***************************************
2025-07-04 12:27:44,404 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:27:44,405 - INFO - After .to(local_rank)***************************************
2025-07-04 12:27:44,405 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:44,405 - INFO - After Normalization***************************************
2025-07-04 12:27:44,405 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:44,715 - INFO - before .to(local_rank)***************************************
2025-07-04 12:27:44,715 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:27:44,716 - INFO - After .to(local_rank)***************************************
2025-07-04 12:27:44,716 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:44,716 - INFO - After Normalization***************************************
2025-07-04 12:27:44,716 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:45,010 - INFO - before .to(local_rank)***************************************
2025-07-04 12:27:45,010 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:27:45,011 - INFO - After .to(local_rank)***************************************
2025-07-04 12:27:45,011 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:45,011 - INFO - After Normalization***************************************
2025-07-04 12:27:45,011 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:48,371 - INFO - Epoch 39/150 - Train Loss: 0.390039, Val Loss: 0.399025
2025-07-04 12:27:50,687 - INFO - before .to(local_rank)***************************************
2025-07-04 12:27:50,701 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:27:50,702 - INFO - After .to(local_rank)***************************************
2025-07-04 12:27:50,702 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:50,702 - INFO - After Normalization***************************************
2025-07-04 12:27:50,703 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:51,012 - INFO - before .to(local_rank)***************************************
2025-07-04 12:27:51,012 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:27:51,012 - INFO - After .to(local_rank)***************************************
2025-07-04 12:27:51,012 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:51,012 - INFO - After Normalization***************************************
2025-07-04 12:27:51,012 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:51,301 - INFO - before .to(local_rank)***************************************
2025-07-04 12:27:51,301 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:27:51,301 - INFO - After .to(local_rank)***************************************
2025-07-04 12:27:51,301 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:51,301 - INFO - After Normalization***************************************
2025-07-04 12:27:51,301 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:54,601 - INFO - Epoch 40/150 - Train Loss: 0.391684, Val Loss: 0.390313
2025-07-04 12:27:54,616 - INFO - New best model saved with Val Loss: 0.390313
2025-07-04 12:27:57,059 - INFO - before .to(local_rank)***************************************
2025-07-04 12:27:57,073 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:27:57,074 - INFO - After .to(local_rank)***************************************
2025-07-04 12:27:57,074 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:57,074 - INFO - After Normalization***************************************
2025-07-04 12:27:57,074 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:57,383 - INFO - before .to(local_rank)***************************************
2025-07-04 12:27:57,384 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:27:57,384 - INFO - After .to(local_rank)***************************************
2025-07-04 12:27:57,384 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:57,384 - INFO - After Normalization***************************************
2025-07-04 12:27:57,384 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:57,673 - INFO - before .to(local_rank)***************************************
2025-07-04 12:27:57,673 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:27:57,673 - INFO - After .to(local_rank)***************************************
2025-07-04 12:27:57,674 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:27:57,674 - INFO - After Normalization***************************************
2025-07-04 12:27:57,674 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:01,001 - INFO - Epoch 41/150 - Train Loss: 0.386746, Val Loss: 0.386531
2025-07-04 12:28:01,026 - INFO - New best model saved with Val Loss: 0.386531
2025-07-04 12:28:03,337 - INFO - before .to(local_rank)***************************************
2025-07-04 12:28:03,353 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:28:03,353 - INFO - After .to(local_rank)***************************************
2025-07-04 12:28:03,353 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:03,353 - INFO - After Normalization***************************************
2025-07-04 12:28:03,353 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:03,659 - INFO - before .to(local_rank)***************************************
2025-07-04 12:28:03,659 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:28:03,659 - INFO - After .to(local_rank)***************************************
2025-07-04 12:28:03,659 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:03,661 - INFO - After Normalization***************************************
2025-07-04 12:28:03,661 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:03,950 - INFO - before .to(local_rank)***************************************
2025-07-04 12:28:03,950 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:28:03,950 - INFO - After .to(local_rank)***************************************
2025-07-04 12:28:03,950 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:03,950 - INFO - After Normalization***************************************
2025-07-04 12:28:03,950 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:07,299 - INFO - Epoch 42/150 - Train Loss: 0.386503, Val Loss: 0.384749
2025-07-04 12:28:07,314 - INFO - New best model saved with Val Loss: 0.384749
2025-07-04 12:28:09,599 - INFO - before .to(local_rank)***************************************
2025-07-04 12:28:09,615 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:28:09,615 - INFO - After .to(local_rank)***************************************
2025-07-04 12:28:09,615 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:09,615 - INFO - After Normalization***************************************
2025-07-04 12:28:09,615 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:09,917 - INFO - before .to(local_rank)***************************************
2025-07-04 12:28:09,917 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:28:09,918 - INFO - After .to(local_rank)***************************************
2025-07-04 12:28:09,918 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:09,918 - INFO - After Normalization***************************************
2025-07-04 12:28:09,918 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:10,213 - INFO - before .to(local_rank)***************************************
2025-07-04 12:28:10,213 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:28:10,213 - INFO - After .to(local_rank)***************************************
2025-07-04 12:28:10,213 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:10,213 - INFO - After Normalization***************************************
2025-07-04 12:28:10,213 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:13,516 - INFO - Epoch 43/150 - Train Loss: 0.385221, Val Loss: 0.382403
2025-07-04 12:28:13,531 - INFO - New best model saved with Val Loss: 0.382403
2025-07-04 12:28:15,847 - INFO - before .to(local_rank)***************************************
2025-07-04 12:28:15,863 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:28:15,863 - INFO - After .to(local_rank)***************************************
2025-07-04 12:28:15,863 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:15,863 - INFO - After Normalization***************************************
2025-07-04 12:28:15,863 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:16,169 - INFO - before .to(local_rank)***************************************
2025-07-04 12:28:16,169 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:28:16,170 - INFO - After .to(local_rank)***************************************
2025-07-04 12:28:16,170 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:16,170 - INFO - After Normalization***************************************
2025-07-04 12:28:16,170 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:16,459 - INFO - before .to(local_rank)***************************************
2025-07-04 12:28:16,459 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:28:16,459 - INFO - After .to(local_rank)***************************************
2025-07-04 12:28:16,459 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:16,461 - INFO - After Normalization***************************************
2025-07-04 12:28:16,461 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:19,800 - INFO - Epoch 44/150 - Train Loss: 0.379563, Val Loss: 0.379401
2025-07-04 12:28:19,816 - INFO - New best model saved with Val Loss: 0.379401
2025-07-04 12:28:22,110 - INFO - before .to(local_rank)***************************************
2025-07-04 12:28:22,125 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:28:22,125 - INFO - After .to(local_rank)***************************************
2025-07-04 12:28:22,125 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:22,125 - INFO - After Normalization***************************************
2025-07-04 12:28:22,125 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:22,451 - INFO - before .to(local_rank)***************************************
2025-07-04 12:28:22,451 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:28:22,451 - INFO - After .to(local_rank)***************************************
2025-07-04 12:28:22,451 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:22,451 - INFO - After Normalization***************************************
2025-07-04 12:28:22,451 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:22,740 - INFO - before .to(local_rank)***************************************
2025-07-04 12:28:22,741 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:28:22,741 - INFO - After .to(local_rank)***************************************
2025-07-04 12:28:22,741 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:22,741 - INFO - After Normalization***************************************
2025-07-04 12:28:22,741 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:26,098 - INFO - Epoch 45/150 - Train Loss: 0.381152, Val Loss: 0.383046
2025-07-04 12:28:28,406 - INFO - before .to(local_rank)***************************************
2025-07-04 12:28:28,421 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:28:28,421 - INFO - After .to(local_rank)***************************************
2025-07-04 12:28:28,421 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:28,421 - INFO - After Normalization***************************************
2025-07-04 12:28:28,421 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:28,731 - INFO - before .to(local_rank)***************************************
2025-07-04 12:28:28,731 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:28:28,731 - INFO - After .to(local_rank)***************************************
2025-07-04 12:28:28,731 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:28,731 - INFO - After Normalization***************************************
2025-07-04 12:28:28,731 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:29,020 - INFO - before .to(local_rank)***************************************
2025-07-04 12:28:29,021 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:28:29,021 - INFO - After .to(local_rank)***************************************
2025-07-04 12:28:29,021 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:29,021 - INFO - After Normalization***************************************
2025-07-04 12:28:29,021 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:32,385 - INFO - Epoch 46/150 - Train Loss: 0.377841, Val Loss: 0.374077
2025-07-04 12:28:32,402 - INFO - New best model saved with Val Loss: 0.374077
2025-07-04 12:28:34,703 - INFO - before .to(local_rank)***************************************
2025-07-04 12:28:34,718 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:28:34,718 - INFO - After .to(local_rank)***************************************
2025-07-04 12:28:34,719 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:34,720 - INFO - After Normalization***************************************
2025-07-04 12:28:34,720 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:35,022 - INFO - before .to(local_rank)***************************************
2025-07-04 12:28:35,022 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:28:35,023 - INFO - After .to(local_rank)***************************************
2025-07-04 12:28:35,023 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:35,023 - INFO - After Normalization***************************************
2025-07-04 12:28:35,023 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:35,316 - INFO - before .to(local_rank)***************************************
2025-07-04 12:28:35,316 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:28:35,316 - INFO - After .to(local_rank)***************************************
2025-07-04 12:28:35,316 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:35,316 - INFO - After Normalization***************************************
2025-07-04 12:28:35,316 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:38,695 - INFO - Epoch 47/150 - Train Loss: 0.376989, Val Loss: 0.374267
2025-07-04 12:28:41,068 - INFO - before .to(local_rank)***************************************
2025-07-04 12:28:41,083 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:28:41,084 - INFO - After .to(local_rank)***************************************
2025-07-04 12:28:41,084 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:41,084 - INFO - After Normalization***************************************
2025-07-04 12:28:41,084 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:41,398 - INFO - before .to(local_rank)***************************************
2025-07-04 12:28:41,398 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:28:41,398 - INFO - After .to(local_rank)***************************************
2025-07-04 12:28:41,398 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:41,398 - INFO - After Normalization***************************************
2025-07-04 12:28:41,398 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:41,687 - INFO - before .to(local_rank)***************************************
2025-07-04 12:28:41,688 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:28:41,688 - INFO - After .to(local_rank)***************************************
2025-07-04 12:28:41,688 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:41,688 - INFO - After Normalization***************************************
2025-07-04 12:28:41,688 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:45,427 - INFO - Epoch 48/150 - Train Loss: 0.372625, Val Loss: 0.375827
2025-07-04 12:28:47,751 - INFO - before .to(local_rank)***************************************
2025-07-04 12:28:47,766 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:28:47,767 - INFO - After .to(local_rank)***************************************
2025-07-04 12:28:47,767 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:47,767 - INFO - After Normalization***************************************
2025-07-04 12:28:47,767 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:48,072 - INFO - before .to(local_rank)***************************************
2025-07-04 12:28:48,072 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:28:48,073 - INFO - After .to(local_rank)***************************************
2025-07-04 12:28:48,073 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:48,074 - INFO - After Normalization***************************************
2025-07-04 12:28:48,074 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:48,369 - INFO - before .to(local_rank)***************************************
2025-07-04 12:28:48,369 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:28:48,369 - INFO - After .to(local_rank)***************************************
2025-07-04 12:28:48,369 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:48,369 - INFO - After Normalization***************************************
2025-07-04 12:28:48,369 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:51,668 - INFO - Epoch 49/150 - Train Loss: 0.373013, Val Loss: 0.377917
2025-07-04 12:28:53,995 - INFO - before .to(local_rank)***************************************
2025-07-04 12:28:54,010 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:28:54,011 - INFO - After .to(local_rank)***************************************
2025-07-04 12:28:54,011 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:54,011 - INFO - After Normalization***************************************
2025-07-04 12:28:54,011 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:54,315 - INFO - before .to(local_rank)***************************************
2025-07-04 12:28:54,315 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:28:54,315 - INFO - After .to(local_rank)***************************************
2025-07-04 12:28:54,315 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:54,315 - INFO - After Normalization***************************************
2025-07-04 12:28:54,315 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:54,611 - INFO - before .to(local_rank)***************************************
2025-07-04 12:28:54,611 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:28:54,612 - INFO - After .to(local_rank)***************************************
2025-07-04 12:28:54,612 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:54,612 - INFO - After Normalization***************************************
2025-07-04 12:28:54,612 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:28:57,948 - INFO - Epoch 50/150 - Train Loss: 0.370192, Val Loss: 0.374004
2025-07-04 12:28:57,965 - INFO - New best model saved with Val Loss: 0.374004
2025-07-04 12:29:00,384 - INFO - before .to(local_rank)***************************************
2025-07-04 12:29:00,399 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:29:00,414 - INFO - After .to(local_rank)***************************************
2025-07-04 12:29:00,429 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:00,443 - INFO - After Normalization***************************************
2025-07-04 12:29:00,457 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:00,777 - INFO - before .to(local_rank)***************************************
2025-07-04 12:29:00,777 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:29:00,778 - INFO - After .to(local_rank)***************************************
2025-07-04 12:29:00,778 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:00,778 - INFO - After Normalization***************************************
2025-07-04 12:29:00,778 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:01,067 - INFO - before .to(local_rank)***************************************
2025-07-04 12:29:01,067 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:29:01,067 - INFO - After .to(local_rank)***************************************
2025-07-04 12:29:01,068 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:01,069 - INFO - After Normalization***************************************
2025-07-04 12:29:01,069 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:04,415 - INFO - Epoch 51/150 - Train Loss: 0.370575, Val Loss: 0.368872
2025-07-04 12:29:04,430 - INFO - New best model saved with Val Loss: 0.368872
2025-07-04 12:29:06,716 - INFO - before .to(local_rank)***************************************
2025-07-04 12:29:06,732 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:29:06,732 - INFO - After .to(local_rank)***************************************
2025-07-04 12:29:06,732 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:06,732 - INFO - After Normalization***************************************
2025-07-04 12:29:06,732 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:07,052 - INFO - before .to(local_rank)***************************************
2025-07-04 12:29:07,052 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:29:07,052 - INFO - After .to(local_rank)***************************************
2025-07-04 12:29:07,052 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:07,053 - INFO - After Normalization***************************************
2025-07-04 12:29:07,053 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:07,342 - INFO - before .to(local_rank)***************************************
2025-07-04 12:29:07,342 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:29:07,342 - INFO - After .to(local_rank)***************************************
2025-07-04 12:29:07,342 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:07,342 - INFO - After Normalization***************************************
2025-07-04 12:29:07,342 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:10,707 - INFO - Epoch 52/150 - Train Loss: 0.366457, Val Loss: 0.366532
2025-07-04 12:29:10,723 - INFO - New best model saved with Val Loss: 0.366532
2025-07-04 12:29:12,995 - INFO - before .to(local_rank)***************************************
2025-07-04 12:29:13,010 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:29:13,011 - INFO - After .to(local_rank)***************************************
2025-07-04 12:29:13,011 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:13,011 - INFO - After Normalization***************************************
2025-07-04 12:29:13,011 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:13,323 - INFO - before .to(local_rank)***************************************
2025-07-04 12:29:13,323 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:29:13,323 - INFO - After .to(local_rank)***************************************
2025-07-04 12:29:13,324 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:13,324 - INFO - After Normalization***************************************
2025-07-04 12:29:13,324 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:13,619 - INFO - before .to(local_rank)***************************************
2025-07-04 12:29:13,619 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:29:13,619 - INFO - After .to(local_rank)***************************************
2025-07-04 12:29:13,620 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:13,620 - INFO - After Normalization***************************************
2025-07-04 12:29:13,620 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:16,962 - INFO - Epoch 53/150 - Train Loss: 0.364227, Val Loss: 0.364998
2025-07-04 12:29:16,975 - INFO - New best model saved with Val Loss: 0.364998
2025-07-04 12:29:19,286 - INFO - before .to(local_rank)***************************************
2025-07-04 12:29:19,296 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:29:19,297 - INFO - After .to(local_rank)***************************************
2025-07-04 12:29:19,297 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:19,298 - INFO - After Normalization***************************************
2025-07-04 12:29:19,298 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:19,615 - INFO - before .to(local_rank)***************************************
2025-07-04 12:29:19,627 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:29:19,640 - INFO - After .to(local_rank)***************************************
2025-07-04 12:29:19,655 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:19,655 - INFO - After Normalization***************************************
2025-07-04 12:29:19,667 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:19,975 - INFO - before .to(local_rank)***************************************
2025-07-04 12:29:19,975 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:29:19,975 - INFO - After .to(local_rank)***************************************
2025-07-04 12:29:19,975 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:19,975 - INFO - After Normalization***************************************
2025-07-04 12:29:19,975 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:23,616 - INFO - Epoch 54/150 - Train Loss: 0.362108, Val Loss: 0.361583
2025-07-04 12:29:23,633 - INFO - New best model saved with Val Loss: 0.361583
2025-07-04 12:29:26,063 - INFO - before .to(local_rank)***************************************
2025-07-04 12:29:26,072 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:29:26,072 - INFO - After .to(local_rank)***************************************
2025-07-04 12:29:26,072 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:26,072 - INFO - After Normalization***************************************
2025-07-04 12:29:26,072 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:26,384 - INFO - before .to(local_rank)***************************************
2025-07-04 12:29:26,384 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:29:26,384 - INFO - After .to(local_rank)***************************************
2025-07-04 12:29:26,384 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:26,384 - INFO - After Normalization***************************************
2025-07-04 12:29:26,384 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:26,673 - INFO - before .to(local_rank)***************************************
2025-07-04 12:29:26,673 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:29:26,673 - INFO - After .to(local_rank)***************************************
2025-07-04 12:29:26,673 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:26,673 - INFO - After Normalization***************************************
2025-07-04 12:29:26,673 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:30,065 - INFO - Epoch 55/150 - Train Loss: 0.362925, Val Loss: 0.360435
2025-07-04 12:29:30,084 - INFO - New best model saved with Val Loss: 0.360435
2025-07-04 12:29:34,765 - INFO - before .to(local_rank)***************************************
2025-07-04 12:29:34,770 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:29:34,771 - INFO - After .to(local_rank)***************************************
2025-07-04 12:29:34,771 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:34,771 - INFO - After Normalization***************************************
2025-07-04 12:29:34,771 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:35,077 - INFO - before .to(local_rank)***************************************
2025-07-04 12:29:35,077 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:29:35,078 - INFO - After .to(local_rank)***************************************
2025-07-04 12:29:35,078 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:35,078 - INFO - After Normalization***************************************
2025-07-04 12:29:35,078 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:35,368 - INFO - before .to(local_rank)***************************************
2025-07-04 12:29:35,368 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:29:35,368 - INFO - After .to(local_rank)***************************************
2025-07-04 12:29:35,368 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:35,368 - INFO - After Normalization***************************************
2025-07-04 12:29:35,368 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:43,429 - INFO - Epoch 56/150 - Train Loss: 0.360084, Val Loss: 0.360202
2025-07-04 12:29:43,450 - INFO - New best model saved with Val Loss: 0.360202
2025-07-04 12:29:50,930 - INFO - before .to(local_rank)***************************************
2025-07-04 12:29:50,936 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:29:50,936 - INFO - After .to(local_rank)***************************************
2025-07-04 12:29:50,936 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:50,936 - INFO - After Normalization***************************************
2025-07-04 12:29:50,936 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:51,254 - INFO - before .to(local_rank)***************************************
2025-07-04 12:29:51,254 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:29:51,255 - INFO - After .to(local_rank)***************************************
2025-07-04 12:29:51,255 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:51,255 - INFO - After Normalization***************************************
2025-07-04 12:29:51,255 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:51,544 - INFO - before .to(local_rank)***************************************
2025-07-04 12:29:51,544 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:29:51,544 - INFO - After .to(local_rank)***************************************
2025-07-04 12:29:51,544 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:51,544 - INFO - After Normalization***************************************
2025-07-04 12:29:51,544 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:29:58,545 - INFO - Epoch 57/150 - Train Loss: 0.356597, Val Loss: 0.362886
2025-07-04 12:30:01,242 - INFO - before .to(local_rank)***************************************
2025-07-04 12:30:01,249 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:30:01,249 - INFO - After .to(local_rank)***************************************
2025-07-04 12:30:01,249 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:01,249 - INFO - After Normalization***************************************
2025-07-04 12:30:01,249 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:01,557 - INFO - before .to(local_rank)***************************************
2025-07-04 12:30:01,557 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:30:01,558 - INFO - After .to(local_rank)***************************************
2025-07-04 12:30:01,558 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:01,558 - INFO - After Normalization***************************************
2025-07-04 12:30:01,558 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:01,852 - INFO - before .to(local_rank)***************************************
2025-07-04 12:30:01,852 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:30:01,854 - INFO - After .to(local_rank)***************************************
2025-07-04 12:30:01,854 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:01,854 - INFO - After Normalization***************************************
2025-07-04 12:30:01,854 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:05,206 - INFO - Epoch 58/150 - Train Loss: 0.359285, Val Loss: 0.363573
2025-07-04 12:30:07,517 - INFO - before .to(local_rank)***************************************
2025-07-04 12:30:07,532 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:30:07,532 - INFO - After .to(local_rank)***************************************
2025-07-04 12:30:07,532 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:07,532 - INFO - After Normalization***************************************
2025-07-04 12:30:07,532 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:07,835 - INFO - before .to(local_rank)***************************************
2025-07-04 12:30:07,835 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:30:07,835 - INFO - After .to(local_rank)***************************************
2025-07-04 12:30:07,835 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:07,835 - INFO - After Normalization***************************************
2025-07-04 12:30:07,835 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:08,130 - INFO - before .to(local_rank)***************************************
2025-07-04 12:30:08,130 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:30:08,130 - INFO - After .to(local_rank)***************************************
2025-07-04 12:30:08,130 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:08,130 - INFO - After Normalization***************************************
2025-07-04 12:30:08,130 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:11,465 - INFO - Epoch 59/150 - Train Loss: 0.353965, Val Loss: 0.367631
2025-07-04 12:30:13,759 - INFO - before .to(local_rank)***************************************
2025-07-04 12:30:13,773 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:30:13,774 - INFO - After .to(local_rank)***************************************
2025-07-04 12:30:13,774 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:13,774 - INFO - After Normalization***************************************
2025-07-04 12:30:13,774 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:14,081 - INFO - before .to(local_rank)***************************************
2025-07-04 12:30:14,081 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:30:14,081 - INFO - After .to(local_rank)***************************************
2025-07-04 12:30:14,082 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:14,082 - INFO - After Normalization***************************************
2025-07-04 12:30:14,082 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:14,371 - INFO - before .to(local_rank)***************************************
2025-07-04 12:30:14,371 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:30:14,371 - INFO - After .to(local_rank)***************************************
2025-07-04 12:30:14,371 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:14,371 - INFO - After Normalization***************************************
2025-07-04 12:30:14,371 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:17,679 - INFO - Epoch 60/150 - Train Loss: 0.355830, Val Loss: 0.363127
2025-07-04 12:30:20,095 - INFO - before .to(local_rank)***************************************
2025-07-04 12:30:20,109 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:30:20,110 - INFO - After .to(local_rank)***************************************
2025-07-04 12:30:20,110 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:20,111 - INFO - After Normalization***************************************
2025-07-04 12:30:20,111 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:20,420 - INFO - before .to(local_rank)***************************************
2025-07-04 12:30:20,420 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:30:20,421 - INFO - After .to(local_rank)***************************************
2025-07-04 12:30:20,421 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:20,421 - INFO - After Normalization***************************************
2025-07-04 12:30:20,421 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:20,710 - INFO - before .to(local_rank)***************************************
2025-07-04 12:30:20,710 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:30:20,710 - INFO - After .to(local_rank)***************************************
2025-07-04 12:30:20,710 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:20,710 - INFO - After Normalization***************************************
2025-07-04 12:30:20,710 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:24,065 - INFO - Epoch 61/150 - Train Loss: 0.352915, Val Loss: 0.355417
2025-07-04 12:30:24,082 - INFO - New best model saved with Val Loss: 0.355417
2025-07-04 12:30:26,351 - INFO - before .to(local_rank)***************************************
2025-07-04 12:30:26,365 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:30:26,365 - INFO - After .to(local_rank)***************************************
2025-07-04 12:30:26,365 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:26,365 - INFO - After Normalization***************************************
2025-07-04 12:30:26,365 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:26,673 - INFO - before .to(local_rank)***************************************
2025-07-04 12:30:26,673 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:30:26,674 - INFO - After .to(local_rank)***************************************
2025-07-04 12:30:26,674 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:26,674 - INFO - After Normalization***************************************
2025-07-04 12:30:26,674 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:26,963 - INFO - before .to(local_rank)***************************************
2025-07-04 12:30:26,963 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:30:26,964 - INFO - After .to(local_rank)***************************************
2025-07-04 12:30:26,964 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:26,964 - INFO - After Normalization***************************************
2025-07-04 12:30:26,964 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:30,312 - INFO - Epoch 62/150 - Train Loss: 0.349458, Val Loss: 0.353605
2025-07-04 12:30:30,327 - INFO - New best model saved with Val Loss: 0.353605
2025-07-04 12:30:32,607 - INFO - before .to(local_rank)***************************************
2025-07-04 12:30:32,620 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:30:32,620 - INFO - After .to(local_rank)***************************************
2025-07-04 12:30:32,620 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:32,620 - INFO - After Normalization***************************************
2025-07-04 12:30:32,620 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:32,926 - INFO - before .to(local_rank)***************************************
2025-07-04 12:30:32,926 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:30:32,928 - INFO - After .to(local_rank)***************************************
2025-07-04 12:30:32,928 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:32,928 - INFO - After Normalization***************************************
2025-07-04 12:30:32,928 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:33,228 - INFO - before .to(local_rank)***************************************
2025-07-04 12:30:33,228 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:30:33,229 - INFO - After .to(local_rank)***************************************
2025-07-04 12:30:33,229 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:33,229 - INFO - After Normalization***************************************
2025-07-04 12:30:33,229 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:36,613 - INFO - Epoch 63/150 - Train Loss: 0.349392, Val Loss: 0.354289
2025-07-04 12:30:38,927 - INFO - before .to(local_rank)***************************************
2025-07-04 12:30:38,940 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:30:38,941 - INFO - After .to(local_rank)***************************************
2025-07-04 12:30:38,941 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:38,941 - INFO - After Normalization***************************************
2025-07-04 12:30:38,941 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:39,263 - INFO - before .to(local_rank)***************************************
2025-07-04 12:30:39,263 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:30:39,263 - INFO - After .to(local_rank)***************************************
2025-07-04 12:30:39,263 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:39,263 - INFO - After Normalization***************************************
2025-07-04 12:30:39,263 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:39,553 - INFO - before .to(local_rank)***************************************
2025-07-04 12:30:39,553 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:30:39,553 - INFO - After .to(local_rank)***************************************
2025-07-04 12:30:39,553 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:39,553 - INFO - After Normalization***************************************
2025-07-04 12:30:39,553 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:42,897 - INFO - Epoch 64/150 - Train Loss: 0.349203, Val Loss: 0.349903
2025-07-04 12:30:42,913 - INFO - New best model saved with Val Loss: 0.349903
2025-07-04 12:30:45,224 - INFO - before .to(local_rank)***************************************
2025-07-04 12:30:45,238 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:30:45,238 - INFO - After .to(local_rank)***************************************
2025-07-04 12:30:45,239 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:45,239 - INFO - After Normalization***************************************
2025-07-04 12:30:45,239 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:45,548 - INFO - before .to(local_rank)***************************************
2025-07-04 12:30:45,548 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:30:45,548 - INFO - After .to(local_rank)***************************************
2025-07-04 12:30:45,548 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:45,549 - INFO - After Normalization***************************************
2025-07-04 12:30:45,549 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:45,838 - INFO - before .to(local_rank)***************************************
2025-07-04 12:30:45,838 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:30:45,839 - INFO - After .to(local_rank)***************************************
2025-07-04 12:30:45,839 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:45,839 - INFO - After Normalization***************************************
2025-07-04 12:30:45,839 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:49,160 - INFO - Epoch 65/150 - Train Loss: 0.348612, Val Loss: 0.350857
2025-07-04 12:30:51,451 - INFO - before .to(local_rank)***************************************
2025-07-04 12:30:51,465 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:30:51,466 - INFO - After .to(local_rank)***************************************
2025-07-04 12:30:51,466 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:51,466 - INFO - After Normalization***************************************
2025-07-04 12:30:51,466 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:51,776 - INFO - before .to(local_rank)***************************************
2025-07-04 12:30:51,776 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:30:51,776 - INFO - After .to(local_rank)***************************************
2025-07-04 12:30:51,776 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:51,776 - INFO - After Normalization***************************************
2025-07-04 12:30:51,776 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:52,065 - INFO - before .to(local_rank)***************************************
2025-07-04 12:30:52,065 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:30:52,066 - INFO - After .to(local_rank)***************************************
2025-07-04 12:30:52,066 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:52,066 - INFO - After Normalization***************************************
2025-07-04 12:30:52,066 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:55,378 - INFO - Epoch 66/150 - Train Loss: 0.344767, Val Loss: 0.353102
2025-07-04 12:30:57,685 - INFO - before .to(local_rank)***************************************
2025-07-04 12:30:57,699 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:30:57,699 - INFO - After .to(local_rank)***************************************
2025-07-04 12:30:57,699 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:57,699 - INFO - After Normalization***************************************
2025-07-04 12:30:57,699 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:58,008 - INFO - before .to(local_rank)***************************************
2025-07-04 12:30:58,009 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:30:58,009 - INFO - After .to(local_rank)***************************************
2025-07-04 12:30:58,009 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:58,009 - INFO - After Normalization***************************************
2025-07-04 12:30:58,009 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:58,303 - INFO - before .to(local_rank)***************************************
2025-07-04 12:30:58,303 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:30:58,303 - INFO - After .to(local_rank)***************************************
2025-07-04 12:30:58,303 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:30:58,303 - INFO - After Normalization***************************************
2025-07-04 12:30:58,303 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:01,668 - INFO - Epoch 67/150 - Train Loss: 0.343171, Val Loss: 0.346992
2025-07-04 12:31:01,684 - INFO - New best model saved with Val Loss: 0.346992
2025-07-04 12:31:04,008 - INFO - before .to(local_rank)***************************************
2025-07-04 12:31:04,022 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:31:04,023 - INFO - After .to(local_rank)***************************************
2025-07-04 12:31:04,023 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:04,023 - INFO - After Normalization***************************************
2025-07-04 12:31:04,023 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:04,327 - INFO - before .to(local_rank)***************************************
2025-07-04 12:31:04,327 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:31:04,328 - INFO - After .to(local_rank)***************************************
2025-07-04 12:31:04,328 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:04,328 - INFO - After Normalization***************************************
2025-07-04 12:31:04,328 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:04,617 - INFO - before .to(local_rank)***************************************
2025-07-04 12:31:04,617 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:31:04,617 - INFO - After .to(local_rank)***************************************
2025-07-04 12:31:04,618 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:04,618 - INFO - After Normalization***************************************
2025-07-04 12:31:04,618 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:07,910 - INFO - Epoch 68/150 - Train Loss: 0.343175, Val Loss: 0.344801
2025-07-04 12:31:07,924 - INFO - New best model saved with Val Loss: 0.344801
2025-07-04 12:31:10,172 - INFO - before .to(local_rank)***************************************
2025-07-04 12:31:10,186 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:31:10,187 - INFO - After .to(local_rank)***************************************
2025-07-04 12:31:10,187 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:10,187 - INFO - After Normalization***************************************
2025-07-04 12:31:10,187 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:10,499 - INFO - before .to(local_rank)***************************************
2025-07-04 12:31:10,499 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:31:10,499 - INFO - After .to(local_rank)***************************************
2025-07-04 12:31:10,499 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:10,499 - INFO - After Normalization***************************************
2025-07-04 12:31:10,499 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:10,788 - INFO - before .to(local_rank)***************************************
2025-07-04 12:31:10,788 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:31:10,789 - INFO - After .to(local_rank)***************************************
2025-07-04 12:31:10,789 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:10,789 - INFO - After Normalization***************************************
2025-07-04 12:31:10,789 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:14,033 - INFO - Epoch 69/150 - Train Loss: 0.342111, Val Loss: 0.345257
2025-07-04 12:31:16,294 - INFO - before .to(local_rank)***************************************
2025-07-04 12:31:16,308 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:31:16,309 - INFO - After .to(local_rank)***************************************
2025-07-04 12:31:16,309 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:16,309 - INFO - After Normalization***************************************
2025-07-04 12:31:16,309 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:16,628 - INFO - before .to(local_rank)***************************************
2025-07-04 12:31:16,629 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:31:16,630 - INFO - After .to(local_rank)***************************************
2025-07-04 12:31:16,630 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:16,630 - INFO - After Normalization***************************************
2025-07-04 12:31:16,630 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:16,918 - INFO - before .to(local_rank)***************************************
2025-07-04 12:31:16,919 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:31:16,919 - INFO - After .to(local_rank)***************************************
2025-07-04 12:31:16,919 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:16,919 - INFO - After Normalization***************************************
2025-07-04 12:31:16,919 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:20,162 - INFO - Epoch 70/150 - Train Loss: 0.338463, Val Loss: 0.343932
2025-07-04 12:31:20,177 - INFO - New best model saved with Val Loss: 0.343932
2025-07-04 12:31:22,584 - INFO - before .to(local_rank)***************************************
2025-07-04 12:31:22,598 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:31:22,599 - INFO - After .to(local_rank)***************************************
2025-07-04 12:31:22,599 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:22,599 - INFO - After Normalization***************************************
2025-07-04 12:31:22,599 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:22,910 - INFO - before .to(local_rank)***************************************
2025-07-04 12:31:22,910 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:31:22,910 - INFO - After .to(local_rank)***************************************
2025-07-04 12:31:22,910 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:22,910 - INFO - After Normalization***************************************
2025-07-04 12:31:22,910 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:23,199 - INFO - before .to(local_rank)***************************************
2025-07-04 12:31:23,199 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:31:23,199 - INFO - After .to(local_rank)***************************************
2025-07-04 12:31:23,199 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:23,199 - INFO - After Normalization***************************************
2025-07-04 12:31:23,199 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:26,450 - INFO - Epoch 71/150 - Train Loss: 0.337893, Val Loss: 0.343028
2025-07-04 12:31:26,464 - INFO - New best model saved with Val Loss: 0.343028
2025-07-04 12:31:28,728 - INFO - before .to(local_rank)***************************************
2025-07-04 12:31:28,742 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:31:28,742 - INFO - After .to(local_rank)***************************************
2025-07-04 12:31:28,742 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:28,742 - INFO - After Normalization***************************************
2025-07-04 12:31:28,742 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:29,042 - INFO - before .to(local_rank)***************************************
2025-07-04 12:31:29,042 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:31:29,043 - INFO - After .to(local_rank)***************************************
2025-07-04 12:31:29,043 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:29,043 - INFO - After Normalization***************************************
2025-07-04 12:31:29,043 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:29,332 - INFO - before .to(local_rank)***************************************
2025-07-04 12:31:29,332 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:31:29,335 - INFO - After .to(local_rank)***************************************
2025-07-04 12:31:29,335 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:29,335 - INFO - After Normalization***************************************
2025-07-04 12:31:29,335 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:32,568 - INFO - Epoch 72/150 - Train Loss: 0.335130, Val Loss: 0.342844
2025-07-04 12:31:32,583 - INFO - New best model saved with Val Loss: 0.342844
2025-07-04 12:31:34,860 - INFO - before .to(local_rank)***************************************
2025-07-04 12:31:34,874 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:31:34,875 - INFO - After .to(local_rank)***************************************
2025-07-04 12:31:34,875 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:34,875 - INFO - After Normalization***************************************
2025-07-04 12:31:34,875 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:35,183 - INFO - before .to(local_rank)***************************************
2025-07-04 12:31:35,184 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:31:35,184 - INFO - After .to(local_rank)***************************************
2025-07-04 12:31:35,184 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:35,184 - INFO - After Normalization***************************************
2025-07-04 12:31:35,184 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:35,502 - INFO - before .to(local_rank)***************************************
2025-07-04 12:31:35,502 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:31:35,502 - INFO - After .to(local_rank)***************************************
2025-07-04 12:31:35,502 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:35,502 - INFO - After Normalization***************************************
2025-07-04 12:31:35,502 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:38,735 - INFO - Epoch 73/150 - Train Loss: 0.336449, Val Loss: 0.340494
2025-07-04 12:31:38,751 - INFO - New best model saved with Val Loss: 0.340494
2025-07-04 12:31:41,030 - INFO - before .to(local_rank)***************************************
2025-07-04 12:31:41,043 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:31:41,044 - INFO - After .to(local_rank)***************************************
2025-07-04 12:31:41,044 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:41,044 - INFO - After Normalization***************************************
2025-07-04 12:31:41,044 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:41,361 - INFO - before .to(local_rank)***************************************
2025-07-04 12:31:41,361 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:31:41,361 - INFO - After .to(local_rank)***************************************
2025-07-04 12:31:41,361 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:41,361 - INFO - After Normalization***************************************
2025-07-04 12:31:41,361 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:41,655 - INFO - before .to(local_rank)***************************************
2025-07-04 12:31:41,655 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:31:41,655 - INFO - After .to(local_rank)***************************************
2025-07-04 12:31:41,655 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:41,655 - INFO - After Normalization***************************************
2025-07-04 12:31:41,655 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:44,903 - INFO - Epoch 74/150 - Train Loss: 0.332509, Val Loss: 0.336325
2025-07-04 12:31:44,918 - INFO - New best model saved with Val Loss: 0.336325
2025-07-04 12:31:47,173 - INFO - before .to(local_rank)***************************************
2025-07-04 12:31:47,187 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:31:47,187 - INFO - After .to(local_rank)***************************************
2025-07-04 12:31:47,187 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:47,187 - INFO - After Normalization***************************************
2025-07-04 12:31:47,188 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:47,495 - INFO - before .to(local_rank)***************************************
2025-07-04 12:31:47,495 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:31:47,495 - INFO - After .to(local_rank)***************************************
2025-07-04 12:31:47,495 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:47,496 - INFO - After Normalization***************************************
2025-07-04 12:31:47,496 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:47,784 - INFO - before .to(local_rank)***************************************
2025-07-04 12:31:47,784 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:31:47,784 - INFO - After .to(local_rank)***************************************
2025-07-04 12:31:47,784 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:47,785 - INFO - After Normalization***************************************
2025-07-04 12:31:47,785 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:51,049 - INFO - Epoch 75/150 - Train Loss: 0.332463, Val Loss: 0.338520
2025-07-04 12:31:53,310 - INFO - before .to(local_rank)***************************************
2025-07-04 12:31:53,324 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:31:53,325 - INFO - After .to(local_rank)***************************************
2025-07-04 12:31:53,325 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:53,325 - INFO - After Normalization***************************************
2025-07-04 12:31:53,325 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:53,642 - INFO - before .to(local_rank)***************************************
2025-07-04 12:31:53,642 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:31:53,643 - INFO - After .to(local_rank)***************************************
2025-07-04 12:31:53,643 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:53,643 - INFO - After Normalization***************************************
2025-07-04 12:31:53,643 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:53,931 - INFO - before .to(local_rank)***************************************
2025-07-04 12:31:53,931 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:31:53,932 - INFO - After .to(local_rank)***************************************
2025-07-04 12:31:53,932 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:53,932 - INFO - After Normalization***************************************
2025-07-04 12:31:53,932 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:57,161 - INFO - Epoch 76/150 - Train Loss: 0.330725, Val Loss: 0.343105
2025-07-04 12:31:59,449 - INFO - before .to(local_rank)***************************************
2025-07-04 12:31:59,463 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:31:59,463 - INFO - After .to(local_rank)***************************************
2025-07-04 12:31:59,463 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:59,463 - INFO - After Normalization***************************************
2025-07-04 12:31:59,464 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:59,771 - INFO - before .to(local_rank)***************************************
2025-07-04 12:31:59,771 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:31:59,771 - INFO - After .to(local_rank)***************************************
2025-07-04 12:31:59,771 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:31:59,771 - INFO - After Normalization***************************************
2025-07-04 12:31:59,771 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:00,060 - INFO - before .to(local_rank)***************************************
2025-07-04 12:32:00,060 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:32:00,060 - INFO - After .to(local_rank)***************************************
2025-07-04 12:32:00,060 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:00,060 - INFO - After Normalization***************************************
2025-07-04 12:32:00,060 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:03,295 - INFO - Epoch 77/150 - Train Loss: 0.329678, Val Loss: 0.336431
2025-07-04 12:32:05,551 - INFO - before .to(local_rank)***************************************
2025-07-04 12:32:05,566 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:32:05,566 - INFO - After .to(local_rank)***************************************
2025-07-04 12:32:05,566 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:05,566 - INFO - After Normalization***************************************
2025-07-04 12:32:05,566 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:05,882 - INFO - before .to(local_rank)***************************************
2025-07-04 12:32:05,882 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:32:05,883 - INFO - After .to(local_rank)***************************************
2025-07-04 12:32:05,883 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:05,883 - INFO - After Normalization***************************************
2025-07-04 12:32:05,883 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:06,171 - INFO - before .to(local_rank)***************************************
2025-07-04 12:32:06,171 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:32:06,172 - INFO - After .to(local_rank)***************************************
2025-07-04 12:32:06,172 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:06,172 - INFO - After Normalization***************************************
2025-07-04 12:32:06,172 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:09,419 - INFO - Epoch 78/150 - Train Loss: 0.332115, Val Loss: 0.340799
2025-07-04 12:32:11,689 - INFO - before .to(local_rank)***************************************
2025-07-04 12:32:11,703 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:32:11,703 - INFO - After .to(local_rank)***************************************
2025-07-04 12:32:11,703 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:11,703 - INFO - After Normalization***************************************
2025-07-04 12:32:11,703 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:12,006 - INFO - before .to(local_rank)***************************************
2025-07-04 12:32:12,006 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:32:12,007 - INFO - After .to(local_rank)***************************************
2025-07-04 12:32:12,007 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:12,007 - INFO - After Normalization***************************************
2025-07-04 12:32:12,007 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:12,295 - INFO - before .to(local_rank)***************************************
2025-07-04 12:32:12,295 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:32:12,296 - INFO - After .to(local_rank)***************************************
2025-07-04 12:32:12,296 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:12,296 - INFO - After Normalization***************************************
2025-07-04 12:32:12,296 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:15,543 - INFO - Epoch 79/150 - Train Loss: 0.323830, Val Loss: 0.352417
2025-07-04 12:32:17,793 - INFO - before .to(local_rank)***************************************
2025-07-04 12:32:17,806 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:32:17,807 - INFO - After .to(local_rank)***************************************
2025-07-04 12:32:17,807 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:17,807 - INFO - After Normalization***************************************
2025-07-04 12:32:17,807 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:18,125 - INFO - before .to(local_rank)***************************************
2025-07-04 12:32:18,125 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:32:18,125 - INFO - After .to(local_rank)***************************************
2025-07-04 12:32:18,125 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:18,125 - INFO - After Normalization***************************************
2025-07-04 12:32:18,125 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:18,414 - INFO - before .to(local_rank)***************************************
2025-07-04 12:32:18,414 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:32:18,414 - INFO - After .to(local_rank)***************************************
2025-07-04 12:32:18,414 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:18,414 - INFO - After Normalization***************************************
2025-07-04 12:32:18,414 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:21,681 - INFO - Epoch 80/150 - Train Loss: 0.324538, Val Loss: 0.337843
2025-07-04 12:32:24,082 - INFO - before .to(local_rank)***************************************
2025-07-04 12:32:24,095 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:32:24,095 - INFO - After .to(local_rank)***************************************
2025-07-04 12:32:24,096 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:24,096 - INFO - After Normalization***************************************
2025-07-04 12:32:24,096 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:24,405 - INFO - before .to(local_rank)***************************************
2025-07-04 12:32:24,405 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:32:24,406 - INFO - After .to(local_rank)***************************************
2025-07-04 12:32:24,406 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:24,406 - INFO - After Normalization***************************************
2025-07-04 12:32:24,406 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:24,698 - INFO - before .to(local_rank)***************************************
2025-07-04 12:32:24,699 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:32:24,699 - INFO - After .to(local_rank)***************************************
2025-07-04 12:32:24,699 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:24,699 - INFO - After Normalization***************************************
2025-07-04 12:32:24,699 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:27,909 - INFO - Epoch 81/150 - Train Loss: 0.323342, Val Loss: 0.337610
2025-07-04 12:32:30,159 - INFO - before .to(local_rank)***************************************
2025-07-04 12:32:30,173 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:32:30,173 - INFO - After .to(local_rank)***************************************
2025-07-04 12:32:30,173 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:30,173 - INFO - After Normalization***************************************
2025-07-04 12:32:30,173 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:30,479 - INFO - before .to(local_rank)***************************************
2025-07-04 12:32:30,479 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:32:30,479 - INFO - After .to(local_rank)***************************************
2025-07-04 12:32:30,479 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:30,479 - INFO - After Normalization***************************************
2025-07-04 12:32:30,480 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:30,772 - INFO - before .to(local_rank)***************************************
2025-07-04 12:32:30,772 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:32:30,772 - INFO - After .to(local_rank)***************************************
2025-07-04 12:32:30,773 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:30,773 - INFO - After Normalization***************************************
2025-07-04 12:32:30,773 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:34,005 - INFO - Epoch 82/150 - Train Loss: 0.323520, Val Loss: 0.327724
2025-07-04 12:32:34,021 - INFO - New best model saved with Val Loss: 0.327724
2025-07-04 12:32:36,284 - INFO - before .to(local_rank)***************************************
2025-07-04 12:32:36,297 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:32:36,297 - INFO - After .to(local_rank)***************************************
2025-07-04 12:32:36,297 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:36,297 - INFO - After Normalization***************************************
2025-07-04 12:32:36,298 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:36,615 - INFO - before .to(local_rank)***************************************
2025-07-04 12:32:36,615 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:32:36,616 - INFO - After .to(local_rank)***************************************
2025-07-04 12:32:36,616 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:36,616 - INFO - After Normalization***************************************
2025-07-04 12:32:36,616 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:36,908 - INFO - before .to(local_rank)***************************************
2025-07-04 12:32:36,908 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:32:36,908 - INFO - After .to(local_rank)***************************************
2025-07-04 12:32:36,908 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:36,908 - INFO - After Normalization***************************************
2025-07-04 12:32:36,908 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:40,151 - INFO - Epoch 83/150 - Train Loss: 0.322984, Val Loss: 0.328694
2025-07-04 12:32:42,422 - INFO - before .to(local_rank)***************************************
2025-07-04 12:32:42,436 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:32:42,436 - INFO - After .to(local_rank)***************************************
2025-07-04 12:32:42,436 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:42,436 - INFO - After Normalization***************************************
2025-07-04 12:32:42,436 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:42,745 - INFO - before .to(local_rank)***************************************
2025-07-04 12:32:42,745 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:32:42,745 - INFO - After .to(local_rank)***************************************
2025-07-04 12:32:42,745 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:42,745 - INFO - After Normalization***************************************
2025-07-04 12:32:42,746 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:43,034 - INFO - before .to(local_rank)***************************************
2025-07-04 12:32:43,034 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:32:43,034 - INFO - After .to(local_rank)***************************************
2025-07-04 12:32:43,035 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:43,035 - INFO - After Normalization***************************************
2025-07-04 12:32:43,035 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:46,276 - INFO - Epoch 84/150 - Train Loss: 0.320235, Val Loss: 0.327149
2025-07-04 12:32:46,292 - INFO - New best model saved with Val Loss: 0.327149
2025-07-04 12:32:48,551 - INFO - before .to(local_rank)***************************************
2025-07-04 12:32:48,565 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:32:48,565 - INFO - After .to(local_rank)***************************************
2025-07-04 12:32:48,565 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:48,566 - INFO - After Normalization***************************************
2025-07-04 12:32:48,566 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:48,886 - INFO - before .to(local_rank)***************************************
2025-07-04 12:32:48,886 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:32:48,886 - INFO - After .to(local_rank)***************************************
2025-07-04 12:32:48,886 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:48,887 - INFO - After Normalization***************************************
2025-07-04 12:32:48,887 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:49,175 - INFO - before .to(local_rank)***************************************
2025-07-04 12:32:49,175 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:32:49,175 - INFO - After .to(local_rank)***************************************
2025-07-04 12:32:49,175 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:49,176 - INFO - After Normalization***************************************
2025-07-04 12:32:49,176 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:52,428 - INFO - Epoch 85/150 - Train Loss: 0.318422, Val Loss: 0.322234
2025-07-04 12:32:52,442 - INFO - New best model saved with Val Loss: 0.322234
2025-07-04 12:32:54,710 - INFO - before .to(local_rank)***************************************
2025-07-04 12:32:54,723 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:32:54,724 - INFO - After .to(local_rank)***************************************
2025-07-04 12:32:54,724 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:54,724 - INFO - After Normalization***************************************
2025-07-04 12:32:54,724 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:55,030 - INFO - before .to(local_rank)***************************************
2025-07-04 12:32:55,030 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:32:55,030 - INFO - After .to(local_rank)***************************************
2025-07-04 12:32:55,030 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:55,030 - INFO - After Normalization***************************************
2025-07-04 12:32:55,030 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:55,319 - INFO - before .to(local_rank)***************************************
2025-07-04 12:32:55,319 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:32:55,319 - INFO - After .to(local_rank)***************************************
2025-07-04 12:32:55,319 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:55,319 - INFO - After Normalization***************************************
2025-07-04 12:32:55,319 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:32:58,718 - INFO - Epoch 86/150 - Train Loss: 0.316809, Val Loss: 0.323506
2025-07-04 12:33:00,992 - INFO - before .to(local_rank)***************************************
2025-07-04 12:33:01,006 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:33:01,007 - INFO - After .to(local_rank)***************************************
2025-07-04 12:33:01,007 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:01,007 - INFO - After Normalization***************************************
2025-07-04 12:33:01,007 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:01,325 - INFO - before .to(local_rank)***************************************
2025-07-04 12:33:01,325 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:33:01,325 - INFO - After .to(local_rank)***************************************
2025-07-04 12:33:01,325 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:01,325 - INFO - After Normalization***************************************
2025-07-04 12:33:01,325 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:01,614 - INFO - before .to(local_rank)***************************************
2025-07-04 12:33:01,614 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:33:01,614 - INFO - After .to(local_rank)***************************************
2025-07-04 12:33:01,614 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:01,614 - INFO - After Normalization***************************************
2025-07-04 12:33:01,614 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:04,853 - INFO - Epoch 87/150 - Train Loss: 0.316298, Val Loss: 0.332799
2025-07-04 12:33:07,132 - INFO - before .to(local_rank)***************************************
2025-07-04 12:33:07,147 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:33:07,147 - INFO - After .to(local_rank)***************************************
2025-07-04 12:33:07,147 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:07,147 - INFO - After Normalization***************************************
2025-07-04 12:33:07,147 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:07,452 - INFO - before .to(local_rank)***************************************
2025-07-04 12:33:07,452 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:33:07,453 - INFO - After .to(local_rank)***************************************
2025-07-04 12:33:07,453 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:07,453 - INFO - After Normalization***************************************
2025-07-04 12:33:07,453 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:07,742 - INFO - before .to(local_rank)***************************************
2025-07-04 12:33:07,742 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:33:07,742 - INFO - After .to(local_rank)***************************************
2025-07-04 12:33:07,742 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:07,742 - INFO - After Normalization***************************************
2025-07-04 12:33:07,742 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:10,996 - INFO - Epoch 88/150 - Train Loss: 0.317903, Val Loss: 0.324952
2025-07-04 12:33:13,265 - INFO - before .to(local_rank)***************************************
2025-07-04 12:33:13,279 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:33:13,280 - INFO - After .to(local_rank)***************************************
2025-07-04 12:33:13,280 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:13,280 - INFO - After Normalization***************************************
2025-07-04 12:33:13,280 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:13,596 - INFO - before .to(local_rank)***************************************
2025-07-04 12:33:13,596 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:33:13,596 - INFO - After .to(local_rank)***************************************
2025-07-04 12:33:13,596 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:13,597 - INFO - After Normalization***************************************
2025-07-04 12:33:13,597 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:13,885 - INFO - before .to(local_rank)***************************************
2025-07-04 12:33:13,886 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:33:13,886 - INFO - After .to(local_rank)***************************************
2025-07-04 12:33:13,886 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:13,886 - INFO - After Normalization***************************************
2025-07-04 12:33:13,886 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:17,145 - INFO - Epoch 89/150 - Train Loss: 0.317754, Val Loss: 0.318536
2025-07-04 12:33:17,160 - INFO - New best model saved with Val Loss: 0.318536
2025-07-04 12:33:19,432 - INFO - before .to(local_rank)***************************************
2025-07-04 12:33:19,446 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:33:19,446 - INFO - After .to(local_rank)***************************************
2025-07-04 12:33:19,446 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:19,446 - INFO - After Normalization***************************************
2025-07-04 12:33:19,446 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:19,748 - INFO - before .to(local_rank)***************************************
2025-07-04 12:33:19,748 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:33:19,749 - INFO - After .to(local_rank)***************************************
2025-07-04 12:33:19,749 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:19,749 - INFO - After Normalization***************************************
2025-07-04 12:33:19,749 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:20,042 - INFO - before .to(local_rank)***************************************
2025-07-04 12:33:20,042 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:33:20,042 - INFO - After .to(local_rank)***************************************
2025-07-04 12:33:20,042 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:20,042 - INFO - After Normalization***************************************
2025-07-04 12:33:20,042 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:23,287 - INFO - Epoch 90/150 - Train Loss: 0.317134, Val Loss: 0.318901
2025-07-04 12:33:25,652 - INFO - before .to(local_rank)***************************************
2025-07-04 12:33:25,665 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:33:25,665 - INFO - After .to(local_rank)***************************************
2025-07-04 12:33:25,665 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:25,665 - INFO - After Normalization***************************************
2025-07-04 12:33:25,665 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:25,968 - INFO - before .to(local_rank)***************************************
2025-07-04 12:33:25,968 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:33:25,968 - INFO - After .to(local_rank)***************************************
2025-07-04 12:33:25,968 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:25,968 - INFO - After Normalization***************************************
2025-07-04 12:33:25,968 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:26,284 - INFO - before .to(local_rank)***************************************
2025-07-04 12:33:26,284 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:33:26,284 - INFO - After .to(local_rank)***************************************
2025-07-04 12:33:26,284 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:26,284 - INFO - After Normalization***************************************
2025-07-04 12:33:26,284 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:29,525 - INFO - Epoch 91/150 - Train Loss: 0.313987, Val Loss: 0.322064
2025-07-04 12:33:31,812 - INFO - before .to(local_rank)***************************************
2025-07-04 12:33:31,826 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:33:31,826 - INFO - After .to(local_rank)***************************************
2025-07-04 12:33:31,827 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:31,827 - INFO - After Normalization***************************************
2025-07-04 12:33:31,827 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:32,140 - INFO - before .to(local_rank)***************************************
2025-07-04 12:33:32,140 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:33:32,140 - INFO - After .to(local_rank)***************************************
2025-07-04 12:33:32,140 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:32,140 - INFO - After Normalization***************************************
2025-07-04 12:33:32,140 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:32,429 - INFO - before .to(local_rank)***************************************
2025-07-04 12:33:32,429 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:33:32,430 - INFO - After .to(local_rank)***************************************
2025-07-04 12:33:32,430 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:32,430 - INFO - After Normalization***************************************
2025-07-04 12:33:32,430 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:35,664 - INFO - Epoch 92/150 - Train Loss: 0.313308, Val Loss: 0.327740
2025-07-04 12:33:37,941 - INFO - before .to(local_rank)***************************************
2025-07-04 12:33:37,954 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:33:37,954 - INFO - After .to(local_rank)***************************************
2025-07-04 12:33:37,955 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:37,955 - INFO - After Normalization***************************************
2025-07-04 12:33:37,955 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:38,260 - INFO - before .to(local_rank)***************************************
2025-07-04 12:33:38,260 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:33:38,261 - INFO - After .to(local_rank)***************************************
2025-07-04 12:33:38,261 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:38,261 - INFO - After Normalization***************************************
2025-07-04 12:33:38,261 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:38,549 - INFO - before .to(local_rank)***************************************
2025-07-04 12:33:38,549 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:33:38,550 - INFO - After .to(local_rank)***************************************
2025-07-04 12:33:38,550 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:38,550 - INFO - After Normalization***************************************
2025-07-04 12:33:38,550 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:41,797 - INFO - Epoch 93/150 - Train Loss: 0.312805, Val Loss: 0.322787
2025-07-04 12:33:44,073 - INFO - before .to(local_rank)***************************************
2025-07-04 12:33:44,088 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:33:44,088 - INFO - After .to(local_rank)***************************************
2025-07-04 12:33:44,088 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:44,088 - INFO - After Normalization***************************************
2025-07-04 12:33:44,088 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:44,396 - INFO - before .to(local_rank)***************************************
2025-07-04 12:33:44,397 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:33:44,397 - INFO - After .to(local_rank)***************************************
2025-07-04 12:33:44,397 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:44,397 - INFO - After Normalization***************************************
2025-07-04 12:33:44,397 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:44,686 - INFO - before .to(local_rank)***************************************
2025-07-04 12:33:44,686 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:33:44,686 - INFO - After .to(local_rank)***************************************
2025-07-04 12:33:44,686 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:44,686 - INFO - After Normalization***************************************
2025-07-04 12:33:44,686 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:47,962 - INFO - Epoch 94/150 - Train Loss: 0.310842, Val Loss: 0.324050
2025-07-04 12:33:50,220 - INFO - before .to(local_rank)***************************************
2025-07-04 12:33:50,233 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:33:50,233 - INFO - After .to(local_rank)***************************************
2025-07-04 12:33:50,233 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:50,233 - INFO - After Normalization***************************************
2025-07-04 12:33:50,233 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:50,553 - INFO - before .to(local_rank)***************************************
2025-07-04 12:33:50,553 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:33:50,553 - INFO - After .to(local_rank)***************************************
2025-07-04 12:33:50,553 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:50,553 - INFO - After Normalization***************************************
2025-07-04 12:33:50,553 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:50,842 - INFO - before .to(local_rank)***************************************
2025-07-04 12:33:50,842 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:33:50,842 - INFO - After .to(local_rank)***************************************
2025-07-04 12:33:50,842 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:50,842 - INFO - After Normalization***************************************
2025-07-04 12:33:50,843 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:54,078 - INFO - Epoch 95/150 - Train Loss: 0.311745, Val Loss: 0.313009
2025-07-04 12:33:54,094 - INFO - New best model saved with Val Loss: 0.313009
2025-07-04 12:33:56,345 - INFO - before .to(local_rank)***************************************
2025-07-04 12:33:56,359 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:33:56,360 - INFO - After .to(local_rank)***************************************
2025-07-04 12:33:56,360 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:56,360 - INFO - After Normalization***************************************
2025-07-04 12:33:56,360 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:56,667 - INFO - before .to(local_rank)***************************************
2025-07-04 12:33:56,667 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:33:56,668 - INFO - After .to(local_rank)***************************************
2025-07-04 12:33:56,668 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:56,668 - INFO - After Normalization***************************************
2025-07-04 12:33:56,668 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:56,956 - INFO - before .to(local_rank)***************************************
2025-07-04 12:33:56,957 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:33:56,957 - INFO - After .to(local_rank)***************************************
2025-07-04 12:33:56,957 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:33:56,957 - INFO - After Normalization***************************************
2025-07-04 12:33:56,957 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:00,212 - INFO - Epoch 96/150 - Train Loss: 0.308067, Val Loss: 0.321982
2025-07-04 12:34:02,487 - INFO - before .to(local_rank)***************************************
2025-07-04 12:34:02,502 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:34:02,502 - INFO - After .to(local_rank)***************************************
2025-07-04 12:34:02,502 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:02,502 - INFO - After Normalization***************************************
2025-07-04 12:34:02,503 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:02,820 - INFO - before .to(local_rank)***************************************
2025-07-04 12:34:02,821 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:34:02,821 - INFO - After .to(local_rank)***************************************
2025-07-04 12:34:02,821 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:02,821 - INFO - After Normalization***************************************
2025-07-04 12:34:02,821 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:03,110 - INFO - before .to(local_rank)***************************************
2025-07-04 12:34:03,110 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:34:03,110 - INFO - After .to(local_rank)***************************************
2025-07-04 12:34:03,110 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:03,110 - INFO - After Normalization***************************************
2025-07-04 12:34:03,110 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:06,332 - INFO - Epoch 97/150 - Train Loss: 0.306806, Val Loss: 0.330466
2025-07-04 12:34:08,602 - INFO - before .to(local_rank)***************************************
2025-07-04 12:34:08,616 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:34:08,616 - INFO - After .to(local_rank)***************************************
2025-07-04 12:34:08,616 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:08,617 - INFO - After Normalization***************************************
2025-07-04 12:34:08,617 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:08,924 - INFO - before .to(local_rank)***************************************
2025-07-04 12:34:08,924 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:34:08,924 - INFO - After .to(local_rank)***************************************
2025-07-04 12:34:08,924 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:08,925 - INFO - After Normalization***************************************
2025-07-04 12:34:08,925 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:09,213 - INFO - before .to(local_rank)***************************************
2025-07-04 12:34:09,213 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:34:09,213 - INFO - After .to(local_rank)***************************************
2025-07-04 12:34:09,213 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:09,214 - INFO - After Normalization***************************************
2025-07-04 12:34:09,214 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:12,446 - INFO - Epoch 98/150 - Train Loss: 0.304537, Val Loss: 0.335054
2025-07-04 12:34:14,704 - INFO - before .to(local_rank)***************************************
2025-07-04 12:34:14,718 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:34:14,719 - INFO - After .to(local_rank)***************************************
2025-07-04 12:34:14,719 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:14,719 - INFO - After Normalization***************************************
2025-07-04 12:34:14,719 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:15,019 - INFO - before .to(local_rank)***************************************
2025-07-04 12:34:15,019 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:34:15,020 - INFO - After .to(local_rank)***************************************
2025-07-04 12:34:15,020 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:15,020 - INFO - After Normalization***************************************
2025-07-04 12:34:15,020 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:15,312 - INFO - before .to(local_rank)***************************************
2025-07-04 12:34:15,312 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:34:15,312 - INFO - After .to(local_rank)***************************************
2025-07-04 12:34:15,313 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:15,313 - INFO - After Normalization***************************************
2025-07-04 12:34:15,313 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:18,537 - INFO - Epoch 99/150 - Train Loss: 0.303622, Val Loss: 0.331282
2025-07-04 12:34:20,811 - INFO - before .to(local_rank)***************************************
2025-07-04 12:34:20,824 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:34:20,825 - INFO - After .to(local_rank)***************************************
2025-07-04 12:34:20,825 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:20,825 - INFO - After Normalization***************************************
2025-07-04 12:34:20,825 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:21,138 - INFO - before .to(local_rank)***************************************
2025-07-04 12:34:21,138 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:34:21,138 - INFO - After .to(local_rank)***************************************
2025-07-04 12:34:21,138 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:21,138 - INFO - After Normalization***************************************
2025-07-04 12:34:21,138 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:21,431 - INFO - before .to(local_rank)***************************************
2025-07-04 12:34:21,432 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:34:21,432 - INFO - After .to(local_rank)***************************************
2025-07-04 12:34:21,432 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:21,432 - INFO - After Normalization***************************************
2025-07-04 12:34:21,432 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:24,668 - INFO - Epoch 100/150 - Train Loss: 0.303389, Val Loss: 0.322971
2025-07-04 12:34:27,041 - INFO - before .to(local_rank)***************************************
2025-07-04 12:34:27,054 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:34:27,054 - INFO - After .to(local_rank)***************************************
2025-07-04 12:34:27,054 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:27,054 - INFO - After Normalization***************************************
2025-07-04 12:34:27,054 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:27,371 - INFO - before .to(local_rank)***************************************
2025-07-04 12:34:27,371 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:34:27,371 - INFO - After .to(local_rank)***************************************
2025-07-04 12:34:27,371 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:27,371 - INFO - After Normalization***************************************
2025-07-04 12:34:27,371 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:27,660 - INFO - before .to(local_rank)***************************************
2025-07-04 12:34:27,660 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:34:27,660 - INFO - After .to(local_rank)***************************************
2025-07-04 12:34:27,660 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:27,660 - INFO - After Normalization***************************************
2025-07-04 12:34:27,660 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:30,908 - INFO - Epoch 101/150 - Train Loss: 0.304374, Val Loss: 0.331376
2025-07-04 12:34:33,181 - INFO - before .to(local_rank)***************************************
2025-07-04 12:34:33,195 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:34:33,196 - INFO - After .to(local_rank)***************************************
2025-07-04 12:34:33,196 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:33,196 - INFO - After Normalization***************************************
2025-07-04 12:34:33,196 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:33,502 - INFO - before .to(local_rank)***************************************
2025-07-04 12:34:33,502 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:34:33,502 - INFO - After .to(local_rank)***************************************
2025-07-04 12:34:33,502 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:33,502 - INFO - After Normalization***************************************
2025-07-04 12:34:33,502 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:33,791 - INFO - before .to(local_rank)***************************************
2025-07-04 12:34:33,791 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:34:33,791 - INFO - After .to(local_rank)***************************************
2025-07-04 12:34:33,791 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:33,791 - INFO - After Normalization***************************************
2025-07-04 12:34:33,791 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:37,021 - INFO - Epoch 102/150 - Train Loss: 0.301968, Val Loss: 0.325183
2025-07-04 12:34:39,304 - INFO - before .to(local_rank)***************************************
2025-07-04 12:34:39,318 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:34:39,319 - INFO - After .to(local_rank)***************************************
2025-07-04 12:34:39,319 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:39,319 - INFO - After Normalization***************************************
2025-07-04 12:34:39,319 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:39,635 - INFO - before .to(local_rank)***************************************
2025-07-04 12:34:39,635 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:34:39,635 - INFO - After .to(local_rank)***************************************
2025-07-04 12:34:39,635 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:39,636 - INFO - After Normalization***************************************
2025-07-04 12:34:39,636 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:39,924 - INFO - before .to(local_rank)***************************************
2025-07-04 12:34:39,924 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:34:39,924 - INFO - After .to(local_rank)***************************************
2025-07-04 12:34:39,925 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:39,925 - INFO - After Normalization***************************************
2025-07-04 12:34:39,925 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:43,160 - INFO - Epoch 103/150 - Train Loss: 0.298230, Val Loss: 0.322976
2025-07-04 12:34:45,440 - INFO - before .to(local_rank)***************************************
2025-07-04 12:34:45,454 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:34:45,467 - INFO - After .to(local_rank)***************************************
2025-07-04 12:34:45,480 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:45,492 - INFO - After Normalization***************************************
2025-07-04 12:34:45,502 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:45,833 - INFO - before .to(local_rank)***************************************
2025-07-04 12:34:45,834 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:34:45,834 - INFO - After .to(local_rank)***************************************
2025-07-04 12:34:45,834 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:45,834 - INFO - After Normalization***************************************
2025-07-04 12:34:45,834 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:46,123 - INFO - before .to(local_rank)***************************************
2025-07-04 12:34:46,123 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:34:46,123 - INFO - After .to(local_rank)***************************************
2025-07-04 12:34:46,123 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:46,123 - INFO - After Normalization***************************************
2025-07-04 12:34:46,123 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:49,341 - INFO - Epoch 104/150 - Train Loss: 0.301941, Val Loss: 0.339548
2025-07-04 12:34:51,607 - INFO - before .to(local_rank)***************************************
2025-07-04 12:34:51,620 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:34:51,621 - INFO - After .to(local_rank)***************************************
2025-07-04 12:34:51,621 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:51,621 - INFO - After Normalization***************************************
2025-07-04 12:34:51,621 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:51,929 - INFO - before .to(local_rank)***************************************
2025-07-04 12:34:51,929 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:34:51,929 - INFO - After .to(local_rank)***************************************
2025-07-04 12:34:51,929 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:51,929 - INFO - After Normalization***************************************
2025-07-04 12:34:51,929 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:52,218 - INFO - before .to(local_rank)***************************************
2025-07-04 12:34:52,218 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:34:52,218 - INFO - After .to(local_rank)***************************************
2025-07-04 12:34:52,218 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:52,218 - INFO - After Normalization***************************************
2025-07-04 12:34:52,218 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:55,462 - INFO - Epoch 105/150 - Train Loss: 0.301876, Val Loss: 0.337391
2025-07-04 12:34:57,720 - INFO - before .to(local_rank)***************************************
2025-07-04 12:34:57,734 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:34:57,734 - INFO - After .to(local_rank)***************************************
2025-07-04 12:34:57,734 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:57,735 - INFO - After Normalization***************************************
2025-07-04 12:34:57,735 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:58,036 - INFO - before .to(local_rank)***************************************
2025-07-04 12:34:58,036 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:34:58,036 - INFO - After .to(local_rank)***************************************
2025-07-04 12:34:58,036 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:58,037 - INFO - After Normalization***************************************
2025-07-04 12:34:58,037 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:58,325 - INFO - before .to(local_rank)***************************************
2025-07-04 12:34:58,325 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:34:58,325 - INFO - After .to(local_rank)***************************************
2025-07-04 12:34:58,325 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:34:58,325 - INFO - After Normalization***************************************
2025-07-04 12:34:58,325 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:01,559 - INFO - Epoch 106/150 - Train Loss: 0.301338, Val Loss: 0.324497
2025-07-04 12:35:03,824 - INFO - before .to(local_rank)***************************************
2025-07-04 12:35:03,838 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:35:03,839 - INFO - After .to(local_rank)***************************************
2025-07-04 12:35:03,839 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:03,839 - INFO - After Normalization***************************************
2025-07-04 12:35:03,839 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:04,151 - INFO - before .to(local_rank)***************************************
2025-07-04 12:35:04,151 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:35:04,152 - INFO - After .to(local_rank)***************************************
2025-07-04 12:35:04,152 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:04,152 - INFO - After Normalization***************************************
2025-07-04 12:35:04,152 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:04,441 - INFO - before .to(local_rank)***************************************
2025-07-04 12:35:04,441 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:35:04,441 - INFO - After .to(local_rank)***************************************
2025-07-04 12:35:04,442 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:04,442 - INFO - After Normalization***************************************
2025-07-04 12:35:04,442 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:07,682 - INFO - Epoch 107/150 - Train Loss: 0.297671, Val Loss: 0.313158
2025-07-04 12:35:09,961 - INFO - before .to(local_rank)***************************************
2025-07-04 12:35:09,975 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:35:09,975 - INFO - After .to(local_rank)***************************************
2025-07-04 12:35:09,975 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:09,975 - INFO - After Normalization***************************************
2025-07-04 12:35:09,975 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:10,277 - INFO - before .to(local_rank)***************************************
2025-07-04 12:35:10,277 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:35:10,278 - INFO - After .to(local_rank)***************************************
2025-07-04 12:35:10,278 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:10,278 - INFO - After Normalization***************************************
2025-07-04 12:35:10,278 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:10,566 - INFO - before .to(local_rank)***************************************
2025-07-04 12:35:10,566 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:35:10,567 - INFO - After .to(local_rank)***************************************
2025-07-04 12:35:10,567 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:10,567 - INFO - After Normalization***************************************
2025-07-04 12:35:10,567 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:13,812 - INFO - Epoch 108/150 - Train Loss: 0.294682, Val Loss: 0.305555
2025-07-04 12:35:13,827 - INFO - New best model saved with Val Loss: 0.305555
2025-07-04 12:35:16,100 - INFO - before .to(local_rank)***************************************
2025-07-04 12:35:16,114 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:35:16,115 - INFO - After .to(local_rank)***************************************
2025-07-04 12:35:16,115 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:16,115 - INFO - After Normalization***************************************
2025-07-04 12:35:16,115 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:16,424 - INFO - before .to(local_rank)***************************************
2025-07-04 12:35:16,425 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:35:16,425 - INFO - After .to(local_rank)***************************************
2025-07-04 12:35:16,425 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:16,425 - INFO - After Normalization***************************************
2025-07-04 12:35:16,425 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:16,718 - INFO - before .to(local_rank)***************************************
2025-07-04 12:35:16,718 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:35:16,718 - INFO - After .to(local_rank)***************************************
2025-07-04 12:35:16,718 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:16,718 - INFO - After Normalization***************************************
2025-07-04 12:35:16,718 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:19,948 - INFO - Epoch 109/150 - Train Loss: 0.297884, Val Loss: 0.303263
2025-07-04 12:35:19,962 - INFO - New best model saved with Val Loss: 0.303263
2025-07-04 12:35:22,214 - INFO - before .to(local_rank)***************************************
2025-07-04 12:35:22,229 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:35:22,229 - INFO - After .to(local_rank)***************************************
2025-07-04 12:35:22,229 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:22,229 - INFO - After Normalization***************************************
2025-07-04 12:35:22,229 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:22,531 - INFO - before .to(local_rank)***************************************
2025-07-04 12:35:22,531 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:35:22,532 - INFO - After .to(local_rank)***************************************
2025-07-04 12:35:22,532 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:22,532 - INFO - After Normalization***************************************
2025-07-04 12:35:22,532 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:22,825 - INFO - before .to(local_rank)***************************************
2025-07-04 12:35:22,825 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:35:22,826 - INFO - After .to(local_rank)***************************************
2025-07-04 12:35:22,826 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:22,826 - INFO - After Normalization***************************************
2025-07-04 12:35:22,826 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:26,042 - INFO - Epoch 110/150 - Train Loss: 0.297559, Val Loss: 0.302826
2025-07-04 12:35:26,058 - INFO - New best model saved with Val Loss: 0.302826
2025-07-04 12:35:28,434 - INFO - before .to(local_rank)***************************************
2025-07-04 12:35:28,449 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:35:28,449 - INFO - After .to(local_rank)***************************************
2025-07-04 12:35:28,449 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:28,449 - INFO - After Normalization***************************************
2025-07-04 12:35:28,449 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:28,751 - INFO - before .to(local_rank)***************************************
2025-07-04 12:35:28,751 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:35:28,752 - INFO - After .to(local_rank)***************************************
2025-07-04 12:35:28,752 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:28,752 - INFO - After Normalization***************************************
2025-07-04 12:35:28,752 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:29,044 - INFO - before .to(local_rank)***************************************
2025-07-04 12:35:29,044 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:35:29,045 - INFO - After .to(local_rank)***************************************
2025-07-04 12:35:29,045 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:29,045 - INFO - After Normalization***************************************
2025-07-04 12:35:29,045 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:32,288 - INFO - Epoch 111/150 - Train Loss: 0.294144, Val Loss: 0.302702
2025-07-04 12:35:32,304 - INFO - New best model saved with Val Loss: 0.302702
2025-07-04 12:35:34,552 - INFO - before .to(local_rank)***************************************
2025-07-04 12:35:34,567 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:35:34,567 - INFO - After .to(local_rank)***************************************
2025-07-04 12:35:34,567 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:34,567 - INFO - After Normalization***************************************
2025-07-04 12:35:34,567 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:34,886 - INFO - before .to(local_rank)***************************************
2025-07-04 12:35:34,886 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:35:34,887 - INFO - After .to(local_rank)***************************************
2025-07-04 12:35:34,887 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:34,887 - INFO - After Normalization***************************************
2025-07-04 12:35:34,887 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:35,176 - INFO - before .to(local_rank)***************************************
2025-07-04 12:35:35,176 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:35:35,176 - INFO - After .to(local_rank)***************************************
2025-07-04 12:35:35,176 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:35,176 - INFO - After Normalization***************************************
2025-07-04 12:35:35,176 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:38,420 - INFO - Epoch 112/150 - Train Loss: 0.294188, Val Loss: 0.303885
2025-07-04 12:35:40,682 - INFO - before .to(local_rank)***************************************
2025-07-04 12:35:40,696 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:35:40,697 - INFO - After .to(local_rank)***************************************
2025-07-04 12:35:40,697 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:40,697 - INFO - After Normalization***************************************
2025-07-04 12:35:40,697 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:41,003 - INFO - before .to(local_rank)***************************************
2025-07-04 12:35:41,004 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:35:41,004 - INFO - After .to(local_rank)***************************************
2025-07-04 12:35:41,004 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:41,004 - INFO - After Normalization***************************************
2025-07-04 12:35:41,004 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:41,293 - INFO - before .to(local_rank)***************************************
2025-07-04 12:35:41,293 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:35:41,294 - INFO - After .to(local_rank)***************************************
2025-07-04 12:35:41,294 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:41,294 - INFO - After Normalization***************************************
2025-07-04 12:35:41,294 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:44,528 - INFO - Epoch 113/150 - Train Loss: 0.294812, Val Loss: 0.302568
2025-07-04 12:35:44,544 - INFO - New best model saved with Val Loss: 0.302568
2025-07-04 12:35:46,818 - INFO - before .to(local_rank)***************************************
2025-07-04 12:35:46,833 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:35:46,833 - INFO - After .to(local_rank)***************************************
2025-07-04 12:35:46,833 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:46,833 - INFO - After Normalization***************************************
2025-07-04 12:35:46,833 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:47,151 - INFO - before .to(local_rank)***************************************
2025-07-04 12:35:47,151 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:35:47,152 - INFO - After .to(local_rank)***************************************
2025-07-04 12:35:47,152 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:47,152 - INFO - After Normalization***************************************
2025-07-04 12:35:47,152 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:47,440 - INFO - before .to(local_rank)***************************************
2025-07-04 12:35:47,440 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:35:47,440 - INFO - After .to(local_rank)***************************************
2025-07-04 12:35:47,441 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:47,441 - INFO - After Normalization***************************************
2025-07-04 12:35:47,441 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:50,681 - INFO - Epoch 114/150 - Train Loss: 0.291335, Val Loss: 0.302743
2025-07-04 12:35:52,954 - INFO - before .to(local_rank)***************************************
2025-07-04 12:35:52,967 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:35:52,968 - INFO - After .to(local_rank)***************************************
2025-07-04 12:35:52,968 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:52,968 - INFO - After Normalization***************************************
2025-07-04 12:35:52,968 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:53,270 - INFO - before .to(local_rank)***************************************
2025-07-04 12:35:53,270 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:35:53,270 - INFO - After .to(local_rank)***************************************
2025-07-04 12:35:53,270 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:53,270 - INFO - After Normalization***************************************
2025-07-04 12:35:53,270 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:53,559 - INFO - before .to(local_rank)***************************************
2025-07-04 12:35:53,559 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:35:53,559 - INFO - After .to(local_rank)***************************************
2025-07-04 12:35:53,559 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:53,560 - INFO - After Normalization***************************************
2025-07-04 12:35:53,560 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:56,791 - INFO - Epoch 115/150 - Train Loss: 0.294847, Val Loss: 0.301672
2025-07-04 12:35:56,807 - INFO - New best model saved with Val Loss: 0.301672
2025-07-04 12:35:59,073 - INFO - before .to(local_rank)***************************************
2025-07-04 12:35:59,086 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:35:59,087 - INFO - After .to(local_rank)***************************************
2025-07-04 12:35:59,087 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:59,087 - INFO - After Normalization***************************************
2025-07-04 12:35:59,087 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:59,400 - INFO - before .to(local_rank)***************************************
2025-07-04 12:35:59,400 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:35:59,400 - INFO - After .to(local_rank)***************************************
2025-07-04 12:35:59,401 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:59,401 - INFO - After Normalization***************************************
2025-07-04 12:35:59,401 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:59,689 - INFO - before .to(local_rank)***************************************
2025-07-04 12:35:59,689 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:35:59,689 - INFO - After .to(local_rank)***************************************
2025-07-04 12:35:59,689 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:35:59,689 - INFO - After Normalization***************************************
2025-07-04 12:35:59,690 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:02,878 - INFO - Epoch 116/150 - Train Loss: 0.291347, Val Loss: 0.301323
2025-07-04 12:36:02,892 - INFO - New best model saved with Val Loss: 0.301323
2025-07-04 12:36:05,154 - INFO - before .to(local_rank)***************************************
2025-07-04 12:36:05,177 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:36:05,177 - INFO - After .to(local_rank)***************************************
2025-07-04 12:36:05,177 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:05,177 - INFO - After Normalization***************************************
2025-07-04 12:36:05,178 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:05,484 - INFO - before .to(local_rank)***************************************
2025-07-04 12:36:05,484 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:36:05,485 - INFO - After .to(local_rank)***************************************
2025-07-04 12:36:05,485 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:05,485 - INFO - After Normalization***************************************
2025-07-04 12:36:05,485 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:05,773 - INFO - before .to(local_rank)***************************************
2025-07-04 12:36:05,773 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:36:05,774 - INFO - After .to(local_rank)***************************************
2025-07-04 12:36:05,774 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:05,774 - INFO - After Normalization***************************************
2025-07-04 12:36:05,774 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:08,966 - INFO - Epoch 117/150 - Train Loss: 0.297098, Val Loss: 0.301480
2025-07-04 12:36:11,213 - INFO - before .to(local_rank)***************************************
2025-07-04 12:36:11,227 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:36:11,227 - INFO - After .to(local_rank)***************************************
2025-07-04 12:36:11,227 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:11,227 - INFO - After Normalization***************************************
2025-07-04 12:36:11,227 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:11,532 - INFO - before .to(local_rank)***************************************
2025-07-04 12:36:11,532 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:36:11,532 - INFO - After .to(local_rank)***************************************
2025-07-04 12:36:11,532 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:11,532 - INFO - After Normalization***************************************
2025-07-04 12:36:11,532 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:11,821 - INFO - before .to(local_rank)***************************************
2025-07-04 12:36:11,821 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:36:11,821 - INFO - After .to(local_rank)***************************************
2025-07-04 12:36:11,821 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:11,821 - INFO - After Normalization***************************************
2025-07-04 12:36:11,821 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:14,985 - INFO - Epoch 118/150 - Train Loss: 0.293385, Val Loss: 0.300978
2025-07-04 12:36:14,999 - INFO - New best model saved with Val Loss: 0.300978
2025-07-04 12:36:17,246 - INFO - before .to(local_rank)***************************************
2025-07-04 12:36:17,259 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:36:17,259 - INFO - After .to(local_rank)***************************************
2025-07-04 12:36:17,259 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:17,259 - INFO - After Normalization***************************************
2025-07-04 12:36:17,259 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:17,564 - INFO - before .to(local_rank)***************************************
2025-07-04 12:36:17,564 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:36:17,564 - INFO - After .to(local_rank)***************************************
2025-07-04 12:36:17,564 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:17,564 - INFO - After Normalization***************************************
2025-07-04 12:36:17,564 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:17,853 - INFO - before .to(local_rank)***************************************
2025-07-04 12:36:17,853 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:36:17,853 - INFO - After .to(local_rank)***************************************
2025-07-04 12:36:17,853 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:17,853 - INFO - After Normalization***************************************
2025-07-04 12:36:17,853 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:21,047 - INFO - Epoch 119/150 - Train Loss: 0.302592, Val Loss: 0.299818
2025-07-04 12:36:21,061 - INFO - New best model saved with Val Loss: 0.299818
2025-07-04 12:36:23,306 - INFO - before .to(local_rank)***************************************
2025-07-04 12:36:23,320 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:36:23,320 - INFO - After .to(local_rank)***************************************
2025-07-04 12:36:23,320 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:23,320 - INFO - After Normalization***************************************
2025-07-04 12:36:23,320 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:23,622 - INFO - before .to(local_rank)***************************************
2025-07-04 12:36:23,622 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:36:23,623 - INFO - After .to(local_rank)***************************************
2025-07-04 12:36:23,623 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:23,623 - INFO - After Normalization***************************************
2025-07-04 12:36:23,623 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:23,911 - INFO - before .to(local_rank)***************************************
2025-07-04 12:36:23,911 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:36:23,912 - INFO - After .to(local_rank)***************************************
2025-07-04 12:36:23,912 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:23,912 - INFO - After Normalization***************************************
2025-07-04 12:36:23,912 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:27,096 - INFO - Epoch 120/150 - Train Loss: 0.294459, Val Loss: 0.300232
2025-07-04 12:36:29,461 - INFO - before .to(local_rank)***************************************
2025-07-04 12:36:29,474 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:36:29,474 - INFO - After .to(local_rank)***************************************
2025-07-04 12:36:29,475 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:29,475 - INFO - After Normalization***************************************
2025-07-04 12:36:29,475 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:29,783 - INFO - before .to(local_rank)***************************************
2025-07-04 12:36:29,783 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:36:29,784 - INFO - After .to(local_rank)***************************************
2025-07-04 12:36:29,784 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:29,784 - INFO - After Normalization***************************************
2025-07-04 12:36:29,784 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:30,072 - INFO - before .to(local_rank)***************************************
2025-07-04 12:36:30,072 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:36:30,072 - INFO - After .to(local_rank)***************************************
2025-07-04 12:36:30,072 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:30,073 - INFO - After Normalization***************************************
2025-07-04 12:36:30,073 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:33,249 - INFO - Epoch 121/150 - Train Loss: 0.292162, Val Loss: 0.299877
2025-07-04 12:36:35,482 - INFO - before .to(local_rank)***************************************
2025-07-04 12:36:35,495 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:36:35,496 - INFO - After .to(local_rank)***************************************
2025-07-04 12:36:35,496 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:35,496 - INFO - After Normalization***************************************
2025-07-04 12:36:35,496 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:35,805 - INFO - before .to(local_rank)***************************************
2025-07-04 12:36:35,805 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:36:35,805 - INFO - After .to(local_rank)***************************************
2025-07-04 12:36:35,805 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:35,805 - INFO - After Normalization***************************************
2025-07-04 12:36:35,806 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:36,094 - INFO - before .to(local_rank)***************************************
2025-07-04 12:36:36,094 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:36:36,094 - INFO - After .to(local_rank)***************************************
2025-07-04 12:36:36,094 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:36,094 - INFO - After Normalization***************************************
2025-07-04 12:36:36,094 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:39,291 - INFO - Epoch 122/150 - Train Loss: 0.293628, Val Loss: 0.300110
2025-07-04 12:36:41,567 - INFO - before .to(local_rank)***************************************
2025-07-04 12:36:41,579 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:36:41,579 - INFO - After .to(local_rank)***************************************
2025-07-04 12:36:41,580 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:41,580 - INFO - After Normalization***************************************
2025-07-04 12:36:41,580 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:41,884 - INFO - before .to(local_rank)***************************************
2025-07-04 12:36:41,884 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:36:41,884 - INFO - After .to(local_rank)***************************************
2025-07-04 12:36:41,884 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:41,884 - INFO - After Normalization***************************************
2025-07-04 12:36:41,884 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:42,173 - INFO - before .to(local_rank)***************************************
2025-07-04 12:36:42,173 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:36:42,173 - INFO - After .to(local_rank)***************************************
2025-07-04 12:36:42,173 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:42,173 - INFO - After Normalization***************************************
2025-07-04 12:36:42,173 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:45,421 - INFO - Epoch 123/150 - Train Loss: 0.290856, Val Loss: 0.300606
2025-07-04 12:36:47,684 - INFO - before .to(local_rank)***************************************
2025-07-04 12:36:47,699 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:36:47,699 - INFO - After .to(local_rank)***************************************
2025-07-04 12:36:47,699 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:47,699 - INFO - After Normalization***************************************
2025-07-04 12:36:47,699 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:48,015 - INFO - before .to(local_rank)***************************************
2025-07-04 12:36:48,015 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:36:48,016 - INFO - After .to(local_rank)***************************************
2025-07-04 12:36:48,016 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:48,016 - INFO - After Normalization***************************************
2025-07-04 12:36:48,016 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:48,309 - INFO - before .to(local_rank)***************************************
2025-07-04 12:36:48,309 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:36:48,309 - INFO - After .to(local_rank)***************************************
2025-07-04 12:36:48,309 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:48,309 - INFO - After Normalization***************************************
2025-07-04 12:36:48,309 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:51,520 - INFO - Epoch 124/150 - Train Loss: 0.294557, Val Loss: 0.300868
2025-07-04 12:36:53,776 - INFO - before .to(local_rank)***************************************
2025-07-04 12:36:53,789 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:36:53,789 - INFO - After .to(local_rank)***************************************
2025-07-04 12:36:53,789 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:53,789 - INFO - After Normalization***************************************
2025-07-04 12:36:53,789 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:54,097 - INFO - before .to(local_rank)***************************************
2025-07-04 12:36:54,097 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:36:54,097 - INFO - After .to(local_rank)***************************************
2025-07-04 12:36:54,097 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:54,097 - INFO - After Normalization***************************************
2025-07-04 12:36:54,097 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:54,389 - INFO - before .to(local_rank)***************************************
2025-07-04 12:36:54,389 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:36:54,390 - INFO - After .to(local_rank)***************************************
2025-07-04 12:36:54,390 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:54,390 - INFO - After Normalization***************************************
2025-07-04 12:36:54,390 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:57,571 - INFO - Epoch 125/150 - Train Loss: 0.293174, Val Loss: 0.300792
2025-07-04 12:36:59,819 - INFO - before .to(local_rank)***************************************
2025-07-04 12:36:59,834 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:36:59,834 - INFO - After .to(local_rank)***************************************
2025-07-04 12:36:59,834 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:36:59,834 - INFO - After Normalization***************************************
2025-07-04 12:36:59,834 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:00,141 - INFO - before .to(local_rank)***************************************
2025-07-04 12:37:00,142 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:37:00,142 - INFO - After .to(local_rank)***************************************
2025-07-04 12:37:00,142 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:00,142 - INFO - After Normalization***************************************
2025-07-04 12:37:00,142 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:00,435 - INFO - before .to(local_rank)***************************************
2025-07-04 12:37:00,435 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:37:00,435 - INFO - After .to(local_rank)***************************************
2025-07-04 12:37:00,435 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:00,435 - INFO - After Normalization***************************************
2025-07-04 12:37:00,436 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:03,620 - INFO - Epoch 126/150 - Train Loss: 0.293391, Val Loss: 0.302475
2025-07-04 12:37:05,880 - INFO - before .to(local_rank)***************************************
2025-07-04 12:37:05,894 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:37:05,894 - INFO - After .to(local_rank)***************************************
2025-07-04 12:37:05,894 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:05,894 - INFO - After Normalization***************************************
2025-07-04 12:37:05,894 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:06,198 - INFO - before .to(local_rank)***************************************
2025-07-04 12:37:06,198 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:37:06,198 - INFO - After .to(local_rank)***************************************
2025-07-04 12:37:06,198 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:06,198 - INFO - After Normalization***************************************
2025-07-04 12:37:06,198 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:06,490 - INFO - before .to(local_rank)***************************************
2025-07-04 12:37:06,490 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:37:06,491 - INFO - After .to(local_rank)***************************************
2025-07-04 12:37:06,491 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:06,491 - INFO - After Normalization***************************************
2025-07-04 12:37:06,491 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:09,693 - INFO - Epoch 127/150 - Train Loss: 0.290767, Val Loss: 0.301194
2025-07-04 12:37:11,925 - INFO - before .to(local_rank)***************************************
2025-07-04 12:37:11,938 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:37:11,939 - INFO - After .to(local_rank)***************************************
2025-07-04 12:37:11,939 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:11,939 - INFO - After Normalization***************************************
2025-07-04 12:37:11,939 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:12,241 - INFO - before .to(local_rank)***************************************
2025-07-04 12:37:12,241 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:37:12,241 - INFO - After .to(local_rank)***************************************
2025-07-04 12:37:12,241 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:12,241 - INFO - After Normalization***************************************
2025-07-04 12:37:12,241 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:12,534 - INFO - before .to(local_rank)***************************************
2025-07-04 12:37:12,534 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:37:12,534 - INFO - After .to(local_rank)***************************************
2025-07-04 12:37:12,534 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:12,534 - INFO - After Normalization***************************************
2025-07-04 12:37:12,534 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:15,739 - INFO - Epoch 128/150 - Train Loss: 0.292764, Val Loss: 0.300578
2025-07-04 12:37:17,980 - INFO - before .to(local_rank)***************************************
2025-07-04 12:37:17,994 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:37:17,994 - INFO - After .to(local_rank)***************************************
2025-07-04 12:37:17,994 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:17,994 - INFO - After Normalization***************************************
2025-07-04 12:37:17,995 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:18,295 - INFO - before .to(local_rank)***************************************
2025-07-04 12:37:18,295 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:37:18,295 - INFO - After .to(local_rank)***************************************
2025-07-04 12:37:18,295 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:18,295 - INFO - After Normalization***************************************
2025-07-04 12:37:18,295 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:18,588 - INFO - before .to(local_rank)***************************************
2025-07-04 12:37:18,588 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:37:18,588 - INFO - After .to(local_rank)***************************************
2025-07-04 12:37:18,589 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:18,589 - INFO - After Normalization***************************************
2025-07-04 12:37:18,589 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:21,783 - INFO - Epoch 129/150 - Train Loss: 0.291864, Val Loss: 0.299356
2025-07-04 12:37:21,799 - INFO - New best model saved with Val Loss: 0.299356
2025-07-04 12:37:24,068 - INFO - before .to(local_rank)***************************************
2025-07-04 12:37:24,082 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:37:24,083 - INFO - After .to(local_rank)***************************************
2025-07-04 12:37:24,083 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:24,083 - INFO - After Normalization***************************************
2025-07-04 12:37:24,083 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:24,397 - INFO - before .to(local_rank)***************************************
2025-07-04 12:37:24,397 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:37:24,398 - INFO - After .to(local_rank)***************************************
2025-07-04 12:37:24,398 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:24,398 - INFO - After Normalization***************************************
2025-07-04 12:37:24,398 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:24,690 - INFO - before .to(local_rank)***************************************
2025-07-04 12:37:24,690 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:37:24,690 - INFO - After .to(local_rank)***************************************
2025-07-04 12:37:24,691 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:24,691 - INFO - After Normalization***************************************
2025-07-04 12:37:24,691 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:27,865 - INFO - Epoch 130/150 - Train Loss: 0.293602, Val Loss: 0.299731
2025-07-04 12:37:30,221 - INFO - before .to(local_rank)***************************************
2025-07-04 12:37:30,235 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:37:30,235 - INFO - After .to(local_rank)***************************************
2025-07-04 12:37:30,235 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:30,235 - INFO - After Normalization***************************************
2025-07-04 12:37:30,235 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:30,541 - INFO - before .to(local_rank)***************************************
2025-07-04 12:37:30,542 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:37:30,542 - INFO - After .to(local_rank)***************************************
2025-07-04 12:37:30,542 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:30,542 - INFO - After Normalization***************************************
2025-07-04 12:37:30,542 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:30,830 - INFO - before .to(local_rank)***************************************
2025-07-04 12:37:30,831 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:37:30,831 - INFO - After .to(local_rank)***************************************
2025-07-04 12:37:30,831 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:30,831 - INFO - After Normalization***************************************
2025-07-04 12:37:30,831 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:34,017 - INFO - Epoch 131/150 - Train Loss: 0.288207, Val Loss: 0.299689
2025-07-04 12:37:36,284 - INFO - before .to(local_rank)***************************************
2025-07-04 12:37:36,298 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:37:36,298 - INFO - After .to(local_rank)***************************************
2025-07-04 12:37:36,298 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:36,298 - INFO - After Normalization***************************************
2025-07-04 12:37:36,298 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:36,615 - INFO - before .to(local_rank)***************************************
2025-07-04 12:37:36,615 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:37:36,616 - INFO - After .to(local_rank)***************************************
2025-07-04 12:37:36,616 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:36,616 - INFO - After Normalization***************************************
2025-07-04 12:37:36,616 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:36,904 - INFO - before .to(local_rank)***************************************
2025-07-04 12:37:36,904 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:37:36,905 - INFO - After .to(local_rank)***************************************
2025-07-04 12:37:36,905 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:36,905 - INFO - After Normalization***************************************
2025-07-04 12:37:36,905 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:40,098 - INFO - Epoch 132/150 - Train Loss: 0.292099, Val Loss: 0.299264
2025-07-04 12:37:40,114 - INFO - New best model saved with Val Loss: 0.299264
2025-07-04 12:37:42,378 - INFO - before .to(local_rank)***************************************
2025-07-04 12:37:42,391 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:37:42,392 - INFO - After .to(local_rank)***************************************
2025-07-04 12:37:42,392 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:42,392 - INFO - After Normalization***************************************
2025-07-04 12:37:42,392 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:42,707 - INFO - before .to(local_rank)***************************************
2025-07-04 12:37:42,707 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:37:42,707 - INFO - After .to(local_rank)***************************************
2025-07-04 12:37:42,707 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:42,707 - INFO - After Normalization***************************************
2025-07-04 12:37:42,707 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:42,995 - INFO - before .to(local_rank)***************************************
2025-07-04 12:37:42,996 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:37:42,996 - INFO - After .to(local_rank)***************************************
2025-07-04 12:37:42,996 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:42,996 - INFO - After Normalization***************************************
2025-07-04 12:37:42,996 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:46,186 - INFO - Epoch 133/150 - Train Loss: 0.290441, Val Loss: 0.299675
2025-07-04 12:37:48,438 - INFO - before .to(local_rank)***************************************
2025-07-04 12:37:48,453 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:37:48,453 - INFO - After .to(local_rank)***************************************
2025-07-04 12:37:48,453 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:48,453 - INFO - After Normalization***************************************
2025-07-04 12:37:48,453 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:48,765 - INFO - before .to(local_rank)***************************************
2025-07-04 12:37:48,765 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:37:48,765 - INFO - After .to(local_rank)***************************************
2025-07-04 12:37:48,765 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:48,765 - INFO - After Normalization***************************************
2025-07-04 12:37:48,765 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:49,054 - INFO - before .to(local_rank)***************************************
2025-07-04 12:37:49,054 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:37:49,054 - INFO - After .to(local_rank)***************************************
2025-07-04 12:37:49,054 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:49,054 - INFO - After Normalization***************************************
2025-07-04 12:37:49,054 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:52,247 - INFO - Epoch 134/150 - Train Loss: 0.289598, Val Loss: 0.298882
2025-07-04 12:37:52,262 - INFO - New best model saved with Val Loss: 0.298882
2025-07-04 12:37:54,487 - INFO - before .to(local_rank)***************************************
2025-07-04 12:37:54,500 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:37:54,501 - INFO - After .to(local_rank)***************************************
2025-07-04 12:37:54,501 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:54,501 - INFO - After Normalization***************************************
2025-07-04 12:37:54,501 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:54,811 - INFO - before .to(local_rank)***************************************
2025-07-04 12:37:54,811 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:37:54,811 - INFO - After .to(local_rank)***************************************
2025-07-04 12:37:54,811 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:54,811 - INFO - After Normalization***************************************
2025-07-04 12:37:54,811 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:55,099 - INFO - before .to(local_rank)***************************************
2025-07-04 12:37:55,100 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:37:55,100 - INFO - After .to(local_rank)***************************************
2025-07-04 12:37:55,100 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:55,100 - INFO - After Normalization***************************************
2025-07-04 12:37:55,100 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:37:58,306 - INFO - Epoch 135/150 - Train Loss: 0.291279, Val Loss: 0.298781
2025-07-04 12:37:58,321 - INFO - New best model saved with Val Loss: 0.298781
2025-07-04 12:38:00,575 - INFO - before .to(local_rank)***************************************
2025-07-04 12:38:00,589 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:38:00,589 - INFO - After .to(local_rank)***************************************
2025-07-04 12:38:00,589 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:00,589 - INFO - After Normalization***************************************
2025-07-04 12:38:00,589 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:00,894 - INFO - before .to(local_rank)***************************************
2025-07-04 12:38:00,895 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:38:00,895 - INFO - After .to(local_rank)***************************************
2025-07-04 12:38:00,895 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:00,895 - INFO - After Normalization***************************************
2025-07-04 12:38:00,895 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:01,183 - INFO - before .to(local_rank)***************************************
2025-07-04 12:38:01,183 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:38:01,184 - INFO - After .to(local_rank)***************************************
2025-07-04 12:38:01,184 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:01,184 - INFO - After Normalization***************************************
2025-07-04 12:38:01,184 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:04,369 - INFO - Epoch 136/150 - Train Loss: 0.291402, Val Loss: 0.298846
2025-07-04 12:38:06,624 - INFO - before .to(local_rank)***************************************
2025-07-04 12:38:06,638 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:38:06,638 - INFO - After .to(local_rank)***************************************
2025-07-04 12:38:06,638 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:06,638 - INFO - After Normalization***************************************
2025-07-04 12:38:06,638 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:06,953 - INFO - before .to(local_rank)***************************************
2025-07-04 12:38:06,953 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:38:06,953 - INFO - After .to(local_rank)***************************************
2025-07-04 12:38:06,953 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:06,953 - INFO - After Normalization***************************************
2025-07-04 12:38:06,953 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:07,241 - INFO - before .to(local_rank)***************************************
2025-07-04 12:38:07,241 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:38:07,242 - INFO - After .to(local_rank)***************************************
2025-07-04 12:38:07,242 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:07,242 - INFO - After Normalization***************************************
2025-07-04 12:38:07,242 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:10,431 - INFO - Epoch 137/150 - Train Loss: 0.289009, Val Loss: 0.298318
2025-07-04 12:38:10,447 - INFO - New best model saved with Val Loss: 0.298318
2025-07-04 12:38:12,711 - INFO - before .to(local_rank)***************************************
2025-07-04 12:38:12,725 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:38:12,725 - INFO - After .to(local_rank)***************************************
2025-07-04 12:38:12,725 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:12,725 - INFO - After Normalization***************************************
2025-07-04 12:38:12,725 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:13,038 - INFO - before .to(local_rank)***************************************
2025-07-04 12:38:13,038 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:38:13,038 - INFO - After .to(local_rank)***************************************
2025-07-04 12:38:13,038 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:13,038 - INFO - After Normalization***************************************
2025-07-04 12:38:13,038 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:13,327 - INFO - before .to(local_rank)***************************************
2025-07-04 12:38:13,327 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:38:13,327 - INFO - After .to(local_rank)***************************************
2025-07-04 12:38:13,327 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:13,327 - INFO - After Normalization***************************************
2025-07-04 12:38:13,327 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:16,530 - INFO - Epoch 138/150 - Train Loss: 0.290120, Val Loss: 0.299168
2025-07-04 12:38:18,759 - INFO - before .to(local_rank)***************************************
2025-07-04 12:38:18,772 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:38:18,772 - INFO - After .to(local_rank)***************************************
2025-07-04 12:38:18,772 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:18,772 - INFO - After Normalization***************************************
2025-07-04 12:38:18,772 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:19,082 - INFO - before .to(local_rank)***************************************
2025-07-04 12:38:19,082 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:38:19,083 - INFO - After .to(local_rank)***************************************
2025-07-04 12:38:19,083 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:19,083 - INFO - After Normalization***************************************
2025-07-04 12:38:19,083 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:19,371 - INFO - before .to(local_rank)***************************************
2025-07-04 12:38:19,371 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:38:19,372 - INFO - After .to(local_rank)***************************************
2025-07-04 12:38:19,372 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:19,372 - INFO - After Normalization***************************************
2025-07-04 12:38:19,372 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:22,579 - INFO - Epoch 139/150 - Train Loss: 0.290107, Val Loss: 0.298576
2025-07-04 12:38:24,832 - INFO - before .to(local_rank)***************************************
2025-07-04 12:38:24,845 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:38:24,845 - INFO - After .to(local_rank)***************************************
2025-07-04 12:38:24,845 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:24,846 - INFO - After Normalization***************************************
2025-07-04 12:38:24,846 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:25,152 - INFO - before .to(local_rank)***************************************
2025-07-04 12:38:25,152 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:38:25,152 - INFO - After .to(local_rank)***************************************
2025-07-04 12:38:25,152 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:25,152 - INFO - After Normalization***************************************
2025-07-04 12:38:25,153 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:25,441 - INFO - before .to(local_rank)***************************************
2025-07-04 12:38:25,441 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:38:25,441 - INFO - After .to(local_rank)***************************************
2025-07-04 12:38:25,441 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:25,441 - INFO - After Normalization***************************************
2025-07-04 12:38:25,441 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:28,634 - INFO - Epoch 140/150 - Train Loss: 0.292133, Val Loss: 0.298386
2025-07-04 12:38:31,000 - INFO - before .to(local_rank)***************************************
2025-07-04 12:38:31,014 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:38:31,014 - INFO - After .to(local_rank)***************************************
2025-07-04 12:38:31,014 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:31,014 - INFO - After Normalization***************************************
2025-07-04 12:38:31,014 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:31,327 - INFO - before .to(local_rank)***************************************
2025-07-04 12:38:31,327 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:38:31,327 - INFO - After .to(local_rank)***************************************
2025-07-04 12:38:31,327 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:31,328 - INFO - After Normalization***************************************
2025-07-04 12:38:31,328 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:31,616 - INFO - before .to(local_rank)***************************************
2025-07-04 12:38:31,616 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:38:31,616 - INFO - After .to(local_rank)***************************************
2025-07-04 12:38:31,616 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:31,616 - INFO - After Normalization***************************************
2025-07-04 12:38:31,616 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:34,813 - INFO - Epoch 141/150 - Train Loss: 0.291022, Val Loss: 0.298982
2025-07-04 12:38:37,058 - INFO - before .to(local_rank)***************************************
2025-07-04 12:38:37,071 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:38:37,071 - INFO - After .to(local_rank)***************************************
2025-07-04 12:38:37,071 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:37,071 - INFO - After Normalization***************************************
2025-07-04 12:38:37,071 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:37,381 - INFO - before .to(local_rank)***************************************
2025-07-04 12:38:37,381 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:38:37,381 - INFO - After .to(local_rank)***************************************
2025-07-04 12:38:37,381 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:37,381 - INFO - After Normalization***************************************
2025-07-04 12:38:37,381 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:37,669 - INFO - before .to(local_rank)***************************************
2025-07-04 12:38:37,670 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:38:37,670 - INFO - After .to(local_rank)***************************************
2025-07-04 12:38:37,670 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:37,670 - INFO - After Normalization***************************************
2025-07-04 12:38:37,670 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:40,866 - INFO - Epoch 142/150 - Train Loss: 0.289283, Val Loss: 0.298855
2025-07-04 12:38:43,133 - INFO - before .to(local_rank)***************************************
2025-07-04 12:38:43,147 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:38:43,147 - INFO - After .to(local_rank)***************************************
2025-07-04 12:38:43,147 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:43,147 - INFO - After Normalization***************************************
2025-07-04 12:38:43,147 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:43,452 - INFO - before .to(local_rank)***************************************
2025-07-04 12:38:43,452 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:38:43,453 - INFO - After .to(local_rank)***************************************
2025-07-04 12:38:43,453 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:43,453 - INFO - After Normalization***************************************
2025-07-04 12:38:43,453 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:43,741 - INFO - before .to(local_rank)***************************************
2025-07-04 12:38:43,741 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:38:43,742 - INFO - After .to(local_rank)***************************************
2025-07-04 12:38:43,742 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:43,742 - INFO - After Normalization***************************************
2025-07-04 12:38:43,742 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:46,953 - INFO - Epoch 143/150 - Train Loss: 0.289318, Val Loss: 0.298431
2025-07-04 12:38:49,225 - INFO - before .to(local_rank)***************************************
2025-07-04 12:38:49,239 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:38:49,239 - INFO - After .to(local_rank)***************************************
2025-07-04 12:38:49,240 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:49,240 - INFO - After Normalization***************************************
2025-07-04 12:38:49,240 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:49,544 - INFO - before .to(local_rank)***************************************
2025-07-04 12:38:49,544 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:38:49,544 - INFO - After .to(local_rank)***************************************
2025-07-04 12:38:49,544 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:49,544 - INFO - After Normalization***************************************
2025-07-04 12:38:49,544 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:49,832 - INFO - before .to(local_rank)***************************************
2025-07-04 12:38:49,833 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:38:49,833 - INFO - After .to(local_rank)***************************************
2025-07-04 12:38:49,833 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:49,833 - INFO - After Normalization***************************************
2025-07-04 12:38:49,833 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:53,021 - INFO - Epoch 144/150 - Train Loss: 0.293004, Val Loss: 0.299563
2025-07-04 12:38:55,270 - INFO - before .to(local_rank)***************************************
2025-07-04 12:38:55,284 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:38:55,284 - INFO - After .to(local_rank)***************************************
2025-07-04 12:38:55,284 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:55,285 - INFO - After Normalization***************************************
2025-07-04 12:38:55,285 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:55,604 - INFO - before .to(local_rank)***************************************
2025-07-04 12:38:55,604 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:38:55,604 - INFO - After .to(local_rank)***************************************
2025-07-04 12:38:55,604 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:55,604 - INFO - After Normalization***************************************
2025-07-04 12:38:55,604 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:55,893 - INFO - before .to(local_rank)***************************************
2025-07-04 12:38:55,893 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:38:55,893 - INFO - After .to(local_rank)***************************************
2025-07-04 12:38:55,893 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:55,893 - INFO - After Normalization***************************************
2025-07-04 12:38:55,893 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:38:59,093 - INFO - Epoch 145/150 - Train Loss: 0.290829, Val Loss: 0.298820
2025-07-04 12:39:01,345 - INFO - before .to(local_rank)***************************************
2025-07-04 12:39:01,358 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:39:01,359 - INFO - After .to(local_rank)***************************************
2025-07-04 12:39:01,359 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:39:01,359 - INFO - After Normalization***************************************
2025-07-04 12:39:01,359 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:39:01,672 - INFO - before .to(local_rank)***************************************
2025-07-04 12:39:01,672 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:39:01,672 - INFO - After .to(local_rank)***************************************
2025-07-04 12:39:01,672 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:39:01,672 - INFO - After Normalization***************************************
2025-07-04 12:39:01,672 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:39:01,965 - INFO - before .to(local_rank)***************************************
2025-07-04 12:39:01,965 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:39:01,965 - INFO - After .to(local_rank)***************************************
2025-07-04 12:39:01,965 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:39:01,965 - INFO - After Normalization***************************************
2025-07-04 12:39:01,965 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:39:05,175 - INFO - Epoch 146/150 - Train Loss: 0.293143, Val Loss: 0.299518
2025-07-04 12:39:07,428 - INFO - before .to(local_rank)***************************************
2025-07-04 12:39:07,442 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:39:07,442 - INFO - After .to(local_rank)***************************************
2025-07-04 12:39:07,442 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:39:07,442 - INFO - After Normalization***************************************
2025-07-04 12:39:07,442 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:39:07,750 - INFO - before .to(local_rank)***************************************
2025-07-04 12:39:07,750 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:39:07,750 - INFO - After .to(local_rank)***************************************
2025-07-04 12:39:07,750 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:39:07,750 - INFO - After Normalization***************************************
2025-07-04 12:39:07,750 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:39:08,043 - INFO - before .to(local_rank)***************************************
2025-07-04 12:39:08,043 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:39:08,044 - INFO - After .to(local_rank)***************************************
2025-07-04 12:39:08,044 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:39:08,044 - INFO - After Normalization***************************************
2025-07-04 12:39:08,044 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:39:11,287 - INFO - Epoch 147/150 - Train Loss: 0.291828, Val Loss: 0.298869
2025-07-04 12:39:13,717 - INFO - before .to(local_rank)***************************************
2025-07-04 12:39:13,731 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:39:13,731 - INFO - After .to(local_rank)***************************************
2025-07-04 12:39:13,731 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:39:13,732 - INFO - After Normalization***************************************
2025-07-04 12:39:13,732 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:39:14,037 - INFO - before .to(local_rank)***************************************
2025-07-04 12:39:14,037 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:39:14,038 - INFO - After .to(local_rank)***************************************
2025-07-04 12:39:14,038 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:39:14,038 - INFO - After Normalization***************************************
2025-07-04 12:39:14,038 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:39:14,326 - INFO - before .to(local_rank)***************************************
2025-07-04 12:39:14,326 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:39:14,326 - INFO - After .to(local_rank)***************************************
2025-07-04 12:39:14,327 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:39:14,327 - INFO - After Normalization***************************************
2025-07-04 12:39:14,327 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:39:17,522 - INFO - Epoch 148/150 - Train Loss: 0.290583, Val Loss: 0.299215
2025-07-04 12:39:19,765 - INFO - before .to(local_rank)***************************************
2025-07-04 12:39:19,779 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:39:19,779 - INFO - After .to(local_rank)***************************************
2025-07-04 12:39:19,779 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:39:19,779 - INFO - After Normalization***************************************
2025-07-04 12:39:19,779 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:39:20,084 - INFO - before .to(local_rank)***************************************
2025-07-04 12:39:20,084 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:39:20,084 - INFO - After .to(local_rank)***************************************
2025-07-04 12:39:20,084 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:39:20,084 - INFO - After Normalization***************************************
2025-07-04 12:39:20,084 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:39:20,373 - INFO - before .to(local_rank)***************************************
2025-07-04 12:39:20,373 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:39:20,373 - INFO - After .to(local_rank)***************************************
2025-07-04 12:39:20,373 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:39:20,373 - INFO - After Normalization***************************************
2025-07-04 12:39:20,373 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:39:23,581 - INFO - Epoch 149/150 - Train Loss: 0.288438, Val Loss: 0.298331
2025-07-04 12:39:25,834 - INFO - before .to(local_rank)***************************************
2025-07-04 12:39:25,847 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:39:25,847 - INFO - After .to(local_rank)***************************************
2025-07-04 12:39:25,847 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:39:25,847 - INFO - After Normalization***************************************
2025-07-04 12:39:25,847 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:39:26,168 - INFO - before .to(local_rank)***************************************
2025-07-04 12:39:26,168 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:39:26,168 - INFO - After .to(local_rank)***************************************
2025-07-04 12:39:26,168 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:39:26,168 - INFO - After Normalization***************************************
2025-07-04 12:39:26,168 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:39:26,457 - INFO - before .to(local_rank)***************************************
2025-07-04 12:39:26,457 - INFO - (device(type='cpu'), device(type='cpu'))
2025-07-04 12:39:26,457 - INFO - After .to(local_rank)***************************************
2025-07-04 12:39:26,457 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:39:26,457 - INFO - After Normalization***************************************
2025-07-04 12:39:26,457 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 12:39:29,644 - INFO - Epoch 150/150 - Train Loss: 0.290288, Val Loss: 0.298573
2025-07-04 12:39:29,786 - INFO - Final model saved to experiments/Train_Test/final_model_tmp
2025-07-04 12:39:29,796 - INFO - Testing the final model
2025-07-04 12:39:29,796 - INFO - Testing the best model
2025-07-04 13:51:26,087 - INFO - args.exp_name : Train_Test
2025-07-04 13:51:26,088 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=6, epochs=150, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-07-04 13:51:26,088 - INFO - Starting training with 1 GPUs
2025-07-04 13:51:29,943 - INFO - Total trainable parameters: 1437705
2025-07-04 13:51:29,986 - INFO - Data loaded: 3 training batches, 1 validation batches, 1 test batches
2025-07-04 13:51:29,989 - INFO - Staring training for 150 epochs
2025-07-04 13:51:33,818 - INFO - before .to(local_rank)***************************************
2025-07-04 13:51:33,821 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:51:33,822 - INFO - After .to(local_rank)***************************************
2025-07-04 13:51:33,822 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:51:33,832 - INFO - After Normalization***************************************
2025-07-04 13:51:33,832 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:51:34,318 - INFO - outputs: cuda:0
2025-07-04 13:51:34,595 - INFO - before .to(local_rank)***************************************
2025-07-04 13:51:34,595 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:51:34,595 - INFO - After .to(local_rank)***************************************
2025-07-04 13:51:34,595 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:51:34,596 - INFO - After Normalization***************************************
2025-07-04 13:51:34,596 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:51:34,602 - INFO - outputs: cuda:0
2025-07-04 13:51:34,885 - INFO - before .to(local_rank)***************************************
2025-07-04 13:51:34,885 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:51:34,885 - INFO - After .to(local_rank)***************************************
2025-07-04 13:51:34,885 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:51:34,885 - INFO - After Normalization***************************************
2025-07-04 13:51:34,885 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:51:34,890 - INFO - outputs: cuda:0
2025-07-04 13:51:38,291 - INFO - Epoch 1/150 - Train Loss: 1.283437, Val Loss: 1.146866
2025-07-04 13:51:38,313 - INFO - New best model saved with Val Loss: 1.146866
2025-07-04 13:51:40,594 - INFO - before .to(local_rank)***************************************
2025-07-04 13:51:40,607 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:51:40,608 - INFO - After .to(local_rank)***************************************
2025-07-04 13:51:40,608 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:51:40,608 - INFO - After Normalization***************************************
2025-07-04 13:51:40,608 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:51:40,613 - INFO - outputs: cuda:0
2025-07-04 13:51:40,918 - INFO - before .to(local_rank)***************************************
2025-07-04 13:51:40,918 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:51:40,918 - INFO - After .to(local_rank)***************************************
2025-07-04 13:51:40,918 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:51:40,918 - INFO - After Normalization***************************************
2025-07-04 13:51:40,918 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:51:40,923 - INFO - outputs: cuda:0
2025-07-04 13:51:41,207 - INFO - before .to(local_rank)***************************************
2025-07-04 13:51:41,207 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:51:41,207 - INFO - After .to(local_rank)***************************************
2025-07-04 13:51:41,207 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:51:41,207 - INFO - After Normalization***************************************
2025-07-04 13:51:41,207 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:51:41,212 - INFO - outputs: cuda:0
2025-07-04 13:51:44,431 - INFO - Epoch 2/150 - Train Loss: 1.159811, Val Loss: 1.148012
2025-07-04 13:51:46,693 - INFO - before .to(local_rank)***************************************
2025-07-04 13:51:46,707 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:51:46,708 - INFO - After .to(local_rank)***************************************
2025-07-04 13:51:46,708 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:51:46,708 - INFO - After Normalization***************************************
2025-07-04 13:51:46,708 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:51:46,713 - INFO - outputs: cuda:0
2025-07-04 13:51:47,010 - INFO - before .to(local_rank)***************************************
2025-07-04 13:51:47,010 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:51:47,011 - INFO - After .to(local_rank)***************************************
2025-07-04 13:51:47,011 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:51:47,011 - INFO - After Normalization***************************************
2025-07-04 13:51:47,011 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:51:47,016 - INFO - outputs: cuda:0
2025-07-04 13:51:47,300 - INFO - before .to(local_rank)***************************************
2025-07-04 13:51:47,300 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:51:47,300 - INFO - After .to(local_rank)***************************************
2025-07-04 13:51:47,300 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:51:47,300 - INFO - After Normalization***************************************
2025-07-04 13:51:47,300 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:51:47,305 - INFO - outputs: cuda:0
2025-07-04 13:51:50,527 - INFO - Epoch 3/150 - Train Loss: 1.015355, Val Loss: 1.148288
2025-07-04 13:51:52,793 - INFO - before .to(local_rank)***************************************
2025-07-04 13:51:52,808 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:51:52,809 - INFO - After .to(local_rank)***************************************
2025-07-04 13:51:52,809 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:51:52,809 - INFO - After Normalization***************************************
2025-07-04 13:51:52,809 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:51:52,814 - INFO - outputs: cuda:0
2025-07-04 13:51:53,126 - INFO - before .to(local_rank)***************************************
2025-07-04 13:51:53,126 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:51:53,126 - INFO - After .to(local_rank)***************************************
2025-07-04 13:51:53,126 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:51:53,127 - INFO - After Normalization***************************************
2025-07-04 13:51:53,127 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:51:53,131 - INFO - outputs: cuda:0
2025-07-04 13:51:53,415 - INFO - before .to(local_rank)***************************************
2025-07-04 13:51:53,415 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:51:53,415 - INFO - After .to(local_rank)***************************************
2025-07-04 13:51:53,415 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:51:53,416 - INFO - After Normalization***************************************
2025-07-04 13:51:53,416 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:51:53,420 - INFO - outputs: cuda:0
2025-07-04 13:51:56,643 - INFO - Epoch 4/150 - Train Loss: 0.916734, Val Loss: 1.249089
2025-07-04 13:51:58,904 - INFO - before .to(local_rank)***************************************
2025-07-04 13:51:58,918 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:51:58,918 - INFO - After .to(local_rank)***************************************
2025-07-04 13:51:58,918 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:51:58,919 - INFO - After Normalization***************************************
2025-07-04 13:51:58,919 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:51:58,923 - INFO - outputs: cuda:0
2025-07-04 13:51:59,226 - INFO - before .to(local_rank)***************************************
2025-07-04 13:51:59,226 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:51:59,227 - INFO - After .to(local_rank)***************************************
2025-07-04 13:51:59,227 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:51:59,227 - INFO - After Normalization***************************************
2025-07-04 13:51:59,227 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:51:59,231 - INFO - outputs: cuda:0
2025-07-04 13:51:59,515 - INFO - before .to(local_rank)***************************************
2025-07-04 13:51:59,515 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:51:59,516 - INFO - After .to(local_rank)***************************************
2025-07-04 13:51:59,516 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:51:59,516 - INFO - After Normalization***************************************
2025-07-04 13:51:59,516 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:51:59,520 - INFO - outputs: cuda:0
2025-07-04 13:52:02,719 - INFO - Epoch 5/150 - Train Loss: 0.839702, Val Loss: 1.442995
2025-07-04 13:52:04,972 - INFO - before .to(local_rank)***************************************
2025-07-04 13:52:04,986 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:52:04,986 - INFO - After .to(local_rank)***************************************
2025-07-04 13:52:04,987 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:04,987 - INFO - After Normalization***************************************
2025-07-04 13:52:04,987 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:04,992 - INFO - outputs: cuda:0
2025-07-04 13:52:05,291 - INFO - before .to(local_rank)***************************************
2025-07-04 13:52:05,291 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:52:05,292 - INFO - After .to(local_rank)***************************************
2025-07-04 13:52:05,292 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:05,292 - INFO - After Normalization***************************************
2025-07-04 13:52:05,292 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:05,296 - INFO - outputs: cuda:0
2025-07-04 13:52:05,585 - INFO - before .to(local_rank)***************************************
2025-07-04 13:52:05,585 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:52:05,585 - INFO - After .to(local_rank)***************************************
2025-07-04 13:52:05,585 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:05,585 - INFO - After Normalization***************************************
2025-07-04 13:52:05,586 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:05,590 - INFO - outputs: cuda:0
2025-07-04 13:52:08,791 - INFO - Epoch 6/150 - Train Loss: 0.757819, Val Loss: 1.361055
2025-07-04 13:52:11,056 - INFO - before .to(local_rank)***************************************
2025-07-04 13:52:11,069 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:52:11,070 - INFO - After .to(local_rank)***************************************
2025-07-04 13:52:11,070 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:11,070 - INFO - After Normalization***************************************
2025-07-04 13:52:11,070 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:11,075 - INFO - outputs: cuda:0
2025-07-04 13:52:11,380 - INFO - before .to(local_rank)***************************************
2025-07-04 13:52:11,380 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:52:11,380 - INFO - After .to(local_rank)***************************************
2025-07-04 13:52:11,380 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:11,380 - INFO - After Normalization***************************************
2025-07-04 13:52:11,380 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:11,385 - INFO - outputs: cuda:0
2025-07-04 13:52:11,672 - INFO - before .to(local_rank)***************************************
2025-07-04 13:52:11,673 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:52:11,673 - INFO - After .to(local_rank)***************************************
2025-07-04 13:52:11,673 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:11,673 - INFO - After Normalization***************************************
2025-07-04 13:52:11,673 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:11,678 - INFO - outputs: cuda:0
2025-07-04 13:52:14,878 - INFO - Epoch 7/150 - Train Loss: 0.661384, Val Loss: 1.379884
2025-07-04 13:52:17,135 - INFO - before .to(local_rank)***************************************
2025-07-04 13:52:17,149 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:52:17,149 - INFO - After .to(local_rank)***************************************
2025-07-04 13:52:17,149 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:17,149 - INFO - After Normalization***************************************
2025-07-04 13:52:17,150 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:17,155 - INFO - outputs: cuda:0
2025-07-04 13:52:17,465 - INFO - before .to(local_rank)***************************************
2025-07-04 13:52:17,466 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:52:17,466 - INFO - After .to(local_rank)***************************************
2025-07-04 13:52:17,466 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:17,466 - INFO - After Normalization***************************************
2025-07-04 13:52:17,466 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:17,471 - INFO - outputs: cuda:0
2025-07-04 13:52:17,759 - INFO - before .to(local_rank)***************************************
2025-07-04 13:52:17,759 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:52:17,760 - INFO - After .to(local_rank)***************************************
2025-07-04 13:52:17,760 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:17,760 - INFO - After Normalization***************************************
2025-07-04 13:52:17,760 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:17,764 - INFO - outputs: cuda:0
2025-07-04 13:52:20,955 - INFO - Epoch 8/150 - Train Loss: 0.608690, Val Loss: 1.595568
2025-07-04 13:52:23,206 - INFO - before .to(local_rank)***************************************
2025-07-04 13:52:23,219 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:52:23,220 - INFO - After .to(local_rank)***************************************
2025-07-04 13:52:23,220 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:23,220 - INFO - After Normalization***************************************
2025-07-04 13:52:23,220 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:23,225 - INFO - outputs: cuda:0
2025-07-04 13:52:23,529 - INFO - before .to(local_rank)***************************************
2025-07-04 13:52:23,529 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:52:23,529 - INFO - After .to(local_rank)***************************************
2025-07-04 13:52:23,529 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:23,529 - INFO - After Normalization***************************************
2025-07-04 13:52:23,529 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:23,534 - INFO - outputs: cuda:0
2025-07-04 13:52:23,822 - INFO - before .to(local_rank)***************************************
2025-07-04 13:52:23,822 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:52:23,822 - INFO - After .to(local_rank)***************************************
2025-07-04 13:52:23,822 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:23,822 - INFO - After Normalization***************************************
2025-07-04 13:52:23,823 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:23,827 - INFO - outputs: cuda:0
2025-07-04 13:52:27,044 - INFO - Epoch 9/150 - Train Loss: 0.560139, Val Loss: 1.838627
2025-07-04 13:52:29,299 - INFO - before .to(local_rank)***************************************
2025-07-04 13:52:29,313 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:52:29,314 - INFO - After .to(local_rank)***************************************
2025-07-04 13:52:29,314 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:29,314 - INFO - After Normalization***************************************
2025-07-04 13:52:29,314 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:29,319 - INFO - outputs: cuda:0
2025-07-04 13:52:29,617 - INFO - before .to(local_rank)***************************************
2025-07-04 13:52:29,617 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:52:29,617 - INFO - After .to(local_rank)***************************************
2025-07-04 13:52:29,617 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:29,617 - INFO - After Normalization***************************************
2025-07-04 13:52:29,617 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:29,622 - INFO - outputs: cuda:0
2025-07-04 13:52:29,910 - INFO - before .to(local_rank)***************************************
2025-07-04 13:52:29,910 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:52:29,911 - INFO - After .to(local_rank)***************************************
2025-07-04 13:52:29,911 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:29,911 - INFO - After Normalization***************************************
2025-07-04 13:52:29,911 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:29,915 - INFO - outputs: cuda:0
2025-07-04 13:52:33,108 - INFO - Epoch 10/150 - Train Loss: 0.526667, Val Loss: 1.521763
2025-07-04 13:52:35,522 - INFO - before .to(local_rank)***************************************
2025-07-04 13:52:35,536 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:52:35,536 - INFO - After .to(local_rank)***************************************
2025-07-04 13:52:35,536 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:35,536 - INFO - After Normalization***************************************
2025-07-04 13:52:35,536 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:35,541 - INFO - outputs: cuda:0
2025-07-04 13:52:35,843 - INFO - before .to(local_rank)***************************************
2025-07-04 13:52:35,843 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:52:35,844 - INFO - After .to(local_rank)***************************************
2025-07-04 13:52:35,844 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:35,844 - INFO - After Normalization***************************************
2025-07-04 13:52:35,844 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:35,849 - INFO - outputs: cuda:0
2025-07-04 13:52:36,132 - INFO - before .to(local_rank)***************************************
2025-07-04 13:52:36,132 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:52:36,133 - INFO - After .to(local_rank)***************************************
2025-07-04 13:52:36,133 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:36,133 - INFO - After Normalization***************************************
2025-07-04 13:52:36,133 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:36,137 - INFO - outputs: cuda:0
2025-07-04 13:52:39,321 - INFO - Epoch 11/150 - Train Loss: 0.494009, Val Loss: 1.437564
2025-07-04 13:52:41,588 - INFO - before .to(local_rank)***************************************
2025-07-04 13:52:41,602 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:52:41,603 - INFO - After .to(local_rank)***************************************
2025-07-04 13:52:41,603 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:41,603 - INFO - After Normalization***************************************
2025-07-04 13:52:41,603 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:41,608 - INFO - outputs: cuda:0
2025-07-04 13:52:41,907 - INFO - before .to(local_rank)***************************************
2025-07-04 13:52:41,907 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:52:41,908 - INFO - After .to(local_rank)***************************************
2025-07-04 13:52:41,908 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:41,909 - INFO - After Normalization***************************************
2025-07-04 13:52:41,909 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:41,913 - INFO - outputs: cuda:0
2025-07-04 13:52:42,197 - INFO - before .to(local_rank)***************************************
2025-07-04 13:52:42,197 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:52:42,197 - INFO - After .to(local_rank)***************************************
2025-07-04 13:52:42,197 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:42,198 - INFO - After Normalization***************************************
2025-07-04 13:52:42,198 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:42,202 - INFO - outputs: cuda:0
2025-07-04 13:52:45,408 - INFO - Epoch 12/150 - Train Loss: 0.474216, Val Loss: 1.348367
2025-07-04 13:52:47,682 - INFO - before .to(local_rank)***************************************
2025-07-04 13:52:47,696 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:52:47,697 - INFO - After .to(local_rank)***************************************
2025-07-04 13:52:47,697 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:47,697 - INFO - After Normalization***************************************
2025-07-04 13:52:47,697 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:47,702 - INFO - outputs: cuda:0
2025-07-04 13:52:48,016 - INFO - before .to(local_rank)***************************************
2025-07-04 13:52:48,016 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:52:48,016 - INFO - After .to(local_rank)***************************************
2025-07-04 13:52:48,016 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:48,016 - INFO - After Normalization***************************************
2025-07-04 13:52:48,016 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:48,021 - INFO - outputs: cuda:0
2025-07-04 13:52:48,305 - INFO - before .to(local_rank)***************************************
2025-07-04 13:52:48,305 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:52:48,305 - INFO - After .to(local_rank)***************************************
2025-07-04 13:52:48,305 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:48,305 - INFO - After Normalization***************************************
2025-07-04 13:52:48,305 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:48,310 - INFO - outputs: cuda:0
2025-07-04 13:52:51,525 - INFO - Epoch 13/150 - Train Loss: 0.457834, Val Loss: 1.089559
2025-07-04 13:52:51,541 - INFO - New best model saved with Val Loss: 1.089559
2025-07-04 13:52:53,785 - INFO - before .to(local_rank)***************************************
2025-07-04 13:52:53,799 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:52:53,799 - INFO - After .to(local_rank)***************************************
2025-07-04 13:52:53,799 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:53,799 - INFO - After Normalization***************************************
2025-07-04 13:52:53,800 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:53,804 - INFO - outputs: cuda:0
2025-07-04 13:52:54,110 - INFO - before .to(local_rank)***************************************
2025-07-04 13:52:54,111 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:52:54,112 - INFO - After .to(local_rank)***************************************
2025-07-04 13:52:54,112 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:54,112 - INFO - After Normalization***************************************
2025-07-04 13:52:54,112 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:54,117 - INFO - outputs: cuda:0
2025-07-04 13:52:54,400 - INFO - before .to(local_rank)***************************************
2025-07-04 13:52:54,400 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:52:54,401 - INFO - After .to(local_rank)***************************************
2025-07-04 13:52:54,401 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:54,401 - INFO - After Normalization***************************************
2025-07-04 13:52:54,401 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:54,405 - INFO - outputs: cuda:0
2025-07-04 13:52:57,608 - INFO - Epoch 14/150 - Train Loss: 0.455360, Val Loss: 0.832426
2025-07-04 13:52:57,625 - INFO - New best model saved with Val Loss: 0.832426
2025-07-04 13:52:59,886 - INFO - before .to(local_rank)***************************************
2025-07-04 13:52:59,900 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:52:59,900 - INFO - After .to(local_rank)***************************************
2025-07-04 13:52:59,901 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:59,901 - INFO - After Normalization***************************************
2025-07-04 13:52:59,901 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:52:59,905 - INFO - outputs: cuda:0
2025-07-04 13:53:00,202 - INFO - before .to(local_rank)***************************************
2025-07-04 13:53:00,202 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:53:00,203 - INFO - After .to(local_rank)***************************************
2025-07-04 13:53:00,203 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:00,203 - INFO - After Normalization***************************************
2025-07-04 13:53:00,203 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:00,208 - INFO - outputs: cuda:0
2025-07-04 13:53:00,492 - INFO - before .to(local_rank)***************************************
2025-07-04 13:53:00,492 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:53:00,492 - INFO - After .to(local_rank)***************************************
2025-07-04 13:53:00,492 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:00,492 - INFO - After Normalization***************************************
2025-07-04 13:53:00,492 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:00,497 - INFO - outputs: cuda:0
2025-07-04 13:53:03,703 - INFO - Epoch 15/150 - Train Loss: 0.447783, Val Loss: 0.654857
2025-07-04 13:53:03,717 - INFO - New best model saved with Val Loss: 0.654857
2025-07-04 13:53:05,989 - INFO - before .to(local_rank)***************************************
2025-07-04 13:53:06,003 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:53:06,003 - INFO - After .to(local_rank)***************************************
2025-07-04 13:53:06,003 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:06,003 - INFO - After Normalization***************************************
2025-07-04 13:53:06,003 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:06,008 - INFO - outputs: cuda:0
2025-07-04 13:53:06,315 - INFO - before .to(local_rank)***************************************
2025-07-04 13:53:06,316 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:53:06,317 - INFO - After .to(local_rank)***************************************
2025-07-04 13:53:06,317 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:06,317 - INFO - After Normalization***************************************
2025-07-04 13:53:06,317 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:06,322 - INFO - outputs: cuda:0
2025-07-04 13:53:06,606 - INFO - before .to(local_rank)***************************************
2025-07-04 13:53:06,606 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:53:06,606 - INFO - After .to(local_rank)***************************************
2025-07-04 13:53:06,606 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:06,606 - INFO - After Normalization***************************************
2025-07-04 13:53:06,606 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:06,611 - INFO - outputs: cuda:0
2025-07-04 13:53:09,810 - INFO - Epoch 16/150 - Train Loss: 0.446389, Val Loss: 0.548675
2025-07-04 13:53:09,825 - INFO - New best model saved with Val Loss: 0.548675
2025-07-04 13:53:12,089 - INFO - before .to(local_rank)***************************************
2025-07-04 13:53:12,104 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:53:12,104 - INFO - After .to(local_rank)***************************************
2025-07-04 13:53:12,104 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:12,104 - INFO - After Normalization***************************************
2025-07-04 13:53:12,104 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:12,109 - INFO - outputs: cuda:0
2025-07-04 13:53:12,409 - INFO - before .to(local_rank)***************************************
2025-07-04 13:53:12,409 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:53:12,409 - INFO - After .to(local_rank)***************************************
2025-07-04 13:53:12,409 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:12,409 - INFO - After Normalization***************************************
2025-07-04 13:53:12,409 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:12,414 - INFO - outputs: cuda:0
2025-07-04 13:53:12,698 - INFO - before .to(local_rank)***************************************
2025-07-04 13:53:12,698 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:53:12,698 - INFO - After .to(local_rank)***************************************
2025-07-04 13:53:12,699 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:12,699 - INFO - After Normalization***************************************
2025-07-04 13:53:12,699 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:12,703 - INFO - outputs: cuda:0
2025-07-04 13:53:15,896 - INFO - Epoch 17/150 - Train Loss: 0.440610, Val Loss: 0.495317
2025-07-04 13:53:15,911 - INFO - New best model saved with Val Loss: 0.495317
2025-07-04 13:53:18,184 - INFO - before .to(local_rank)***************************************
2025-07-04 13:53:18,197 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:53:18,198 - INFO - After .to(local_rank)***************************************
2025-07-04 13:53:18,198 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:18,198 - INFO - After Normalization***************************************
2025-07-04 13:53:18,198 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:18,203 - INFO - outputs: cuda:0
2025-07-04 13:53:18,511 - INFO - before .to(local_rank)***************************************
2025-07-04 13:53:18,511 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:53:18,512 - INFO - After .to(local_rank)***************************************
2025-07-04 13:53:18,512 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:18,512 - INFO - After Normalization***************************************
2025-07-04 13:53:18,512 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:18,517 - INFO - outputs: cuda:0
2025-07-04 13:53:18,801 - INFO - before .to(local_rank)***************************************
2025-07-04 13:53:18,801 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:53:18,801 - INFO - After .to(local_rank)***************************************
2025-07-04 13:53:18,802 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:18,802 - INFO - After Normalization***************************************
2025-07-04 13:53:18,802 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:18,806 - INFO - outputs: cuda:0
2025-07-04 13:53:22,030 - INFO - Epoch 18/150 - Train Loss: 0.438833, Val Loss: 0.464275
2025-07-04 13:53:22,045 - INFO - New best model saved with Val Loss: 0.464275
2025-07-04 13:53:24,302 - INFO - before .to(local_rank)***************************************
2025-07-04 13:53:24,316 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:53:24,317 - INFO - After .to(local_rank)***************************************
2025-07-04 13:53:24,317 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:24,317 - INFO - After Normalization***************************************
2025-07-04 13:53:24,317 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:24,322 - INFO - outputs: cuda:0
2025-07-04 13:53:24,625 - INFO - before .to(local_rank)***************************************
2025-07-04 13:53:24,625 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:53:24,625 - INFO - After .to(local_rank)***************************************
2025-07-04 13:53:24,625 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:24,625 - INFO - After Normalization***************************************
2025-07-04 13:53:24,625 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:24,630 - INFO - outputs: cuda:0
2025-07-04 13:53:24,914 - INFO - before .to(local_rank)***************************************
2025-07-04 13:53:24,914 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:53:24,914 - INFO - After .to(local_rank)***************************************
2025-07-04 13:53:24,914 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:24,914 - INFO - After Normalization***************************************
2025-07-04 13:53:24,914 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:24,919 - INFO - outputs: cuda:0
2025-07-04 13:53:28,130 - INFO - Epoch 19/150 - Train Loss: 0.439969, Val Loss: 0.443737
2025-07-04 13:53:28,146 - INFO - New best model saved with Val Loss: 0.443737
2025-07-04 13:53:30,419 - INFO - before .to(local_rank)***************************************
2025-07-04 13:53:30,433 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:53:30,433 - INFO - After .to(local_rank)***************************************
2025-07-04 13:53:30,433 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:30,434 - INFO - After Normalization***************************************
2025-07-04 13:53:30,434 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:30,438 - INFO - outputs: cuda:0
2025-07-04 13:53:30,733 - INFO - before .to(local_rank)***************************************
2025-07-04 13:53:30,733 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:53:30,734 - INFO - After .to(local_rank)***************************************
2025-07-04 13:53:30,734 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:30,734 - INFO - After Normalization***************************************
2025-07-04 13:53:30,734 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:30,739 - INFO - outputs: cuda:0
2025-07-04 13:53:31,023 - INFO - before .to(local_rank)***************************************
2025-07-04 13:53:31,023 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:53:31,023 - INFO - After .to(local_rank)***************************************
2025-07-04 13:53:31,023 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:31,024 - INFO - After Normalization***************************************
2025-07-04 13:53:31,024 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:31,028 - INFO - outputs: cuda:0
2025-07-04 13:53:34,240 - INFO - Epoch 20/150 - Train Loss: 0.431883, Val Loss: 0.428062
2025-07-04 13:53:34,258 - INFO - New best model saved with Val Loss: 0.428062
2025-07-04 13:53:36,639 - INFO - before .to(local_rank)***************************************
2025-07-04 13:53:36,653 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:53:36,653 - INFO - After .to(local_rank)***************************************
2025-07-04 13:53:36,653 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:36,653 - INFO - After Normalization***************************************
2025-07-04 13:53:36,653 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:36,658 - INFO - outputs: cuda:0
2025-07-04 13:53:36,954 - INFO - before .to(local_rank)***************************************
2025-07-04 13:53:36,954 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:53:36,954 - INFO - After .to(local_rank)***************************************
2025-07-04 13:53:36,954 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:36,954 - INFO - After Normalization***************************************
2025-07-04 13:53:36,954 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:36,959 - INFO - outputs: cuda:0
2025-07-04 13:53:37,247 - INFO - before .to(local_rank)***************************************
2025-07-04 13:53:37,247 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:53:37,247 - INFO - After .to(local_rank)***************************************
2025-07-04 13:53:37,247 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:37,248 - INFO - After Normalization***************************************
2025-07-04 13:53:37,248 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:37,252 - INFO - outputs: cuda:0
2025-07-04 13:53:40,434 - INFO - Epoch 21/150 - Train Loss: 0.431155, Val Loss: 0.423547
2025-07-04 13:53:40,449 - INFO - New best model saved with Val Loss: 0.423547
2025-07-04 13:53:42,721 - INFO - before .to(local_rank)***************************************
2025-07-04 13:53:42,734 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:53:42,735 - INFO - After .to(local_rank)***************************************
2025-07-04 13:53:42,735 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:42,735 - INFO - After Normalization***************************************
2025-07-04 13:53:42,735 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:42,740 - INFO - outputs: cuda:0
2025-07-04 13:53:43,051 - INFO - before .to(local_rank)***************************************
2025-07-04 13:53:43,051 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:53:43,052 - INFO - After .to(local_rank)***************************************
2025-07-04 13:53:43,052 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:43,052 - INFO - After Normalization***************************************
2025-07-04 13:53:43,052 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:43,057 - INFO - outputs: cuda:0
2025-07-04 13:53:43,344 - INFO - before .to(local_rank)***************************************
2025-07-04 13:53:43,344 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:53:43,345 - INFO - After .to(local_rank)***************************************
2025-07-04 13:53:43,345 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:43,345 - INFO - After Normalization***************************************
2025-07-04 13:53:43,345 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:43,349 - INFO - outputs: cuda:0
2025-07-04 13:53:46,536 - INFO - Epoch 22/150 - Train Loss: 0.428144, Val Loss: 0.426146
2025-07-04 13:53:48,810 - INFO - before .to(local_rank)***************************************
2025-07-04 13:53:48,824 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:53:48,824 - INFO - After .to(local_rank)***************************************
2025-07-04 13:53:48,824 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:48,824 - INFO - After Normalization***************************************
2025-07-04 13:53:48,825 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:48,829 - INFO - outputs: cuda:0
2025-07-04 13:53:49,133 - INFO - before .to(local_rank)***************************************
2025-07-04 13:53:49,133 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:53:49,133 - INFO - After .to(local_rank)***************************************
2025-07-04 13:53:49,133 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:49,133 - INFO - After Normalization***************************************
2025-07-04 13:53:49,133 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:49,138 - INFO - outputs: cuda:0
2025-07-04 13:53:49,426 - INFO - before .to(local_rank)***************************************
2025-07-04 13:53:49,427 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:53:49,427 - INFO - After .to(local_rank)***************************************
2025-07-04 13:53:49,427 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:49,427 - INFO - After Normalization***************************************
2025-07-04 13:53:49,427 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:49,432 - INFO - outputs: cuda:0
2025-07-04 13:53:52,637 - INFO - Epoch 23/150 - Train Loss: 0.425435, Val Loss: 0.427524
2025-07-04 13:53:54,898 - INFO - before .to(local_rank)***************************************
2025-07-04 13:53:54,912 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:53:54,913 - INFO - After .to(local_rank)***************************************
2025-07-04 13:53:54,913 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:54,913 - INFO - After Normalization***************************************
2025-07-04 13:53:54,913 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:54,918 - INFO - outputs: cuda:0
2025-07-04 13:53:55,215 - INFO - before .to(local_rank)***************************************
2025-07-04 13:53:55,216 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:53:55,216 - INFO - After .to(local_rank)***************************************
2025-07-04 13:53:55,216 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:55,217 - INFO - After Normalization***************************************
2025-07-04 13:53:55,217 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:55,222 - INFO - outputs: cuda:0
2025-07-04 13:53:55,510 - INFO - before .to(local_rank)***************************************
2025-07-04 13:53:55,510 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:53:55,510 - INFO - After .to(local_rank)***************************************
2025-07-04 13:53:55,511 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:55,511 - INFO - After Normalization***************************************
2025-07-04 13:53:55,511 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:53:55,515 - INFO - outputs: cuda:0
2025-07-04 13:53:58,710 - INFO - Epoch 24/150 - Train Loss: 0.422210, Val Loss: 0.422279
2025-07-04 13:53:58,724 - INFO - New best model saved with Val Loss: 0.422279
2025-07-04 13:54:00,958 - INFO - before .to(local_rank)***************************************
2025-07-04 13:54:00,972 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:54:00,972 - INFO - After .to(local_rank)***************************************
2025-07-04 13:54:00,972 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:00,972 - INFO - After Normalization***************************************
2025-07-04 13:54:00,972 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:00,977 - INFO - outputs: cuda:0
2025-07-04 13:54:01,273 - INFO - before .to(local_rank)***************************************
2025-07-04 13:54:01,273 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:54:01,273 - INFO - After .to(local_rank)***************************************
2025-07-04 13:54:01,285 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:01,296 - INFO - After Normalization***************************************
2025-07-04 13:54:01,307 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:01,322 - INFO - outputs: cuda:0
2025-07-04 13:54:01,610 - INFO - before .to(local_rank)***************************************
2025-07-04 13:54:01,610 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:54:01,610 - INFO - After .to(local_rank)***************************************
2025-07-04 13:54:01,610 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:01,610 - INFO - After Normalization***************************************
2025-07-04 13:54:01,610 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:01,615 - INFO - outputs: cuda:0
2025-07-04 13:54:04,815 - INFO - Epoch 25/150 - Train Loss: 0.423424, Val Loss: 0.427988
2025-07-04 13:54:07,071 - INFO - before .to(local_rank)***************************************
2025-07-04 13:54:07,084 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:54:07,085 - INFO - After .to(local_rank)***************************************
2025-07-04 13:54:07,085 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:07,085 - INFO - After Normalization***************************************
2025-07-04 13:54:07,085 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:07,090 - INFO - outputs: cuda:0
2025-07-04 13:54:07,398 - INFO - before .to(local_rank)***************************************
2025-07-04 13:54:07,398 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:54:07,399 - INFO - After .to(local_rank)***************************************
2025-07-04 13:54:07,399 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:07,399 - INFO - After Normalization***************************************
2025-07-04 13:54:07,400 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:07,404 - INFO - outputs: cuda:0
2025-07-04 13:54:07,688 - INFO - before .to(local_rank)***************************************
2025-07-04 13:54:07,688 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:54:07,688 - INFO - After .to(local_rank)***************************************
2025-07-04 13:54:07,688 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:07,689 - INFO - After Normalization***************************************
2025-07-04 13:54:07,689 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:07,693 - INFO - outputs: cuda:0
2025-07-04 13:54:10,897 - INFO - Epoch 26/150 - Train Loss: 0.416589, Val Loss: 0.438708
2025-07-04 13:54:13,166 - INFO - before .to(local_rank)***************************************
2025-07-04 13:54:13,179 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:54:13,180 - INFO - After .to(local_rank)***************************************
2025-07-04 13:54:13,180 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:13,180 - INFO - After Normalization***************************************
2025-07-04 13:54:13,180 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:13,185 - INFO - outputs: cuda:0
2025-07-04 13:54:13,488 - INFO - before .to(local_rank)***************************************
2025-07-04 13:54:13,488 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:54:13,488 - INFO - After .to(local_rank)***************************************
2025-07-04 13:54:13,488 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:13,488 - INFO - After Normalization***************************************
2025-07-04 13:54:13,489 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:13,493 - INFO - outputs: cuda:0
2025-07-04 13:54:13,777 - INFO - before .to(local_rank)***************************************
2025-07-04 13:54:13,777 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:54:13,777 - INFO - After .to(local_rank)***************************************
2025-07-04 13:54:13,777 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:13,778 - INFO - After Normalization***************************************
2025-07-04 13:54:13,778 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:13,782 - INFO - outputs: cuda:0
2025-07-04 13:54:16,995 - INFO - Epoch 27/150 - Train Loss: 0.415543, Val Loss: 0.429039
2025-07-04 13:54:19,253 - INFO - before .to(local_rank)***************************************
2025-07-04 13:54:19,266 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:54:19,266 - INFO - After .to(local_rank)***************************************
2025-07-04 13:54:19,266 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:19,267 - INFO - After Normalization***************************************
2025-07-04 13:54:19,267 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:19,271 - INFO - outputs: cuda:0
2025-07-04 13:54:19,585 - INFO - before .to(local_rank)***************************************
2025-07-04 13:54:19,585 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:54:19,586 - INFO - After .to(local_rank)***************************************
2025-07-04 13:54:19,586 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:19,586 - INFO - After Normalization***************************************
2025-07-04 13:54:19,586 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:19,591 - INFO - outputs: cuda:0
2025-07-04 13:54:19,875 - INFO - before .to(local_rank)***************************************
2025-07-04 13:54:19,875 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:54:19,875 - INFO - After .to(local_rank)***************************************
2025-07-04 13:54:19,876 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:19,876 - INFO - After Normalization***************************************
2025-07-04 13:54:19,876 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:19,880 - INFO - outputs: cuda:0
2025-07-04 13:54:23,067 - INFO - Epoch 28/150 - Train Loss: 0.413719, Val Loss: 0.420002
2025-07-04 13:54:23,085 - INFO - New best model saved with Val Loss: 0.420002
2025-07-04 13:54:25,337 - INFO - before .to(local_rank)***************************************
2025-07-04 13:54:25,350 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:54:25,351 - INFO - After .to(local_rank)***************************************
2025-07-04 13:54:25,351 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:25,351 - INFO - After Normalization***************************************
2025-07-04 13:54:25,351 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:25,356 - INFO - outputs: cuda:0
2025-07-04 13:54:25,668 - INFO - before .to(local_rank)***************************************
2025-07-04 13:54:25,668 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:54:25,668 - INFO - After .to(local_rank)***************************************
2025-07-04 13:54:25,668 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:25,668 - INFO - After Normalization***************************************
2025-07-04 13:54:25,668 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:25,673 - INFO - outputs: cuda:0
2025-07-04 13:54:25,957 - INFO - before .to(local_rank)***************************************
2025-07-04 13:54:25,957 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:54:25,957 - INFO - After .to(local_rank)***************************************
2025-07-04 13:54:25,957 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:25,957 - INFO - After Normalization***************************************
2025-07-04 13:54:25,957 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:25,962 - INFO - outputs: cuda:0
2025-07-04 13:54:29,178 - INFO - Epoch 29/150 - Train Loss: 0.410406, Val Loss: 0.413966
2025-07-04 13:54:29,193 - INFO - New best model saved with Val Loss: 0.413966
2025-07-04 13:54:31,433 - INFO - before .to(local_rank)***************************************
2025-07-04 13:54:31,446 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:54:31,447 - INFO - After .to(local_rank)***************************************
2025-07-04 13:54:31,447 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:31,447 - INFO - After Normalization***************************************
2025-07-04 13:54:31,447 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:31,452 - INFO - outputs: cuda:0
2025-07-04 13:54:31,756 - INFO - before .to(local_rank)***************************************
2025-07-04 13:54:31,756 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:54:31,757 - INFO - After .to(local_rank)***************************************
2025-07-04 13:54:31,757 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:31,757 - INFO - After Normalization***************************************
2025-07-04 13:54:31,757 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:31,762 - INFO - outputs: cuda:0
2025-07-04 13:54:32,046 - INFO - before .to(local_rank)***************************************
2025-07-04 13:54:32,046 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:54:32,046 - INFO - After .to(local_rank)***************************************
2025-07-04 13:54:32,046 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:32,046 - INFO - After Normalization***************************************
2025-07-04 13:54:32,047 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:32,051 - INFO - outputs: cuda:0
2025-07-04 13:54:35,254 - INFO - Epoch 30/150 - Train Loss: 0.409573, Val Loss: 0.411146
2025-07-04 13:54:35,269 - INFO - New best model saved with Val Loss: 0.411146
2025-07-04 13:54:37,646 - INFO - before .to(local_rank)***************************************
2025-07-04 13:54:37,659 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:54:37,660 - INFO - After .to(local_rank)***************************************
2025-07-04 13:54:37,660 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:37,660 - INFO - After Normalization***************************************
2025-07-04 13:54:37,660 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:37,665 - INFO - outputs: cuda:0
2025-07-04 13:54:37,968 - INFO - before .to(local_rank)***************************************
2025-07-04 13:54:37,968 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:54:37,968 - INFO - After .to(local_rank)***************************************
2025-07-04 13:54:37,968 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:37,968 - INFO - After Normalization***************************************
2025-07-04 13:54:37,969 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:37,973 - INFO - outputs: cuda:0
2025-07-04 13:54:38,257 - INFO - before .to(local_rank)***************************************
2025-07-04 13:54:38,257 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:54:38,257 - INFO - After .to(local_rank)***************************************
2025-07-04 13:54:38,258 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:38,258 - INFO - After Normalization***************************************
2025-07-04 13:54:38,258 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:38,262 - INFO - outputs: cuda:0
2025-07-04 13:54:41,473 - INFO - Epoch 31/150 - Train Loss: 0.407763, Val Loss: 0.405612
2025-07-04 13:54:41,488 - INFO - New best model saved with Val Loss: 0.405612
2025-07-04 13:54:43,744 - INFO - before .to(local_rank)***************************************
2025-07-04 13:54:43,758 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:54:43,758 - INFO - After .to(local_rank)***************************************
2025-07-04 13:54:43,758 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:43,759 - INFO - After Normalization***************************************
2025-07-04 13:54:43,759 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:43,763 - INFO - outputs: cuda:0
2025-07-04 13:54:44,059 - INFO - before .to(local_rank)***************************************
2025-07-04 13:54:44,059 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:54:44,059 - INFO - After .to(local_rank)***************************************
2025-07-04 13:54:44,060 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:44,060 - INFO - After Normalization***************************************
2025-07-04 13:54:44,060 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:44,065 - INFO - outputs: cuda:0
2025-07-04 13:54:44,349 - INFO - before .to(local_rank)***************************************
2025-07-04 13:54:44,349 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:54:44,349 - INFO - After .to(local_rank)***************************************
2025-07-04 13:54:44,349 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:44,349 - INFO - After Normalization***************************************
2025-07-04 13:54:44,350 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:44,354 - INFO - outputs: cuda:0
2025-07-04 13:54:47,553 - INFO - Epoch 32/150 - Train Loss: 0.407623, Val Loss: 0.406176
2025-07-04 13:54:49,818 - INFO - before .to(local_rank)***************************************
2025-07-04 13:54:49,831 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:54:49,831 - INFO - After .to(local_rank)***************************************
2025-07-04 13:54:49,831 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:49,831 - INFO - After Normalization***************************************
2025-07-04 13:54:49,831 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:49,836 - INFO - outputs: cuda:0
2025-07-04 13:54:50,148 - INFO - before .to(local_rank)***************************************
2025-07-04 13:54:50,149 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:54:50,149 - INFO - After .to(local_rank)***************************************
2025-07-04 13:54:50,149 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:50,149 - INFO - After Normalization***************************************
2025-07-04 13:54:50,149 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:50,154 - INFO - outputs: cuda:0
2025-07-04 13:54:50,437 - INFO - before .to(local_rank)***************************************
2025-07-04 13:54:50,438 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:54:50,438 - INFO - After .to(local_rank)***************************************
2025-07-04 13:54:50,438 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:50,438 - INFO - After Normalization***************************************
2025-07-04 13:54:50,438 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:50,443 - INFO - outputs: cuda:0
2025-07-04 13:54:53,636 - INFO - Epoch 33/150 - Train Loss: 0.403604, Val Loss: 0.407962
2025-07-04 13:54:55,892 - INFO - before .to(local_rank)***************************************
2025-07-04 13:54:55,906 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:54:55,906 - INFO - After .to(local_rank)***************************************
2025-07-04 13:54:55,906 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:55,907 - INFO - After Normalization***************************************
2025-07-04 13:54:55,907 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:55,911 - INFO - outputs: cuda:0
2025-07-04 13:54:56,217 - INFO - before .to(local_rank)***************************************
2025-07-04 13:54:56,217 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:54:56,217 - INFO - After .to(local_rank)***************************************
2025-07-04 13:54:56,218 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:56,218 - INFO - After Normalization***************************************
2025-07-04 13:54:56,218 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:56,222 - INFO - outputs: cuda:0
2025-07-04 13:54:56,506 - INFO - before .to(local_rank)***************************************
2025-07-04 13:54:56,507 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:54:56,507 - INFO - After .to(local_rank)***************************************
2025-07-04 13:54:56,507 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:56,507 - INFO - After Normalization***************************************
2025-07-04 13:54:56,507 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:54:56,512 - INFO - outputs: cuda:0
2025-07-04 13:54:59,721 - INFO - Epoch 34/150 - Train Loss: 0.399802, Val Loss: 0.401497
2025-07-04 13:54:59,736 - INFO - New best model saved with Val Loss: 0.401497
2025-07-04 13:55:02,003 - INFO - before .to(local_rank)***************************************
2025-07-04 13:55:02,016 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:55:02,017 - INFO - After .to(local_rank)***************************************
2025-07-04 13:55:02,017 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:02,017 - INFO - After Normalization***************************************
2025-07-04 13:55:02,017 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:02,022 - INFO - outputs: cuda:0
2025-07-04 13:55:02,319 - INFO - before .to(local_rank)***************************************
2025-07-04 13:55:02,319 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:55:02,320 - INFO - After .to(local_rank)***************************************
2025-07-04 13:55:02,320 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:02,320 - INFO - After Normalization***************************************
2025-07-04 13:55:02,320 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:02,325 - INFO - outputs: cuda:0
2025-07-04 13:55:02,608 - INFO - before .to(local_rank)***************************************
2025-07-04 13:55:02,608 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:55:02,609 - INFO - After .to(local_rank)***************************************
2025-07-04 13:55:02,609 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:02,609 - INFO - After Normalization***************************************
2025-07-04 13:55:02,609 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:02,613 - INFO - outputs: cuda:0
2025-07-04 13:55:05,818 - INFO - Epoch 35/150 - Train Loss: 0.400421, Val Loss: 0.400646
2025-07-04 13:55:05,833 - INFO - New best model saved with Val Loss: 0.400646
2025-07-04 13:55:08,088 - INFO - before .to(local_rank)***************************************
2025-07-04 13:55:08,102 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:55:08,102 - INFO - After .to(local_rank)***************************************
2025-07-04 13:55:08,102 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:08,102 - INFO - After Normalization***************************************
2025-07-04 13:55:08,102 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:08,107 - INFO - outputs: cuda:0
2025-07-04 13:55:08,421 - INFO - before .to(local_rank)***************************************
2025-07-04 13:55:08,421 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:55:08,421 - INFO - After .to(local_rank)***************************************
2025-07-04 13:55:08,421 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:08,421 - INFO - After Normalization***************************************
2025-07-04 13:55:08,422 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:08,426 - INFO - outputs: cuda:0
2025-07-04 13:55:08,714 - INFO - before .to(local_rank)***************************************
2025-07-04 13:55:08,715 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:55:08,715 - INFO - After .to(local_rank)***************************************
2025-07-04 13:55:08,715 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:08,716 - INFO - After Normalization***************************************
2025-07-04 13:55:08,716 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:08,720 - INFO - outputs: cuda:0
2025-07-04 13:55:11,928 - INFO - Epoch 36/150 - Train Loss: 0.395775, Val Loss: 0.403946
2025-07-04 13:55:14,179 - INFO - before .to(local_rank)***************************************
2025-07-04 13:55:14,192 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:55:14,193 - INFO - After .to(local_rank)***************************************
2025-07-04 13:55:14,193 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:14,193 - INFO - After Normalization***************************************
2025-07-04 13:55:14,193 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:14,198 - INFO - outputs: cuda:0
2025-07-04 13:55:14,503 - INFO - before .to(local_rank)***************************************
2025-07-04 13:55:14,503 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:55:14,504 - INFO - After .to(local_rank)***************************************
2025-07-04 13:55:14,504 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:14,504 - INFO - After Normalization***************************************
2025-07-04 13:55:14,504 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:14,508 - INFO - outputs: cuda:0
2025-07-04 13:55:14,795 - INFO - before .to(local_rank)***************************************
2025-07-04 13:55:14,795 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:55:14,796 - INFO - After .to(local_rank)***************************************
2025-07-04 13:55:14,796 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:14,796 - INFO - After Normalization***************************************
2025-07-04 13:55:14,796 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:14,800 - INFO - outputs: cuda:0
2025-07-04 13:55:17,996 - INFO - Epoch 37/150 - Train Loss: 0.395949, Val Loss: 0.401222
2025-07-04 13:55:20,248 - INFO - before .to(local_rank)***************************************
2025-07-04 13:55:20,262 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:55:20,262 - INFO - After .to(local_rank)***************************************
2025-07-04 13:55:20,262 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:20,262 - INFO - After Normalization***************************************
2025-07-04 13:55:20,262 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:20,267 - INFO - outputs: cuda:0
2025-07-04 13:55:20,569 - INFO - before .to(local_rank)***************************************
2025-07-04 13:55:20,569 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:55:20,570 - INFO - After .to(local_rank)***************************************
2025-07-04 13:55:20,570 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:20,570 - INFO - After Normalization***************************************
2025-07-04 13:55:20,570 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:20,575 - INFO - outputs: cuda:0
2025-07-04 13:55:20,862 - INFO - before .to(local_rank)***************************************
2025-07-04 13:55:20,862 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:55:20,862 - INFO - After .to(local_rank)***************************************
2025-07-04 13:55:20,863 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:20,863 - INFO - After Normalization***************************************
2025-07-04 13:55:20,863 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:20,868 - INFO - outputs: cuda:0
2025-07-04 13:55:24,067 - INFO - Epoch 38/150 - Train Loss: 0.393724, Val Loss: 0.398120
2025-07-04 13:55:24,083 - INFO - New best model saved with Val Loss: 0.398120
2025-07-04 13:55:26,355 - INFO - before .to(local_rank)***************************************
2025-07-04 13:55:26,368 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:55:26,369 - INFO - After .to(local_rank)***************************************
2025-07-04 13:55:26,369 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:26,369 - INFO - After Normalization***************************************
2025-07-04 13:55:26,369 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:26,373 - INFO - outputs: cuda:0
2025-07-04 13:55:26,677 - INFO - before .to(local_rank)***************************************
2025-07-04 13:55:26,677 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:55:26,677 - INFO - After .to(local_rank)***************************************
2025-07-04 13:55:26,677 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:26,677 - INFO - After Normalization***************************************
2025-07-04 13:55:26,677 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:26,682 - INFO - outputs: cuda:0
2025-07-04 13:55:26,969 - INFO - before .to(local_rank)***************************************
2025-07-04 13:55:26,969 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:55:26,969 - INFO - After .to(local_rank)***************************************
2025-07-04 13:55:26,969 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:26,969 - INFO - After Normalization***************************************
2025-07-04 13:55:26,969 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:26,974 - INFO - outputs: cuda:0
2025-07-04 13:55:30,194 - INFO - Epoch 39/150 - Train Loss: 0.390039, Val Loss: 0.399025
2025-07-04 13:55:32,462 - INFO - before .to(local_rank)***************************************
2025-07-04 13:55:32,477 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:55:32,477 - INFO - After .to(local_rank)***************************************
2025-07-04 13:55:32,477 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:32,477 - INFO - After Normalization***************************************
2025-07-04 13:55:32,477 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:32,482 - INFO - outputs: cuda:0
2025-07-04 13:55:32,791 - INFO - before .to(local_rank)***************************************
2025-07-04 13:55:32,791 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:55:32,792 - INFO - After .to(local_rank)***************************************
2025-07-04 13:55:32,792 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:32,792 - INFO - After Normalization***************************************
2025-07-04 13:55:32,792 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:32,797 - INFO - outputs: cuda:0
2025-07-04 13:55:33,080 - INFO - before .to(local_rank)***************************************
2025-07-04 13:55:33,080 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:55:33,081 - INFO - After .to(local_rank)***************************************
2025-07-04 13:55:33,081 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:33,082 - INFO - After Normalization***************************************
2025-07-04 13:55:33,082 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:33,086 - INFO - outputs: cuda:0
2025-07-04 13:55:36,289 - INFO - Epoch 40/150 - Train Loss: 0.391684, Val Loss: 0.390313
2025-07-04 13:55:36,305 - INFO - New best model saved with Val Loss: 0.390313
2025-07-04 13:55:38,663 - INFO - before .to(local_rank)***************************************
2025-07-04 13:55:38,678 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:55:38,678 - INFO - After .to(local_rank)***************************************
2025-07-04 13:55:38,678 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:38,678 - INFO - After Normalization***************************************
2025-07-04 13:55:38,678 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:38,684 - INFO - outputs: cuda:0
2025-07-04 13:55:38,996 - INFO - before .to(local_rank)***************************************
2025-07-04 13:55:38,997 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:55:38,997 - INFO - After .to(local_rank)***************************************
2025-07-04 13:55:38,997 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:38,997 - INFO - After Normalization***************************************
2025-07-04 13:55:38,997 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:39,002 - INFO - outputs: cuda:0
2025-07-04 13:55:39,286 - INFO - before .to(local_rank)***************************************
2025-07-04 13:55:39,286 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:55:39,286 - INFO - After .to(local_rank)***************************************
2025-07-04 13:55:39,286 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:39,286 - INFO - After Normalization***************************************
2025-07-04 13:55:39,286 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:39,291 - INFO - outputs: cuda:0
2025-07-04 13:55:42,498 - INFO - Epoch 41/150 - Train Loss: 0.386746, Val Loss: 0.386531
2025-07-04 13:55:42,513 - INFO - New best model saved with Val Loss: 0.386531
2025-07-04 13:55:44,769 - INFO - before .to(local_rank)***************************************
2025-07-04 13:55:44,783 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:55:44,784 - INFO - After .to(local_rank)***************************************
2025-07-04 13:55:44,784 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:44,784 - INFO - After Normalization***************************************
2025-07-04 13:55:44,784 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:44,789 - INFO - outputs: cuda:0
2025-07-04 13:55:45,093 - INFO - before .to(local_rank)***************************************
2025-07-04 13:55:45,093 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:55:45,093 - INFO - After .to(local_rank)***************************************
2025-07-04 13:55:45,093 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:45,094 - INFO - After Normalization***************************************
2025-07-04 13:55:45,094 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:45,098 - INFO - outputs: cuda:0
2025-07-04 13:55:45,382 - INFO - before .to(local_rank)***************************************
2025-07-04 13:55:45,382 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:55:45,382 - INFO - After .to(local_rank)***************************************
2025-07-04 13:55:45,383 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:45,384 - INFO - After Normalization***************************************
2025-07-04 13:55:45,384 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:45,388 - INFO - outputs: cuda:0
2025-07-04 13:55:48,590 - INFO - Epoch 42/150 - Train Loss: 0.386503, Val Loss: 0.384749
2025-07-04 13:55:48,605 - INFO - New best model saved with Val Loss: 0.384749
2025-07-04 13:55:50,845 - INFO - before .to(local_rank)***************************************
2025-07-04 13:55:50,859 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:55:50,859 - INFO - After .to(local_rank)***************************************
2025-07-04 13:55:50,860 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:50,860 - INFO - After Normalization***************************************
2025-07-04 13:55:50,860 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:50,865 - INFO - outputs: cuda:0
2025-07-04 13:55:51,164 - INFO - before .to(local_rank)***************************************
2025-07-04 13:55:51,164 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:55:51,164 - INFO - After .to(local_rank)***************************************
2025-07-04 13:55:51,164 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:51,165 - INFO - After Normalization***************************************
2025-07-04 13:55:51,165 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:51,169 - INFO - outputs: cuda:0
2025-07-04 13:55:51,453 - INFO - before .to(local_rank)***************************************
2025-07-04 13:55:51,453 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:55:51,454 - INFO - After .to(local_rank)***************************************
2025-07-04 13:55:51,454 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:51,454 - INFO - After Normalization***************************************
2025-07-04 13:55:51,454 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:51,458 - INFO - outputs: cuda:0
2025-07-04 13:55:54,644 - INFO - Epoch 43/150 - Train Loss: 0.385221, Val Loss: 0.382403
2025-07-04 13:55:54,657 - INFO - New best model saved with Val Loss: 0.382403
2025-07-04 13:55:56,914 - INFO - before .to(local_rank)***************************************
2025-07-04 13:55:56,928 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:55:56,928 - INFO - After .to(local_rank)***************************************
2025-07-04 13:55:56,929 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:56,929 - INFO - After Normalization***************************************
2025-07-04 13:55:56,929 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:56,933 - INFO - outputs: cuda:0
2025-07-04 13:55:57,246 - INFO - before .to(local_rank)***************************************
2025-07-04 13:55:57,246 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:55:57,247 - INFO - After .to(local_rank)***************************************
2025-07-04 13:55:57,247 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:57,247 - INFO - After Normalization***************************************
2025-07-04 13:55:57,247 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:57,251 - INFO - outputs: cuda:0
2025-07-04 13:55:57,536 - INFO - before .to(local_rank)***************************************
2025-07-04 13:55:57,536 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:55:57,536 - INFO - After .to(local_rank)***************************************
2025-07-04 13:55:57,536 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:57,537 - INFO - After Normalization***************************************
2025-07-04 13:55:57,537 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:55:57,542 - INFO - outputs: cuda:0
2025-07-04 13:56:00,748 - INFO - Epoch 44/150 - Train Loss: 0.379563, Val Loss: 0.379401
2025-07-04 13:56:00,762 - INFO - New best model saved with Val Loss: 0.379401
2025-07-04 13:56:03,034 - INFO - before .to(local_rank)***************************************
2025-07-04 13:56:03,048 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:56:03,048 - INFO - After .to(local_rank)***************************************
2025-07-04 13:56:03,048 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:03,049 - INFO - After Normalization***************************************
2025-07-04 13:56:03,049 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:03,053 - INFO - outputs: cuda:0
2025-07-04 13:56:03,356 - INFO - before .to(local_rank)***************************************
2025-07-04 13:56:03,356 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:56:03,356 - INFO - After .to(local_rank)***************************************
2025-07-04 13:56:03,356 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:03,356 - INFO - After Normalization***************************************
2025-07-04 13:56:03,356 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:03,361 - INFO - outputs: cuda:0
2025-07-04 13:56:03,645 - INFO - before .to(local_rank)***************************************
2025-07-04 13:56:03,645 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:56:03,645 - INFO - After .to(local_rank)***************************************
2025-07-04 13:56:03,645 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:03,645 - INFO - After Normalization***************************************
2025-07-04 13:56:03,645 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:03,650 - INFO - outputs: cuda:0
2025-07-04 13:56:06,848 - INFO - Epoch 45/150 - Train Loss: 0.381152, Val Loss: 0.383046
2025-07-04 13:56:09,119 - INFO - before .to(local_rank)***************************************
2025-07-04 13:56:09,132 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:56:09,133 - INFO - After .to(local_rank)***************************************
2025-07-04 13:56:09,133 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:09,133 - INFO - After Normalization***************************************
2025-07-04 13:56:09,133 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:09,138 - INFO - outputs: cuda:0
2025-07-04 13:56:09,435 - INFO - before .to(local_rank)***************************************
2025-07-04 13:56:09,435 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:56:09,435 - INFO - After .to(local_rank)***************************************
2025-07-04 13:56:09,435 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:09,435 - INFO - After Normalization***************************************
2025-07-04 13:56:09,435 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:09,440 - INFO - outputs: cuda:0
2025-07-04 13:56:09,724 - INFO - before .to(local_rank)***************************************
2025-07-04 13:56:09,724 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:56:09,724 - INFO - After .to(local_rank)***************************************
2025-07-04 13:56:09,724 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:09,724 - INFO - After Normalization***************************************
2025-07-04 13:56:09,725 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:09,730 - INFO - outputs: cuda:0
2025-07-04 13:56:12,933 - INFO - Epoch 46/150 - Train Loss: 0.377841, Val Loss: 0.374077
2025-07-04 13:56:12,950 - INFO - New best model saved with Val Loss: 0.374077
2025-07-04 13:56:15,218 - INFO - before .to(local_rank)***************************************
2025-07-04 13:56:15,232 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:56:15,232 - INFO - After .to(local_rank)***************************************
2025-07-04 13:56:15,232 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:15,232 - INFO - After Normalization***************************************
2025-07-04 13:56:15,232 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:15,237 - INFO - outputs: cuda:0
2025-07-04 13:56:15,548 - INFO - before .to(local_rank)***************************************
2025-07-04 13:56:15,548 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:56:15,548 - INFO - After .to(local_rank)***************************************
2025-07-04 13:56:15,548 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:15,548 - INFO - After Normalization***************************************
2025-07-04 13:56:15,548 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:15,553 - INFO - outputs: cuda:0
2025-07-04 13:56:15,837 - INFO - before .to(local_rank)***************************************
2025-07-04 13:56:15,837 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:56:15,837 - INFO - After .to(local_rank)***************************************
2025-07-04 13:56:15,837 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:15,837 - INFO - After Normalization***************************************
2025-07-04 13:56:15,837 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:15,842 - INFO - outputs: cuda:0
2025-07-04 13:56:19,067 - INFO - Epoch 47/150 - Train Loss: 0.376989, Val Loss: 0.374267
2025-07-04 13:56:21,327 - INFO - before .to(local_rank)***************************************
2025-07-04 13:56:21,342 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:56:21,342 - INFO - After .to(local_rank)***************************************
2025-07-04 13:56:21,342 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:21,342 - INFO - After Normalization***************************************
2025-07-04 13:56:21,342 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:21,347 - INFO - outputs: cuda:0
2025-07-04 13:56:21,648 - INFO - before .to(local_rank)***************************************
2025-07-04 13:56:21,649 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:56:21,649 - INFO - After .to(local_rank)***************************************
2025-07-04 13:56:21,649 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:21,649 - INFO - After Normalization***************************************
2025-07-04 13:56:21,649 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:21,654 - INFO - outputs: cuda:0
2025-07-04 13:56:21,938 - INFO - before .to(local_rank)***************************************
2025-07-04 13:56:21,938 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:56:21,938 - INFO - After .to(local_rank)***************************************
2025-07-04 13:56:21,938 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:21,938 - INFO - After Normalization***************************************
2025-07-04 13:56:21,938 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:21,944 - INFO - outputs: cuda:0
2025-07-04 13:56:25,155 - INFO - Epoch 48/150 - Train Loss: 0.372625, Val Loss: 0.375827
2025-07-04 13:56:27,419 - INFO - before .to(local_rank)***************************************
2025-07-04 13:56:27,434 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:56:27,434 - INFO - After .to(local_rank)***************************************
2025-07-04 13:56:27,434 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:27,434 - INFO - After Normalization***************************************
2025-07-04 13:56:27,434 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:27,439 - INFO - outputs: cuda:0
2025-07-04 13:56:27,734 - INFO - before .to(local_rank)***************************************
2025-07-04 13:56:27,734 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:56:27,735 - INFO - After .to(local_rank)***************************************
2025-07-04 13:56:27,735 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:27,735 - INFO - After Normalization***************************************
2025-07-04 13:56:27,735 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:27,740 - INFO - outputs: cuda:0
2025-07-04 13:56:28,023 - INFO - before .to(local_rank)***************************************
2025-07-04 13:56:28,023 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:56:28,024 - INFO - After .to(local_rank)***************************************
2025-07-04 13:56:28,024 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:28,024 - INFO - After Normalization***************************************
2025-07-04 13:56:28,024 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:28,029 - INFO - outputs: cuda:0
2025-07-04 13:56:31,223 - INFO - Epoch 49/150 - Train Loss: 0.373013, Val Loss: 0.377917
2025-07-04 13:56:33,485 - INFO - before .to(local_rank)***************************************
2025-07-04 13:56:33,498 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:56:33,499 - INFO - After .to(local_rank)***************************************
2025-07-04 13:56:33,499 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:33,499 - INFO - After Normalization***************************************
2025-07-04 13:56:33,499 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:33,504 - INFO - outputs: cuda:0
2025-07-04 13:56:33,817 - INFO - before .to(local_rank)***************************************
2025-07-04 13:56:33,817 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:56:33,817 - INFO - After .to(local_rank)***************************************
2025-07-04 13:56:33,817 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:33,817 - INFO - After Normalization***************************************
2025-07-04 13:56:33,817 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:33,822 - INFO - outputs: cuda:0
2025-07-04 13:56:34,106 - INFO - before .to(local_rank)***************************************
2025-07-04 13:56:34,106 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:56:34,106 - INFO - After .to(local_rank)***************************************
2025-07-04 13:56:34,106 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:34,106 - INFO - After Normalization***************************************
2025-07-04 13:56:34,106 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:34,111 - INFO - outputs: cuda:0
2025-07-04 13:56:37,307 - INFO - Epoch 50/150 - Train Loss: 0.370192, Val Loss: 0.374004
2025-07-04 13:56:37,323 - INFO - New best model saved with Val Loss: 0.374004
2025-07-04 13:56:39,714 - INFO - before .to(local_rank)***************************************
2025-07-04 13:56:39,728 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:56:39,729 - INFO - After .to(local_rank)***************************************
2025-07-04 13:56:39,729 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:39,729 - INFO - After Normalization***************************************
2025-07-04 13:56:39,729 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:39,734 - INFO - outputs: cuda:0
2025-07-04 13:56:40,046 - INFO - before .to(local_rank)***************************************
2025-07-04 13:56:40,046 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:56:40,046 - INFO - After .to(local_rank)***************************************
2025-07-04 13:56:40,047 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:40,047 - INFO - After Normalization***************************************
2025-07-04 13:56:40,047 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:40,051 - INFO - outputs: cuda:0
2025-07-04 13:56:40,339 - INFO - before .to(local_rank)***************************************
2025-07-04 13:56:40,340 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:56:40,340 - INFO - After .to(local_rank)***************************************
2025-07-04 13:56:40,340 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:40,340 - INFO - After Normalization***************************************
2025-07-04 13:56:40,340 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:40,345 - INFO - outputs: cuda:0
2025-07-04 13:56:43,555 - INFO - Epoch 51/150 - Train Loss: 0.370575, Val Loss: 0.368872
2025-07-04 13:56:43,569 - INFO - New best model saved with Val Loss: 0.368872
2025-07-04 13:56:45,843 - INFO - before .to(local_rank)***************************************
2025-07-04 13:56:45,857 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:56:45,858 - INFO - After .to(local_rank)***************************************
2025-07-04 13:56:45,858 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:45,858 - INFO - After Normalization***************************************
2025-07-04 13:56:45,858 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:45,863 - INFO - outputs: cuda:0
2025-07-04 13:56:46,164 - INFO - before .to(local_rank)***************************************
2025-07-04 13:56:46,164 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:56:46,164 - INFO - After .to(local_rank)***************************************
2025-07-04 13:56:46,164 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:46,165 - INFO - After Normalization***************************************
2025-07-04 13:56:46,165 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:46,169 - INFO - outputs: cuda:0
2025-07-04 13:56:46,458 - INFO - before .to(local_rank)***************************************
2025-07-04 13:56:46,458 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:56:46,458 - INFO - After .to(local_rank)***************************************
2025-07-04 13:56:46,458 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:46,458 - INFO - After Normalization***************************************
2025-07-04 13:56:46,458 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:46,463 - INFO - outputs: cuda:0
2025-07-04 13:56:49,676 - INFO - Epoch 52/150 - Train Loss: 0.366457, Val Loss: 0.366532
2025-07-04 13:56:49,693 - INFO - New best model saved with Val Loss: 0.366532
2025-07-04 13:56:51,961 - INFO - before .to(local_rank)***************************************
2025-07-04 13:56:51,975 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:56:51,975 - INFO - After .to(local_rank)***************************************
2025-07-04 13:56:51,976 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:51,976 - INFO - After Normalization***************************************
2025-07-04 13:56:51,976 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:51,980 - INFO - outputs: cuda:0
2025-07-04 13:56:52,298 - INFO - before .to(local_rank)***************************************
2025-07-04 13:56:52,298 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:56:52,298 - INFO - After .to(local_rank)***************************************
2025-07-04 13:56:52,299 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:52,299 - INFO - After Normalization***************************************
2025-07-04 13:56:52,299 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:52,303 - INFO - outputs: cuda:0
2025-07-04 13:56:52,587 - INFO - before .to(local_rank)***************************************
2025-07-04 13:56:52,587 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:56:52,588 - INFO - After .to(local_rank)***************************************
2025-07-04 13:56:52,588 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:52,588 - INFO - After Normalization***************************************
2025-07-04 13:56:52,588 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:52,592 - INFO - outputs: cuda:0
2025-07-04 13:56:55,773 - INFO - Epoch 53/150 - Train Loss: 0.364227, Val Loss: 0.364998
2025-07-04 13:56:55,788 - INFO - New best model saved with Val Loss: 0.364998
2025-07-04 13:56:58,045 - INFO - before .to(local_rank)***************************************
2025-07-04 13:56:58,059 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:56:58,060 - INFO - After .to(local_rank)***************************************
2025-07-04 13:56:58,060 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:58,060 - INFO - After Normalization***************************************
2025-07-04 13:56:58,060 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:58,065 - INFO - outputs: cuda:0
2025-07-04 13:56:58,373 - INFO - before .to(local_rank)***************************************
2025-07-04 13:56:58,374 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:56:58,374 - INFO - After .to(local_rank)***************************************
2025-07-04 13:56:58,374 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:58,374 - INFO - After Normalization***************************************
2025-07-04 13:56:58,374 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:58,379 - INFO - outputs: cuda:0
2025-07-04 13:56:58,663 - INFO - before .to(local_rank)***************************************
2025-07-04 13:56:58,663 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:56:58,663 - INFO - After .to(local_rank)***************************************
2025-07-04 13:56:58,663 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:58,663 - INFO - After Normalization***************************************
2025-07-04 13:56:58,663 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:56:58,668 - INFO - outputs: cuda:0
2025-07-04 13:57:01,858 - INFO - Epoch 54/150 - Train Loss: 0.362108, Val Loss: 0.361583
2025-07-04 13:57:01,874 - INFO - New best model saved with Val Loss: 0.361583
2025-07-04 13:57:04,127 - INFO - before .to(local_rank)***************************************
2025-07-04 13:57:04,141 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:57:04,141 - INFO - After .to(local_rank)***************************************
2025-07-04 13:57:04,141 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:04,141 - INFO - After Normalization***************************************
2025-07-04 13:57:04,141 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:04,146 - INFO - outputs: cuda:0
2025-07-04 13:57:04,481 - INFO - before .to(local_rank)***************************************
2025-07-04 13:57:04,481 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:57:04,481 - INFO - After .to(local_rank)***************************************
2025-07-04 13:57:04,481 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:04,481 - INFO - After Normalization***************************************
2025-07-04 13:57:04,481 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:04,486 - INFO - outputs: cuda:0
2025-07-04 13:57:04,770 - INFO - before .to(local_rank)***************************************
2025-07-04 13:57:04,770 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:57:04,770 - INFO - After .to(local_rank)***************************************
2025-07-04 13:57:04,770 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:04,770 - INFO - After Normalization***************************************
2025-07-04 13:57:04,770 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:04,775 - INFO - outputs: cuda:0
2025-07-04 13:57:07,972 - INFO - Epoch 55/150 - Train Loss: 0.362925, Val Loss: 0.360435
2025-07-04 13:57:07,988 - INFO - New best model saved with Val Loss: 0.360435
2025-07-04 13:57:10,261 - INFO - before .to(local_rank)***************************************
2025-07-04 13:57:10,275 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:57:10,276 - INFO - After .to(local_rank)***************************************
2025-07-04 13:57:10,276 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:10,276 - INFO - After Normalization***************************************
2025-07-04 13:57:10,276 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:10,281 - INFO - outputs: cuda:0
2025-07-04 13:57:10,595 - INFO - before .to(local_rank)***************************************
2025-07-04 13:57:10,595 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:57:10,596 - INFO - After .to(local_rank)***************************************
2025-07-04 13:57:10,596 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:10,596 - INFO - After Normalization***************************************
2025-07-04 13:57:10,596 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:10,600 - INFO - outputs: cuda:0
2025-07-04 13:57:10,884 - INFO - before .to(local_rank)***************************************
2025-07-04 13:57:10,884 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:57:10,885 - INFO - After .to(local_rank)***************************************
2025-07-04 13:57:10,885 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:10,885 - INFO - After Normalization***************************************
2025-07-04 13:57:10,885 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:10,889 - INFO - outputs: cuda:0
2025-07-04 13:57:14,089 - INFO - Epoch 56/150 - Train Loss: 0.360084, Val Loss: 0.360202
2025-07-04 13:57:14,104 - INFO - New best model saved with Val Loss: 0.360202
2025-07-04 13:57:16,369 - INFO - before .to(local_rank)***************************************
2025-07-04 13:57:16,383 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:57:16,383 - INFO - After .to(local_rank)***************************************
2025-07-04 13:57:16,383 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:16,383 - INFO - After Normalization***************************************
2025-07-04 13:57:16,383 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:16,388 - INFO - outputs: cuda:0
2025-07-04 13:57:16,689 - INFO - before .to(local_rank)***************************************
2025-07-04 13:57:16,689 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:57:16,690 - INFO - After .to(local_rank)***************************************
2025-07-04 13:57:16,690 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:16,690 - INFO - After Normalization***************************************
2025-07-04 13:57:16,690 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:16,694 - INFO - outputs: cuda:0
2025-07-04 13:57:16,978 - INFO - before .to(local_rank)***************************************
2025-07-04 13:57:16,978 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:57:16,978 - INFO - After .to(local_rank)***************************************
2025-07-04 13:57:16,979 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:16,979 - INFO - After Normalization***************************************
2025-07-04 13:57:16,979 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:16,983 - INFO - outputs: cuda:0
2025-07-04 13:57:20,193 - INFO - Epoch 57/150 - Train Loss: 0.356597, Val Loss: 0.362886
2025-07-04 13:57:22,449 - INFO - before .to(local_rank)***************************************
2025-07-04 13:57:22,462 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:57:22,463 - INFO - After .to(local_rank)***************************************
2025-07-04 13:57:22,463 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:22,463 - INFO - After Normalization***************************************
2025-07-04 13:57:22,463 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:22,468 - INFO - outputs: cuda:0
2025-07-04 13:57:22,764 - INFO - before .to(local_rank)***************************************
2025-07-04 13:57:22,765 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:57:22,765 - INFO - After .to(local_rank)***************************************
2025-07-04 13:57:22,765 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:22,765 - INFO - After Normalization***************************************
2025-07-04 13:57:22,765 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:22,770 - INFO - outputs: cuda:0
2025-07-04 13:57:23,053 - INFO - before .to(local_rank)***************************************
2025-07-04 13:57:23,053 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:57:23,054 - INFO - After .to(local_rank)***************************************
2025-07-04 13:57:23,054 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:23,054 - INFO - After Normalization***************************************
2025-07-04 13:57:23,054 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:23,058 - INFO - outputs: cuda:0
2025-07-04 13:57:26,270 - INFO - Epoch 58/150 - Train Loss: 0.359285, Val Loss: 0.363573
2025-07-04 13:57:28,516 - INFO - before .to(local_rank)***************************************
2025-07-04 13:57:28,530 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:57:28,531 - INFO - After .to(local_rank)***************************************
2025-07-04 13:57:28,531 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:28,531 - INFO - After Normalization***************************************
2025-07-04 13:57:28,531 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:28,536 - INFO - outputs: cuda:0
2025-07-04 13:57:28,851 - INFO - before .to(local_rank)***************************************
2025-07-04 13:57:28,851 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:57:28,851 - INFO - After .to(local_rank)***************************************
2025-07-04 13:57:28,851 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:28,851 - INFO - After Normalization***************************************
2025-07-04 13:57:28,851 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:28,856 - INFO - outputs: cuda:0
2025-07-04 13:57:29,140 - INFO - before .to(local_rank)***************************************
2025-07-04 13:57:29,140 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:57:29,140 - INFO - After .to(local_rank)***************************************
2025-07-04 13:57:29,140 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:29,140 - INFO - After Normalization***************************************
2025-07-04 13:57:29,140 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:29,145 - INFO - outputs: cuda:0
2025-07-04 13:57:32,342 - INFO - Epoch 59/150 - Train Loss: 0.353965, Val Loss: 0.367631
2025-07-04 13:57:34,599 - INFO - before .to(local_rank)***************************************
2025-07-04 13:57:34,612 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:57:34,613 - INFO - After .to(local_rank)***************************************
2025-07-04 13:57:34,613 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:34,613 - INFO - After Normalization***************************************
2025-07-04 13:57:34,613 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:34,618 - INFO - outputs: cuda:0
2025-07-04 13:57:34,926 - INFO - before .to(local_rank)***************************************
2025-07-04 13:57:34,927 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:57:34,927 - INFO - After .to(local_rank)***************************************
2025-07-04 13:57:34,927 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:34,927 - INFO - After Normalization***************************************
2025-07-04 13:57:34,927 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:34,932 - INFO - outputs: cuda:0
2025-07-04 13:57:35,216 - INFO - before .to(local_rank)***************************************
2025-07-04 13:57:35,216 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:57:35,216 - INFO - After .to(local_rank)***************************************
2025-07-04 13:57:35,216 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:35,216 - INFO - After Normalization***************************************
2025-07-04 13:57:35,216 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:35,221 - INFO - outputs: cuda:0
2025-07-04 13:57:38,408 - INFO - Epoch 60/150 - Train Loss: 0.355830, Val Loss: 0.363127
2025-07-04 13:57:40,789 - INFO - before .to(local_rank)***************************************
2025-07-04 13:57:40,803 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:57:40,804 - INFO - After .to(local_rank)***************************************
2025-07-04 13:57:40,804 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:40,804 - INFO - After Normalization***************************************
2025-07-04 13:57:40,804 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:40,809 - INFO - outputs: cuda:0
2025-07-04 13:57:41,122 - INFO - before .to(local_rank)***************************************
2025-07-04 13:57:41,122 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:57:41,122 - INFO - After .to(local_rank)***************************************
2025-07-04 13:57:41,122 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:41,122 - INFO - After Normalization***************************************
2025-07-04 13:57:41,122 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:41,127 - INFO - outputs: cuda:0
2025-07-04 13:57:41,411 - INFO - before .to(local_rank)***************************************
2025-07-04 13:57:41,411 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:57:41,411 - INFO - After .to(local_rank)***************************************
2025-07-04 13:57:41,411 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:41,411 - INFO - After Normalization***************************************
2025-07-04 13:57:41,411 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:41,416 - INFO - outputs: cuda:0
2025-07-04 13:57:44,607 - INFO - Epoch 61/150 - Train Loss: 0.352915, Val Loss: 0.355417
2025-07-04 13:57:44,622 - INFO - New best model saved with Val Loss: 0.355417
2025-07-04 13:57:46,864 - INFO - before .to(local_rank)***************************************
2025-07-04 13:57:46,878 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:57:46,878 - INFO - After .to(local_rank)***************************************
2025-07-04 13:57:46,878 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:46,878 - INFO - After Normalization***************************************
2025-07-04 13:57:46,878 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:46,883 - INFO - outputs: cuda:0
2025-07-04 13:57:47,189 - INFO - before .to(local_rank)***************************************
2025-07-04 13:57:47,189 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:57:47,189 - INFO - After .to(local_rank)***************************************
2025-07-04 13:57:47,189 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:47,189 - INFO - After Normalization***************************************
2025-07-04 13:57:47,189 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:47,194 - INFO - outputs: cuda:0
2025-07-04 13:57:47,478 - INFO - before .to(local_rank)***************************************
2025-07-04 13:57:47,478 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:57:47,478 - INFO - After .to(local_rank)***************************************
2025-07-04 13:57:47,478 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:47,478 - INFO - After Normalization***************************************
2025-07-04 13:57:47,478 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:47,483 - INFO - outputs: cuda:0
2025-07-04 13:57:50,710 - INFO - Epoch 62/150 - Train Loss: 0.349458, Val Loss: 0.353605
2025-07-04 13:57:50,725 - INFO - New best model saved with Val Loss: 0.353605
2025-07-04 13:57:52,982 - INFO - before .to(local_rank)***************************************
2025-07-04 13:57:52,996 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:57:52,999 - INFO - After .to(local_rank)***************************************
2025-07-04 13:57:52,999 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:52,999 - INFO - After Normalization***************************************
2025-07-04 13:57:52,999 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:53,004 - INFO - outputs: cuda:0
2025-07-04 13:57:53,301 - INFO - before .to(local_rank)***************************************
2025-07-04 13:57:53,301 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:57:53,302 - INFO - After .to(local_rank)***************************************
2025-07-04 13:57:53,302 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:53,302 - INFO - After Normalization***************************************
2025-07-04 13:57:53,302 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:53,306 - INFO - outputs: cuda:0
2025-07-04 13:57:53,593 - INFO - before .to(local_rank)***************************************
2025-07-04 13:57:53,593 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:57:53,594 - INFO - After .to(local_rank)***************************************
2025-07-04 13:57:53,594 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:53,594 - INFO - After Normalization***************************************
2025-07-04 13:57:53,594 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:53,598 - INFO - outputs: cuda:0
2025-07-04 13:57:56,807 - INFO - Epoch 63/150 - Train Loss: 0.349392, Val Loss: 0.354289
2025-07-04 13:57:59,074 - INFO - before .to(local_rank)***************************************
2025-07-04 13:57:59,088 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:57:59,088 - INFO - After .to(local_rank)***************************************
2025-07-04 13:57:59,088 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:59,089 - INFO - After Normalization***************************************
2025-07-04 13:57:59,089 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:59,093 - INFO - outputs: cuda:0
2025-07-04 13:57:59,406 - INFO - before .to(local_rank)***************************************
2025-07-04 13:57:59,406 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:57:59,407 - INFO - After .to(local_rank)***************************************
2025-07-04 13:57:59,407 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:59,407 - INFO - After Normalization***************************************
2025-07-04 13:57:59,407 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:59,412 - INFO - outputs: cuda:0
2025-07-04 13:57:59,698 - INFO - before .to(local_rank)***************************************
2025-07-04 13:57:59,699 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:57:59,699 - INFO - After .to(local_rank)***************************************
2025-07-04 13:57:59,699 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:59,699 - INFO - After Normalization***************************************
2025-07-04 13:57:59,699 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:57:59,704 - INFO - outputs: cuda:0
2025-07-04 13:58:02,900 - INFO - Epoch 64/150 - Train Loss: 0.349203, Val Loss: 0.349903
2025-07-04 13:58:02,915 - INFO - New best model saved with Val Loss: 0.349903
2025-07-04 13:58:05,165 - INFO - before .to(local_rank)***************************************
2025-07-04 13:58:05,179 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:58:05,179 - INFO - After .to(local_rank)***************************************
2025-07-04 13:58:05,179 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:05,180 - INFO - After Normalization***************************************
2025-07-04 13:58:05,180 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:05,184 - INFO - outputs: cuda:0
2025-07-04 13:58:05,489 - INFO - before .to(local_rank)***************************************
2025-07-04 13:58:05,489 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:58:05,489 - INFO - After .to(local_rank)***************************************
2025-07-04 13:58:05,489 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:05,489 - INFO - After Normalization***************************************
2025-07-04 13:58:05,489 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:05,494 - INFO - outputs: cuda:0
2025-07-04 13:58:05,801 - INFO - before .to(local_rank)***************************************
2025-07-04 13:58:05,802 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:58:05,802 - INFO - After .to(local_rank)***************************************
2025-07-04 13:58:05,802 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:05,802 - INFO - After Normalization***************************************
2025-07-04 13:58:05,802 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:05,807 - INFO - outputs: cuda:0
2025-07-04 13:58:09,013 - INFO - Epoch 65/150 - Train Loss: 0.348612, Val Loss: 0.350857
2025-07-04 13:58:11,278 - INFO - before .to(local_rank)***************************************
2025-07-04 13:58:11,291 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:58:11,291 - INFO - After .to(local_rank)***************************************
2025-07-04 13:58:11,292 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:11,292 - INFO - After Normalization***************************************
2025-07-04 13:58:11,292 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:11,296 - INFO - outputs: cuda:0
2025-07-04 13:58:11,594 - INFO - before .to(local_rank)***************************************
2025-07-04 13:58:11,594 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:58:11,594 - INFO - After .to(local_rank)***************************************
2025-07-04 13:58:11,594 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:11,594 - INFO - After Normalization***************************************
2025-07-04 13:58:11,594 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:11,599 - INFO - outputs: cuda:0
2025-07-04 13:58:11,886 - INFO - before .to(local_rank)***************************************
2025-07-04 13:58:11,886 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:58:11,887 - INFO - After .to(local_rank)***************************************
2025-07-04 13:58:11,887 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:11,887 - INFO - After Normalization***************************************
2025-07-04 13:58:11,887 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:11,891 - INFO - outputs: cuda:0
2025-07-04 13:58:15,110 - INFO - Epoch 66/150 - Train Loss: 0.344767, Val Loss: 0.353102
2025-07-04 13:58:17,386 - INFO - before .to(local_rank)***************************************
2025-07-04 13:58:17,400 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:58:17,400 - INFO - After .to(local_rank)***************************************
2025-07-04 13:58:17,400 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:17,400 - INFO - After Normalization***************************************
2025-07-04 13:58:17,400 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:17,405 - INFO - outputs: cuda:0
2025-07-04 13:58:17,718 - INFO - before .to(local_rank)***************************************
2025-07-04 13:58:17,718 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:58:17,718 - INFO - After .to(local_rank)***************************************
2025-07-04 13:58:17,719 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:17,719 - INFO - After Normalization***************************************
2025-07-04 13:58:17,719 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:17,723 - INFO - outputs: cuda:0
2025-07-04 13:58:18,007 - INFO - before .to(local_rank)***************************************
2025-07-04 13:58:18,007 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:58:18,008 - INFO - After .to(local_rank)***************************************
2025-07-04 13:58:18,008 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:18,008 - INFO - After Normalization***************************************
2025-07-04 13:58:18,008 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:18,012 - INFO - outputs: cuda:0
2025-07-04 13:58:21,224 - INFO - Epoch 67/150 - Train Loss: 0.343171, Val Loss: 0.346992
2025-07-04 13:58:21,238 - INFO - New best model saved with Val Loss: 0.346992
2025-07-04 13:58:23,500 - INFO - before .to(local_rank)***************************************
2025-07-04 13:58:23,515 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:58:23,515 - INFO - After .to(local_rank)***************************************
2025-07-04 13:58:23,515 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:23,515 - INFO - After Normalization***************************************
2025-07-04 13:58:23,515 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:23,520 - INFO - outputs: cuda:0
2025-07-04 13:58:23,824 - INFO - before .to(local_rank)***************************************
2025-07-04 13:58:23,824 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:58:23,824 - INFO - After .to(local_rank)***************************************
2025-07-04 13:58:23,824 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:23,824 - INFO - After Normalization***************************************
2025-07-04 13:58:23,824 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:23,829 - INFO - outputs: cuda:0
2025-07-04 13:58:24,113 - INFO - before .to(local_rank)***************************************
2025-07-04 13:58:24,113 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:58:24,113 - INFO - After .to(local_rank)***************************************
2025-07-04 13:58:24,113 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:24,113 - INFO - After Normalization***************************************
2025-07-04 13:58:24,114 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:24,118 - INFO - outputs: cuda:0
2025-07-04 13:58:27,326 - INFO - Epoch 68/150 - Train Loss: 0.343175, Val Loss: 0.344801
2025-07-04 13:58:27,341 - INFO - New best model saved with Val Loss: 0.344801
2025-07-04 13:58:29,590 - INFO - before .to(local_rank)***************************************
2025-07-04 13:58:29,605 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:58:29,605 - INFO - After .to(local_rank)***************************************
2025-07-04 13:58:29,605 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:29,605 - INFO - After Normalization***************************************
2025-07-04 13:58:29,605 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:29,610 - INFO - outputs: cuda:0
2025-07-04 13:58:29,919 - INFO - before .to(local_rank)***************************************
2025-07-04 13:58:29,920 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:58:29,920 - INFO - After .to(local_rank)***************************************
2025-07-04 13:58:29,920 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:29,920 - INFO - After Normalization***************************************
2025-07-04 13:58:29,920 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:29,925 - INFO - outputs: cuda:0
2025-07-04 13:58:30,208 - INFO - before .to(local_rank)***************************************
2025-07-04 13:58:30,209 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:58:30,209 - INFO - After .to(local_rank)***************************************
2025-07-04 13:58:30,209 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:30,209 - INFO - After Normalization***************************************
2025-07-04 13:58:30,209 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:30,214 - INFO - outputs: cuda:0
2025-07-04 13:58:33,437 - INFO - Epoch 69/150 - Train Loss: 0.342111, Val Loss: 0.345257
2025-07-04 13:58:35,691 - INFO - before .to(local_rank)***************************************
2025-07-04 13:58:35,706 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:58:35,706 - INFO - After .to(local_rank)***************************************
2025-07-04 13:58:35,706 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:35,706 - INFO - After Normalization***************************************
2025-07-04 13:58:35,706 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:35,711 - INFO - outputs: cuda:0
2025-07-04 13:58:36,021 - INFO - before .to(local_rank)***************************************
2025-07-04 13:58:36,021 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:58:36,021 - INFO - After .to(local_rank)***************************************
2025-07-04 13:58:36,021 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:36,022 - INFO - After Normalization***************************************
2025-07-04 13:58:36,022 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:36,026 - INFO - outputs: cuda:0
2025-07-04 13:58:36,310 - INFO - before .to(local_rank)***************************************
2025-07-04 13:58:36,310 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:58:36,310 - INFO - After .to(local_rank)***************************************
2025-07-04 13:58:36,310 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:36,311 - INFO - After Normalization***************************************
2025-07-04 13:58:36,311 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:36,315 - INFO - outputs: cuda:0
2025-07-04 13:58:39,534 - INFO - Epoch 70/150 - Train Loss: 0.338463, Val Loss: 0.343932
2025-07-04 13:58:39,549 - INFO - New best model saved with Val Loss: 0.343932
2025-07-04 13:58:41,932 - INFO - before .to(local_rank)***************************************
2025-07-04 13:58:41,956 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:58:41,956 - INFO - After .to(local_rank)***************************************
2025-07-04 13:58:41,956 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:41,957 - INFO - After Normalization***************************************
2025-07-04 13:58:41,957 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:41,961 - INFO - outputs: cuda:0
2025-07-04 13:58:42,265 - INFO - before .to(local_rank)***************************************
2025-07-04 13:58:42,265 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:58:42,265 - INFO - After .to(local_rank)***************************************
2025-07-04 13:58:42,265 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:42,265 - INFO - After Normalization***************************************
2025-07-04 13:58:42,265 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:42,270 - INFO - outputs: cuda:0
2025-07-04 13:58:42,554 - INFO - before .to(local_rank)***************************************
2025-07-04 13:58:42,554 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:58:42,554 - INFO - After .to(local_rank)***************************************
2025-07-04 13:58:42,554 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:42,554 - INFO - After Normalization***************************************
2025-07-04 13:58:42,554 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:42,559 - INFO - outputs: cuda:0
2025-07-04 13:58:45,754 - INFO - Epoch 71/150 - Train Loss: 0.337893, Val Loss: 0.343028
2025-07-04 13:58:45,769 - INFO - New best model saved with Val Loss: 0.343028
2025-07-04 13:58:48,043 - INFO - before .to(local_rank)***************************************
2025-07-04 13:58:48,058 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:58:48,058 - INFO - After .to(local_rank)***************************************
2025-07-04 13:58:48,058 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:48,058 - INFO - After Normalization***************************************
2025-07-04 13:58:48,058 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:48,063 - INFO - outputs: cuda:0
2025-07-04 13:58:48,360 - INFO - before .to(local_rank)***************************************
2025-07-04 13:58:48,360 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:58:48,361 - INFO - After .to(local_rank)***************************************
2025-07-04 13:58:48,361 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:48,361 - INFO - After Normalization***************************************
2025-07-04 13:58:48,361 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:48,366 - INFO - outputs: cuda:0
2025-07-04 13:58:48,649 - INFO - before .to(local_rank)***************************************
2025-07-04 13:58:48,649 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:58:48,650 - INFO - After .to(local_rank)***************************************
2025-07-04 13:58:48,650 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:48,650 - INFO - After Normalization***************************************
2025-07-04 13:58:48,650 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:48,654 - INFO - outputs: cuda:0
2025-07-04 13:58:51,855 - INFO - Epoch 72/150 - Train Loss: 0.335130, Val Loss: 0.342844
2025-07-04 13:58:51,869 - INFO - New best model saved with Val Loss: 0.342844
2025-07-04 13:58:54,124 - INFO - before .to(local_rank)***************************************
2025-07-04 13:58:54,138 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:58:54,139 - INFO - After .to(local_rank)***************************************
2025-07-04 13:58:54,139 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:54,139 - INFO - After Normalization***************************************
2025-07-04 13:58:54,139 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:54,144 - INFO - outputs: cuda:0
2025-07-04 13:58:54,456 - INFO - before .to(local_rank)***************************************
2025-07-04 13:58:54,456 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:58:54,456 - INFO - After .to(local_rank)***************************************
2025-07-04 13:58:54,456 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:54,457 - INFO - After Normalization***************************************
2025-07-04 13:58:54,457 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:54,461 - INFO - outputs: cuda:0
2025-07-04 13:58:54,745 - INFO - before .to(local_rank)***************************************
2025-07-04 13:58:54,745 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:58:54,746 - INFO - After .to(local_rank)***************************************
2025-07-04 13:58:54,746 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:54,746 - INFO - After Normalization***************************************
2025-07-04 13:58:54,746 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:58:54,750 - INFO - outputs: cuda:0
2025-07-04 13:58:57,968 - INFO - Epoch 73/150 - Train Loss: 0.336449, Val Loss: 0.340494
2025-07-04 13:58:57,983 - INFO - New best model saved with Val Loss: 0.340494
2025-07-04 13:59:00,238 - INFO - before .to(local_rank)***************************************
2025-07-04 13:59:00,252 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:59:00,252 - INFO - After .to(local_rank)***************************************
2025-07-04 13:59:00,253 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:59:00,253 - INFO - After Normalization***************************************
2025-07-04 13:59:00,253 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:59:00,257 - INFO - outputs: cuda:0
2025-07-04 13:59:00,560 - INFO - before .to(local_rank)***************************************
2025-07-04 13:59:00,561 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:59:00,561 - INFO - After .to(local_rank)***************************************
2025-07-04 13:59:00,561 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:59:00,561 - INFO - After Normalization***************************************
2025-07-04 13:59:00,561 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:59:00,566 - INFO - outputs: cuda:0
2025-07-04 13:59:00,850 - INFO - before .to(local_rank)***************************************
2025-07-04 13:59:00,850 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:59:00,850 - INFO - After .to(local_rank)***************************************
2025-07-04 13:59:00,850 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:59:00,850 - INFO - After Normalization***************************************
2025-07-04 13:59:00,850 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:59:00,855 - INFO - outputs: cuda:0
2025-07-04 13:59:04,085 - INFO - Epoch 74/150 - Train Loss: 0.332509, Val Loss: 0.336325
2025-07-04 13:59:04,099 - INFO - New best model saved with Val Loss: 0.336325
2025-07-04 13:59:06,360 - INFO - before .to(local_rank)***************************************
2025-07-04 13:59:06,374 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:59:06,374 - INFO - After .to(local_rank)***************************************
2025-07-04 13:59:06,374 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:59:06,375 - INFO - After Normalization***************************************
2025-07-04 13:59:06,375 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:59:06,379 - INFO - outputs: cuda:0
2025-07-04 13:59:06,694 - INFO - before .to(local_rank)***************************************
2025-07-04 13:59:06,694 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:59:06,695 - INFO - After .to(local_rank)***************************************
2025-07-04 13:59:06,695 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:59:06,695 - INFO - After Normalization***************************************
2025-07-04 13:59:06,695 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:59:06,699 - INFO - outputs: cuda:0
2025-07-04 13:59:06,988 - INFO - before .to(local_rank)***************************************
2025-07-04 13:59:06,988 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:59:06,988 - INFO - After .to(local_rank)***************************************
2025-07-04 13:59:06,988 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:59:06,988 - INFO - After Normalization***************************************
2025-07-04 13:59:06,988 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:59:06,993 - INFO - outputs: cuda:0
2025-07-04 13:59:10,195 - INFO - Epoch 75/150 - Train Loss: 0.332463, Val Loss: 0.338520
2025-07-04 13:59:12,434 - INFO - before .to(local_rank)***************************************
2025-07-04 13:59:12,434 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:59:12,435 - INFO - After .to(local_rank)***************************************
2025-07-04 13:59:12,435 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:59:12,435 - INFO - After Normalization***************************************
2025-07-04 13:59:12,435 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:59:12,440 - INFO - outputs: cuda:0
2025-07-04 13:59:12,750 - INFO - before .to(local_rank)***************************************
2025-07-04 13:59:12,750 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:59:12,750 - INFO - After .to(local_rank)***************************************
2025-07-04 13:59:12,750 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:59:12,750 - INFO - After Normalization***************************************
2025-07-04 13:59:12,750 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:59:12,755 - INFO - outputs: cuda:0
2025-07-04 13:59:13,039 - INFO - before .to(local_rank)***************************************
2025-07-04 13:59:13,039 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:59:13,039 - INFO - After .to(local_rank)***************************************
2025-07-04 13:59:13,039 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:59:13,039 - INFO - After Normalization***************************************
2025-07-04 13:59:13,039 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:59:13,044 - INFO - outputs: cuda:0
2025-07-04 13:59:16,244 - INFO - Epoch 76/150 - Train Loss: 0.330725, Val Loss: 0.343105
2025-07-04 13:59:18,525 - INFO - before .to(local_rank)***************************************
2025-07-04 13:59:18,525 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:59:18,526 - INFO - After .to(local_rank)***************************************
2025-07-04 13:59:18,526 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:59:18,526 - INFO - After Normalization***************************************
2025-07-04 13:59:18,526 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:59:18,531 - INFO - outputs: cuda:0
2025-07-04 13:59:18,833 - INFO - before .to(local_rank)***************************************
2025-07-04 13:59:18,833 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:59:18,834 - INFO - After .to(local_rank)***************************************
2025-07-04 13:59:18,834 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:59:18,834 - INFO - After Normalization***************************************
2025-07-04 13:59:18,834 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:59:18,839 - INFO - outputs: cuda:0
2025-07-04 13:59:19,123 - INFO - before .to(local_rank)***************************************
2025-07-04 13:59:19,123 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:59:19,123 - INFO - After .to(local_rank)***************************************
2025-07-04 13:59:19,123 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:59:19,123 - INFO - After Normalization***************************************
2025-07-04 13:59:19,123 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:59:19,128 - INFO - outputs: cuda:0
2025-07-04 13:59:22,359 - INFO - Epoch 77/150 - Train Loss: 0.329678, Val Loss: 0.336431
2025-07-04 13:59:24,617 - INFO - before .to(local_rank)***************************************
2025-07-04 13:59:24,617 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:59:24,618 - INFO - After .to(local_rank)***************************************
2025-07-04 13:59:24,618 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:59:24,618 - INFO - After Normalization***************************************
2025-07-04 13:59:24,618 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:59:24,623 - INFO - outputs: cuda:0
2025-07-04 13:59:24,919 - INFO - before .to(local_rank)***************************************
2025-07-04 13:59:24,919 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:59:24,919 - INFO - After .to(local_rank)***************************************
2025-07-04 13:59:24,920 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:59:24,920 - INFO - After Normalization***************************************
2025-07-04 13:59:24,920 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:59:24,924 - INFO - outputs: cuda:0
2025-07-04 13:59:25,208 - INFO - before .to(local_rank)***************************************
2025-07-04 13:59:25,208 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:59:25,209 - INFO - After .to(local_rank)***************************************
2025-07-04 13:59:25,209 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:59:25,209 - INFO - After Normalization***************************************
2025-07-04 13:59:25,209 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:59:25,213 - INFO - outputs: cuda:0
2025-07-04 13:59:28,395 - INFO - Epoch 78/150 - Train Loss: 0.332115, Val Loss: 0.340799
2025-07-04 13:59:30,633 - INFO - before .to(local_rank)***************************************
2025-07-04 13:59:30,633 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:59:30,634 - INFO - After .to(local_rank)***************************************
2025-07-04 13:59:30,634 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:59:30,634 - INFO - After Normalization***************************************
2025-07-04 13:59:30,634 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:59:30,639 - INFO - outputs: cuda:0
2025-07-04 13:59:30,936 - INFO - before .to(local_rank)***************************************
2025-07-04 13:59:30,936 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:59:30,936 - INFO - After .to(local_rank)***************************************
2025-07-04 13:59:30,936 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:59:30,937 - INFO - After Normalization***************************************
2025-07-04 13:59:30,937 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:59:30,941 - INFO - outputs: cuda:0
2025-07-04 13:59:31,225 - INFO - before .to(local_rank)***************************************
2025-07-04 13:59:31,225 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 13:59:31,226 - INFO - After .to(local_rank)***************************************
2025-07-04 13:59:31,226 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:59:31,226 - INFO - After Normalization***************************************
2025-07-04 13:59:31,226 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 13:59:31,230 - INFO - outputs: cuda:0
2025-07-04 13:59:34,424 - INFO - Epoch 79/150 - Train Loss: 0.323830, Val Loss: 0.352417
2025-07-04 13:59:52,745 - INFO - args.exp_name : Train_Test
2025-07-04 13:59:52,750 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=6, epochs=150, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-07-04 13:59:52,750 - INFO - Starting training with 1 GPUs
2025-07-04 13:59:57,016 - INFO - Total trainable parameters: 1437705
2025-07-04 13:59:57,039 - INFO - Data loaded: 3 training batches, 1 validation batches, 1 test batches
2025-07-04 13:59:57,042 - INFO - Staring training for 150 epochs
2025-07-04 14:00:01,303 - INFO - before .to(local_rank)***************************************
2025-07-04 14:00:01,307 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:00:01,307 - INFO - After .to(local_rank)***************************************
2025-07-04 14:00:01,308 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:01,317 - INFO - After Normalization***************************************
2025-07-04 14:00:01,318 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:01,801 - INFO - outputs: cuda:0
2025-07-04 14:00:02,096 - INFO - before .to(local_rank)***************************************
2025-07-04 14:00:02,096 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:00:02,096 - INFO - After .to(local_rank)***************************************
2025-07-04 14:00:02,096 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:02,096 - INFO - After Normalization***************************************
2025-07-04 14:00:02,096 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:02,102 - INFO - outputs: cuda:0
2025-07-04 14:00:02,385 - INFO - before .to(local_rank)***************************************
2025-07-04 14:00:02,385 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:00:02,386 - INFO - After .to(local_rank)***************************************
2025-07-04 14:00:02,386 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:02,386 - INFO - After Normalization***************************************
2025-07-04 14:00:02,386 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:02,390 - INFO - outputs: cuda:0
2025-07-04 14:00:05,810 - INFO - Epoch 1/150 - Train Loss: 1.283437, Val Loss: 1.146866
2025-07-04 14:00:05,829 - INFO - New best model saved with Val Loss: 1.146866
2025-07-04 14:00:08,078 - INFO - before .to(local_rank)***************************************
2025-07-04 14:00:08,093 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:00:08,093 - INFO - After .to(local_rank)***************************************
2025-07-04 14:00:08,094 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:08,094 - INFO - After Normalization***************************************
2025-07-04 14:00:08,094 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:08,098 - INFO - outputs: cuda:0
2025-07-04 14:00:08,401 - INFO - before .to(local_rank)***************************************
2025-07-04 14:00:08,401 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:00:08,402 - INFO - After .to(local_rank)***************************************
2025-07-04 14:00:08,402 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:08,402 - INFO - After Normalization***************************************
2025-07-04 14:00:08,402 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:08,407 - INFO - outputs: cuda:0
2025-07-04 14:00:08,690 - INFO - before .to(local_rank)***************************************
2025-07-04 14:00:08,690 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:00:08,691 - INFO - After .to(local_rank)***************************************
2025-07-04 14:00:08,691 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:08,691 - INFO - After Normalization***************************************
2025-07-04 14:00:08,691 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:08,695 - INFO - outputs: cuda:0
2025-07-04 14:00:11,876 - INFO - Epoch 2/150 - Train Loss: 1.159811, Val Loss: 1.148012
2025-07-04 14:00:14,148 - INFO - before .to(local_rank)***************************************
2025-07-04 14:00:14,163 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:00:14,163 - INFO - After .to(local_rank)***************************************
2025-07-04 14:00:14,163 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:14,163 - INFO - After Normalization***************************************
2025-07-04 14:00:14,163 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:14,168 - INFO - outputs: cuda:0
2025-07-04 14:00:14,466 - INFO - before .to(local_rank)***************************************
2025-07-04 14:00:14,466 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:00:14,467 - INFO - After .to(local_rank)***************************************
2025-07-04 14:00:14,467 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:14,467 - INFO - After Normalization***************************************
2025-07-04 14:00:14,467 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:14,472 - INFO - outputs: cuda:0
2025-07-04 14:00:14,755 - INFO - before .to(local_rank)***************************************
2025-07-04 14:00:14,755 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:00:14,756 - INFO - After .to(local_rank)***************************************
2025-07-04 14:00:14,756 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:14,756 - INFO - After Normalization***************************************
2025-07-04 14:00:14,756 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:14,760 - INFO - outputs: cuda:0
2025-07-04 14:00:17,941 - INFO - Epoch 3/150 - Train Loss: 1.015355, Val Loss: 1.148288
2025-07-04 14:00:20,196 - INFO - before .to(local_rank)***************************************
2025-07-04 14:00:20,210 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:00:20,210 - INFO - After .to(local_rank)***************************************
2025-07-04 14:00:20,211 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:20,211 - INFO - After Normalization***************************************
2025-07-04 14:00:20,211 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:20,216 - INFO - outputs: cuda:0
2025-07-04 14:00:20,513 - INFO - before .to(local_rank)***************************************
2025-07-04 14:00:20,513 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:00:20,513 - INFO - After .to(local_rank)***************************************
2025-07-04 14:00:20,513 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:20,514 - INFO - After Normalization***************************************
2025-07-04 14:00:20,514 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:20,518 - INFO - outputs: cuda:0
2025-07-04 14:00:20,802 - INFO - before .to(local_rank)***************************************
2025-07-04 14:00:20,802 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:00:20,802 - INFO - After .to(local_rank)***************************************
2025-07-04 14:00:20,802 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:20,802 - INFO - After Normalization***************************************
2025-07-04 14:00:20,802 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:20,807 - INFO - outputs: cuda:0
2025-07-04 14:00:24,021 - INFO - Epoch 4/150 - Train Loss: 0.916734, Val Loss: 1.249089
2025-07-04 14:00:26,289 - INFO - before .to(local_rank)***************************************
2025-07-04 14:00:26,304 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:00:26,304 - INFO - After .to(local_rank)***************************************
2025-07-04 14:00:26,304 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:26,304 - INFO - After Normalization***************************************
2025-07-04 14:00:26,304 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:26,309 - INFO - outputs: cuda:0
2025-07-04 14:00:26,621 - INFO - before .to(local_rank)***************************************
2025-07-04 14:00:26,622 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:00:26,622 - INFO - After .to(local_rank)***************************************
2025-07-04 14:00:26,622 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:26,622 - INFO - After Normalization***************************************
2025-07-04 14:00:26,622 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:26,627 - INFO - outputs: cuda:0
2025-07-04 14:00:26,910 - INFO - before .to(local_rank)***************************************
2025-07-04 14:00:26,910 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:00:26,911 - INFO - After .to(local_rank)***************************************
2025-07-04 14:00:26,911 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:26,911 - INFO - After Normalization***************************************
2025-07-04 14:00:26,911 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:26,915 - INFO - outputs: cuda:0
2025-07-04 14:00:30,083 - INFO - Epoch 5/150 - Train Loss: 0.839702, Val Loss: 1.442995
2025-07-04 14:00:32,322 - INFO - before .to(local_rank)***************************************
2025-07-04 14:00:32,336 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:00:32,336 - INFO - After .to(local_rank)***************************************
2025-07-04 14:00:32,336 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:32,337 - INFO - After Normalization***************************************
2025-07-04 14:00:32,337 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:32,342 - INFO - outputs: cuda:0
2025-07-04 14:00:32,654 - INFO - before .to(local_rank)***************************************
2025-07-04 14:00:32,654 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:00:32,654 - INFO - After .to(local_rank)***************************************
2025-07-04 14:00:32,654 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:32,654 - INFO - After Normalization***************************************
2025-07-04 14:00:32,655 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:32,659 - INFO - outputs: cuda:0
2025-07-04 14:00:32,943 - INFO - before .to(local_rank)***************************************
2025-07-04 14:00:32,943 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:00:32,943 - INFO - After .to(local_rank)***************************************
2025-07-04 14:00:32,943 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:32,943 - INFO - After Normalization***************************************
2025-07-04 14:00:32,943 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:32,948 - INFO - outputs: cuda:0
2025-07-04 14:00:36,139 - INFO - Epoch 6/150 - Train Loss: 0.757819, Val Loss: 1.361055
2025-07-04 14:00:38,393 - INFO - before .to(local_rank)***************************************
2025-07-04 14:00:38,406 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:00:38,406 - INFO - After .to(local_rank)***************************************
2025-07-04 14:00:38,406 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:38,407 - INFO - After Normalization***************************************
2025-07-04 14:00:38,407 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:38,411 - INFO - outputs: cuda:0
2025-07-04 14:00:38,718 - INFO - before .to(local_rank)***************************************
2025-07-04 14:00:38,718 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:00:38,718 - INFO - After .to(local_rank)***************************************
2025-07-04 14:00:38,718 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:38,718 - INFO - After Normalization***************************************
2025-07-04 14:00:38,718 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:38,723 - INFO - outputs: cuda:0
2025-07-04 14:00:39,006 - INFO - before .to(local_rank)***************************************
2025-07-04 14:00:39,007 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:00:39,007 - INFO - After .to(local_rank)***************************************
2025-07-04 14:00:39,007 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:39,007 - INFO - After Normalization***************************************
2025-07-04 14:00:39,007 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:39,011 - INFO - outputs: cuda:0
2025-07-04 14:00:42,216 - INFO - Epoch 7/150 - Train Loss: 0.661384, Val Loss: 1.379884
2025-07-04 14:00:44,464 - INFO - before .to(local_rank)***************************************
2025-07-04 14:00:44,478 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:00:44,478 - INFO - After .to(local_rank)***************************************
2025-07-04 14:00:44,478 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:44,478 - INFO - After Normalization***************************************
2025-07-04 14:00:44,478 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:44,484 - INFO - outputs: cuda:0
2025-07-04 14:00:44,787 - INFO - before .to(local_rank)***************************************
2025-07-04 14:00:44,787 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:00:44,787 - INFO - After .to(local_rank)***************************************
2025-07-04 14:00:44,787 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:44,787 - INFO - After Normalization***************************************
2025-07-04 14:00:44,787 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:44,792 - INFO - outputs: cuda:0
2025-07-04 14:00:45,076 - INFO - before .to(local_rank)***************************************
2025-07-04 14:00:45,076 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:00:45,076 - INFO - After .to(local_rank)***************************************
2025-07-04 14:00:45,076 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:45,076 - INFO - After Normalization***************************************
2025-07-04 14:00:45,076 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:45,081 - INFO - outputs: cuda:0
2025-07-04 14:00:48,259 - INFO - Epoch 8/150 - Train Loss: 0.608690, Val Loss: 1.595568
2025-07-04 14:00:50,499 - INFO - before .to(local_rank)***************************************
2025-07-04 14:00:50,513 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:00:50,513 - INFO - After .to(local_rank)***************************************
2025-07-04 14:00:50,513 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:50,513 - INFO - After Normalization***************************************
2025-07-04 14:00:50,514 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:50,518 - INFO - outputs: cuda:0
2025-07-04 14:00:50,820 - INFO - before .to(local_rank)***************************************
2025-07-04 14:00:50,820 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:00:50,820 - INFO - After .to(local_rank)***************************************
2025-07-04 14:00:50,820 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:50,820 - INFO - After Normalization***************************************
2025-07-04 14:00:50,820 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:50,825 - INFO - outputs: cuda:0
2025-07-04 14:00:51,109 - INFO - before .to(local_rank)***************************************
2025-07-04 14:00:51,109 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:00:51,109 - INFO - After .to(local_rank)***************************************
2025-07-04 14:00:51,109 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:51,109 - INFO - After Normalization***************************************
2025-07-04 14:00:51,109 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:51,114 - INFO - outputs: cuda:0
2025-07-04 14:00:54,319 - INFO - Epoch 9/150 - Train Loss: 0.560139, Val Loss: 1.838627
2025-07-04 14:00:56,580 - INFO - before .to(local_rank)***************************************
2025-07-04 14:00:56,593 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:00:56,593 - INFO - After .to(local_rank)***************************************
2025-07-04 14:00:56,594 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:56,594 - INFO - After Normalization***************************************
2025-07-04 14:00:56,594 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:56,598 - INFO - outputs: cuda:0
2025-07-04 14:00:56,895 - INFO - before .to(local_rank)***************************************
2025-07-04 14:00:56,896 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:00:56,897 - INFO - After .to(local_rank)***************************************
2025-07-04 14:00:56,897 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:56,897 - INFO - After Normalization***************************************
2025-07-04 14:00:56,897 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:56,902 - INFO - outputs: cuda:0
2025-07-04 14:00:57,185 - INFO - before .to(local_rank)***************************************
2025-07-04 14:00:57,185 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:00:57,185 - INFO - After .to(local_rank)***************************************
2025-07-04 14:00:57,186 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:57,186 - INFO - After Normalization***************************************
2025-07-04 14:00:57,186 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:00:57,190 - INFO - outputs: cuda:0
2025-07-04 14:01:00,344 - INFO - Epoch 10/150 - Train Loss: 0.526667, Val Loss: 1.521763
2025-07-04 14:01:02,770 - INFO - before .to(local_rank)***************************************
2025-07-04 14:01:02,783 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:01:02,783 - INFO - After .to(local_rank)***************************************
2025-07-04 14:01:02,783 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:02,784 - INFO - After Normalization***************************************
2025-07-04 14:01:02,784 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:02,788 - INFO - outputs: cuda:0
2025-07-04 14:01:03,089 - INFO - before .to(local_rank)***************************************
2025-07-04 14:01:03,089 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:01:03,089 - INFO - After .to(local_rank)***************************************
2025-07-04 14:01:03,089 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:03,089 - INFO - After Normalization***************************************
2025-07-04 14:01:03,089 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:03,094 - INFO - outputs: cuda:0
2025-07-04 14:01:03,382 - INFO - before .to(local_rank)***************************************
2025-07-04 14:01:03,382 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:01:03,382 - INFO - After .to(local_rank)***************************************
2025-07-04 14:01:03,382 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:03,382 - INFO - After Normalization***************************************
2025-07-04 14:01:03,382 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:03,387 - INFO - outputs: cuda:0
2025-07-04 14:01:06,544 - INFO - Epoch 11/150 - Train Loss: 0.494009, Val Loss: 1.437564
2025-07-04 14:01:08,794 - INFO - before .to(local_rank)***************************************
2025-07-04 14:01:08,808 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:01:08,808 - INFO - After .to(local_rank)***************************************
2025-07-04 14:01:08,808 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:08,808 - INFO - After Normalization***************************************
2025-07-04 14:01:08,808 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:08,813 - INFO - outputs: cuda:0
2025-07-04 14:01:09,114 - INFO - before .to(local_rank)***************************************
2025-07-04 14:01:09,114 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:01:09,114 - INFO - After .to(local_rank)***************************************
2025-07-04 14:01:09,115 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:09,115 - INFO - After Normalization***************************************
2025-07-04 14:01:09,115 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:09,120 - INFO - outputs: cuda:0
2025-07-04 14:01:09,408 - INFO - before .to(local_rank)***************************************
2025-07-04 14:01:09,408 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:01:09,408 - INFO - After .to(local_rank)***************************************
2025-07-04 14:01:09,408 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:09,409 - INFO - After Normalization***************************************
2025-07-04 14:01:09,409 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:09,413 - INFO - outputs: cuda:0
2025-07-04 14:01:12,608 - INFO - Epoch 12/150 - Train Loss: 0.474216, Val Loss: 1.348367
2025-07-04 14:01:14,860 - INFO - before .to(local_rank)***************************************
2025-07-04 14:01:14,874 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:01:14,874 - INFO - After .to(local_rank)***************************************
2025-07-04 14:01:14,874 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:14,875 - INFO - After Normalization***************************************
2025-07-04 14:01:14,875 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:14,879 - INFO - outputs: cuda:0
2025-07-04 14:01:15,177 - INFO - before .to(local_rank)***************************************
2025-07-04 14:01:15,177 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:01:15,177 - INFO - After .to(local_rank)***************************************
2025-07-04 14:01:15,177 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:15,177 - INFO - After Normalization***************************************
2025-07-04 14:01:15,177 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:15,182 - INFO - outputs: cuda:0
2025-07-04 14:01:15,469 - INFO - before .to(local_rank)***************************************
2025-07-04 14:01:15,469 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:01:15,469 - INFO - After .to(local_rank)***************************************
2025-07-04 14:01:15,470 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:15,470 - INFO - After Normalization***************************************
2025-07-04 14:01:15,470 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:15,474 - INFO - outputs: cuda:0
2025-07-04 14:01:18,677 - INFO - Epoch 13/150 - Train Loss: 0.457834, Val Loss: 1.089559
2025-07-04 14:01:18,693 - INFO - New best model saved with Val Loss: 1.089559
2025-07-04 14:01:20,954 - INFO - before .to(local_rank)***************************************
2025-07-04 14:01:20,967 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:01:20,967 - INFO - After .to(local_rank)***************************************
2025-07-04 14:01:20,967 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:20,967 - INFO - After Normalization***************************************
2025-07-04 14:01:20,967 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:20,972 - INFO - outputs: cuda:0
2025-07-04 14:01:21,285 - INFO - before .to(local_rank)***************************************
2025-07-04 14:01:21,285 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:01:21,285 - INFO - After .to(local_rank)***************************************
2025-07-04 14:01:21,285 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:21,286 - INFO - After Normalization***************************************
2025-07-04 14:01:21,286 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:21,291 - INFO - outputs: cuda:0
2025-07-04 14:01:21,579 - INFO - before .to(local_rank)***************************************
2025-07-04 14:01:21,579 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:01:21,579 - INFO - After .to(local_rank)***************************************
2025-07-04 14:01:21,579 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:21,579 - INFO - After Normalization***************************************
2025-07-04 14:01:21,580 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:21,584 - INFO - outputs: cuda:0
2025-07-04 14:01:24,792 - INFO - Epoch 14/150 - Train Loss: 0.455360, Val Loss: 0.832426
2025-07-04 14:01:24,808 - INFO - New best model saved with Val Loss: 0.832426
2025-07-04 14:01:27,066 - INFO - before .to(local_rank)***************************************
2025-07-04 14:01:27,080 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:01:27,081 - INFO - After .to(local_rank)***************************************
2025-07-04 14:01:27,081 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:27,081 - INFO - After Normalization***************************************
2025-07-04 14:01:27,081 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:27,085 - INFO - outputs: cuda:0
2025-07-04 14:01:27,392 - INFO - before .to(local_rank)***************************************
2025-07-04 14:01:27,393 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:01:27,393 - INFO - After .to(local_rank)***************************************
2025-07-04 14:01:27,393 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:27,393 - INFO - After Normalization***************************************
2025-07-04 14:01:27,393 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:27,398 - INFO - outputs: cuda:0
2025-07-04 14:01:27,681 - INFO - before .to(local_rank)***************************************
2025-07-04 14:01:27,681 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:01:27,682 - INFO - After .to(local_rank)***************************************
2025-07-04 14:01:27,682 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:27,682 - INFO - After Normalization***************************************
2025-07-04 14:01:27,682 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:27,686 - INFO - outputs: cuda:0
2025-07-04 14:01:30,881 - INFO - Epoch 15/150 - Train Loss: 0.447783, Val Loss: 0.654857
2025-07-04 14:01:30,897 - INFO - New best model saved with Val Loss: 0.654857
2025-07-04 14:01:33,164 - INFO - before .to(local_rank)***************************************
2025-07-04 14:01:33,178 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:01:33,179 - INFO - After .to(local_rank)***************************************
2025-07-04 14:01:33,179 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:33,179 - INFO - After Normalization***************************************
2025-07-04 14:01:33,179 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:33,183 - INFO - outputs: cuda:0
2025-07-04 14:01:33,483 - INFO - before .to(local_rank)***************************************
2025-07-04 14:01:33,483 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:01:33,484 - INFO - After .to(local_rank)***************************************
2025-07-04 14:01:33,484 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:33,484 - INFO - After Normalization***************************************
2025-07-04 14:01:33,485 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:33,489 - INFO - outputs: cuda:0
2025-07-04 14:01:33,773 - INFO - before .to(local_rank)***************************************
2025-07-04 14:01:33,773 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:01:33,773 - INFO - After .to(local_rank)***************************************
2025-07-04 14:01:33,773 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:33,773 - INFO - After Normalization***************************************
2025-07-04 14:01:33,773 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:33,778 - INFO - outputs: cuda:0
2025-07-04 14:01:36,953 - INFO - Epoch 16/150 - Train Loss: 0.446389, Val Loss: 0.548675
2025-07-04 14:01:36,967 - INFO - New best model saved with Val Loss: 0.548675
2025-07-04 14:01:39,224 - INFO - before .to(local_rank)***************************************
2025-07-04 14:01:39,238 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:01:39,238 - INFO - After .to(local_rank)***************************************
2025-07-04 14:01:39,238 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:39,238 - INFO - After Normalization***************************************
2025-07-04 14:01:39,238 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:39,243 - INFO - outputs: cuda:0
2025-07-04 14:01:39,562 - INFO - before .to(local_rank)***************************************
2025-07-04 14:01:39,562 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:01:39,563 - INFO - After .to(local_rank)***************************************
2025-07-04 14:01:39,563 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:39,563 - INFO - After Normalization***************************************
2025-07-04 14:01:39,563 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:39,567 - INFO - outputs: cuda:0
2025-07-04 14:01:39,851 - INFO - before .to(local_rank)***************************************
2025-07-04 14:01:39,851 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:01:39,851 - INFO - After .to(local_rank)***************************************
2025-07-04 14:01:39,851 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:39,852 - INFO - After Normalization***************************************
2025-07-04 14:01:39,852 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:39,856 - INFO - outputs: cuda:0
2025-07-04 14:01:43,041 - INFO - Epoch 17/150 - Train Loss: 0.440610, Val Loss: 0.495317
2025-07-04 14:01:43,056 - INFO - New best model saved with Val Loss: 0.495317
2025-07-04 14:01:45,318 - INFO - before .to(local_rank)***************************************
2025-07-04 14:01:45,331 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:01:45,332 - INFO - After .to(local_rank)***************************************
2025-07-04 14:01:45,332 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:45,332 - INFO - After Normalization***************************************
2025-07-04 14:01:45,332 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:45,337 - INFO - outputs: cuda:0
2025-07-04 14:01:45,645 - INFO - before .to(local_rank)***************************************
2025-07-04 14:01:45,646 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:01:45,646 - INFO - After .to(local_rank)***************************************
2025-07-04 14:01:45,646 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:45,647 - INFO - After Normalization***************************************
2025-07-04 14:01:45,647 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:45,651 - INFO - outputs: cuda:0
2025-07-04 14:01:45,935 - INFO - before .to(local_rank)***************************************
2025-07-04 14:01:45,935 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:01:45,935 - INFO - After .to(local_rank)***************************************
2025-07-04 14:01:45,935 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:45,936 - INFO - After Normalization***************************************
2025-07-04 14:01:45,936 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:45,940 - INFO - outputs: cuda:0
2025-07-04 14:01:49,111 - INFO - Epoch 18/150 - Train Loss: 0.438833, Val Loss: 0.464275
2025-07-04 14:01:49,127 - INFO - New best model saved with Val Loss: 0.464275
2025-07-04 14:01:51,385 - INFO - before .to(local_rank)***************************************
2025-07-04 14:01:51,398 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:01:51,399 - INFO - After .to(local_rank)***************************************
2025-07-04 14:01:51,399 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:51,399 - INFO - After Normalization***************************************
2025-07-04 14:01:51,399 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:51,403 - INFO - outputs: cuda:0
2025-07-04 14:01:51,710 - INFO - before .to(local_rank)***************************************
2025-07-04 14:01:51,710 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:01:51,710 - INFO - After .to(local_rank)***************************************
2025-07-04 14:01:51,710 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:51,710 - INFO - After Normalization***************************************
2025-07-04 14:01:51,710 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:51,715 - INFO - outputs: cuda:0
2025-07-04 14:01:51,999 - INFO - before .to(local_rank)***************************************
2025-07-04 14:01:51,999 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:01:51,999 - INFO - After .to(local_rank)***************************************
2025-07-04 14:01:51,999 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:51,999 - INFO - After Normalization***************************************
2025-07-04 14:01:51,999 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:52,004 - INFO - outputs: cuda:0
2025-07-04 14:01:55,192 - INFO - Epoch 19/150 - Train Loss: 0.439969, Val Loss: 0.443737
2025-07-04 14:01:55,207 - INFO - New best model saved with Val Loss: 0.443737
2025-07-04 14:01:57,449 - INFO - before .to(local_rank)***************************************
2025-07-04 14:01:57,462 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:01:57,463 - INFO - After .to(local_rank)***************************************
2025-07-04 14:01:57,463 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:57,463 - INFO - After Normalization***************************************
2025-07-04 14:01:57,463 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:57,468 - INFO - outputs: cuda:0
2025-07-04 14:01:57,770 - INFO - before .to(local_rank)***************************************
2025-07-04 14:01:57,770 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:01:57,770 - INFO - After .to(local_rank)***************************************
2025-07-04 14:01:57,771 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:57,771 - INFO - After Normalization***************************************
2025-07-04 14:01:57,771 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:57,776 - INFO - outputs: cuda:0
2025-07-04 14:01:58,060 - INFO - before .to(local_rank)***************************************
2025-07-04 14:01:58,060 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:01:58,060 - INFO - After .to(local_rank)***************************************
2025-07-04 14:01:58,060 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:58,060 - INFO - After Normalization***************************************
2025-07-04 14:01:58,060 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:01:58,065 - INFO - outputs: cuda:0
2025-07-04 14:02:01,240 - INFO - Epoch 20/150 - Train Loss: 0.431883, Val Loss: 0.428062
2025-07-04 14:02:01,255 - INFO - New best model saved with Val Loss: 0.428062
2025-07-04 14:02:03,624 - INFO - before .to(local_rank)***************************************
2025-07-04 14:02:03,624 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:02:03,624 - INFO - After .to(local_rank)***************************************
2025-07-04 14:02:03,624 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:03,625 - INFO - After Normalization***************************************
2025-07-04 14:02:03,625 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:03,629 - INFO - outputs: cuda:0
2025-07-04 14:02:03,935 - INFO - before .to(local_rank)***************************************
2025-07-04 14:02:03,935 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:02:03,935 - INFO - After .to(local_rank)***************************************
2025-07-04 14:02:03,935 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:03,935 - INFO - After Normalization***************************************
2025-07-04 14:02:03,935 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:03,940 - INFO - outputs: cuda:0
2025-07-04 14:02:04,223 - INFO - before .to(local_rank)***************************************
2025-07-04 14:02:04,223 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:02:04,224 - INFO - After .to(local_rank)***************************************
2025-07-04 14:02:04,224 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:04,224 - INFO - After Normalization***************************************
2025-07-04 14:02:04,224 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:04,228 - INFO - outputs: cuda:0
2025-07-04 14:02:07,422 - INFO - Epoch 21/150 - Train Loss: 0.431155, Val Loss: 0.423547
2025-07-04 14:02:07,438 - INFO - New best model saved with Val Loss: 0.423547
2025-07-04 14:02:09,708 - INFO - before .to(local_rank)***************************************
2025-07-04 14:02:09,708 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:02:09,709 - INFO - After .to(local_rank)***************************************
2025-07-04 14:02:09,709 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:09,709 - INFO - After Normalization***************************************
2025-07-04 14:02:09,709 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:09,714 - INFO - outputs: cuda:0
2025-07-04 14:02:10,014 - INFO - before .to(local_rank)***************************************
2025-07-04 14:02:10,015 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:02:10,015 - INFO - After .to(local_rank)***************************************
2025-07-04 14:02:10,015 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:10,016 - INFO - After Normalization***************************************
2025-07-04 14:02:10,016 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:10,021 - INFO - outputs: cuda:0
2025-07-04 14:02:10,304 - INFO - before .to(local_rank)***************************************
2025-07-04 14:02:10,304 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:02:10,305 - INFO - After .to(local_rank)***************************************
2025-07-04 14:02:10,305 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:10,305 - INFO - After Normalization***************************************
2025-07-04 14:02:10,305 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:10,309 - INFO - outputs: cuda:0
2025-07-04 14:02:13,508 - INFO - Epoch 22/150 - Train Loss: 0.428144, Val Loss: 0.426146
2025-07-04 14:02:15,778 - INFO - before .to(local_rank)***************************************
2025-07-04 14:02:15,778 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:02:15,778 - INFO - After .to(local_rank)***************************************
2025-07-04 14:02:15,779 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:15,779 - INFO - After Normalization***************************************
2025-07-04 14:02:15,779 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:15,783 - INFO - outputs: cuda:0
2025-07-04 14:02:16,080 - INFO - before .to(local_rank)***************************************
2025-07-04 14:02:16,081 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:02:16,081 - INFO - After .to(local_rank)***************************************
2025-07-04 14:02:16,081 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:16,081 - INFO - After Normalization***************************************
2025-07-04 14:02:16,081 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:16,086 - INFO - outputs: cuda:0
2025-07-04 14:02:16,369 - INFO - before .to(local_rank)***************************************
2025-07-04 14:02:16,369 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:02:16,370 - INFO - After .to(local_rank)***************************************
2025-07-04 14:02:16,370 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:16,370 - INFO - After Normalization***************************************
2025-07-04 14:02:16,370 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:16,374 - INFO - outputs: cuda:0
2025-07-04 14:02:19,579 - INFO - Epoch 23/150 - Train Loss: 0.425435, Val Loss: 0.427524
2025-07-04 14:02:21,833 - INFO - before .to(local_rank)***************************************
2025-07-04 14:02:21,833 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:02:21,833 - INFO - After .to(local_rank)***************************************
2025-07-04 14:02:21,833 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:21,834 - INFO - After Normalization***************************************
2025-07-04 14:02:21,834 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:21,838 - INFO - outputs: cuda:0
2025-07-04 14:02:22,137 - INFO - before .to(local_rank)***************************************
2025-07-04 14:02:22,137 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:02:22,137 - INFO - After .to(local_rank)***************************************
2025-07-04 14:02:22,137 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:22,137 - INFO - After Normalization***************************************
2025-07-04 14:02:22,138 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:22,143 - INFO - outputs: cuda:0
2025-07-04 14:02:22,426 - INFO - before .to(local_rank)***************************************
2025-07-04 14:02:22,426 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:02:22,427 - INFO - After .to(local_rank)***************************************
2025-07-04 14:02:22,427 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:22,427 - INFO - After Normalization***************************************
2025-07-04 14:02:22,427 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:22,431 - INFO - outputs: cuda:0
2025-07-04 14:02:25,616 - INFO - Epoch 24/150 - Train Loss: 0.422210, Val Loss: 0.422279
2025-07-04 14:02:25,631 - INFO - New best model saved with Val Loss: 0.422279
2025-07-04 14:02:27,871 - INFO - before .to(local_rank)***************************************
2025-07-04 14:02:27,871 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:02:27,872 - INFO - After .to(local_rank)***************************************
2025-07-04 14:02:27,872 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:27,872 - INFO - After Normalization***************************************
2025-07-04 14:02:27,872 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:27,877 - INFO - outputs: cuda:0
2025-07-04 14:02:28,187 - INFO - before .to(local_rank)***************************************
2025-07-04 14:02:28,187 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:02:28,187 - INFO - After .to(local_rank)***************************************
2025-07-04 14:02:28,187 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:28,187 - INFO - After Normalization***************************************
2025-07-04 14:02:28,187 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:28,192 - INFO - outputs: cuda:0
2025-07-04 14:02:28,475 - INFO - before .to(local_rank)***************************************
2025-07-04 14:02:28,475 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:02:28,475 - INFO - After .to(local_rank)***************************************
2025-07-04 14:02:28,476 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:28,476 - INFO - After Normalization***************************************
2025-07-04 14:02:28,476 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:28,480 - INFO - outputs: cuda:0
2025-07-04 14:02:31,663 - INFO - Epoch 25/150 - Train Loss: 0.423424, Val Loss: 0.427988
2025-07-04 14:02:33,890 - INFO - before .to(local_rank)***************************************
2025-07-04 14:02:33,891 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:02:33,891 - INFO - After .to(local_rank)***************************************
2025-07-04 14:02:33,891 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:33,891 - INFO - After Normalization***************************************
2025-07-04 14:02:33,891 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:33,896 - INFO - outputs: cuda:0
2025-07-04 14:02:34,195 - INFO - before .to(local_rank)***************************************
2025-07-04 14:02:34,195 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:02:34,196 - INFO - After .to(local_rank)***************************************
2025-07-04 14:02:34,196 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:34,196 - INFO - After Normalization***************************************
2025-07-04 14:02:34,196 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:34,201 - INFO - outputs: cuda:0
2025-07-04 14:02:34,485 - INFO - before .to(local_rank)***************************************
2025-07-04 14:02:34,485 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:02:34,485 - INFO - After .to(local_rank)***************************************
2025-07-04 14:02:34,485 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:34,485 - INFO - After Normalization***************************************
2025-07-04 14:02:34,485 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:34,490 - INFO - outputs: cuda:0
2025-07-04 14:02:37,674 - INFO - Epoch 26/150 - Train Loss: 0.416589, Val Loss: 0.438708
2025-07-04 14:02:39,928 - INFO - before .to(local_rank)***************************************
2025-07-04 14:02:39,928 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:02:39,929 - INFO - After .to(local_rank)***************************************
2025-07-04 14:02:39,929 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:39,929 - INFO - After Normalization***************************************
2025-07-04 14:02:39,929 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:39,934 - INFO - outputs: cuda:0
2025-07-04 14:02:40,245 - INFO - before .to(local_rank)***************************************
2025-07-04 14:02:40,245 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:02:40,245 - INFO - After .to(local_rank)***************************************
2025-07-04 14:02:40,245 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:40,245 - INFO - After Normalization***************************************
2025-07-04 14:02:40,245 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:40,250 - INFO - outputs: cuda:0
2025-07-04 14:02:40,533 - INFO - before .to(local_rank)***************************************
2025-07-04 14:02:40,534 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:02:40,534 - INFO - After .to(local_rank)***************************************
2025-07-04 14:02:40,534 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:40,534 - INFO - After Normalization***************************************
2025-07-04 14:02:40,534 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:40,539 - INFO - outputs: cuda:0
2025-07-04 14:02:43,695 - INFO - Epoch 27/150 - Train Loss: 0.415543, Val Loss: 0.429039
2025-07-04 14:02:45,939 - INFO - before .to(local_rank)***************************************
2025-07-04 14:02:45,939 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:02:45,940 - INFO - After .to(local_rank)***************************************
2025-07-04 14:02:45,940 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:45,940 - INFO - After Normalization***************************************
2025-07-04 14:02:45,940 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:45,944 - INFO - outputs: cuda:0
2025-07-04 14:02:46,239 - INFO - before .to(local_rank)***************************************
2025-07-04 14:02:46,239 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:02:46,240 - INFO - After .to(local_rank)***************************************
2025-07-04 14:02:46,240 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:46,240 - INFO - After Normalization***************************************
2025-07-04 14:02:46,240 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:46,244 - INFO - outputs: cuda:0
2025-07-04 14:02:46,528 - INFO - before .to(local_rank)***************************************
2025-07-04 14:02:46,529 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:02:46,529 - INFO - After .to(local_rank)***************************************
2025-07-04 14:02:46,529 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:46,529 - INFO - After Normalization***************************************
2025-07-04 14:02:46,529 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:46,534 - INFO - outputs: cuda:0
2025-07-04 14:02:49,700 - INFO - Epoch 28/150 - Train Loss: 0.413719, Val Loss: 0.420002
2025-07-04 14:02:49,716 - INFO - New best model saved with Val Loss: 0.420002
2025-07-04 14:02:51,972 - INFO - before .to(local_rank)***************************************
2025-07-04 14:02:51,972 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:02:51,973 - INFO - After .to(local_rank)***************************************
2025-07-04 14:02:51,973 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:51,973 - INFO - After Normalization***************************************
2025-07-04 14:02:51,973 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:51,978 - INFO - outputs: cuda:0
2025-07-04 14:02:52,276 - INFO - before .to(local_rank)***************************************
2025-07-04 14:02:52,276 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:02:52,276 - INFO - After .to(local_rank)***************************************
2025-07-04 14:02:52,276 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:52,276 - INFO - After Normalization***************************************
2025-07-04 14:02:52,276 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:52,281 - INFO - outputs: cuda:0
2025-07-04 14:02:52,565 - INFO - before .to(local_rank)***************************************
2025-07-04 14:02:52,565 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:02:52,565 - INFO - After .to(local_rank)***************************************
2025-07-04 14:02:52,565 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:52,565 - INFO - After Normalization***************************************
2025-07-04 14:02:52,565 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:52,570 - INFO - outputs: cuda:0
2025-07-04 14:02:55,747 - INFO - Epoch 29/150 - Train Loss: 0.410406, Val Loss: 0.413966
2025-07-04 14:02:55,761 - INFO - New best model saved with Val Loss: 0.413966
2025-07-04 14:02:58,022 - INFO - before .to(local_rank)***************************************
2025-07-04 14:02:58,022 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:02:58,023 - INFO - After .to(local_rank)***************************************
2025-07-04 14:02:58,023 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:58,023 - INFO - After Normalization***************************************
2025-07-04 14:02:58,023 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:58,028 - INFO - outputs: cuda:0
2025-07-04 14:02:58,342 - INFO - before .to(local_rank)***************************************
2025-07-04 14:02:58,343 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:02:58,343 - INFO - After .to(local_rank)***************************************
2025-07-04 14:02:58,343 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:58,343 - INFO - After Normalization***************************************
2025-07-04 14:02:58,343 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:58,348 - INFO - outputs: cuda:0
2025-07-04 14:02:58,631 - INFO - before .to(local_rank)***************************************
2025-07-04 14:02:58,632 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:02:58,632 - INFO - After .to(local_rank)***************************************
2025-07-04 14:02:58,632 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:58,633 - INFO - After Normalization***************************************
2025-07-04 14:02:58,633 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:02:58,637 - INFO - outputs: cuda:0
2025-07-04 14:03:01,817 - INFO - Epoch 30/150 - Train Loss: 0.409573, Val Loss: 0.411146
2025-07-04 14:03:01,831 - INFO - New best model saved with Val Loss: 0.411146
2025-07-04 14:03:04,208 - INFO - before .to(local_rank)***************************************
2025-07-04 14:03:04,208 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:03:04,208 - INFO - After .to(local_rank)***************************************
2025-07-04 14:03:04,208 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:04,208 - INFO - After Normalization***************************************
2025-07-04 14:03:04,208 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:04,213 - INFO - outputs: cuda:0
2025-07-04 14:03:04,510 - INFO - before .to(local_rank)***************************************
2025-07-04 14:03:04,510 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:03:04,510 - INFO - After .to(local_rank)***************************************
2025-07-04 14:03:04,510 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:04,511 - INFO - After Normalization***************************************
2025-07-04 14:03:04,511 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:04,515 - INFO - outputs: cuda:0
2025-07-04 14:03:04,799 - INFO - before .to(local_rank)***************************************
2025-07-04 14:03:04,799 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:03:04,799 - INFO - After .to(local_rank)***************************************
2025-07-04 14:03:04,799 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:04,799 - INFO - After Normalization***************************************
2025-07-04 14:03:04,799 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:04,804 - INFO - outputs: cuda:0
2025-07-04 14:03:07,996 - INFO - Epoch 31/150 - Train Loss: 0.407763, Val Loss: 0.405612
2025-07-04 14:03:08,015 - INFO - New best model saved with Val Loss: 0.405612
2025-07-04 14:03:10,260 - INFO - before .to(local_rank)***************************************
2025-07-04 14:03:10,260 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:03:10,260 - INFO - After .to(local_rank)***************************************
2025-07-04 14:03:10,260 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:10,260 - INFO - After Normalization***************************************
2025-07-04 14:03:10,260 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:10,265 - INFO - outputs: cuda:0
2025-07-04 14:03:10,562 - INFO - before .to(local_rank)***************************************
2025-07-04 14:03:10,562 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:03:10,562 - INFO - After .to(local_rank)***************************************
2025-07-04 14:03:10,562 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:10,562 - INFO - After Normalization***************************************
2025-07-04 14:03:10,563 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:10,567 - INFO - outputs: cuda:0
2025-07-04 14:03:10,851 - INFO - before .to(local_rank)***************************************
2025-07-04 14:03:10,852 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:03:10,852 - INFO - After .to(local_rank)***************************************
2025-07-04 14:03:10,852 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:10,852 - INFO - After Normalization***************************************
2025-07-04 14:03:10,852 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:10,857 - INFO - outputs: cuda:0
2025-07-04 14:03:14,040 - INFO - Epoch 32/150 - Train Loss: 0.407623, Val Loss: 0.406176
2025-07-04 14:03:16,273 - INFO - before .to(local_rank)***************************************
2025-07-04 14:03:16,273 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:03:16,274 - INFO - After .to(local_rank)***************************************
2025-07-04 14:03:16,274 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:16,274 - INFO - After Normalization***************************************
2025-07-04 14:03:16,274 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:16,279 - INFO - outputs: cuda:0
2025-07-04 14:03:16,575 - INFO - before .to(local_rank)***************************************
2025-07-04 14:03:16,575 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:03:16,575 - INFO - After .to(local_rank)***************************************
2025-07-04 14:03:16,575 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:16,575 - INFO - After Normalization***************************************
2025-07-04 14:03:16,576 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:16,580 - INFO - outputs: cuda:0
2025-07-04 14:03:16,864 - INFO - before .to(local_rank)***************************************
2025-07-04 14:03:16,864 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:03:16,864 - INFO - After .to(local_rank)***************************************
2025-07-04 14:03:16,864 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:16,864 - INFO - After Normalization***************************************
2025-07-04 14:03:16,864 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:16,869 - INFO - outputs: cuda:0
2025-07-04 14:03:20,036 - INFO - Epoch 33/150 - Train Loss: 0.403604, Val Loss: 0.407962
2025-07-04 14:03:22,279 - INFO - before .to(local_rank)***************************************
2025-07-04 14:03:22,279 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:03:22,280 - INFO - After .to(local_rank)***************************************
2025-07-04 14:03:22,280 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:22,280 - INFO - After Normalization***************************************
2025-07-04 14:03:22,280 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:22,285 - INFO - outputs: cuda:0
2025-07-04 14:03:22,583 - INFO - before .to(local_rank)***************************************
2025-07-04 14:03:22,583 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:03:22,583 - INFO - After .to(local_rank)***************************************
2025-07-04 14:03:22,583 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:22,583 - INFO - After Normalization***************************************
2025-07-04 14:03:22,583 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:22,588 - INFO - outputs: cuda:0
2025-07-04 14:03:22,871 - INFO - before .to(local_rank)***************************************
2025-07-04 14:03:22,872 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:03:22,872 - INFO - After .to(local_rank)***************************************
2025-07-04 14:03:22,873 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:22,873 - INFO - After Normalization***************************************
2025-07-04 14:03:22,873 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:22,877 - INFO - outputs: cuda:0
2025-07-04 14:03:26,046 - INFO - Epoch 34/150 - Train Loss: 0.399802, Val Loss: 0.401497
2025-07-04 14:03:26,062 - INFO - New best model saved with Val Loss: 0.401497
2025-07-04 14:03:28,313 - INFO - before .to(local_rank)***************************************
2025-07-04 14:03:28,313 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:03:28,314 - INFO - After .to(local_rank)***************************************
2025-07-04 14:03:28,314 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:28,314 - INFO - After Normalization***************************************
2025-07-04 14:03:28,314 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:28,319 - INFO - outputs: cuda:0
2025-07-04 14:03:28,616 - INFO - before .to(local_rank)***************************************
2025-07-04 14:03:28,616 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:03:28,616 - INFO - After .to(local_rank)***************************************
2025-07-04 14:03:28,616 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:28,616 - INFO - After Normalization***************************************
2025-07-04 14:03:28,616 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:28,621 - INFO - outputs: cuda:0
2025-07-04 14:03:28,905 - INFO - before .to(local_rank)***************************************
2025-07-04 14:03:28,905 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:03:28,905 - INFO - After .to(local_rank)***************************************
2025-07-04 14:03:28,905 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:28,905 - INFO - After Normalization***************************************
2025-07-04 14:03:28,905 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:28,910 - INFO - outputs: cuda:0
2025-07-04 14:03:32,089 - INFO - Epoch 35/150 - Train Loss: 0.400421, Val Loss: 0.400646
2025-07-04 14:03:32,104 - INFO - New best model saved with Val Loss: 0.400646
2025-07-04 14:03:34,376 - INFO - before .to(local_rank)***************************************
2025-07-04 14:03:34,376 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:03:34,377 - INFO - After .to(local_rank)***************************************
2025-07-04 14:03:34,377 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:34,377 - INFO - After Normalization***************************************
2025-07-04 14:03:34,377 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:34,382 - INFO - outputs: cuda:0
2025-07-04 14:03:34,683 - INFO - before .to(local_rank)***************************************
2025-07-04 14:03:34,683 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:03:34,683 - INFO - After .to(local_rank)***************************************
2025-07-04 14:03:34,684 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:34,684 - INFO - After Normalization***************************************
2025-07-04 14:03:34,684 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:34,688 - INFO - outputs: cuda:0
2025-07-04 14:03:34,972 - INFO - before .to(local_rank)***************************************
2025-07-04 14:03:34,972 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:03:34,972 - INFO - After .to(local_rank)***************************************
2025-07-04 14:03:34,973 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:34,973 - INFO - After Normalization***************************************
2025-07-04 14:03:34,973 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:34,978 - INFO - outputs: cuda:0
2025-07-04 14:03:38,155 - INFO - Epoch 36/150 - Train Loss: 0.395775, Val Loss: 0.403946
2025-07-04 14:03:40,392 - INFO - before .to(local_rank)***************************************
2025-07-04 14:03:40,393 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:03:40,393 - INFO - After .to(local_rank)***************************************
2025-07-04 14:03:40,393 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:40,393 - INFO - After Normalization***************************************
2025-07-04 14:03:40,393 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:40,398 - INFO - outputs: cuda:0
2025-07-04 14:03:40,693 - INFO - before .to(local_rank)***************************************
2025-07-04 14:03:40,694 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:03:40,694 - INFO - After .to(local_rank)***************************************
2025-07-04 14:03:40,694 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:40,694 - INFO - After Normalization***************************************
2025-07-04 14:03:40,694 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:40,699 - INFO - outputs: cuda:0
2025-07-04 14:03:40,982 - INFO - before .to(local_rank)***************************************
2025-07-04 14:03:40,982 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:03:40,983 - INFO - After .to(local_rank)***************************************
2025-07-04 14:03:40,983 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:40,983 - INFO - After Normalization***************************************
2025-07-04 14:03:40,983 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:40,987 - INFO - outputs: cuda:0
2025-07-04 14:03:44,180 - INFO - Epoch 37/150 - Train Loss: 0.395949, Val Loss: 0.401222
2025-07-04 14:03:46,426 - INFO - before .to(local_rank)***************************************
2025-07-04 14:03:46,426 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:03:46,426 - INFO - After .to(local_rank)***************************************
2025-07-04 14:03:46,426 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:46,426 - INFO - After Normalization***************************************
2025-07-04 14:03:46,427 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:46,431 - INFO - outputs: cuda:0
2025-07-04 14:03:46,728 - INFO - before .to(local_rank)***************************************
2025-07-04 14:03:46,728 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:03:46,728 - INFO - After .to(local_rank)***************************************
2025-07-04 14:03:46,728 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:46,729 - INFO - After Normalization***************************************
2025-07-04 14:03:46,729 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:46,733 - INFO - outputs: cuda:0
2025-07-04 14:03:47,017 - INFO - before .to(local_rank)***************************************
2025-07-04 14:03:47,017 - INFO - data and targets: (device(type='cpu'), device(type='cpu'))
2025-07-04 14:03:47,017 - INFO - After .to(local_rank)***************************************
2025-07-04 14:03:47,017 - INFO - (device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:47,017 - INFO - After Normalization***************************************
2025-07-04 14:03:47,018 - INFO - data and targets:(device(type='cuda', index=0), device(type='cuda', index=0))
2025-07-04 14:03:47,022 - INFO - outputs: cuda:0
2025-07-04 14:03:50,195 - INFO - Epoch 38/150 - Train Loss: 0.393724, Val Loss: 0.398120
2025-07-04 14:03:50,210 - INFO - New best model saved with Val Loss: 0.398120
2025-07-04 14:04:10,422 - INFO - args.exp_name : Train_Test
2025-07-04 14:04:10,428 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/Data_Pressure/Pressure_VTK', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/Data_Pressure/Cache_data', num_points=10000, batch_size=6, epochs=150, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-07-04 14:04:10,428 - INFO - Starting training with 1 GPUs
2025-07-04 14:04:14,610 - INFO - Total trainable parameters: 1437705
2025-07-04 14:04:14,639 - INFO - Data loaded: 3 training batches, 1 validation batches, 1 test batches
2025-07-04 14:04:14,640 - INFO - Staring training for 150 epochs
2025-07-04 14:04:22,781 - INFO - Epoch 1/150 - Train Loss: 1.283437, Val Loss: 1.146866
2025-07-04 14:04:22,800 - INFO - New best model saved with Val Loss: 1.146866
2025-07-04 14:04:28,883 - INFO - Epoch 2/150 - Train Loss: 1.159811, Val Loss: 1.148012
2025-07-04 14:04:34,995 - INFO - Epoch 3/150 - Train Loss: 1.015355, Val Loss: 1.148288
2025-07-04 14:04:41,081 - INFO - Epoch 4/150 - Train Loss: 0.916734, Val Loss: 1.249089
2025-07-04 14:04:47,161 - INFO - Epoch 5/150 - Train Loss: 0.839702, Val Loss: 1.442995
2025-07-04 14:04:53,276 - INFO - Epoch 6/150 - Train Loss: 0.757819, Val Loss: 1.361055
2025-07-04 14:04:59,359 - INFO - Epoch 7/150 - Train Loss: 0.661384, Val Loss: 1.379884
2025-07-04 14:05:05,449 - INFO - Epoch 8/150 - Train Loss: 0.608690, Val Loss: 1.595568
2025-07-04 14:05:11,570 - INFO - Epoch 9/150 - Train Loss: 0.560139, Val Loss: 1.838627
2025-07-04 14:05:17,655 - INFO - Epoch 10/150 - Train Loss: 0.526667, Val Loss: 1.521763
2025-07-04 14:05:23,895 - INFO - Epoch 11/150 - Train Loss: 0.494009, Val Loss: 1.437564
2025-07-04 14:05:29,973 - INFO - Epoch 12/150 - Train Loss: 0.474216, Val Loss: 1.348367
2025-07-04 14:05:36,057 - INFO - Epoch 13/150 - Train Loss: 0.457834, Val Loss: 1.089559
2025-07-04 14:05:36,072 - INFO - New best model saved with Val Loss: 1.089559
2025-07-04 14:05:42,158 - INFO - Epoch 14/150 - Train Loss: 0.455360, Val Loss: 0.832426
2025-07-04 14:05:42,172 - INFO - New best model saved with Val Loss: 0.832426
2025-07-04 14:05:48,231 - INFO - Epoch 15/150 - Train Loss: 0.447783, Val Loss: 0.654857
2025-07-04 14:05:48,245 - INFO - New best model saved with Val Loss: 0.654857
2025-07-04 14:05:54,295 - INFO - Epoch 16/150 - Train Loss: 0.446389, Val Loss: 0.548675
2025-07-04 14:05:54,309 - INFO - New best model saved with Val Loss: 0.548675
2025-07-04 14:06:00,408 - INFO - Epoch 17/150 - Train Loss: 0.440610, Val Loss: 0.495317
2025-07-04 14:06:00,421 - INFO - New best model saved with Val Loss: 0.495317
2025-07-04 14:06:06,488 - INFO - Epoch 18/150 - Train Loss: 0.438833, Val Loss: 0.464275
2025-07-04 14:06:06,503 - INFO - New best model saved with Val Loss: 0.464275
2025-07-04 14:06:12,558 - INFO - Epoch 19/150 - Train Loss: 0.439969, Val Loss: 0.443737
2025-07-04 14:06:12,574 - INFO - New best model saved with Val Loss: 0.443737
2025-07-04 14:06:18,648 - INFO - Epoch 20/150 - Train Loss: 0.431883, Val Loss: 0.428062
2025-07-04 14:06:18,661 - INFO - New best model saved with Val Loss: 0.428062
2025-07-04 14:06:24,819 - INFO - Epoch 21/150 - Train Loss: 0.431155, Val Loss: 0.423547
2025-07-04 14:06:24,833 - INFO - New best model saved with Val Loss: 0.423547
2025-07-04 14:06:30,899 - INFO - Epoch 22/150 - Train Loss: 0.428144, Val Loss: 0.426146
2025-07-04 14:06:36,979 - INFO - Epoch 23/150 - Train Loss: 0.425435, Val Loss: 0.427524
2025-07-04 14:06:43,061 - INFO - Epoch 24/150 - Train Loss: 0.422210, Val Loss: 0.422279
2025-07-04 14:06:43,077 - INFO - New best model saved with Val Loss: 0.422279
2025-07-04 14:06:49,154 - INFO - Epoch 25/150 - Train Loss: 0.423424, Val Loss: 0.427988
2025-07-04 14:06:55,255 - INFO - Epoch 26/150 - Train Loss: 0.416589, Val Loss: 0.438708
2025-07-04 14:07:01,340 - INFO - Epoch 27/150 - Train Loss: 0.415543, Val Loss: 0.429039
2025-07-04 14:07:07,374 - INFO - Epoch 28/150 - Train Loss: 0.413719, Val Loss: 0.420002
2025-07-04 14:07:07,391 - INFO - New best model saved with Val Loss: 0.420002
2025-07-04 14:07:13,473 - INFO - Epoch 29/150 - Train Loss: 0.410406, Val Loss: 0.413966
2025-07-04 14:07:13,486 - INFO - New best model saved with Val Loss: 0.413966
2025-07-04 14:07:19,583 - INFO - Epoch 30/150 - Train Loss: 0.409573, Val Loss: 0.411146
2025-07-04 14:07:19,600 - INFO - New best model saved with Val Loss: 0.411146
2025-07-04 14:07:25,826 - INFO - Epoch 31/150 - Train Loss: 0.407763, Val Loss: 0.405612
2025-07-04 14:07:25,841 - INFO - New best model saved with Val Loss: 0.405612
2025-07-04 14:07:31,901 - INFO - Epoch 32/150 - Train Loss: 0.407623, Val Loss: 0.406176
2025-07-04 14:07:37,963 - INFO - Epoch 33/150 - Train Loss: 0.403604, Val Loss: 0.407962
2025-07-04 14:07:44,038 - INFO - Epoch 34/150 - Train Loss: 0.399802, Val Loss: 0.401497
2025-07-04 14:07:44,054 - INFO - New best model saved with Val Loss: 0.401497
2025-07-04 14:07:50,137 - INFO - Epoch 35/150 - Train Loss: 0.400421, Val Loss: 0.400646
2025-07-04 14:07:50,151 - INFO - New best model saved with Val Loss: 0.400646
2025-07-04 14:07:56,225 - INFO - Epoch 36/150 - Train Loss: 0.395775, Val Loss: 0.403946
2025-07-04 14:08:02,322 - INFO - Epoch 37/150 - Train Loss: 0.395949, Val Loss: 0.401222
2025-07-04 14:08:08,402 - INFO - Epoch 38/150 - Train Loss: 0.393724, Val Loss: 0.398120
2025-07-04 14:08:08,418 - INFO - New best model saved with Val Loss: 0.398120
2025-07-04 14:08:14,493 - INFO - Epoch 39/150 - Train Loss: 0.390039, Val Loss: 0.399025
2025-07-04 14:08:20,581 - INFO - Epoch 40/150 - Train Loss: 0.391684, Val Loss: 0.390313
2025-07-04 14:08:20,595 - INFO - New best model saved with Val Loss: 0.390313
2025-07-04 14:08:26,806 - INFO - Epoch 41/150 - Train Loss: 0.386746, Val Loss: 0.386531
2025-07-04 14:08:26,821 - INFO - New best model saved with Val Loss: 0.386531
2025-07-04 14:08:32,947 - INFO - Epoch 42/150 - Train Loss: 0.386503, Val Loss: 0.384749
2025-07-04 14:08:32,963 - INFO - New best model saved with Val Loss: 0.384749
2025-07-04 14:08:39,053 - INFO - Epoch 43/150 - Train Loss: 0.385221, Val Loss: 0.382403
2025-07-04 14:08:39,067 - INFO - New best model saved with Val Loss: 0.382403
2025-07-04 14:08:45,166 - INFO - Epoch 44/150 - Train Loss: 0.379563, Val Loss: 0.379401
2025-07-04 14:08:45,181 - INFO - New best model saved with Val Loss: 0.379401
2025-07-04 14:08:51,239 - INFO - Epoch 45/150 - Train Loss: 0.381152, Val Loss: 0.383046
2025-07-04 14:08:57,307 - INFO - Epoch 46/150 - Train Loss: 0.377841, Val Loss: 0.374077
2025-07-04 14:08:57,322 - INFO - New best model saved with Val Loss: 0.374077
2025-07-04 14:09:03,438 - INFO - Epoch 47/150 - Train Loss: 0.376989, Val Loss: 0.374267
2025-07-04 14:09:09,535 - INFO - Epoch 48/150 - Train Loss: 0.372625, Val Loss: 0.375827
2025-07-04 14:09:15,586 - INFO - Epoch 49/150 - Train Loss: 0.373013, Val Loss: 0.377917
2025-07-04 14:09:21,631 - INFO - Epoch 50/150 - Train Loss: 0.370192, Val Loss: 0.374004
2025-07-04 14:09:21,646 - INFO - New best model saved with Val Loss: 0.374004
2025-07-04 14:09:27,811 - INFO - Epoch 51/150 - Train Loss: 0.370575, Val Loss: 0.368872
2025-07-04 14:09:27,826 - INFO - New best model saved with Val Loss: 0.368872
2025-07-04 14:09:33,870 - INFO - Epoch 52/150 - Train Loss: 0.366457, Val Loss: 0.366532
2025-07-04 14:09:33,883 - INFO - New best model saved with Val Loss: 0.366532
2025-07-04 14:09:39,957 - INFO - Epoch 53/150 - Train Loss: 0.364227, Val Loss: 0.364998
2025-07-04 14:09:39,970 - INFO - New best model saved with Val Loss: 0.364998
2025-07-04 14:09:46,019 - INFO - Epoch 54/150 - Train Loss: 0.362108, Val Loss: 0.361583
2025-07-04 14:09:46,034 - INFO - New best model saved with Val Loss: 0.361583
2025-07-04 14:09:52,086 - INFO - Epoch 55/150 - Train Loss: 0.362925, Val Loss: 0.360435
2025-07-04 14:09:52,101 - INFO - New best model saved with Val Loss: 0.360435
2025-07-04 14:09:58,156 - INFO - Epoch 56/150 - Train Loss: 0.360084, Val Loss: 0.360202
2025-07-04 14:09:58,171 - INFO - New best model saved with Val Loss: 0.360202
2025-07-04 14:10:04,242 - INFO - Epoch 57/150 - Train Loss: 0.356597, Val Loss: 0.362886
2025-07-04 14:10:10,343 - INFO - Epoch 58/150 - Train Loss: 0.359285, Val Loss: 0.363573
2025-07-04 14:10:16,464 - INFO - Epoch 59/150 - Train Loss: 0.353965, Val Loss: 0.367631
2025-07-04 14:10:22,528 - INFO - Epoch 60/150 - Train Loss: 0.355830, Val Loss: 0.363127
2025-07-04 14:10:28,701 - INFO - Epoch 61/150 - Train Loss: 0.352915, Val Loss: 0.355417
2025-07-04 14:10:28,717 - INFO - New best model saved with Val Loss: 0.355417
2025-07-04 14:10:34,787 - INFO - Epoch 62/150 - Train Loss: 0.349458, Val Loss: 0.353605
2025-07-04 14:10:34,801 - INFO - New best model saved with Val Loss: 0.353605
2025-07-04 14:10:40,846 - INFO - Epoch 63/150 - Train Loss: 0.349392, Val Loss: 0.354289
2025-07-04 14:10:46,925 - INFO - Epoch 64/150 - Train Loss: 0.349203, Val Loss: 0.349903
2025-07-04 14:10:46,939 - INFO - New best model saved with Val Loss: 0.349903
2025-07-04 14:10:53,028 - INFO - Epoch 65/150 - Train Loss: 0.348612, Val Loss: 0.350857
2025-07-04 14:10:59,063 - INFO - Epoch 66/150 - Train Loss: 0.344767, Val Loss: 0.353102
2025-07-04 14:11:05,129 - INFO - Epoch 67/150 - Train Loss: 0.343171, Val Loss: 0.346992
2025-07-04 14:11:05,143 - INFO - New best model saved with Val Loss: 0.346992
2025-07-04 14:11:11,214 - INFO - Epoch 68/150 - Train Loss: 0.343175, Val Loss: 0.344801
2025-07-04 14:11:11,229 - INFO - New best model saved with Val Loss: 0.344801
2025-07-04 14:11:17,282 - INFO - Epoch 69/150 - Train Loss: 0.342111, Val Loss: 0.345257
2025-07-04 14:11:23,348 - INFO - Epoch 70/150 - Train Loss: 0.338463, Val Loss: 0.343932
2025-07-04 14:11:23,363 - INFO - New best model saved with Val Loss: 0.343932
2025-07-04 14:11:29,540 - INFO - Epoch 71/150 - Train Loss: 0.337893, Val Loss: 0.343028
2025-07-04 14:11:29,555 - INFO - New best model saved with Val Loss: 0.343028
2025-07-04 14:11:35,586 - INFO - Epoch 72/150 - Train Loss: 0.335130, Val Loss: 0.342844
2025-07-04 14:11:35,601 - INFO - New best model saved with Val Loss: 0.342844
2025-07-04 14:11:41,651 - INFO - Epoch 73/150 - Train Loss: 0.336449, Val Loss: 0.340494
2025-07-04 14:11:41,666 - INFO - New best model saved with Val Loss: 0.340494
2025-07-04 14:11:47,731 - INFO - Epoch 74/150 - Train Loss: 0.332509, Val Loss: 0.336325
2025-07-04 14:11:47,747 - INFO - New best model saved with Val Loss: 0.336325
2025-07-04 14:11:53,843 - INFO - Epoch 75/150 - Train Loss: 0.332463, Val Loss: 0.338520
2025-07-04 14:11:59,922 - INFO - Epoch 76/150 - Train Loss: 0.330725, Val Loss: 0.343105
2025-07-04 14:12:05,976 - INFO - Epoch 77/150 - Train Loss: 0.329678, Val Loss: 0.336431
2025-07-04 14:12:12,035 - INFO - Epoch 78/150 - Train Loss: 0.332115, Val Loss: 0.340799
2025-07-04 14:12:18,095 - INFO - Epoch 79/150 - Train Loss: 0.323830, Val Loss: 0.352417
2025-07-04 14:12:24,165 - INFO - Epoch 80/150 - Train Loss: 0.324538, Val Loss: 0.337843
2025-07-04 14:12:30,361 - INFO - Epoch 81/150 - Train Loss: 0.323342, Val Loss: 0.337610
2025-07-04 14:12:36,449 - INFO - Epoch 82/150 - Train Loss: 0.323520, Val Loss: 0.327724
2025-07-04 14:12:36,464 - INFO - New best model saved with Val Loss: 0.327724
2025-07-04 14:12:42,508 - INFO - Epoch 83/150 - Train Loss: 0.322984, Val Loss: 0.328694
2025-07-04 14:12:48,561 - INFO - Epoch 84/150 - Train Loss: 0.320235, Val Loss: 0.327149
2025-07-04 14:12:48,576 - INFO - New best model saved with Val Loss: 0.327149
2025-07-04 14:12:54,645 - INFO - Epoch 85/150 - Train Loss: 0.318422, Val Loss: 0.322234
2025-07-04 14:12:54,659 - INFO - New best model saved with Val Loss: 0.322234
2025-07-04 14:13:00,708 - INFO - Epoch 86/150 - Train Loss: 0.316809, Val Loss: 0.323506
2025-07-04 14:13:06,762 - INFO - Epoch 87/150 - Train Loss: 0.316298, Val Loss: 0.332799
2025-07-04 14:13:12,832 - INFO - Epoch 88/150 - Train Loss: 0.317903, Val Loss: 0.324952
2025-07-04 14:13:18,902 - INFO - Epoch 89/150 - Train Loss: 0.317754, Val Loss: 0.318536
2025-07-04 14:13:18,917 - INFO - New best model saved with Val Loss: 0.318536
2025-07-04 14:13:24,951 - INFO - Epoch 90/150 - Train Loss: 0.317134, Val Loss: 0.318901
2025-07-04 14:13:31,110 - INFO - Epoch 91/150 - Train Loss: 0.313987, Val Loss: 0.322064
2025-07-04 14:13:37,168 - INFO - Epoch 92/150 - Train Loss: 0.313308, Val Loss: 0.327740
2025-07-04 14:13:43,242 - INFO - Epoch 93/150 - Train Loss: 0.312805, Val Loss: 0.322787
2025-07-04 14:13:49,330 - INFO - Epoch 94/150 - Train Loss: 0.310842, Val Loss: 0.324050
2025-07-04 14:13:55,382 - INFO - Epoch 95/150 - Train Loss: 0.311745, Val Loss: 0.313009
2025-07-04 14:13:55,397 - INFO - New best model saved with Val Loss: 0.313009
2025-07-04 14:14:01,452 - INFO - Epoch 96/150 - Train Loss: 0.308067, Val Loss: 0.321982
2025-07-04 14:14:07,525 - INFO - Epoch 97/150 - Train Loss: 0.306806, Val Loss: 0.330466
2025-07-04 14:14:13,609 - INFO - Epoch 98/150 - Train Loss: 0.304537, Val Loss: 0.335054
2025-07-04 14:14:19,692 - INFO - Epoch 99/150 - Train Loss: 0.303622, Val Loss: 0.331282
2025-07-04 14:14:25,748 - INFO - Epoch 100/150 - Train Loss: 0.303389, Val Loss: 0.322971
2025-07-04 14:14:31,920 - INFO - Epoch 101/150 - Train Loss: 0.304374, Val Loss: 0.331376
2025-07-04 14:14:37,954 - INFO - Epoch 102/150 - Train Loss: 0.301968, Val Loss: 0.325183
2025-07-04 14:14:44,013 - INFO - Epoch 103/150 - Train Loss: 0.298230, Val Loss: 0.322976
2025-07-04 14:14:50,092 - INFO - Epoch 104/150 - Train Loss: 0.301941, Val Loss: 0.339548
2025-07-04 14:14:56,163 - INFO - Epoch 105/150 - Train Loss: 0.301876, Val Loss: 0.337391
2025-07-04 14:15:02,225 - INFO - Epoch 106/150 - Train Loss: 0.301338, Val Loss: 0.324497
2025-07-04 14:15:08,267 - INFO - Epoch 107/150 - Train Loss: 0.297671, Val Loss: 0.313158
2025-07-04 14:15:14,333 - INFO - Epoch 108/150 - Train Loss: 0.294682, Val Loss: 0.305555
2025-07-04 14:15:14,348 - INFO - New best model saved with Val Loss: 0.305555
2025-07-04 14:15:20,429 - INFO - Epoch 109/150 - Train Loss: 0.297884, Val Loss: 0.303263
2025-07-04 14:15:20,445 - INFO - New best model saved with Val Loss: 0.303263
2025-07-04 14:15:26,528 - INFO - Epoch 110/150 - Train Loss: 0.297559, Val Loss: 0.302826
2025-07-04 14:15:26,545 - INFO - New best model saved with Val Loss: 0.302826
2025-07-04 14:15:32,728 - INFO - Epoch 111/150 - Train Loss: 0.294144, Val Loss: 0.302702
2025-07-04 14:15:32,745 - INFO - New best model saved with Val Loss: 0.302702
2025-07-04 14:15:38,800 - INFO - Epoch 112/150 - Train Loss: 0.294188, Val Loss: 0.303885
2025-07-04 14:15:44,864 - INFO - Epoch 113/150 - Train Loss: 0.294812, Val Loss: 0.302568
2025-07-04 14:15:44,879 - INFO - New best model saved with Val Loss: 0.302568
2025-07-04 14:15:50,933 - INFO - Epoch 114/150 - Train Loss: 0.291335, Val Loss: 0.302743
2025-07-04 14:15:57,006 - INFO - Epoch 115/150 - Train Loss: 0.294847, Val Loss: 0.301672
2025-07-04 14:15:57,022 - INFO - New best model saved with Val Loss: 0.301672
2025-07-04 14:16:03,104 - INFO - Epoch 116/150 - Train Loss: 0.291347, Val Loss: 0.301323
2025-07-04 14:16:03,120 - INFO - New best model saved with Val Loss: 0.301323
2025-07-04 14:16:09,159 - INFO - Epoch 117/150 - Train Loss: 0.297098, Val Loss: 0.301480
2025-07-04 14:16:15,210 - INFO - Epoch 118/150 - Train Loss: 0.293385, Val Loss: 0.300978
2025-07-04 14:16:15,225 - INFO - New best model saved with Val Loss: 0.300978
2025-07-04 14:16:21,283 - INFO - Epoch 119/150 - Train Loss: 0.302592, Val Loss: 0.299818
2025-07-04 14:16:21,298 - INFO - New best model saved with Val Loss: 0.299818
2025-07-04 14:16:27,375 - INFO - Epoch 120/150 - Train Loss: 0.294459, Val Loss: 0.300232
2025-07-04 14:16:33,542 - INFO - Epoch 121/150 - Train Loss: 0.292162, Val Loss: 0.299877
2025-07-04 14:16:39,592 - INFO - Epoch 122/150 - Train Loss: 0.293628, Val Loss: 0.300110
2025-07-04 14:16:45,667 - INFO - Epoch 123/150 - Train Loss: 0.290856, Val Loss: 0.300606
2025-07-04 14:16:51,719 - INFO - Epoch 124/150 - Train Loss: 0.294557, Val Loss: 0.300868
2025-07-04 14:16:57,769 - INFO - Epoch 125/150 - Train Loss: 0.293174, Val Loss: 0.300792
2025-07-04 14:17:03,808 - INFO - Epoch 126/150 - Train Loss: 0.293391, Val Loss: 0.302475
2025-07-04 14:17:09,864 - INFO - Epoch 127/150 - Train Loss: 0.290767, Val Loss: 0.301194
2025-07-04 14:17:15,933 - INFO - Epoch 128/150 - Train Loss: 0.292764, Val Loss: 0.300578
2025-07-04 14:17:21,995 - INFO - Epoch 129/150 - Train Loss: 0.291864, Val Loss: 0.299356
2025-07-04 14:17:22,011 - INFO - New best model saved with Val Loss: 0.299356
2025-07-04 14:17:28,067 - INFO - Epoch 130/150 - Train Loss: 0.293602, Val Loss: 0.299731
2025-07-04 14:17:34,244 - INFO - Epoch 131/150 - Train Loss: 0.288207, Val Loss: 0.299689
2025-07-04 14:17:40,323 - INFO - Epoch 132/150 - Train Loss: 0.292099, Val Loss: 0.299264
2025-07-04 14:17:40,339 - INFO - New best model saved with Val Loss: 0.299264
2025-07-04 14:17:46,405 - INFO - Epoch 133/150 - Train Loss: 0.290441, Val Loss: 0.299675
2025-07-04 14:17:52,459 - INFO - Epoch 134/150 - Train Loss: 0.289598, Val Loss: 0.298882
2025-07-04 14:17:52,473 - INFO - New best model saved with Val Loss: 0.298882
2025-07-04 14:17:58,549 - INFO - Epoch 135/150 - Train Loss: 0.291279, Val Loss: 0.298781
2025-07-04 14:17:58,564 - INFO - New best model saved with Val Loss: 0.298781
2025-07-04 14:18:04,639 - INFO - Epoch 136/150 - Train Loss: 0.291402, Val Loss: 0.298846
2025-07-04 14:18:10,708 - INFO - Epoch 137/150 - Train Loss: 0.289009, Val Loss: 0.298318
2025-07-04 14:18:10,724 - INFO - New best model saved with Val Loss: 0.298318
2025-07-04 14:18:16,806 - INFO - Epoch 138/150 - Train Loss: 0.290120, Val Loss: 0.299168
2025-07-04 14:18:22,889 - INFO - Epoch 139/150 - Train Loss: 0.290107, Val Loss: 0.298576
2025-07-04 14:18:28,949 - INFO - Epoch 140/150 - Train Loss: 0.292133, Val Loss: 0.298386
2025-07-04 14:18:35,130 - INFO - Epoch 141/150 - Train Loss: 0.291022, Val Loss: 0.298982
2025-07-04 14:18:41,201 - INFO - Epoch 142/150 - Train Loss: 0.289283, Val Loss: 0.298855
2025-07-04 14:18:47,281 - INFO - Epoch 143/150 - Train Loss: 0.289318, Val Loss: 0.298431
2025-07-04 14:18:53,401 - INFO - Epoch 144/150 - Train Loss: 0.293004, Val Loss: 0.299563
2025-07-04 14:18:59,493 - INFO - Epoch 145/150 - Train Loss: 0.290829, Val Loss: 0.298820
2025-07-04 14:19:05,550 - INFO - Epoch 146/150 - Train Loss: 0.293143, Val Loss: 0.299518
2025-07-04 14:19:11,626 - INFO - Epoch 147/150 - Train Loss: 0.291828, Val Loss: 0.298869
2025-07-04 14:19:17,708 - INFO - Epoch 148/150 - Train Loss: 0.290583, Val Loss: 0.299215
2025-07-04 14:19:23,805 - INFO - Epoch 149/150 - Train Loss: 0.288438, Val Loss: 0.298331
2025-07-04 14:19:29,879 - INFO - Epoch 150/150 - Train Loss: 0.290288, Val Loss: 0.298573
2025-07-04 14:19:30,027 - INFO - Final model saved to experiments/Train_Test/final_model_tmp
2025-07-04 14:19:30,027 - INFO - Testing the final model
2025-07-04 14:19:30,027 - INFO - Testing the best model
2025-07-04 14:21:40,215 - INFO - args.exp_name : Train_Test
2025-07-04 14:21:40,216 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data', num_points=10000, batch_size=6, epochs=150, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-07-04 14:21:40,216 - INFO - Starting training with 1 GPUs
2025-07-04 14:21:44,240 - INFO - Total trainable parameters: 1437705
2025-07-04 14:21:44,379 - INFO - Data loaded: 39 training batches, 8 validation batches, 9 test batches
2025-07-04 14:21:44,380 - INFO - Staring training for 150 epochs
2025-07-04 14:22:04,933 - INFO - Epoch 1/150 - Train Loss: 0.765392, Val Loss: 1.117532
2025-07-04 14:22:04,952 - INFO - New best model saved with Val Loss: 1.117532
2025-07-04 14:22:22,641 - INFO - Epoch 2/150 - Train Loss: 0.425968, Val Loss: 0.480214
2025-07-04 14:22:22,656 - INFO - New best model saved with Val Loss: 0.480214
2025-07-04 14:22:40,391 - INFO - Epoch 3/150 - Train Loss: 0.359811, Val Loss: 0.444877
2025-07-04 14:22:40,405 - INFO - New best model saved with Val Loss: 0.444877
2025-07-04 14:22:58,111 - INFO - Epoch 4/150 - Train Loss: 0.312085, Val Loss: 0.590544
2025-07-04 14:23:15,808 - INFO - Epoch 5/150 - Train Loss: 0.284683, Val Loss: 0.833210
2025-07-04 14:23:33,573 - INFO - Epoch 6/150 - Train Loss: 0.266364, Val Loss: 1.044873
2025-07-04 14:23:51,297 - INFO - Epoch 7/150 - Train Loss: 0.244517, Val Loss: 0.458772
2025-07-04 14:24:09,010 - INFO - Epoch 8/150 - Train Loss: 0.227804, Val Loss: 1.118219
2025-07-04 14:24:26,707 - INFO - Epoch 9/150 - Train Loss: 0.222722, Val Loss: 0.292218
2025-07-04 14:24:26,723 - INFO - New best model saved with Val Loss: 0.292218
2025-07-04 14:24:44,424 - INFO - Epoch 10/150 - Train Loss: 0.213346, Val Loss: 0.264306
2025-07-04 14:24:44,441 - INFO - New best model saved with Val Loss: 0.264306
2025-07-04 14:25:02,335 - INFO - Epoch 11/150 - Train Loss: 0.198541, Val Loss: 1.010461
2025-07-04 14:25:20,079 - INFO - Epoch 12/150 - Train Loss: 0.188102, Val Loss: 0.402349
2025-07-04 14:25:37,842 - INFO - Epoch 13/150 - Train Loss: 0.190205, Val Loss: 0.351225
2025-07-04 14:25:55,564 - INFO - Epoch 14/150 - Train Loss: 0.188799, Val Loss: 0.817092
2025-07-04 14:26:13,282 - INFO - Epoch 15/150 - Train Loss: 0.181614, Val Loss: 0.227752
2025-07-04 14:26:13,300 - INFO - New best model saved with Val Loss: 0.227752
2025-07-04 14:26:31,012 - INFO - Epoch 16/150 - Train Loss: 0.177835, Val Loss: 0.312880
2025-07-04 14:26:48,764 - INFO - Epoch 17/150 - Train Loss: 0.174542, Val Loss: 0.204217
2025-07-04 14:26:48,780 - INFO - New best model saved with Val Loss: 0.204217
2025-07-04 14:27:06,561 - INFO - Epoch 18/150 - Train Loss: 0.171377, Val Loss: 0.178336
2025-07-04 14:27:06,576 - INFO - New best model saved with Val Loss: 0.178336
2025-07-04 14:27:24,362 - INFO - Epoch 19/150 - Train Loss: 0.167564, Val Loss: 0.218340
2025-07-04 14:27:42,141 - INFO - Epoch 20/150 - Train Loss: 0.167842, Val Loss: 0.332284
2025-07-04 14:27:59,984 - INFO - Epoch 21/150 - Train Loss: 0.163059, Val Loss: 0.209619
2025-07-04 14:28:17,759 - INFO - Epoch 22/150 - Train Loss: 0.160918, Val Loss: 0.248925
2025-07-04 14:28:35,486 - INFO - Epoch 23/150 - Train Loss: 0.157175, Val Loss: 0.624631
2025-07-04 14:28:53,297 - INFO - Epoch 24/150 - Train Loss: 0.156025, Val Loss: 0.170956
2025-07-04 14:28:53,314 - INFO - New best model saved with Val Loss: 0.170956
2025-07-04 14:29:11,030 - INFO - Epoch 25/150 - Train Loss: 0.153771, Val Loss: 0.321865
2025-07-04 14:29:28,755 - INFO - Epoch 26/150 - Train Loss: 0.148996, Val Loss: 0.149375
2025-07-04 14:29:28,771 - INFO - New best model saved with Val Loss: 0.149375
2025-07-04 14:29:46,533 - INFO - Epoch 27/150 - Train Loss: 0.149616, Val Loss: 0.178216
2025-07-04 14:30:04,300 - INFO - Epoch 28/150 - Train Loss: 0.154057, Val Loss: 0.161862
2025-07-04 14:30:22,043 - INFO - Epoch 29/150 - Train Loss: 0.146227, Val Loss: 0.175928
2025-07-04 14:30:39,780 - INFO - Epoch 30/150 - Train Loss: 0.146135, Val Loss: 0.377274
2025-07-04 14:30:57,611 - INFO - Epoch 31/150 - Train Loss: 0.145402, Val Loss: 0.213034
2025-07-04 14:31:15,385 - INFO - Epoch 32/150 - Train Loss: 0.142771, Val Loss: 0.151741
2025-07-04 14:31:33,121 - INFO - Epoch 33/150 - Train Loss: 0.145088, Val Loss: 0.146101
2025-07-04 14:31:33,136 - INFO - New best model saved with Val Loss: 0.146101
2025-07-04 14:31:50,905 - INFO - Epoch 34/150 - Train Loss: 0.139568, Val Loss: 0.273251
2025-07-04 14:32:08,681 - INFO - Epoch 35/150 - Train Loss: 0.140397, Val Loss: 0.148392
2025-07-04 14:32:26,433 - INFO - Epoch 36/150 - Train Loss: 0.136741, Val Loss: 0.150139
2025-07-04 14:32:44,209 - INFO - Epoch 37/150 - Train Loss: 0.135322, Val Loss: 0.148857
2025-07-04 14:33:01,974 - INFO - Epoch 38/150 - Train Loss: 0.132527, Val Loss: 0.130883
2025-07-04 14:33:01,989 - INFO - New best model saved with Val Loss: 0.130883
2025-07-04 14:33:19,738 - INFO - Epoch 39/150 - Train Loss: 0.135555, Val Loss: 0.149993
2025-07-04 14:33:37,525 - INFO - Epoch 40/150 - Train Loss: 0.135385, Val Loss: 0.164116
2025-07-04 14:33:55,391 - INFO - Epoch 41/150 - Train Loss: 0.132284, Val Loss: 0.146587
2025-07-04 14:34:13,111 - INFO - Epoch 42/150 - Train Loss: 0.133476, Val Loss: 0.166374
2025-07-04 14:34:30,853 - INFO - Epoch 43/150 - Train Loss: 0.132089, Val Loss: 0.138480
2025-07-04 14:34:48,613 - INFO - Epoch 44/150 - Train Loss: 0.131016, Val Loss: 0.134061
2025-07-04 14:35:06,365 - INFO - Epoch 45/150 - Train Loss: 0.131406, Val Loss: 0.128516
2025-07-04 14:35:06,381 - INFO - New best model saved with Val Loss: 0.128516
2025-07-04 14:35:24,088 - INFO - Epoch 46/150 - Train Loss: 0.127681, Val Loss: 0.202615
2025-07-04 14:35:41,829 - INFO - Epoch 47/150 - Train Loss: 0.126269, Val Loss: 0.136413
2025-07-04 14:35:59,606 - INFO - Epoch 48/150 - Train Loss: 0.128555, Val Loss: 0.211257
2025-07-04 14:36:17,334 - INFO - Epoch 49/150 - Train Loss: 0.128324, Val Loss: 0.134678
2025-07-04 14:36:35,082 - INFO - Epoch 50/150 - Train Loss: 0.125648, Val Loss: 0.164913
2025-07-04 14:36:52,912 - INFO - Epoch 51/150 - Train Loss: 0.124183, Val Loss: 0.121055
2025-07-04 14:36:52,928 - INFO - New best model saved with Val Loss: 0.121055
2025-07-04 14:37:10,653 - INFO - Epoch 52/150 - Train Loss: 0.125603, Val Loss: 0.207307
2025-07-04 14:37:28,422 - INFO - Epoch 53/150 - Train Loss: 0.122962, Val Loss: 0.134787
2025-07-04 14:37:46,178 - INFO - Epoch 54/150 - Train Loss: 0.122586, Val Loss: 0.152079
2025-07-04 14:38:03,931 - INFO - Epoch 55/150 - Train Loss: 0.122021, Val Loss: 0.123622
2025-07-04 14:38:21,660 - INFO - Epoch 56/150 - Train Loss: 0.121857, Val Loss: 0.212121
2025-07-04 14:38:39,435 - INFO - Epoch 57/150 - Train Loss: 0.123328, Val Loss: 0.150480
2025-07-04 14:38:57,197 - INFO - Epoch 58/150 - Train Loss: 0.122286, Val Loss: 0.167857
2025-07-04 14:39:14,939 - INFO - Epoch 59/150 - Train Loss: 0.121922, Val Loss: 0.140145
2025-07-04 14:39:32,703 - INFO - Epoch 60/150 - Train Loss: 0.117993, Val Loss: 0.169449
2025-07-04 14:39:50,612 - INFO - Epoch 61/150 - Train Loss: 0.120024, Val Loss: 0.118396
2025-07-04 14:39:50,628 - INFO - New best model saved with Val Loss: 0.118396
2025-07-04 14:40:08,427 - INFO - Epoch 62/150 - Train Loss: 0.120212, Val Loss: 0.193534
2025-07-04 14:40:26,182 - INFO - Epoch 63/150 - Train Loss: 0.121789, Val Loss: 0.137048
2025-07-04 14:40:43,961 - INFO - Epoch 64/150 - Train Loss: 0.119106, Val Loss: 0.115732
2025-07-04 14:40:43,978 - INFO - New best model saved with Val Loss: 0.115732
2025-07-04 14:41:01,737 - INFO - Epoch 65/150 - Train Loss: 0.116286, Val Loss: 0.150539
2025-07-04 14:41:19,486 - INFO - Epoch 66/150 - Train Loss: 0.116608, Val Loss: 0.204416
2025-07-04 14:41:37,251 - INFO - Epoch 67/150 - Train Loss: 0.116302, Val Loss: 0.160922
2025-07-04 14:41:54,988 - INFO - Epoch 68/150 - Train Loss: 0.120537, Val Loss: 0.140712
2025-07-04 14:42:12,760 - INFO - Epoch 69/150 - Train Loss: 0.116008, Val Loss: 0.133827
2025-07-04 14:42:30,473 - INFO - Epoch 70/150 - Train Loss: 0.117500, Val Loss: 0.125367
2025-07-04 14:42:48,329 - INFO - Epoch 71/150 - Train Loss: 0.115497, Val Loss: 0.111867
2025-07-04 14:42:48,346 - INFO - New best model saved with Val Loss: 0.111867
2025-07-04 14:43:06,082 - INFO - Epoch 72/150 - Train Loss: 0.113848, Val Loss: 0.149078
2025-07-04 14:43:23,840 - INFO - Epoch 73/150 - Train Loss: 0.115463, Val Loss: 0.112712
2025-07-04 14:43:41,626 - INFO - Epoch 74/150 - Train Loss: 0.112697, Val Loss: 0.117975
2025-07-04 14:43:59,360 - INFO - Epoch 75/150 - Train Loss: 0.116695, Val Loss: 0.156708
2025-07-04 14:44:17,131 - INFO - Epoch 76/150 - Train Loss: 0.115100, Val Loss: 0.130494
2025-07-04 14:44:34,889 - INFO - Epoch 77/150 - Train Loss: 0.112540, Val Loss: 0.115179
2025-07-04 14:44:52,656 - INFO - Epoch 78/150 - Train Loss: 0.111732, Val Loss: 0.116926
2025-07-04 14:45:10,370 - INFO - Epoch 79/150 - Train Loss: 0.110727, Val Loss: 0.126542
2025-07-04 14:45:28,138 - INFO - Epoch 80/150 - Train Loss: 0.111588, Val Loss: 0.117037
2025-07-04 14:45:46,031 - INFO - Epoch 81/150 - Train Loss: 0.111193, Val Loss: 0.166504
2025-07-04 14:46:03,767 - INFO - Epoch 82/150 - Train Loss: 0.111560, Val Loss: 0.212419
2025-07-04 14:46:21,538 - INFO - Epoch 83/150 - Train Loss: 0.103109, Val Loss: 0.092613
2025-07-04 14:46:21,553 - INFO - New best model saved with Val Loss: 0.092613
2025-07-04 14:46:39,289 - INFO - Epoch 84/150 - Train Loss: 0.098936, Val Loss: 0.090915
2025-07-04 14:46:39,303 - INFO - New best model saved with Val Loss: 0.090915
2025-07-04 14:46:57,077 - INFO - Epoch 85/150 - Train Loss: 0.097921, Val Loss: 0.090856
2025-07-04 14:46:57,092 - INFO - New best model saved with Val Loss: 0.090856
2025-07-04 14:47:14,839 - INFO - Epoch 86/150 - Train Loss: 0.097712, Val Loss: 0.091261
2025-07-04 14:47:32,627 - INFO - Epoch 87/150 - Train Loss: 0.097985, Val Loss: 0.089322
2025-07-04 14:47:32,643 - INFO - New best model saved with Val Loss: 0.089322
2025-07-04 14:47:50,408 - INFO - Epoch 88/150 - Train Loss: 0.097777, Val Loss: 0.090429
2025-07-04 14:48:08,166 - INFO - Epoch 89/150 - Train Loss: 0.097160, Val Loss: 0.090603
2025-07-04 14:48:25,943 - INFO - Epoch 90/150 - Train Loss: 0.097306, Val Loss: 0.090642
2025-07-04 14:48:43,783 - INFO - Epoch 91/150 - Train Loss: 0.096543, Val Loss: 0.092955
2025-07-04 14:49:01,511 - INFO - Epoch 92/150 - Train Loss: 0.097235, Val Loss: 0.090075
2025-07-04 14:49:19,220 - INFO - Epoch 93/150 - Train Loss: 0.096742, Val Loss: 0.090382
2025-07-04 14:49:36,970 - INFO - Epoch 94/150 - Train Loss: 0.095817, Val Loss: 0.090097
2025-07-04 14:49:54,750 - INFO - Epoch 95/150 - Train Loss: 0.096246, Val Loss: 0.089551
2025-07-04 14:50:12,486 - INFO - Epoch 96/150 - Train Loss: 0.095710, Val Loss: 0.088552
2025-07-04 14:50:12,501 - INFO - New best model saved with Val Loss: 0.088552
2025-07-04 14:50:30,231 - INFO - Epoch 97/150 - Train Loss: 0.096374, Val Loss: 0.089566
2025-07-04 14:50:47,938 - INFO - Epoch 98/150 - Train Loss: 0.096752, Val Loss: 0.088469
2025-07-04 14:50:47,953 - INFO - New best model saved with Val Loss: 0.088469
2025-07-04 14:51:05,705 - INFO - Epoch 99/150 - Train Loss: 0.093261, Val Loss: 0.089550
2025-07-04 14:51:23,544 - INFO - Epoch 100/150 - Train Loss: 0.095612, Val Loss: 0.096346
2025-07-04 14:51:45,063 - INFO - Epoch 101/150 - Train Loss: 0.096476, Val Loss: 0.128738
2025-07-04 14:52:06,414 - INFO - Epoch 102/150 - Train Loss: 0.096039, Val Loss: 0.090330
2025-07-04 14:52:26,856 - INFO - Epoch 103/150 - Train Loss: 0.094943, Val Loss: 0.120177
2025-07-04 14:52:45,026 - INFO - Epoch 104/150 - Train Loss: 0.095132, Val Loss: 0.088605
2025-07-04 14:53:02,876 - INFO - Epoch 105/150 - Train Loss: 0.095240, Val Loss: 0.088804
2025-07-04 14:53:20,712 - INFO - Epoch 106/150 - Train Loss: 0.095847, Val Loss: 0.092196
2025-07-04 14:53:38,570 - INFO - Epoch 107/150 - Train Loss: 0.095251, Val Loss: 0.097188
2025-07-04 14:53:56,448 - INFO - Epoch 108/150 - Train Loss: 0.096115, Val Loss: 0.095816
2025-07-04 14:54:14,302 - INFO - Epoch 109/150 - Train Loss: 0.095379, Val Loss: 0.088785
2025-07-04 14:54:32,125 - INFO - Epoch 110/150 - Train Loss: 0.094124, Val Loss: 0.086502
2025-07-04 14:54:32,146 - INFO - New best model saved with Val Loss: 0.086502
2025-07-04 14:54:50,077 - INFO - Epoch 111/150 - Train Loss: 0.093858, Val Loss: 0.087059
2025-07-04 14:55:07,937 - INFO - Epoch 112/150 - Train Loss: 0.094762, Val Loss: 0.086803
2025-07-04 14:55:25,735 - INFO - Epoch 113/150 - Train Loss: 0.094220, Val Loss: 0.086305
2025-07-04 14:55:25,750 - INFO - New best model saved with Val Loss: 0.086305
2025-07-04 14:55:43,608 - INFO - Epoch 114/150 - Train Loss: 0.093979, Val Loss: 0.086554
2025-07-04 14:56:01,460 - INFO - Epoch 115/150 - Train Loss: 0.093502, Val Loss: 0.086534
2025-07-04 14:56:19,303 - INFO - Epoch 116/150 - Train Loss: 0.093854, Val Loss: 0.086689
2025-07-04 14:56:37,142 - INFO - Epoch 117/150 - Train Loss: 0.093443, Val Loss: 0.086520
2025-07-04 14:56:54,970 - INFO - Epoch 118/150 - Train Loss: 0.093456, Val Loss: 0.086879
2025-07-04 14:57:12,822 - INFO - Epoch 119/150 - Train Loss: 0.093429, Val Loss: 0.086754
2025-07-04 14:57:30,670 - INFO - Epoch 120/150 - Train Loss: 0.093038, Val Loss: 0.086636
2025-07-04 14:57:48,584 - INFO - Epoch 121/150 - Train Loss: 0.093188, Val Loss: 0.086384
2025-07-04 14:58:07,979 - INFO - Epoch 122/150 - Train Loss: 0.093174, Val Loss: 0.086662
2025-07-04 14:58:25,809 - INFO - Epoch 123/150 - Train Loss: 0.093458, Val Loss: 0.086432
2025-07-04 14:58:43,689 - INFO - Epoch 124/150 - Train Loss: 0.093784, Val Loss: 0.086574
2025-07-04 14:59:01,520 - INFO - Epoch 125/150 - Train Loss: 0.093038, Val Loss: 0.086059
2025-07-04 14:59:01,535 - INFO - New best model saved with Val Loss: 0.086059
2025-07-04 14:59:19,302 - INFO - Epoch 126/150 - Train Loss: 0.091458, Val Loss: 0.086364
2025-07-04 14:59:37,119 - INFO - Epoch 127/150 - Train Loss: 0.092800, Val Loss: 0.086594
2025-07-04 14:59:54,932 - INFO - Epoch 128/150 - Train Loss: 0.093453, Val Loss: 0.086473
2025-07-04 15:00:12,737 - INFO - Epoch 129/150 - Train Loss: 0.092883, Val Loss: 0.086414
2025-07-04 15:00:30,462 - INFO - Epoch 130/150 - Train Loss: 0.093339, Val Loss: 0.086173
2025-07-04 15:00:48,311 - INFO - Epoch 131/150 - Train Loss: 0.093019, Val Loss: 0.086383
2025-07-04 15:01:06,067 - INFO - Epoch 132/150 - Train Loss: 0.093502, Val Loss: 0.086444
2025-07-04 15:01:23,816 - INFO - Epoch 133/150 - Train Loss: 0.093330, Val Loss: 0.086222
2025-07-04 15:01:41,541 - INFO - Epoch 134/150 - Train Loss: 0.093427, Val Loss: 0.086623
2025-07-04 15:01:59,274 - INFO - Epoch 135/150 - Train Loss: 0.093817, Val Loss: 0.086278
2025-07-04 15:02:17,003 - INFO - Epoch 136/150 - Train Loss: 0.093156, Val Loss: 0.086409
2025-07-04 15:02:34,755 - INFO - Epoch 137/150 - Train Loss: 0.092966, Val Loss: 0.086330
2025-07-04 15:02:52,485 - INFO - Epoch 138/150 - Train Loss: 0.093484, Val Loss: 0.086202
2025-07-04 15:03:10,228 - INFO - Epoch 139/150 - Train Loss: 0.092633, Val Loss: 0.086555
2025-07-04 15:03:27,994 - INFO - Epoch 140/150 - Train Loss: 0.092953, Val Loss: 0.086549
2025-07-04 15:03:49,838 - INFO - Epoch 141/150 - Train Loss: 0.092855, Val Loss: 0.086349
2025-07-04 15:04:07,975 - INFO - Epoch 142/150 - Train Loss: 0.093116, Val Loss: 0.086281
2025-07-04 15:04:25,760 - INFO - Epoch 143/150 - Train Loss: 0.093006, Val Loss: 0.086377
2025-07-04 15:04:43,548 - INFO - Epoch 144/150 - Train Loss: 0.092932, Val Loss: 0.086349
2025-07-04 15:05:01,354 - INFO - Epoch 145/150 - Train Loss: 0.092390, Val Loss: 0.086420
2025-07-04 15:05:19,137 - INFO - Epoch 146/150 - Train Loss: 0.093185, Val Loss: 0.086400
2025-07-04 15:05:36,924 - INFO - Epoch 147/150 - Train Loss: 0.093196, Val Loss: 0.086339
2025-07-04 15:05:54,688 - INFO - Epoch 148/150 - Train Loss: 0.092870, Val Loss: 0.086243
2025-07-04 15:06:12,465 - INFO - Epoch 149/150 - Train Loss: 0.092973, Val Loss: 0.086341
2025-07-04 15:06:30,243 - INFO - Epoch 150/150 - Train Loss: 0.093295, Val Loss: 0.086364
2025-07-04 15:06:30,393 - INFO - Final model saved to experiments/Train_Test/final_model_tmp
2025-07-04 15:06:30,403 - INFO - Testing the final model
2025-07-04 15:06:30,403 - INFO - Testing the best model
2025-07-04 15:15:36,984 - INFO - args.exp_name : Train_Test
2025-07-04 15:15:36,990 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data', num_points=10000, batch_size=6, epochs=150, lr=0.001, num_workers=1, test_only=False, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-07-04 15:15:36,990 - INFO - Starting training with 1 GPUs
2025-07-04 15:15:41,726 - INFO - Total trainable parameters: 1437705
2025-07-04 15:15:41,874 - INFO - Data loaded: 39 training batches, 8 validation batches, 9 test batches
2025-07-04 15:15:41,878 - INFO - Staring training for 150 epochs
2025-07-04 15:16:02,360 - INFO - Epoch 1/150 - Train Loss: 0.765392, Val Loss: 1.117532
2025-07-04 15:16:02,391 - INFO - New best model saved with Val Loss: 1.117532
2025-07-04 15:16:20,170 - INFO - Epoch 2/150 - Train Loss: 0.425968, Val Loss: 0.480214
2025-07-04 15:16:20,186 - INFO - New best model saved with Val Loss: 0.480214
2025-07-04 15:16:37,996 - INFO - Epoch 3/150 - Train Loss: 0.359811, Val Loss: 0.444877
2025-07-04 15:16:38,011 - INFO - New best model saved with Val Loss: 0.444877
2025-07-04 15:16:55,774 - INFO - Epoch 4/150 - Train Loss: 0.312085, Val Loss: 0.590544
2025-07-04 15:17:13,544 - INFO - Epoch 5/150 - Train Loss: 0.284683, Val Loss: 0.833210
2025-07-04 15:17:31,339 - INFO - Epoch 6/150 - Train Loss: 0.266364, Val Loss: 1.044873
2025-07-04 15:17:49,153 - INFO - Epoch 7/150 - Train Loss: 0.244517, Val Loss: 0.458772
2025-07-04 15:18:06,932 - INFO - Epoch 8/150 - Train Loss: 0.227804, Val Loss: 1.118219
2025-07-04 15:18:24,732 - INFO - Epoch 9/150 - Train Loss: 0.222722, Val Loss: 0.292218
2025-07-04 15:18:24,749 - INFO - New best model saved with Val Loss: 0.292218
2025-07-04 15:18:42,524 - INFO - Epoch 10/150 - Train Loss: 0.213346, Val Loss: 0.264306
2025-07-04 15:18:42,539 - INFO - New best model saved with Val Loss: 0.264306
2025-07-04 15:19:00,432 - INFO - Epoch 11/150 - Train Loss: 0.198541, Val Loss: 1.010461
2025-07-04 15:19:18,210 - INFO - Epoch 12/150 - Train Loss: 0.188102, Val Loss: 0.402349
2025-07-04 15:19:35,960 - INFO - Epoch 13/150 - Train Loss: 0.190205, Val Loss: 0.351225
2025-07-04 15:19:53,716 - INFO - Epoch 14/150 - Train Loss: 0.188799, Val Loss: 0.817092
2025-07-04 15:20:11,474 - INFO - Epoch 15/150 - Train Loss: 0.181614, Val Loss: 0.227752
2025-07-04 15:20:11,491 - INFO - New best model saved with Val Loss: 0.227752
2025-07-04 15:20:29,255 - INFO - Epoch 16/150 - Train Loss: 0.177835, Val Loss: 0.312880
2025-07-04 15:20:47,059 - INFO - Epoch 17/150 - Train Loss: 0.174542, Val Loss: 0.204217
2025-07-04 15:20:47,074 - INFO - New best model saved with Val Loss: 0.204217
2025-07-04 15:21:04,848 - INFO - Epoch 18/150 - Train Loss: 0.171377, Val Loss: 0.178336
2025-07-04 15:21:04,862 - INFO - New best model saved with Val Loss: 0.178336
2025-07-04 15:21:22,641 - INFO - Epoch 19/150 - Train Loss: 0.167564, Val Loss: 0.218340
2025-07-04 15:21:40,380 - INFO - Epoch 20/150 - Train Loss: 0.167842, Val Loss: 0.332284
2025-07-04 15:21:58,255 - INFO - Epoch 21/150 - Train Loss: 0.163059, Val Loss: 0.209619
2025-07-04 15:22:16,009 - INFO - Epoch 22/150 - Train Loss: 0.160918, Val Loss: 0.248925
2025-07-04 15:22:33,781 - INFO - Epoch 23/150 - Train Loss: 0.157175, Val Loss: 0.624631
2025-07-04 15:22:51,781 - INFO - Epoch 24/150 - Train Loss: 0.156025, Val Loss: 0.170956
2025-07-04 15:22:51,799 - INFO - New best model saved with Val Loss: 0.170956
2025-07-04 15:23:09,662 - INFO - Epoch 25/150 - Train Loss: 0.153771, Val Loss: 0.321865
2025-07-04 15:23:27,404 - INFO - Epoch 26/150 - Train Loss: 0.148996, Val Loss: 0.149375
2025-07-04 15:23:27,419 - INFO - New best model saved with Val Loss: 0.149375
2025-07-04 15:23:45,201 - INFO - Epoch 27/150 - Train Loss: 0.149616, Val Loss: 0.178216
2025-07-04 15:24:02,950 - INFO - Epoch 28/150 - Train Loss: 0.154057, Val Loss: 0.161862
2025-07-04 15:24:20,713 - INFO - Epoch 29/150 - Train Loss: 0.146227, Val Loss: 0.175928
2025-07-04 15:24:38,497 - INFO - Epoch 30/150 - Train Loss: 0.146135, Val Loss: 0.377274
2025-07-04 15:24:56,388 - INFO - Epoch 31/150 - Train Loss: 0.145402, Val Loss: 0.213034
2025-07-04 15:25:14,147 - INFO - Epoch 32/150 - Train Loss: 0.142771, Val Loss: 0.151741
2025-07-04 15:25:31,947 - INFO - Epoch 33/150 - Train Loss: 0.145088, Val Loss: 0.146101
2025-07-04 15:25:31,962 - INFO - New best model saved with Val Loss: 0.146101
2025-07-04 15:25:49,724 - INFO - Epoch 34/150 - Train Loss: 0.139568, Val Loss: 0.273251
2025-07-04 15:26:07,553 - INFO - Epoch 35/150 - Train Loss: 0.140397, Val Loss: 0.148392
2025-07-04 15:26:25,346 - INFO - Epoch 36/150 - Train Loss: 0.136741, Val Loss: 0.150139
2025-07-04 15:26:43,163 - INFO - Epoch 37/150 - Train Loss: 0.135322, Val Loss: 0.148857
2025-07-04 15:27:00,933 - INFO - Epoch 38/150 - Train Loss: 0.132527, Val Loss: 0.130883
2025-07-04 15:27:00,950 - INFO - New best model saved with Val Loss: 0.130883
2025-07-04 15:27:18,727 - INFO - Epoch 39/150 - Train Loss: 0.135555, Val Loss: 0.149993
2025-07-04 15:27:36,506 - INFO - Epoch 40/150 - Train Loss: 0.135385, Val Loss: 0.164116
2025-07-04 15:27:54,408 - INFO - Epoch 41/150 - Train Loss: 0.132284, Val Loss: 0.146587
2025-07-04 15:28:12,224 - INFO - Epoch 42/150 - Train Loss: 0.133476, Val Loss: 0.166374
2025-07-04 15:28:29,993 - INFO - Epoch 43/150 - Train Loss: 0.132089, Val Loss: 0.138480
2025-07-04 15:28:47,812 - INFO - Epoch 44/150 - Train Loss: 0.131016, Val Loss: 0.134061
2025-07-04 15:29:05,585 - INFO - Epoch 45/150 - Train Loss: 0.131406, Val Loss: 0.128516
2025-07-04 15:29:05,602 - INFO - New best model saved with Val Loss: 0.128516
2025-07-04 15:29:23,388 - INFO - Epoch 46/150 - Train Loss: 0.127681, Val Loss: 0.202615
2025-07-04 15:29:41,156 - INFO - Epoch 47/150 - Train Loss: 0.126269, Val Loss: 0.136413
2025-07-04 15:29:58,934 - INFO - Epoch 48/150 - Train Loss: 0.128555, Val Loss: 0.211257
2025-07-04 15:30:16,712 - INFO - Epoch 49/150 - Train Loss: 0.128324, Val Loss: 0.134678
2025-07-04 15:30:34,450 - INFO - Epoch 50/150 - Train Loss: 0.125648, Val Loss: 0.164913
2025-07-04 15:30:52,325 - INFO - Epoch 51/150 - Train Loss: 0.124183, Val Loss: 0.121055
2025-07-04 15:30:52,341 - INFO - New best model saved with Val Loss: 0.121055
2025-07-04 15:31:10,131 - INFO - Epoch 52/150 - Train Loss: 0.125603, Val Loss: 0.207307
2025-07-04 15:31:27,893 - INFO - Epoch 53/150 - Train Loss: 0.122962, Val Loss: 0.134787
2025-07-04 15:31:45,644 - INFO - Epoch 54/150 - Train Loss: 0.122586, Val Loss: 0.152079
2025-07-04 15:32:03,411 - INFO - Epoch 55/150 - Train Loss: 0.122021, Val Loss: 0.123622
2025-07-04 15:32:21,178 - INFO - Epoch 56/150 - Train Loss: 0.121857, Val Loss: 0.212121
2025-07-04 15:32:38,954 - INFO - Epoch 57/150 - Train Loss: 0.123328, Val Loss: 0.150480
2025-07-04 15:32:56,734 - INFO - Epoch 58/150 - Train Loss: 0.122286, Val Loss: 0.167857
2025-07-04 15:33:14,497 - INFO - Epoch 59/150 - Train Loss: 0.121922, Val Loss: 0.140145
2025-07-04 15:33:32,267 - INFO - Epoch 60/150 - Train Loss: 0.117993, Val Loss: 0.169449
2025-07-04 15:33:50,172 - INFO - Epoch 61/150 - Train Loss: 0.120024, Val Loss: 0.118396
2025-07-04 15:33:50,188 - INFO - New best model saved with Val Loss: 0.118396
2025-07-04 15:34:07,961 - INFO - Epoch 62/150 - Train Loss: 0.120212, Val Loss: 0.193534
2025-07-04 15:34:25,740 - INFO - Epoch 63/150 - Train Loss: 0.121789, Val Loss: 0.137048
2025-07-04 15:34:43,498 - INFO - Epoch 64/150 - Train Loss: 0.119106, Val Loss: 0.115732
2025-07-04 15:34:43,515 - INFO - New best model saved with Val Loss: 0.115732
2025-07-04 15:35:01,323 - INFO - Epoch 65/150 - Train Loss: 0.116286, Val Loss: 0.150539
2025-07-04 15:35:19,109 - INFO - Epoch 66/150 - Train Loss: 0.116608, Val Loss: 0.204416
2025-07-04 15:35:37,762 - INFO - Epoch 67/150 - Train Loss: 0.116302, Val Loss: 0.160922
2025-07-04 15:35:55,688 - INFO - Epoch 68/150 - Train Loss: 0.120537, Val Loss: 0.140712
2025-07-04 15:36:13,459 - INFO - Epoch 69/150 - Train Loss: 0.116008, Val Loss: 0.133827
2025-07-04 15:36:31,233 - INFO - Epoch 70/150 - Train Loss: 0.117500, Val Loss: 0.125367
2025-07-04 15:36:49,083 - INFO - Epoch 71/150 - Train Loss: 0.115497, Val Loss: 0.111867
2025-07-04 15:36:49,097 - INFO - New best model saved with Val Loss: 0.111867
2025-07-04 15:37:06,811 - INFO - Epoch 72/150 - Train Loss: 0.113848, Val Loss: 0.149078
2025-07-04 15:37:24,545 - INFO - Epoch 73/150 - Train Loss: 0.115463, Val Loss: 0.112712
2025-07-04 15:37:42,269 - INFO - Epoch 74/150 - Train Loss: 0.112697, Val Loss: 0.117975
2025-07-04 15:38:00,035 - INFO - Epoch 75/150 - Train Loss: 0.116695, Val Loss: 0.156708
2025-07-04 15:38:17,799 - INFO - Epoch 76/150 - Train Loss: 0.115100, Val Loss: 0.130494
2025-07-04 15:38:35,572 - INFO - Epoch 77/150 - Train Loss: 0.112540, Val Loss: 0.115179
2025-07-04 15:38:53,355 - INFO - Epoch 78/150 - Train Loss: 0.111732, Val Loss: 0.116926
2025-07-04 15:39:11,108 - INFO - Epoch 79/150 - Train Loss: 0.110727, Val Loss: 0.126542
2025-07-04 15:39:28,843 - INFO - Epoch 80/150 - Train Loss: 0.111588, Val Loss: 0.117037
2025-07-04 15:39:46,704 - INFO - Epoch 81/150 - Train Loss: 0.111193, Val Loss: 0.166504
2025-07-04 15:40:04,431 - INFO - Epoch 82/150 - Train Loss: 0.111560, Val Loss: 0.212419
2025-07-04 15:40:22,223 - INFO - Epoch 83/150 - Train Loss: 0.103109, Val Loss: 0.092613
2025-07-04 15:40:22,238 - INFO - New best model saved with Val Loss: 0.092613
2025-07-04 15:40:40,028 - INFO - Epoch 84/150 - Train Loss: 0.098936, Val Loss: 0.090915
2025-07-04 15:40:40,042 - INFO - New best model saved with Val Loss: 0.090915
2025-07-04 15:40:57,829 - INFO - Epoch 85/150 - Train Loss: 0.097921, Val Loss: 0.090856
2025-07-04 15:40:57,843 - INFO - New best model saved with Val Loss: 0.090856
2025-07-04 15:41:15,643 - INFO - Epoch 86/150 - Train Loss: 0.097712, Val Loss: 0.091261
2025-07-04 15:41:33,427 - INFO - Epoch 87/150 - Train Loss: 0.097985, Val Loss: 0.089322
2025-07-04 15:41:33,442 - INFO - New best model saved with Val Loss: 0.089322
2025-07-04 15:41:51,196 - INFO - Epoch 88/150 - Train Loss: 0.097777, Val Loss: 0.090429
2025-07-04 15:42:09,003 - INFO - Epoch 89/150 - Train Loss: 0.097160, Val Loss: 0.090603
2025-07-04 15:42:26,775 - INFO - Epoch 90/150 - Train Loss: 0.097306, Val Loss: 0.090642
2025-07-04 15:42:44,630 - INFO - Epoch 91/150 - Train Loss: 0.096543, Val Loss: 0.092955
2025-07-04 15:43:02,436 - INFO - Epoch 92/150 - Train Loss: 0.097235, Val Loss: 0.090075
2025-07-04 15:43:20,208 - INFO - Epoch 93/150 - Train Loss: 0.096742, Val Loss: 0.090382
2025-07-04 15:43:37,988 - INFO - Epoch 94/150 - Train Loss: 0.095817, Val Loss: 0.090097
2025-07-04 15:43:55,726 - INFO - Epoch 95/150 - Train Loss: 0.096246, Val Loss: 0.089551
2025-07-04 15:44:13,447 - INFO - Epoch 96/150 - Train Loss: 0.095710, Val Loss: 0.088552
2025-07-04 15:44:13,463 - INFO - New best model saved with Val Loss: 0.088552
2025-07-04 15:44:32,161 - INFO - Epoch 97/150 - Train Loss: 0.096374, Val Loss: 0.089566
2025-07-04 15:44:49,989 - INFO - Epoch 98/150 - Train Loss: 0.096752, Val Loss: 0.088469
2025-07-04 15:44:50,004 - INFO - New best model saved with Val Loss: 0.088469
2025-07-04 15:45:07,732 - INFO - Epoch 99/150 - Train Loss: 0.093261, Val Loss: 0.089550
2025-07-04 15:45:25,488 - INFO - Epoch 100/150 - Train Loss: 0.095612, Val Loss: 0.096346
2025-07-04 15:45:43,338 - INFO - Epoch 101/150 - Train Loss: 0.096476, Val Loss: 0.128738
2025-07-04 15:46:01,074 - INFO - Epoch 102/150 - Train Loss: 0.096039, Val Loss: 0.090330
2025-07-04 15:46:18,846 - INFO - Epoch 103/150 - Train Loss: 0.094943, Val Loss: 0.120177
2025-07-04 15:46:37,916 - INFO - Epoch 104/150 - Train Loss: 0.095132, Val Loss: 0.088605
2025-07-04 15:46:55,702 - INFO - Epoch 105/150 - Train Loss: 0.095240, Val Loss: 0.088804
2025-07-04 15:47:13,555 - INFO - Epoch 106/150 - Train Loss: 0.095847, Val Loss: 0.092196
2025-07-04 15:47:31,325 - INFO - Epoch 107/150 - Train Loss: 0.095251, Val Loss: 0.097188
2025-07-04 15:47:49,111 - INFO - Epoch 108/150 - Train Loss: 0.096115, Val Loss: 0.095816
2025-07-04 15:48:06,856 - INFO - Epoch 109/150 - Train Loss: 0.095379, Val Loss: 0.088785
2025-07-04 15:48:24,609 - INFO - Epoch 110/150 - Train Loss: 0.094124, Val Loss: 0.086502
2025-07-04 15:48:24,624 - INFO - New best model saved with Val Loss: 0.086502
2025-07-04 15:48:42,492 - INFO - Epoch 111/150 - Train Loss: 0.093858, Val Loss: 0.087059
2025-07-04 15:49:00,278 - INFO - Epoch 112/150 - Train Loss: 0.094762, Val Loss: 0.086803
2025-07-04 15:49:18,019 - INFO - Epoch 113/150 - Train Loss: 0.094220, Val Loss: 0.086305
2025-07-04 15:49:18,034 - INFO - New best model saved with Val Loss: 0.086305
2025-07-04 15:49:35,785 - INFO - Epoch 114/150 - Train Loss: 0.093979, Val Loss: 0.086554
2025-07-04 15:49:53,555 - INFO - Epoch 115/150 - Train Loss: 0.093502, Val Loss: 0.086534
2025-07-04 15:50:11,325 - INFO - Epoch 116/150 - Train Loss: 0.093854, Val Loss: 0.086689
2025-07-04 15:50:29,207 - INFO - Epoch 117/150 - Train Loss: 0.093443, Val Loss: 0.086520
2025-07-04 15:50:46,971 - INFO - Epoch 118/150 - Train Loss: 0.093456, Val Loss: 0.086879
2025-07-04 15:51:04,737 - INFO - Epoch 119/150 - Train Loss: 0.093429, Val Loss: 0.086754
2025-07-04 15:51:22,596 - INFO - Epoch 120/150 - Train Loss: 0.093038, Val Loss: 0.086636
2025-07-04 15:51:40,490 - INFO - Epoch 121/150 - Train Loss: 0.093188, Val Loss: 0.086384
2025-07-04 15:51:58,259 - INFO - Epoch 122/150 - Train Loss: 0.093174, Val Loss: 0.086662
2025-07-04 15:52:16,027 - INFO - Epoch 123/150 - Train Loss: 0.093458, Val Loss: 0.086432
2025-07-04 15:52:34,006 - INFO - Epoch 124/150 - Train Loss: 0.093784, Val Loss: 0.086574
2025-07-04 15:52:51,859 - INFO - Epoch 125/150 - Train Loss: 0.093038, Val Loss: 0.086059
2025-07-04 15:52:51,874 - INFO - New best model saved with Val Loss: 0.086059
2025-07-04 15:53:09,642 - INFO - Epoch 126/150 - Train Loss: 0.091458, Val Loss: 0.086364
2025-07-04 15:53:27,428 - INFO - Epoch 127/150 - Train Loss: 0.092800, Val Loss: 0.086594
2025-07-04 15:53:45,191 - INFO - Epoch 128/150 - Train Loss: 0.093453, Val Loss: 0.086473
2025-07-04 15:54:02,948 - INFO - Epoch 129/150 - Train Loss: 0.092883, Val Loss: 0.086414
2025-07-04 15:54:20,730 - INFO - Epoch 130/150 - Train Loss: 0.093339, Val Loss: 0.086173
2025-07-04 15:54:38,633 - INFO - Epoch 131/150 - Train Loss: 0.093019, Val Loss: 0.086383
2025-07-04 15:54:56,401 - INFO - Epoch 132/150 - Train Loss: 0.093502, Val Loss: 0.086444
2025-07-04 15:55:14,151 - INFO - Epoch 133/150 - Train Loss: 0.093330, Val Loss: 0.086222
2025-07-04 15:55:31,917 - INFO - Epoch 134/150 - Train Loss: 0.093427, Val Loss: 0.086623
2025-07-04 15:55:49,679 - INFO - Epoch 135/150 - Train Loss: 0.093817, Val Loss: 0.086278
2025-07-04 15:56:07,471 - INFO - Epoch 136/150 - Train Loss: 0.093156, Val Loss: 0.086409
2025-07-04 15:56:25,275 - INFO - Epoch 137/150 - Train Loss: 0.092966, Val Loss: 0.086330
2025-07-04 15:56:43,680 - INFO - Epoch 138/150 - Train Loss: 0.093484, Val Loss: 0.086202
2025-07-04 15:57:01,421 - INFO - Epoch 139/150 - Train Loss: 0.092633, Val Loss: 0.086555
2025-07-04 15:57:19,162 - INFO - Epoch 140/150 - Train Loss: 0.092953, Val Loss: 0.086549
2025-07-04 15:57:37,046 - INFO - Epoch 141/150 - Train Loss: 0.092855, Val Loss: 0.086349
2025-07-04 15:57:54,789 - INFO - Epoch 142/150 - Train Loss: 0.093116, Val Loss: 0.086281
2025-07-04 15:58:12,604 - INFO - Epoch 143/150 - Train Loss: 0.093006, Val Loss: 0.086377
2025-07-04 15:58:30,350 - INFO - Epoch 144/150 - Train Loss: 0.092932, Val Loss: 0.086349
2025-07-04 15:58:48,127 - INFO - Epoch 145/150 - Train Loss: 0.092390, Val Loss: 0.086420
2025-07-04 15:59:05,911 - INFO - Epoch 146/150 - Train Loss: 0.093185, Val Loss: 0.086400
2025-07-04 15:59:23,714 - INFO - Epoch 147/150 - Train Loss: 0.093196, Val Loss: 0.086339
2025-07-04 15:59:43,290 - INFO - Epoch 148/150 - Train Loss: 0.092870, Val Loss: 0.086243
2025-07-04 16:00:01,047 - INFO - Epoch 149/150 - Train Loss: 0.092973, Val Loss: 0.086341
2025-07-04 16:00:18,859 - INFO - Epoch 150/150 - Train Loss: 0.093295, Val Loss: 0.086364
2025-07-04 16:00:19,000 - INFO - Final model saved to experiments/Train_Test/final_model_tmp
2025-07-04 16:00:19,001 - INFO - Testing the final model
2025-07-04 16:00:19,001 - INFO - Testing the best model
2025-07-05 08:18:54,313 - INFO - args.exp_name : Train_Test
2025-07-05 08:18:54,316 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data', num_points=10000, batch_size=6, epochs=150, lr=0.001, test_only=False, num_workers=1, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-07-05 08:18:54,316 - INFO - Starting training with 1 GPUs
2025-07-05 08:19:02,149 - INFO - Total trainable parameters: 1437705
2025-07-05 08:19:02,385 - INFO - Data loaded: 39 training batches, 8 validation batches, 9 test batches
2025-07-05 08:19:02,387 - INFO - Staring training for 150 epochs
2025-07-05 08:19:54,268 - INFO - Epoch 1/150 - Train Loss: 0.752180, Val Loss: 1.124732
2025-07-05 08:19:54,315 - INFO - New best model saved with Val Loss: 1.124732
2025-07-05 08:20:41,753 - INFO - Epoch 2/150 - Train Loss: 0.410244, Val Loss: 0.379351
2025-07-05 08:20:41,780 - INFO - New best model saved with Val Loss: 0.379351
2025-07-05 08:21:29,276 - INFO - Epoch 3/150 - Train Loss: 0.348636, Val Loss: 0.409999
2025-07-05 08:21:43,964 - INFO - args.exp_name : Train_Test
2025-07-05 08:21:43,964 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data', num_points=10000, batch_size=6, epochs=150, lr=0.001, test_only=False, num_workers=1, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-07-05 08:21:43,964 - INFO - Starting training with 1 GPUs
2025-07-05 08:21:46,385 - INFO - Total trainable parameters: 1437705
2025-07-05 08:21:46,570 - INFO - Data loaded: 39 training batches, 8 validation batches, 9 test batches
2025-07-05 08:21:46,571 - INFO - Staring training for 150 epochs
2025-07-05 08:22:35,918 - INFO - Epoch 1/150 - Train Loss: 0.752180, Val Loss: 1.124732
2025-07-05 08:22:35,949 - INFO - New best model saved with Val Loss: 1.124732
2025-07-05 08:35:12,858 - INFO - args.exp_name : Train_Test
2025-07-05 08:35:12,859 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data', num_points=10000, batch_size=6, epochs=150, lr=0.001, test_only=False, num_workers=1, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-07-05 08:35:12,859 - INFO - Starting training with 1 GPUs
2025-07-05 08:35:15,213 - INFO - Total trainable parameters: 1437705
2025-07-05 08:35:15,398 - INFO - Data loaded: 39 training batches, 8 validation batches, 9 test batches
2025-07-05 08:35:15,413 - INFO - Staring training for 150 epochs
2025-07-05 08:36:29,926 - INFO - args.exp_name : Train_Test
2025-07-05 08:36:29,930 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data', num_points=10000, batch_size=6, epochs=150, lr=0.001, test_only=False, num_workers=1, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-07-05 08:36:29,930 - INFO - Starting training with 1 GPUs
2025-07-05 08:36:32,281 - INFO - Total trainable parameters: 1437705
2025-07-05 08:36:32,466 - INFO - Data loaded: 39 training batches, 8 validation batches, 9 test batches
2025-07-05 08:36:32,468 - INFO - Staring training for 150 epochs
2025-07-05 08:37:21,723 - INFO - Epoch 1/150 - Train Loss: 0.752180, Val Loss: 1.124732
2025-07-05 08:37:21,754 - INFO - New best model saved with Val Loss: 1.124732
2025-07-05 08:38:17,877 - INFO - args.exp_name : Train_Test
2025-07-05 08:38:17,877 - INFO - Arguments: Namespace(exp_name='Train_Test', seed=1, dataset_path='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM', subset_dir='/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits', cache_dir='/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data', num_points=10000, batch_size=6, epochs=150, lr=0.001, test_only=True, num_workers=1, gpus='0', dropout=0.4, emb_dims=1024, k=40, output_channels=1)
2025-07-05 08:38:17,877 - INFO - Starting training with 1 GPUs
2025-07-05 08:38:20,218 - INFO - Total trainable parameters: 1437705
2025-07-05 08:38:20,404 - INFO - Data loaded: 39 training batches, 8 validation batches, 9 test batches
2025-07-05 08:38:20,406 - INFO - Loading best model for testing only
2025-07-05 08:38:27,928 - INFO - Total MSE across all processes: 60.050479888916016
2025-07-05 08:38:27,931 - INFO - mean value for all_targets: {tmp}
2025-07-05 08:38:27,936 - INFO - Test MSE: 1.112046, Test MAE: 0.720236, Max AE: 20.402550, Test R2: 0.0066
2025-07-05 08:38:27,936 - INFO - Relative L2 Error: 0.997422, Relative L1 error: 1.113837
2025-07-05 08:38:27,936 - INFO - Total inference time:  0.75s for 54 samples
2025-07-05 09:05:29,111 - INFO - args.exp_name : Train_Test
2025-07-05 09:05:29,115 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data',
  'dataset_path': '/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM',
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 150,
  'exp_name': 'Train_Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'seed': 1,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits',
  'test_only': 0}
2025-07-05 09:05:29,115 - INFO - Starting training with 1 GPUs
2025-07-05 09:05:31,379 - INFO - Total trainable parameters: 1437705
2025-07-05 09:05:31,565 - INFO - Data loaded: 39 training batches, 8 validation batches, 9 test batches
2025-07-05 09:05:31,566 - INFO - Staring training for 150 epochs
2025-07-05 09:06:21,263 - INFO - Epoch 1/150 - Train Loss: 0.752180, Val Loss: 1.124732
2025-07-05 09:06:21,292 - INFO - New best model saved with Val Loss: 1.124732
2025-07-05 09:07:08,792 - INFO - Epoch 2/150 - Train Loss: 0.410244, Val Loss: 0.379351
2025-07-05 09:07:08,819 - INFO - New best model saved with Val Loss: 0.379351
2025-07-05 09:07:56,373 - INFO - Epoch 3/150 - Train Loss: 0.348636, Val Loss: 0.409999
2025-07-05 09:08:43,886 - INFO - Epoch 4/150 - Train Loss: 0.313532, Val Loss: 0.295374
2025-07-05 09:08:43,913 - INFO - New best model saved with Val Loss: 0.295374
2025-07-05 09:09:31,494 - INFO - Epoch 5/150 - Train Loss: 0.286809, Val Loss: 0.481297
2025-07-05 09:10:19,029 - INFO - Epoch 6/150 - Train Loss: 0.267345, Val Loss: 3.256105
2025-07-05 09:11:06,563 - INFO - Epoch 7/150 - Train Loss: 0.248175, Val Loss: 0.297765
2025-07-05 09:11:54,074 - INFO - Epoch 8/150 - Train Loss: 0.233266, Val Loss: 0.295982
2025-07-05 09:12:41,595 - INFO - Epoch 9/150 - Train Loss: 0.223489, Val Loss: 0.655006
2025-07-05 09:13:29,133 - INFO - Epoch 10/150 - Train Loss: 0.215305, Val Loss: 0.423533
2025-07-05 09:14:16,998 - INFO - Epoch 11/150 - Train Loss: 0.203425, Val Loss: 0.388887
2025-07-05 09:15:04,533 - INFO - Epoch 12/150 - Train Loss: 0.193738, Val Loss: 0.255016
2025-07-05 09:15:04,561 - INFO - New best model saved with Val Loss: 0.255016
2025-07-05 09:15:52,090 - INFO - Epoch 13/150 - Train Loss: 0.193163, Val Loss: 0.278204
2025-07-05 09:16:39,612 - INFO - Epoch 14/150 - Train Loss: 0.191126, Val Loss: 0.221406
2025-07-05 09:16:39,640 - INFO - New best model saved with Val Loss: 0.221406
2025-07-05 09:17:27,161 - INFO - Epoch 15/150 - Train Loss: 0.184478, Val Loss: 0.215028
2025-07-05 09:17:27,188 - INFO - New best model saved with Val Loss: 0.215028
2025-07-05 09:18:14,711 - INFO - Epoch 16/150 - Train Loss: 0.178109, Val Loss: 0.325122
2025-07-05 09:19:02,243 - INFO - Epoch 17/150 - Train Loss: 0.174796, Val Loss: 0.258391
2025-07-05 09:19:49,737 - INFO - Epoch 18/150 - Train Loss: 0.174784, Val Loss: 0.225220
2025-07-05 09:20:37,282 - INFO - Epoch 19/150 - Train Loss: 0.169611, Val Loss: 0.248846
2025-07-05 09:21:24,805 - INFO - Epoch 20/150 - Train Loss: 0.167436, Val Loss: 0.471155
2025-07-05 09:22:12,493 - INFO - Epoch 21/150 - Train Loss: 0.163698, Val Loss: 0.192040
2025-07-05 09:22:12,520 - INFO - New best model saved with Val Loss: 0.192040
2025-07-05 09:23:00,044 - INFO - Epoch 22/150 - Train Loss: 0.161416, Val Loss: 0.370374
2025-07-05 09:23:47,686 - INFO - Epoch 23/150 - Train Loss: 0.158124, Val Loss: 0.158734
2025-07-05 09:23:47,714 - INFO - New best model saved with Val Loss: 0.158734
2025-07-05 09:24:35,246 - INFO - Epoch 24/150 - Train Loss: 0.155866, Val Loss: 0.205952
2025-07-05 09:25:22,831 - INFO - Epoch 25/150 - Train Loss: 0.155378, Val Loss: 0.184193
2025-07-05 09:26:10,362 - INFO - Epoch 26/150 - Train Loss: 0.150835, Val Loss: 0.167461
2025-07-05 09:26:57,922 - INFO - Epoch 27/150 - Train Loss: 0.149848, Val Loss: 0.153055
2025-07-05 09:26:57,949 - INFO - New best model saved with Val Loss: 0.153055
2025-07-05 09:27:45,468 - INFO - Epoch 28/150 - Train Loss: 0.154199, Val Loss: 0.136550
2025-07-05 09:27:45,495 - INFO - New best model saved with Val Loss: 0.136550
2025-07-05 09:28:33,022 - INFO - Epoch 29/150 - Train Loss: 0.143742, Val Loss: 0.152760
2025-07-05 09:29:20,569 - INFO - Epoch 30/150 - Train Loss: 0.144288, Val Loss: 0.193623
2025-07-05 09:30:08,342 - INFO - Epoch 31/150 - Train Loss: 0.145189, Val Loss: 0.166961
2025-07-05 09:30:55,884 - INFO - Epoch 32/150 - Train Loss: 0.141460, Val Loss: 0.157264
2025-07-05 09:31:43,446 - INFO - Epoch 33/150 - Train Loss: 0.145188, Val Loss: 0.219487
2025-07-05 09:32:30,967 - INFO - Epoch 34/150 - Train Loss: 0.138041, Val Loss: 0.179359
2025-07-05 09:33:18,515 - INFO - Epoch 35/150 - Train Loss: 0.139006, Val Loss: 0.147838
2025-07-05 09:34:06,066 - INFO - Epoch 36/150 - Train Loss: 0.133996, Val Loss: 0.173444
2025-07-05 09:34:53,576 - INFO - Epoch 37/150 - Train Loss: 0.133981, Val Loss: 0.150009
2025-07-05 09:35:41,059 - INFO - Epoch 38/150 - Train Loss: 0.130496, Val Loss: 0.138145
2025-07-05 09:36:28,629 - INFO - Epoch 39/150 - Train Loss: 0.134783, Val Loss: 0.167007
2025-07-05 09:37:16,187 - INFO - Epoch 40/150 - Train Loss: 0.123822, Val Loss: 0.106565
2025-07-05 09:37:16,216 - INFO - New best model saved with Val Loss: 0.106565
2025-07-05 09:38:03,875 - INFO - Epoch 41/150 - Train Loss: 0.119583, Val Loss: 0.107501
2025-07-05 09:38:51,459 - INFO - Epoch 42/150 - Train Loss: 0.119099, Val Loss: 0.107230
2025-07-05 09:39:39,038 - INFO - Epoch 43/150 - Train Loss: 0.118426, Val Loss: 0.105269
2025-07-05 09:39:39,064 - INFO - New best model saved with Val Loss: 0.105269
2025-07-05 09:40:26,571 - INFO - Epoch 44/150 - Train Loss: 0.117692, Val Loss: 0.106267
2025-07-05 09:41:14,138 - INFO - Epoch 45/150 - Train Loss: 0.116777, Val Loss: 0.105962
2025-07-05 09:42:01,693 - INFO - Epoch 46/150 - Train Loss: 0.117086, Val Loss: 0.104997
2025-07-05 09:42:01,719 - INFO - New best model saved with Val Loss: 0.104997
2025-07-05 09:42:49,292 - INFO - Epoch 47/150 - Train Loss: 0.116806, Val Loss: 0.104811
2025-07-05 09:42:49,319 - INFO - New best model saved with Val Loss: 0.104811
2025-07-05 09:43:36,862 - INFO - Epoch 48/150 - Train Loss: 0.116484, Val Loss: 0.103583
2025-07-05 09:43:36,891 - INFO - New best model saved with Val Loss: 0.103583
2025-07-05 09:44:24,407 - INFO - Epoch 49/150 - Train Loss: 0.115938, Val Loss: 0.105950
2025-07-05 09:45:11,992 - INFO - Epoch 50/150 - Train Loss: 0.115517, Val Loss: 0.107515
2025-07-05 09:45:59,657 - INFO - Epoch 51/150 - Train Loss: 0.115423, Val Loss: 0.103660
2025-07-05 09:46:47,252 - INFO - Epoch 52/150 - Train Loss: 0.115276, Val Loss: 0.104326
2025-07-05 09:47:34,792 - INFO - Epoch 53/150 - Train Loss: 0.114554, Val Loss: 0.103713
2025-07-05 09:48:22,381 - INFO - Epoch 54/150 - Train Loss: 0.114361, Val Loss: 0.106248
2025-07-05 09:49:09,944 - INFO - Epoch 55/150 - Train Loss: 0.115308, Val Loss: 0.104109
2025-07-05 09:49:57,500 - INFO - Epoch 56/150 - Train Loss: 0.114578, Val Loss: 0.105009
2025-07-05 09:50:45,066 - INFO - Epoch 57/150 - Train Loss: 0.115096, Val Loss: 0.103757
2025-07-05 09:51:32,578 - INFO - Epoch 58/150 - Train Loss: 0.114655, Val Loss: 0.106341
2025-07-05 09:52:20,147 - INFO - Epoch 59/150 - Train Loss: 0.115159, Val Loss: 0.107205
2025-07-05 09:53:07,650 - INFO - Epoch 60/150 - Train Loss: 0.112579, Val Loss: 0.101850
2025-07-05 09:53:07,677 - INFO - New best model saved with Val Loss: 0.101850
2025-07-05 09:53:55,400 - INFO - Epoch 61/150 - Train Loss: 0.112142, Val Loss: 0.101521
2025-07-05 09:53:55,426 - INFO - New best model saved with Val Loss: 0.101521
2025-07-05 09:54:42,992 - INFO - Epoch 62/150 - Train Loss: 0.112451, Val Loss: 0.101256
2025-07-05 09:54:43,019 - INFO - New best model saved with Val Loss: 0.101256
2025-07-05 09:55:30,626 - INFO - Epoch 63/150 - Train Loss: 0.112573, Val Loss: 0.101790
2025-07-05 09:56:18,194 - INFO - Epoch 64/150 - Train Loss: 0.112334, Val Loss: 0.101467
2025-07-05 09:57:05,733 - INFO - Epoch 65/150 - Train Loss: 0.112359, Val Loss: 0.101630
2025-07-05 09:57:53,276 - INFO - Epoch 66/150 - Train Loss: 0.112317, Val Loss: 0.101602
2025-07-05 09:58:40,808 - INFO - Epoch 67/150 - Train Loss: 0.111656, Val Loss: 0.101648
2025-07-05 09:59:28,301 - INFO - Epoch 68/150 - Train Loss: 0.112325, Val Loss: 0.101424
2025-07-05 10:00:15,806 - INFO - Epoch 69/150 - Train Loss: 0.112211, Val Loss: 0.101313
2025-07-05 10:01:03,351 - INFO - Epoch 70/150 - Train Loss: 0.111580, Val Loss: 0.101064
2025-07-05 10:01:03,379 - INFO - New best model saved with Val Loss: 0.101064
2025-07-05 10:01:51,085 - INFO - Epoch 71/150 - Train Loss: 0.111994, Val Loss: 0.101423
2025-07-05 10:02:38,643 - INFO - Epoch 72/150 - Train Loss: 0.111675, Val Loss: 0.101559
2025-07-05 10:03:26,191 - INFO - Epoch 73/150 - Train Loss: 0.112274, Val Loss: 0.101257
2025-07-05 10:04:13,772 - INFO - Epoch 74/150 - Train Loss: 0.111927, Val Loss: 0.101388
2025-07-05 10:05:01,360 - INFO - Epoch 75/150 - Train Loss: 0.112268, Val Loss: 0.101364
2025-07-05 10:05:48,903 - INFO - Epoch 76/150 - Train Loss: 0.111703, Val Loss: 0.101176
2025-07-05 10:06:36,423 - INFO - Epoch 77/150 - Train Loss: 0.111602, Val Loss: 0.100929
2025-07-05 10:06:36,451 - INFO - New best model saved with Val Loss: 0.100929
2025-07-05 10:07:23,960 - INFO - Epoch 78/150 - Train Loss: 0.110812, Val Loss: 0.101396
2025-07-05 10:08:11,463 - INFO - Epoch 79/150 - Train Loss: 0.111649, Val Loss: 0.101161
2025-07-05 10:08:58,997 - INFO - Epoch 80/150 - Train Loss: 0.111938, Val Loss: 0.101558
2025-07-05 10:09:46,777 - INFO - Epoch 81/150 - Train Loss: 0.111773, Val Loss: 0.100997
2025-07-05 10:10:34,312 - INFO - Epoch 82/150 - Train Loss: 0.111186, Val Loss: 0.101250
2025-07-05 10:11:21,918 - INFO - Epoch 83/150 - Train Loss: 0.112286, Val Loss: 0.101473
2025-07-05 10:12:09,423 - INFO - Epoch 84/150 - Train Loss: 0.111227, Val Loss: 0.101389
2025-07-05 10:12:56,933 - INFO - Epoch 85/150 - Train Loss: 0.111354, Val Loss: 0.101104
2025-07-05 10:13:44,466 - INFO - Epoch 86/150 - Train Loss: 0.111357, Val Loss: 0.101038
2025-07-05 10:14:31,975 - INFO - Epoch 87/150 - Train Loss: 0.111645, Val Loss: 0.100999
2025-07-05 10:15:19,477 - INFO - Epoch 88/150 - Train Loss: 0.112036, Val Loss: 0.100978
2025-07-05 10:16:06,975 - INFO - Epoch 89/150 - Train Loss: 0.111140, Val Loss: 0.100872
2025-07-05 10:16:07,003 - INFO - New best model saved with Val Loss: 0.100872
2025-07-05 10:16:54,502 - INFO - Epoch 90/150 - Train Loss: 0.111373, Val Loss: 0.101360
2025-07-05 10:17:42,210 - INFO - Epoch 91/150 - Train Loss: 0.110803, Val Loss: 0.100967
2025-07-05 10:18:29,740 - INFO - Epoch 92/150 - Train Loss: 0.111550, Val Loss: 0.101122
2025-07-05 10:19:17,273 - INFO - Epoch 93/150 - Train Loss: 0.111214, Val Loss: 0.101079
2025-07-05 10:20:04,824 - INFO - Epoch 94/150 - Train Loss: 0.110622, Val Loss: 0.101070
2025-07-05 10:20:52,447 - INFO - Epoch 95/150 - Train Loss: 0.111025, Val Loss: 0.100847
2025-07-05 10:20:52,474 - INFO - New best model saved with Val Loss: 0.100847
2025-07-05 10:21:40,006 - INFO - Epoch 96/150 - Train Loss: 0.110931, Val Loss: 0.100946
2025-07-05 10:22:27,493 - INFO - Epoch 97/150 - Train Loss: 0.111296, Val Loss: 0.101126
2025-07-05 10:23:15,018 - INFO - Epoch 98/150 - Train Loss: 0.111636, Val Loss: 0.100806
2025-07-05 10:23:15,045 - INFO - New best model saved with Val Loss: 0.100806
2025-07-05 10:24:02,599 - INFO - Epoch 99/150 - Train Loss: 0.107761, Val Loss: 0.100924
2025-07-05 10:24:50,190 - INFO - Epoch 100/150 - Train Loss: 0.110888, Val Loss: 0.100864
2025-07-05 10:25:37,899 - INFO - Epoch 101/150 - Train Loss: 0.111423, Val Loss: 0.100831
2025-07-05 10:26:25,455 - INFO - Epoch 102/150 - Train Loss: 0.111504, Val Loss: 0.100779
2025-07-05 10:26:25,482 - INFO - New best model saved with Val Loss: 0.100779
2025-07-05 10:27:13,042 - INFO - Epoch 103/150 - Train Loss: 0.110363, Val Loss: 0.100840
2025-07-05 10:28:00,566 - INFO - Epoch 104/150 - Train Loss: 0.111284, Val Loss: 0.100882
2025-07-05 10:28:48,112 - INFO - Epoch 105/150 - Train Loss: 0.110993, Val Loss: 0.101063
2025-07-05 10:29:35,613 - INFO - Epoch 106/150 - Train Loss: 0.111335, Val Loss: 0.100919
2025-07-05 10:30:23,151 - INFO - Epoch 107/150 - Train Loss: 0.111190, Val Loss: 0.101027
2025-07-05 10:31:10,660 - INFO - Epoch 108/150 - Train Loss: 0.111392, Val Loss: 0.101150
2025-07-05 10:31:58,218 - INFO - Epoch 109/150 - Train Loss: 0.111451, Val Loss: 0.100945
2025-07-05 10:32:45,791 - INFO - Epoch 110/150 - Train Loss: 0.111334, Val Loss: 0.100793
2025-07-05 10:33:33,524 - INFO - Epoch 111/150 - Train Loss: 0.111340, Val Loss: 0.100805
2025-07-05 10:34:21,024 - INFO - Epoch 112/150 - Train Loss: 0.112088, Val Loss: 0.100891
2025-07-05 10:35:08,561 - INFO - Epoch 113/150 - Train Loss: 0.112194, Val Loss: 0.100758
2025-07-05 10:35:08,588 - INFO - New best model saved with Val Loss: 0.100758
2025-07-05 10:35:56,132 - INFO - Epoch 114/150 - Train Loss: 0.111665, Val Loss: 0.101036
2025-07-05 10:36:43,730 - INFO - Epoch 115/150 - Train Loss: 0.111541, Val Loss: 0.100667
2025-07-05 10:36:43,756 - INFO - New best model saved with Val Loss: 0.100667
2025-07-05 10:37:31,257 - INFO - Epoch 116/150 - Train Loss: 0.111737, Val Loss: 0.101022
2025-07-05 10:38:18,751 - INFO - Epoch 117/150 - Train Loss: 0.111449, Val Loss: 0.100828
2025-07-05 10:39:06,293 - INFO - Epoch 118/150 - Train Loss: 0.110879, Val Loss: 0.101010
2025-07-05 10:39:53,904 - INFO - Epoch 119/150 - Train Loss: 0.111162, Val Loss: 0.101130
2025-07-05 10:40:41,430 - INFO - Epoch 120/150 - Train Loss: 0.110652, Val Loss: 0.101108
2025-07-05 10:41:29,112 - INFO - Epoch 121/150 - Train Loss: 0.111208, Val Loss: 0.101022
2025-07-05 10:42:16,678 - INFO - Epoch 122/150 - Train Loss: 0.111119, Val Loss: 0.100764
2025-07-05 10:43:04,218 - INFO - Epoch 123/150 - Train Loss: 0.111224, Val Loss: 0.100755
2025-07-05 10:43:51,739 - INFO - Epoch 124/150 - Train Loss: 0.111680, Val Loss: 0.100771
2025-07-05 10:44:39,273 - INFO - Epoch 125/150 - Train Loss: 0.111103, Val Loss: 0.100727
2025-07-05 10:45:26,844 - INFO - Epoch 126/150 - Train Loss: 0.109218, Val Loss: 0.101016
2025-07-05 10:46:14,413 - INFO - Epoch 127/150 - Train Loss: 0.110773, Val Loss: 0.100918
2025-07-05 10:47:01,956 - INFO - Epoch 128/150 - Train Loss: 0.111515, Val Loss: 0.100885
2025-07-05 10:47:49,473 - INFO - Epoch 129/150 - Train Loss: 0.110828, Val Loss: 0.100919
2025-07-05 10:48:37,032 - INFO - Epoch 130/150 - Train Loss: 0.111200, Val Loss: 0.100731
2025-07-05 10:49:24,727 - INFO - Epoch 131/150 - Train Loss: 0.111076, Val Loss: 0.100860
2025-07-05 10:50:12,282 - INFO - Epoch 132/150 - Train Loss: 0.111362, Val Loss: 0.100931
2025-07-05 10:50:59,801 - INFO - Epoch 133/150 - Train Loss: 0.111084, Val Loss: 0.100533
2025-07-05 10:50:59,828 - INFO - New best model saved with Val Loss: 0.100533
2025-07-05 10:51:47,400 - INFO - Epoch 134/150 - Train Loss: 0.111459, Val Loss: 0.100953
2025-07-05 10:52:34,987 - INFO - Epoch 135/150 - Train Loss: 0.111771, Val Loss: 0.100807
2025-07-05 10:53:22,459 - INFO - Epoch 136/150 - Train Loss: 0.110902, Val Loss: 0.100884
2025-07-05 10:54:09,966 - INFO - Epoch 137/150 - Train Loss: 0.110943, Val Loss: 0.101010
2025-07-05 10:54:57,551 - INFO - Epoch 138/150 - Train Loss: 0.111562, Val Loss: 0.100699
2025-07-05 10:55:45,106 - INFO - Epoch 139/150 - Train Loss: 0.110941, Val Loss: 0.101229
2025-07-05 10:56:32,679 - INFO - Epoch 140/150 - Train Loss: 0.111054, Val Loss: 0.100888
2025-07-05 10:57:20,367 - INFO - Epoch 141/150 - Train Loss: 0.111287, Val Loss: 0.100840
2025-07-05 10:58:07,869 - INFO - Epoch 142/150 - Train Loss: 0.111119, Val Loss: 0.100915
2025-07-05 10:58:55,481 - INFO - Epoch 143/150 - Train Loss: 0.111254, Val Loss: 0.101041
2025-07-05 10:59:43,026 - INFO - Epoch 144/150 - Train Loss: 0.111139, Val Loss: 0.100839
2025-07-05 11:00:30,547 - INFO - Epoch 145/150 - Train Loss: 0.110496, Val Loss: 0.101012
2025-07-05 11:01:18,069 - INFO - Epoch 146/150 - Train Loss: 0.111641, Val Loss: 0.100863
2025-07-05 11:02:05,625 - INFO - Epoch 147/150 - Train Loss: 0.111523, Val Loss: 0.100461
2025-07-05 11:02:05,653 - INFO - New best model saved with Val Loss: 0.100461
2025-07-05 11:02:53,170 - INFO - Epoch 148/150 - Train Loss: 0.110912, Val Loss: 0.100984
2025-07-05 11:03:40,723 - INFO - Epoch 149/150 - Train Loss: 0.110507, Val Loss: 0.100842
2025-07-05 11:04:28,263 - INFO - Epoch 150/150 - Train Loss: 0.111389, Val Loss: 0.100568
2025-07-05 11:04:28,493 - INFO - Final model saved to experiments/Train_Test/final_model_pth
2025-07-05 11:04:28,494 - INFO - Testing the final model
2025-07-05 11:04:28,494 - INFO - Testing the best model
2025-07-05 11:54:21,673 - INFO - args.exp_name : Train_Test
2025-07-05 11:54:21,674 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data',
  'dataset_path': '/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM',
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 150,
  'exp_name': 'Train_Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'seed': 1,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits',
  'test_only': 1}
2025-07-05 11:54:21,674 - INFO - Starting training with 1 GPUs
2025-07-05 11:54:25,203 - INFO - Total trainable parameters: 1437705
2025-07-05 11:54:25,387 - INFO - Data loaded: 39 training batches, 8 validation batches, 9 test batches
2025-07-05 11:54:25,388 - INFO - Loading best model for testing only
2025-07-05 11:54:33,609 - INFO - Total MSE across all processes: 5.320414066314697
2025-07-05 11:54:33,613 - INFO - mean value for all_targets: {tmp}
2025-07-05 11:54:33,616 - INFO - Test MSE: 0.098526, Test MAE: 0.177215, Max AE: 17.375210, Test R2: 0.9120
2025-07-05 11:54:33,616 - INFO - Relative L2 Error: 0.295874, Relative L1 error: 0.273636
2025-07-05 11:54:33,617 - INFO - Total inference time:  0.81s for 54 samples
2025-07-09 08:12:45,741 - INFO - args.exp_name : Train_Test
2025-07-09 08:12:45,744 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data',
  'dataset_path': '/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM',
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 150,
  'exp_name': 'Train_Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'seed': 1,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits',
  'test_only': 1}
2025-07-09 08:12:45,744 - INFO - Starting training with 1 GPUs
2025-07-09 08:12:53,213 - INFO - Total trainable parameters: 1437705
2025-07-09 08:12:53,445 - INFO - Data loaded: 39 training batches, 8 validation batches, 9 test batches
2025-07-09 08:12:53,447 - INFO - Loading best model for testing only
2025-07-09 08:13:01,631 - INFO - Total MSE across all processes: 5.320414066314697
2025-07-09 08:13:01,635 - INFO - mean value for all_targets: {tmp}
2025-07-09 08:13:01,640 - INFO - Test MSE: 0.098526, Test MAE: 0.177215, Max AE: 17.375210, Test R2: 0.9120
2025-07-09 08:13:01,640 - INFO - Relative L2 Error: 0.295874, Relative L1 error: 0.273636
2025-07-09 08:13:01,640 - INFO - Total inference time:  0.91s for 54 samples
2025-07-09 08:13:21,719 - INFO - args.exp_name : Train_Test
2025-07-09 08:13:21,720 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data',
  'dataset_path': '/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM',
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 150,
  'exp_name': 'Train_Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'seed': 1,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits',
  'test_only': 0}
2025-07-09 08:13:21,721 - INFO - Starting training with 1 GPUs
2025-07-09 08:13:24,127 - INFO - Total trainable parameters: 1437705
2025-07-09 08:13:24,313 - INFO - Data loaded: 39 training batches, 8 validation batches, 9 test batches
2025-07-09 08:13:24,314 - INFO - Staring training for 150 epochs
2025-07-09 08:13:48,894 - INFO - args.exp_name : Train_Test
2025-07-09 08:13:48,898 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data',
  'dataset_path': '/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM',
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 150,
  'exp_name': 'Train_Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'seed': 1,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits',
  'test_only': 0}
2025-07-09 08:13:48,898 - INFO - Starting training with 1 GPUs
2025-07-09 08:13:51,268 - INFO - Total trainable parameters: 1437705
2025-07-09 08:13:51,456 - INFO - Data loaded: 39 training batches, 8 validation batches, 9 test batches
2025-07-09 08:13:51,457 - INFO - Staring training for 150 epochs
2025-07-09 08:14:42,651 - INFO - Epoch 1/150 - Train Loss: 0.752180, Val Loss: 1.124732
2025-07-09 08:14:42,685 - INFO - New best model saved with Val Loss: 1.124732
2025-07-09 08:15:31,699 - INFO - Epoch 2/150 - Train Loss: 0.410244, Val Loss: 0.379351
2025-07-09 08:15:31,732 - INFO - New best model saved with Val Loss: 0.379351
2025-07-09 08:16:20,480 - INFO - Epoch 3/150 - Train Loss: 0.348636, Val Loss: 0.409999
2025-07-09 08:17:09,324 - INFO - Epoch 4/150 - Train Loss: 0.313532, Val Loss: 0.295374
2025-07-09 08:17:09,356 - INFO - New best model saved with Val Loss: 0.295374
2025-07-09 08:17:58,306 - INFO - Epoch 5/150 - Train Loss: 0.286809, Val Loss: 0.481297
2025-07-09 08:18:47,103 - INFO - Epoch 6/150 - Train Loss: 0.267345, Val Loss: 3.256105
2025-07-09 08:19:35,957 - INFO - Epoch 7/150 - Train Loss: 0.248175, Val Loss: 0.297765
2025-07-09 08:20:24,732 - INFO - Epoch 8/150 - Train Loss: 0.233266, Val Loss: 0.295982
2025-07-09 08:21:13,344 - INFO - Epoch 9/150 - Train Loss: 0.223489, Val Loss: 0.655006
2025-07-09 08:22:01,981 - INFO - Epoch 10/150 - Train Loss: 0.215305, Val Loss: 0.423533
2025-07-09 08:22:51,132 - INFO - Epoch 11/150 - Train Loss: 0.203425, Val Loss: 0.388887
2025-07-09 08:23:39,831 - INFO - Epoch 12/150 - Train Loss: 0.193738, Val Loss: 0.255016
2025-07-09 08:23:39,864 - INFO - New best model saved with Val Loss: 0.255016
2025-07-09 08:24:28,555 - INFO - Epoch 13/150 - Train Loss: 0.193163, Val Loss: 0.278204
2025-07-09 08:25:17,321 - INFO - Epoch 14/150 - Train Loss: 0.191126, Val Loss: 0.221406
2025-07-09 08:25:17,353 - INFO - New best model saved with Val Loss: 0.221406
2025-07-09 08:26:06,045 - INFO - Epoch 15/150 - Train Loss: 0.184478, Val Loss: 0.215028
2025-07-09 08:26:06,077 - INFO - New best model saved with Val Loss: 0.215028
2025-07-09 08:26:54,948 - INFO - Epoch 16/150 - Train Loss: 0.178109, Val Loss: 0.325122
2025-07-09 08:27:43,819 - INFO - Epoch 17/150 - Train Loss: 0.174796, Val Loss: 0.258391
2025-07-09 08:28:32,672 - INFO - Epoch 18/150 - Train Loss: 0.174784, Val Loss: 0.225220
2025-07-09 08:29:21,892 - INFO - Epoch 19/150 - Train Loss: 0.169611, Val Loss: 0.248846
2025-07-09 08:30:11,040 - INFO - Epoch 20/150 - Train Loss: 0.167436, Val Loss: 0.471155
2025-07-09 08:31:00,353 - INFO - Epoch 21/150 - Train Loss: 0.163698, Val Loss: 0.192040
2025-07-09 08:31:00,385 - INFO - New best model saved with Val Loss: 0.192040
2025-07-09 08:31:49,250 - INFO - Epoch 22/150 - Train Loss: 0.161416, Val Loss: 0.370374
2025-07-09 08:32:38,200 - INFO - Epoch 23/150 - Train Loss: 0.158124, Val Loss: 0.158734
2025-07-09 08:32:38,232 - INFO - New best model saved with Val Loss: 0.158734
2025-07-09 08:33:27,027 - INFO - Epoch 24/150 - Train Loss: 0.155866, Val Loss: 0.205952
2025-07-09 08:34:15,933 - INFO - Epoch 25/150 - Train Loss: 0.155378, Val Loss: 0.184193
2025-07-09 08:35:04,546 - INFO - Epoch 26/150 - Train Loss: 0.150835, Val Loss: 0.167461
2025-07-09 08:35:53,394 - INFO - Epoch 27/150 - Train Loss: 0.149848, Val Loss: 0.153055
2025-07-09 08:35:53,440 - INFO - New best model saved with Val Loss: 0.153055
2025-07-09 08:36:42,268 - INFO - Epoch 28/150 - Train Loss: 0.154199, Val Loss: 0.136550
2025-07-09 08:36:42,300 - INFO - New best model saved with Val Loss: 0.136550
2025-07-09 08:37:31,171 - INFO - Epoch 29/150 - Train Loss: 0.143742, Val Loss: 0.152760
2025-07-09 08:38:19,864 - INFO - Epoch 30/150 - Train Loss: 0.144288, Val Loss: 0.193623
2025-07-09 08:39:08,801 - INFO - Epoch 31/150 - Train Loss: 0.145189, Val Loss: 0.166961
2025-07-09 08:39:57,423 - INFO - Epoch 32/150 - Train Loss: 0.141460, Val Loss: 0.157264
2025-07-09 08:40:46,027 - INFO - Epoch 33/150 - Train Loss: 0.145188, Val Loss: 0.219487
2025-07-09 08:41:34,963 - INFO - Epoch 34/150 - Train Loss: 0.138041, Val Loss: 0.179359
2025-07-09 08:42:23,784 - INFO - Epoch 35/150 - Train Loss: 0.139006, Val Loss: 0.147838
2025-07-09 08:43:12,535 - INFO - Epoch 36/150 - Train Loss: 0.133996, Val Loss: 0.173444
2025-07-09 08:44:01,348 - INFO - Epoch 37/150 - Train Loss: 0.133981, Val Loss: 0.150009
2025-07-09 08:44:50,005 - INFO - Epoch 38/150 - Train Loss: 0.130496, Val Loss: 0.138145
2025-07-09 08:45:38,869 - INFO - Epoch 39/150 - Train Loss: 0.134783, Val Loss: 0.167007
2025-07-09 08:46:27,678 - INFO - Epoch 40/150 - Train Loss: 0.123822, Val Loss: 0.106565
2025-07-09 08:46:27,711 - INFO - New best model saved with Val Loss: 0.106565
2025-07-09 08:47:16,782 - INFO - Epoch 41/150 - Train Loss: 0.119583, Val Loss: 0.107501
2025-07-09 08:48:05,637 - INFO - Epoch 42/150 - Train Loss: 0.119099, Val Loss: 0.107230
2025-07-09 08:48:54,599 - INFO - Epoch 43/150 - Train Loss: 0.118426, Val Loss: 0.105269
2025-07-09 08:48:54,632 - INFO - New best model saved with Val Loss: 0.105269
2025-07-09 08:49:43,417 - INFO - Epoch 44/150 - Train Loss: 0.117692, Val Loss: 0.106267
2025-07-09 08:50:32,198 - INFO - Epoch 45/150 - Train Loss: 0.116777, Val Loss: 0.105962
2025-07-09 08:51:20,803 - INFO - Epoch 46/150 - Train Loss: 0.117086, Val Loss: 0.104997
2025-07-09 08:51:20,834 - INFO - New best model saved with Val Loss: 0.104997
2025-07-09 08:52:09,930 - INFO - Epoch 47/150 - Train Loss: 0.116806, Val Loss: 0.104811
2025-07-09 08:52:09,961 - INFO - New best model saved with Val Loss: 0.104811
2025-07-09 08:52:58,763 - INFO - Epoch 48/150 - Train Loss: 0.116484, Val Loss: 0.103583
2025-07-09 08:52:58,796 - INFO - New best model saved with Val Loss: 0.103583
2025-07-09 08:53:47,377 - INFO - Epoch 49/150 - Train Loss: 0.115938, Val Loss: 0.105950
2025-07-09 08:54:35,989 - INFO - Epoch 50/150 - Train Loss: 0.115517, Val Loss: 0.107515
2025-07-09 08:55:24,969 - INFO - Epoch 51/150 - Train Loss: 0.115423, Val Loss: 0.103660
2025-07-09 08:56:13,781 - INFO - Epoch 52/150 - Train Loss: 0.115276, Val Loss: 0.104326
2025-07-09 08:57:02,501 - INFO - Epoch 53/150 - Train Loss: 0.114554, Val Loss: 0.103713
2025-07-09 08:57:51,396 - INFO - Epoch 54/150 - Train Loss: 0.114361, Val Loss: 0.106248
2025-07-09 08:58:40,243 - INFO - Epoch 55/150 - Train Loss: 0.115308, Val Loss: 0.104109
2025-07-09 08:59:28,999 - INFO - Epoch 56/150 - Train Loss: 0.114578, Val Loss: 0.105009
2025-07-09 09:00:17,853 - INFO - Epoch 57/150 - Train Loss: 0.115096, Val Loss: 0.103757
2025-07-09 09:01:06,719 - INFO - Epoch 58/150 - Train Loss: 0.114655, Val Loss: 0.106341
2025-07-09 09:01:55,380 - INFO - Epoch 59/150 - Train Loss: 0.115159, Val Loss: 0.107205
2025-07-09 09:02:44,310 - INFO - Epoch 60/150 - Train Loss: 0.112579, Val Loss: 0.101850
2025-07-09 09:02:44,345 - INFO - New best model saved with Val Loss: 0.101850
2025-07-09 09:03:33,879 - INFO - Epoch 61/150 - Train Loss: 0.112142, Val Loss: 0.101521
2025-07-09 09:03:33,913 - INFO - New best model saved with Val Loss: 0.101521
2025-07-09 09:04:23,269 - INFO - Epoch 62/150 - Train Loss: 0.112451, Val Loss: 0.101256
2025-07-09 09:04:23,301 - INFO - New best model saved with Val Loss: 0.101256
2025-07-09 09:05:12,211 - INFO - Epoch 63/150 - Train Loss: 0.112573, Val Loss: 0.101790
2025-07-09 09:06:01,360 - INFO - Epoch 64/150 - Train Loss: 0.112334, Val Loss: 0.101467
2025-07-09 09:06:50,157 - INFO - Epoch 65/150 - Train Loss: 0.112359, Val Loss: 0.101630
2025-07-09 09:07:38,968 - INFO - Epoch 66/150 - Train Loss: 0.112317, Val Loss: 0.101602
2025-07-09 09:08:27,919 - INFO - Epoch 67/150 - Train Loss: 0.111656, Val Loss: 0.101648
2025-07-09 09:09:16,830 - INFO - Epoch 68/150 - Train Loss: 0.112325, Val Loss: 0.101424
2025-07-09 09:10:05,647 - INFO - Epoch 69/150 - Train Loss: 0.112211, Val Loss: 0.101313
2025-07-09 09:10:54,272 - INFO - Epoch 70/150 - Train Loss: 0.111580, Val Loss: 0.101064
2025-07-09 09:10:54,305 - INFO - New best model saved with Val Loss: 0.101064
2025-07-09 09:11:43,350 - INFO - Epoch 71/150 - Train Loss: 0.111994, Val Loss: 0.101423
2025-07-09 09:12:32,168 - INFO - Epoch 72/150 - Train Loss: 0.111675, Val Loss: 0.101559
2025-07-09 09:13:21,079 - INFO - Epoch 73/150 - Train Loss: 0.112274, Val Loss: 0.101257
2025-07-09 09:14:09,728 - INFO - Epoch 74/150 - Train Loss: 0.111927, Val Loss: 0.101388
2025-07-09 09:14:58,585 - INFO - Epoch 75/150 - Train Loss: 0.112268, Val Loss: 0.101364
2025-07-09 09:15:47,589 - INFO - Epoch 76/150 - Train Loss: 0.111703, Val Loss: 0.101176
2025-07-09 09:16:36,445 - INFO - Epoch 77/150 - Train Loss: 0.111602, Val Loss: 0.100929
2025-07-09 09:16:36,477 - INFO - New best model saved with Val Loss: 0.100929
2025-07-09 09:17:25,334 - INFO - Epoch 78/150 - Train Loss: 0.110812, Val Loss: 0.101396
2025-07-09 09:18:14,019 - INFO - Epoch 79/150 - Train Loss: 0.111649, Val Loss: 0.101161
2025-07-09 09:19:02,757 - INFO - Epoch 80/150 - Train Loss: 0.111938, Val Loss: 0.101558
2025-07-09 09:19:51,727 - INFO - Epoch 81/150 - Train Loss: 0.111773, Val Loss: 0.100997
2025-07-09 09:20:40,549 - INFO - Epoch 82/150 - Train Loss: 0.111186, Val Loss: 0.101250
2025-07-09 09:21:29,401 - INFO - Epoch 83/150 - Train Loss: 0.112286, Val Loss: 0.101473
2025-07-09 09:22:18,229 - INFO - Epoch 84/150 - Train Loss: 0.111227, Val Loss: 0.101389
2025-07-09 09:23:07,127 - INFO - Epoch 85/150 - Train Loss: 0.111354, Val Loss: 0.101104
2025-07-09 09:23:55,918 - INFO - Epoch 86/150 - Train Loss: 0.111357, Val Loss: 0.101038
2025-07-09 09:24:44,815 - INFO - Epoch 87/150 - Train Loss: 0.111645, Val Loss: 0.100999
2025-07-09 09:25:33,442 - INFO - Epoch 88/150 - Train Loss: 0.112036, Val Loss: 0.100978
2025-07-09 09:26:22,157 - INFO - Epoch 89/150 - Train Loss: 0.111140, Val Loss: 0.100872
2025-07-09 09:26:22,207 - INFO - New best model saved with Val Loss: 0.100872
2025-07-09 09:27:11,154 - INFO - Epoch 90/150 - Train Loss: 0.111373, Val Loss: 0.101360
2025-07-09 09:28:00,090 - INFO - Epoch 91/150 - Train Loss: 0.110803, Val Loss: 0.100967
2025-07-09 09:28:48,855 - INFO - Epoch 92/150 - Train Loss: 0.111550, Val Loss: 0.101122
2025-07-09 09:29:37,549 - INFO - Epoch 93/150 - Train Loss: 0.111214, Val Loss: 0.101079
2025-07-09 09:30:26,366 - INFO - Epoch 94/150 - Train Loss: 0.110622, Val Loss: 0.101070
2025-07-09 09:31:15,236 - INFO - Epoch 95/150 - Train Loss: 0.111025, Val Loss: 0.100847
2025-07-09 09:31:15,271 - INFO - New best model saved with Val Loss: 0.100847
2025-07-09 09:32:04,036 - INFO - Epoch 96/150 - Train Loss: 0.110931, Val Loss: 0.100946
2025-07-09 09:32:52,843 - INFO - Epoch 97/150 - Train Loss: 0.111296, Val Loss: 0.101126
2025-07-09 09:33:41,599 - INFO - Epoch 98/150 - Train Loss: 0.111636, Val Loss: 0.100806
2025-07-09 09:33:41,650 - INFO - New best model saved with Val Loss: 0.100806
2025-07-09 09:34:30,477 - INFO - Epoch 99/150 - Train Loss: 0.107761, Val Loss: 0.100924
2025-07-09 09:35:19,253 - INFO - Epoch 100/150 - Train Loss: 0.110888, Val Loss: 0.100864
2025-07-09 09:36:08,332 - INFO - Epoch 101/150 - Train Loss: 0.111423, Val Loss: 0.100831
2025-07-09 09:36:57,715 - INFO - Epoch 102/150 - Train Loss: 0.111504, Val Loss: 0.100779
2025-07-09 09:36:57,762 - INFO - New best model saved with Val Loss: 0.100779
2025-07-09 09:37:46,971 - INFO - Epoch 103/150 - Train Loss: 0.110363, Val Loss: 0.100840
2025-07-09 09:38:35,800 - INFO - Epoch 104/150 - Train Loss: 0.111284, Val Loss: 0.100882
2025-07-09 09:39:24,661 - INFO - Epoch 105/150 - Train Loss: 0.110993, Val Loss: 0.101063
2025-07-09 09:40:13,634 - INFO - Epoch 106/150 - Train Loss: 0.111335, Val Loss: 0.100919
2025-07-09 09:41:02,375 - INFO - Epoch 107/150 - Train Loss: 0.111190, Val Loss: 0.101027
2025-07-09 09:41:51,208 - INFO - Epoch 108/150 - Train Loss: 0.111392, Val Loss: 0.101150
2025-07-09 09:42:39,946 - INFO - Epoch 109/150 - Train Loss: 0.111451, Val Loss: 0.100945
2025-07-09 09:43:28,797 - INFO - Epoch 110/150 - Train Loss: 0.111334, Val Loss: 0.100793
2025-07-09 09:44:17,610 - INFO - Epoch 111/150 - Train Loss: 0.111340, Val Loss: 0.100805
2025-07-09 09:45:06,397 - INFO - Epoch 112/150 - Train Loss: 0.112088, Val Loss: 0.100891
2025-07-09 09:45:55,106 - INFO - Epoch 113/150 - Train Loss: 0.112194, Val Loss: 0.100758
2025-07-09 09:45:55,139 - INFO - New best model saved with Val Loss: 0.100758
2025-07-09 09:46:43,754 - INFO - Epoch 114/150 - Train Loss: 0.111665, Val Loss: 0.101036
2025-07-09 09:47:32,616 - INFO - Epoch 115/150 - Train Loss: 0.111541, Val Loss: 0.100667
2025-07-09 09:47:32,648 - INFO - New best model saved with Val Loss: 0.100667
2025-07-09 09:48:21,616 - INFO - Epoch 116/150 - Train Loss: 0.111737, Val Loss: 0.101022
2025-07-09 09:49:10,375 - INFO - Epoch 117/150 - Train Loss: 0.111449, Val Loss: 0.100828
2025-07-09 09:49:59,155 - INFO - Epoch 118/150 - Train Loss: 0.110879, Val Loss: 0.101010
2025-07-09 09:50:47,968 - INFO - Epoch 119/150 - Train Loss: 0.111162, Val Loss: 0.101130
2025-07-09 09:51:36,874 - INFO - Epoch 120/150 - Train Loss: 0.110652, Val Loss: 0.101108
2025-07-09 09:52:25,778 - INFO - Epoch 121/150 - Train Loss: 0.111208, Val Loss: 0.101022
2025-07-09 09:53:14,449 - INFO - Epoch 122/150 - Train Loss: 0.111119, Val Loss: 0.100764
2025-07-09 09:54:03,137 - INFO - Epoch 123/150 - Train Loss: 0.111224, Val Loss: 0.100755
2025-07-09 09:54:51,988 - INFO - Epoch 124/150 - Train Loss: 0.111680, Val Loss: 0.100771
2025-07-09 09:55:40,799 - INFO - Epoch 125/150 - Train Loss: 0.111103, Val Loss: 0.100727
2025-07-09 09:56:29,909 - INFO - Epoch 126/150 - Train Loss: 0.109218, Val Loss: 0.101016
2025-07-09 09:57:18,924 - INFO - Epoch 127/150 - Train Loss: 0.110773, Val Loss: 0.100918
2025-07-09 09:58:09,431 - INFO - Epoch 128/150 - Train Loss: 0.111515, Val Loss: 0.100885
2025-07-09 09:58:58,353 - INFO - Epoch 129/150 - Train Loss: 0.110828, Val Loss: 0.100919
2025-07-09 09:59:47,305 - INFO - Epoch 130/150 - Train Loss: 0.111200, Val Loss: 0.100731
2025-07-09 10:00:36,311 - INFO - Epoch 131/150 - Train Loss: 0.111076, Val Loss: 0.100860
2025-07-09 10:01:26,388 - INFO - Epoch 132/150 - Train Loss: 0.111362, Val Loss: 0.100931
2025-07-09 10:02:16,315 - INFO - Epoch 133/150 - Train Loss: 0.111084, Val Loss: 0.100533
2025-07-09 10:02:16,349 - INFO - New best model saved with Val Loss: 0.100533
2025-07-09 10:03:05,245 - INFO - Epoch 134/150 - Train Loss: 0.111459, Val Loss: 0.100953
2025-07-09 10:03:54,164 - INFO - Epoch 135/150 - Train Loss: 0.111771, Val Loss: 0.100807
2025-07-09 10:04:43,022 - INFO - Epoch 136/150 - Train Loss: 0.110902, Val Loss: 0.100884
2025-07-09 10:05:31,644 - INFO - Epoch 137/150 - Train Loss: 0.110943, Val Loss: 0.101010
2025-07-09 10:06:20,404 - INFO - Epoch 138/150 - Train Loss: 0.111562, Val Loss: 0.100699
2025-07-09 10:07:09,323 - INFO - Epoch 139/150 - Train Loss: 0.110941, Val Loss: 0.101229
2025-07-09 10:07:58,054 - INFO - Epoch 140/150 - Train Loss: 0.111054, Val Loss: 0.100888
2025-07-09 10:08:47,049 - INFO - Epoch 141/150 - Train Loss: 0.111287, Val Loss: 0.100840
2025-07-09 10:09:35,925 - INFO - Epoch 142/150 - Train Loss: 0.111119, Val Loss: 0.100915
2025-07-09 10:10:25,153 - INFO - Epoch 143/150 - Train Loss: 0.111254, Val Loss: 0.101041
2025-07-09 10:11:14,398 - INFO - Epoch 144/150 - Train Loss: 0.111139, Val Loss: 0.100839
2025-07-09 10:12:03,353 - INFO - Epoch 145/150 - Train Loss: 0.110496, Val Loss: 0.101012
2025-07-09 10:12:52,414 - INFO - Epoch 146/150 - Train Loss: 0.111641, Val Loss: 0.100863
2025-07-09 10:13:41,575 - INFO - Epoch 147/150 - Train Loss: 0.111523, Val Loss: 0.100461
2025-07-09 10:13:41,608 - INFO - New best model saved with Val Loss: 0.100461
2025-07-09 10:14:30,504 - INFO - Epoch 148/150 - Train Loss: 0.110912, Val Loss: 0.100984
2025-07-09 10:15:19,243 - INFO - Epoch 149/150 - Train Loss: 0.110507, Val Loss: 0.100842
2025-07-09 10:16:08,076 - INFO - Epoch 150/150 - Train Loss: 0.111389, Val Loss: 0.100568
2025-07-09 10:16:08,322 - INFO - Final model saved to experiments/Train_Test/final_model_pth
2025-07-09 10:16:08,323 - INFO - Testing the final model
2025-07-09 10:16:08,323 - INFO - Testing the best model
2025-07-09 11:42:08,630 - INFO - args.exp_name : Train_Test
2025-07-09 11:42:08,633 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data',
  'dataset_path': '/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM',
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 150,
  'exp_name': 'Train_Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'seed': 1,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits',
  'test_only': 1}
2025-07-09 11:42:08,634 - INFO - Starting training with 1 GPUs
2025-07-09 11:42:11,968 - INFO - Total trainable parameters: 1437705
2025-07-09 11:42:12,156 - INFO - Data loaded: 39 training batches, 8 validation batches, 9 test batches
2025-07-09 11:42:12,158 - INFO - Loading best model for testing only
2025-07-09 11:51:13,369 - INFO - args.exp_name : Train_Test
2025-07-09 11:51:13,371 - INFO - Arguments:
{ 'batch_size': 6,
  'cache_dir': '/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Cache_data',
  'dataset_path': '/work/mae-zhangbj/ML_Turbulent/Data_Pressure_Field/Data_Pressure/PressureVTK/N_S_WWS_WM',
  'dropout': 0.4,
  'emb_dims': 1024,
  'epochs': 150,
  'exp_name': 'Train_Test',
  'gpus': '0',
  'k': 40,
  'lr': 0.001,
  'num_points': 10000,
  'num_workers': 1,
  'output_channels': 1,
  'seed': 1,
  'subset_dir': '/work/mae-zhangbj/ML_Turbulent/DrivAerNet/train_val_test_splits',
  'test_only': 1}
2025-07-09 11:51:13,371 - INFO - Starting training with 1 GPUs
2025-07-09 11:51:15,819 - INFO - Total trainable parameters: 1437705
2025-07-09 11:51:16,005 - INFO - Data loaded: 39 training batches, 8 validation batches, 9 test batches
2025-07-09 11:51:16,009 - INFO - Loading best model for testing only
